source code,label
"  public static Gfsh getInstance(boolean launchShell, String[] args, GfshConfig gfshConfig)
    throws ClassNotFoundException, IOException
  {
    if (instance == null) {
      synchronized (INSTANCE_LOCK) {
        if (instance == null) {
          instance = new Gfsh(launchShell, args, gfshConfig);
        }
      }
    }

    return instance;
  }",True
"  public static Gfsh getInstance(boolean launchShell, String[] args, GfshConfig gfshConfig)
    throws ClassNotFoundException, IOException
  {
    if (instance == null) {
      synchronized (INSTANCE_LOCK) {
        if (instance == null) {
          instance = new Gfsh(launchShell, args, gfshConfig);
          instance.executeInitFileIfPresent();
        }
      }
    }

    return instance;
  }",False
"  private void executeInitFileIfPresent() {

    String initFileName = this.gfshConfig.getInitFileName();
    if (initFileName != null) {
      this.gfshFileLogger.info(""Using "" + initFileName);
      try {
        File gfshInitFile = new File(initFileName);
        boolean continueOnError = false;
        this.executeScript(gfshInitFile, isQuietMode(), continueOnError);
      } catch (Exception exception) {
        this.gfshFileLogger.severe(initFileName, exception);
        setLastExecutionStatus(-1);
      }
    }

  }",False
"  public GfshConfig() {
    this(HISTORY_FILE.getAbsolutePath(), DEFAULT_PROMPT, MAX_HISTORY_SIZE, null, null, null, null);
  }",True
"
  public GfshConfig(String historyFileName, String defaultPrompt,
      int historySize, String logDir, Level logLevel, Integer logLimit,
      Integer logCount, String initFileName) {
    this.historyFileName = historyFileName;
    this.defaultPrompt   = defaultPrompt;
    this.historySize     = historySize;

    if (initFileName == null) {
      this.initFileName = this.searchForInitFileName();
    } else {
      this.initFileName = initFileName;
    }

    // Logger properties
    if (logDir == null) {
      this.logDir = System.getProperty(LOG_DIR_PROPERTY, ""."");
    } else {
      this.logDir = logDir;
    }
    if (logLevel == null) {
      this.logLevel = getLogLevel(System.getProperty(LOG_LEVEL_PROPERTY, DEFAULT_LOGLEVEL.getName()));
    } else {
      this.logLevel = logLevel;
    }
    if (logLimit == null) {
      this.logFileSizeLimit = getParsedOrDefault(System.getProperty(LOG_FILE_SIZE_LIMIT_PROPERTY), LOG_FILE_SIZE_LIMIT_PROPERTY, DEFAULT_LOGFILE_SIZE_LIMIT);
    } else {
      this.logFileSizeLimit = logLimit;
    }",False
"  private String getLoggerConfig() {
    StringBuilder builder = new StringBuilder();
    builder.append(""log-file=""+getLogFilePath()).append(Gfsh.LINE_SEPARATOR);
    builder.append(""log-level=""+getLogLevel().getName()).append(Gfsh.LINE_SEPARATOR);
    builder.append(""log-file-size-limit=""+getLogFileSizeLimit()).append(Gfsh.LINE_SEPARATOR);
    builder.append(""log-disk-space-limit=""+getLogFileDiskLimit()).append(Gfsh.LINE_SEPARATOR);
    builder.append(""log-count=""+getLogFileCount()).append(Gfsh.LINE_SEPARATOR);

    return builder.toString();
  }",True
"  private String getLoggerConfig() {
    StringBuilder builder = new StringBuilder();
    builder.append(
        ""init-file="" + (getInitFileName() == null ? """" : getInitFileName()))
        .append(Gfsh.LINE_SEPARATOR);
    builder.append(""log-file=""+getLogFilePath()).append(Gfsh.LINE_SEPARATOR);
    builder.append(""log-level=""+getLogLevel().getName()).append(Gfsh.LINE_SEPARATOR);
    builder.append(""log-file-size-limit=""+getLogFileSizeLimit()).append(Gfsh.LINE_SEPARATOR);
    builder.append(""log-disk-space-limit=""+getLogFileDiskLimit()).append(Gfsh.LINE_SEPARATOR);
    builder.append(""log-count=""+getLogFileCount()).append(Gfsh.LINE_SEPARATOR);

    return builder.toString();
  }",False
"  private String searchForInitFileName() {
    String homeDirectoryInitFileName = System.getProperty(""user.home"")
        + File.separatorChar + DEFAULT_INIT_FILE_NAME;
    String currentDirectoryInitFileName = System.getProperty(""user.dir"")
        + File.separatorChar + DEFAULT_INIT_FILE_NAME;
    String systemPropertyInitFileName = System.getProperty(INIT_FILE_PROPERTY);

    String[] initFileNames = { systemPropertyInitFileName,
        currentDirectoryInitFileName, homeDirectoryInitFileName };

    for (String initFileName : initFileNames) {
      if (IOUtils.isExistingPathname(initFileName)) {
        return initFileName;
      }
    }

    return null;
  }",False
"  public GfshConfig(String historyFileName, String defaultPrompt,
      int historySize, String logDir, Level logLevel, Integer logLimit,
      Integer logCount, String initFileName) {
    this.historyFileName = historyFileName;
    this.defaultPrompt   = defaultPrompt;
    this.historySize     = historySize;

    if (initFileName == null) {
      this.initFileName = this.searchForInitFileName();
    } else {
      this.initFileName = initFileName;
    }

    // Logger properties
    if (logDir == null) {
      this.logDir = System.getProperty(LOG_DIR_PROPERTY, ""."");
    } else {
      this.logDir = logDir;
    }
    if (logLevel == null) {
      this.logLevel = getLogLevel(System.getProperty(LOG_LEVEL_PROPERTY, DEFAULT_LOGLEVEL.getName()));
    } else {
      this.logLevel = logLevel;
    }
    if (logLimit == null) {
      this.logFileSizeLimit = getParsedOrDefault(System.getProperty(LOG_FILE_SIZE_LIMIT_PROPERTY), LOG_FILE_SIZE_LIMIT_PROPERTY, DEFAULT_LOGFILE_SIZE_LIMIT);
    } else {
      this.logFileSizeLimit = logLimit;
    }
    if (logCount == null) {
      // validation & correction to default is done in getLogFileCount()
      this.logFileDiskLimit = getParsedOrDefault(System.getProperty(LOG_DISK_SPACE_LIMIT_PROPERTY), LOG_DISK_SPACE_LIMIT_PROPERTY, DEFAULT_LOGFILE_DISK_USAGE);
    } else {
      this.logFileDiskLimit = logCount;
    }
  }",False
"  public GfshConfig() {
    this(HISTORY_FILE.getAbsolutePath(), DEFAULT_PROMPT, MAX_HISTORY_SIZE, null, null, null, null, null);
  }",False
"  public String toString() {
    StringBuilder builder = new StringBuilder();
    builder.append(getClass().getSimpleName());
    builder.append("" [historyFileName="");
    builder.append(getHistoryFileName());
    builder.append("", historySize="");
    builder.append(getHistorySize());
    builder.append("", loggerConfig={"");
    builder.append(getLoggerConfig()).append(""}"");
    builder.append("", isANSISupported="");
    builder.append(isANSISupported());
    builder.append(""]"");
    return builder.toString();
  }",True
"  public String toString() {
    StringBuilder builder = new StringBuilder();
    builder.append(getClass().getSimpleName());
    builder.append("" [initFileName="");
    builder.append(getInitFileName() == null ? """" : getInitFileName());
    builder.append("", historyFileName="");
    builder.append(getHistoryFileName());
    builder.append("", historySize="");
    builder.append(getHistorySize());
    builder.append("", loggerConfig={"");
    builder.append(getLoggerConfig()).append(""}"");
    builder.append("", isANSISupported="");
    builder.append(isANSISupported());
    builder.append(""]"");
    return builder.toString();
  }",False
"  public String getInitFileName() {
    return initFileName;
  }",False
"  public void currentDirectorySelectedSecond() throws Exception {
    temporaryFolder_HomeDirectory.newFile(INIT_FILE_NAME);
    String fileName = temporaryFolder_CurrentDirectory.newFile(INIT_FILE_NAME)
        .getAbsolutePath();

    /*
     * String historyFileName, String defaultPrompt, int historySize, String
     * logDir, Level logLevel, Integer logLimit, Integer logCount, String
     * initFileName
     */
    GfshConfig gfshConfig = new GfshConfig(""historyFileName"", """", 0,
        temporaryFolder_CurrentDirectory.getRoot().getAbsolutePath(), null,
        null, null, null);

    String result = gfshConfig.getInitFileName();

    assertEquals(fileName, result);
  }",False
"  public void noMatches() throws Exception {
    /*
     * String historyFileName, String defaultPrompt, int historySize, String
     * logDir, Level logLevel, Integer logLimit, Integer logCount, String
     * initFileName
     */
    GfshConfig gfshConfig = new GfshConfig(""historyFileName"", """", 0,
        temporaryFolder_CurrentDirectory.getRoot().getAbsolutePath(), null,
        null, null, null);

    String result = gfshConfig.getInitFileName();

    assertNull(result);
  }",False
"  public void homeDirectorySelectedThird() throws Exception {
    String fileName = temporaryFolder_HomeDirectory.newFile(INIT_FILE_NAME)
        .getAbsolutePath();

    /*
     * String historyFileName, String defaultPrompt, int historySize, String
     * logDir, Level logLevel, Integer logLimit, Integer logCount, String
     * initFileName
     */
    GfshConfig gfshConfig = new GfshConfig(""historyFileName"", """", 0,
        temporaryFolder_CurrentDirectory.getRoot().getAbsolutePath(), null,
        null, null, null);

    String result = gfshConfig.getInitFileName();

    assertEquals(fileName, result);
  }",False
"  public static void tearDownAfterClass() throws Exception {
    if (saveUserDir == null) {
      System.clearProperty(""user.dir"");
    } else {
      System.setProperty(""user.dir"", saveUserDir);
    }
    if (saveUserHome == null) {
      System.clearProperty(""user.home"");
    } else {
      System.setProperty(""user.home"", saveUserHome);
    }
  }",False
"  public void setUp() throws Exception {
    String userDir = temporaryFolder_CurrentDirectory.getRoot()
        .getAbsolutePath();
    String userHome = temporaryFolder_HomeDirectory.getRoot().getAbsolutePath();

    System.setProperty(""user.dir"", userDir);
    System.setProperty(""user.home"", userHome);

    // Abort all tests if system properties cannot be overridden
    assertEquals(""user.dir"", System.getProperty(""user.dir""), userDir);
    assertEquals(""user.home"", System.getProperty(""user.home""), userHome);
  }",False
"  public static void setUpBeforeClass() throws Exception {
    saveUserDir = System.getProperty(""user.dir"");
    saveUserHome = System.getProperty(""user.home"");
  }",False
"  public void systemPropertySelectedFirst() throws Exception {
    temporaryFolder_HomeDirectory.newFile(INIT_FILE_NAME);
    temporaryFolder_CurrentDirectory.newFile(INIT_FILE_NAME);
    String fileName = temporaryFolder_AnotherDirectory.newFile(INIT_FILE_NAME)
        .getAbsolutePath();
    System.setProperty(INIT_FILE_PROPERTY, fileName);

    /*
     * String historyFileName, String defaultPrompt, int historySize, String
     * logDir, Level logLevel, Integer logLimit, Integer logCount, String
     * initFileName
     */
    GfshConfig gfshConfig = new GfshConfig(""historyFileName"", """", 0,
        temporaryFolder_CurrentDirectory.getRoot().getAbsolutePath(), null,
        null, null, null);

    String result = gfshConfig.getInitFileName();

    assertEquals(fileName, result);
  }",False
"  public void constructorArgumentUsed() throws Exception {
    temporaryFolder_HomeDirectory.newFile(INIT_FILE_NAME);
    temporaryFolder_CurrentDirectory.newFile(INIT_FILE_NAME);
    System.setProperty(INIT_FILE_PROPERTY, temporaryFolder_AnotherDirectory
        .newFile(INIT_FILE_NAME).getAbsolutePath());

    String argument = temporaryFolder_AnotherDirectory.newFile(""junit"")
        .getAbsolutePath();

    /*
     * String historyFileName, String defaultPrompt, int historySize, String
     * logDir, Level logLevel, Integer logLimit, Integer logCount, String
     * initFileName
     */
    GfshConfig gfshConfig = new GfshConfig(""historyFileName"", """", 0,
        temporaryFolder_CurrentDirectory.getRoot().getAbsolutePath(), null,
        null, null, argument);

    String result = gfshConfig.getInitFileName();

    assertEquals(argument, result);
  }",False
"  public void testInitFile_BadAndGoodCommands() throws Exception {
    File initFile = temporaryFolder_CurrentDirectory.newFile(INIT_FILE_NAME);
    FileUtils.writeStringToFile(initFile, ""fail"" + Gfsh.LINE_SEPARATOR, APPEND);
    FileUtils.writeStringToFile(initFile, ""echo --string=goodbye""
        + Gfsh.LINE_SEPARATOR, APPEND);

    /*
     * String historyFileName, String defaultPrompt, int historySize, String
     * logDir, Level logLevel, Integer logLimit, Integer logCount, String
     * initFileName
     */
    GfshConfig gfshConfig = new GfshConfig(this.gfshHistoryFileName, """", 0,
        temporaryFolder_CurrentDirectory.getRoot().getAbsolutePath(), null,
        null, null, initFile.getAbsolutePath());
    assertNotNull(INIT_FILE_NAME, gfshConfig.getInitFileName());

    /*
     * boolean launchShell, String[] args, GfshConfig gfshConfig
     */
    Gfsh gfsh = Gfsh.getInstance(false, new String[] {}, gfshConfig);

    int actualStatus = gfsh.getLastExecutionStatus();
    int expectedStatus = 0;
    assertNotEquals(""Status <0==failure"", expectedStatus, actualStatus);

    int expectedLogCount = BANNER_LINES + INIT_FILE_CITATION_LINES + 1;
    assertEquals(""Log records written"", expectedLogCount,
        this.junitLoggerHandler.getLog().size());
    for (LogRecord logRecord : this.junitLoggerHandler.getLog()) {
      assertNull(""No exceptions in log"", logRecord.getThrown());
    }
  }",False
"  public void testInitFile_TwoGoodCommands() throws Exception {
    File initFile = temporaryFolder_CurrentDirectory.newFile(INIT_FILE_NAME);
    FileUtils.writeStringToFile(initFile, ""echo --string=hello""
        + Gfsh.LINE_SEPARATOR, APPEND);
    FileUtils.writeStringToFile(initFile, ""echo --string=goodbye""
        + Gfsh.LINE_SEPARATOR, APPEND);

    /*
     * String historyFileName, String defaultPrompt, int historySize, String
     * logDir, Level logLevel, Integer logLimit, Integer logCount, String
     * initFileName
     */
    GfshConfig gfshConfig = new GfshConfig(this.gfshHistoryFileName, """", 0,
        temporaryFolder_CurrentDirectory.getRoot().getAbsolutePath(), null,
        null, null, initFile.getAbsolutePath());
    assertNotNull(INIT_FILE_NAME, gfshConfig.getInitFileName());

    /*
     * boolean launchShell, String[] args, GfshConfig gfshConfig
     */
    Gfsh gfsh = Gfsh.getInstance(false, new String[] {}, gfshConfig);

    int actualStatus = gfsh.getLastExecutionStatus();
    int expectedStatus = 0;
    assertEquals(""Status 0==success"", expectedStatus, actualStatus);

    int expectedLogCount = BANNER_LINES + INIT_FILE_CITATION_LINES + 1;
    assertEquals(""Log records written"", expectedLogCount,
        this.junitLoggerHandler.getLog().size());
    for (LogRecord logRecord : this.junitLoggerHandler.getLog()) {
      assertNull(""No exceptions in log"", logRecord.getThrown());
    }
  }",False
"  public void testInitFile_TwoBadCommands() throws Exception {
    File initFile = temporaryFolder_CurrentDirectory.newFile(INIT_FILE_NAME);
    FileUtils.writeStringToFile(initFile, ""fail"" + Gfsh.LINE_SEPARATOR, APPEND);
    FileUtils.writeStringToFile(initFile, ""fail"" + Gfsh.LINE_SEPARATOR, APPEND);

    /*
     * String historyFileName, String defaultPrompt, int historySize, String
     * logDir, Level logLevel, Integer logLimit, Integer logCount, String
     * initFileName
     */
    GfshConfig gfshConfig = new GfshConfig(this.gfshHistoryFileName, """", 0,
        temporaryFolder_CurrentDirectory.getRoot().getAbsolutePath(), null,
        null, null, initFile.getAbsolutePath());
    assertNotNull(INIT_FILE_NAME, gfshConfig.getInitFileName());

    /*
     * boolean launchShell, String[] args, GfshConfig gfshConfig
     */
    Gfsh gfsh = Gfsh.getInstance(false, new String[] {}, gfshConfig);

    int actualStatus = gfsh.getLastExecutionStatus();
    int expectedStatus = 0;
    assertNotEquals(""Status <0==failure"", expectedStatus, actualStatus);

    int expectedLogCount = BANNER_LINES + INIT_FILE_CITATION_LINES + 1;
    assertEquals(""Log records written"", expectedLogCount,
        this.junitLoggerHandler.getLog().size());
    for (LogRecord logRecord : this.junitLoggerHandler.getLog()) {
      assertNull(""No exceptions in log"", logRecord.getThrown());
    }
  }",False
"    public void close() throws SecurityException {
    }",False
"    public List<LogRecord> getLog() {
      return log;
    }",False
"  public void testInitFile_OneGoodCommand() throws Exception {
    File initFile = temporaryFolder_CurrentDirectory.newFile(INIT_FILE_NAME);
    FileUtils.writeStringToFile(initFile, ""echo --string=hello""
        + Gfsh.LINE_SEPARATOR, APPEND);

    /*
     * String historyFileName, String defaultPrompt, int historySize, String
     * logDir, Level logLevel, Integer logLimit, Integer logCount, String
     * initFileName
     */
    GfshConfig gfshConfig = new GfshConfig(this.gfshHistoryFileName, """", 0,
        temporaryFolder_CurrentDirectory.getRoot().getAbsolutePath(), null,
        null, null, initFile.getAbsolutePath());
    assertNotNull(INIT_FILE_NAME, gfshConfig.getInitFileName());

    /*
     * boolean launchShell, String[] args, GfshConfig gfshConfig
     */
    Gfsh gfsh = Gfsh.getInstance(false, new String[] {}, gfshConfig);

    int actualStatus = gfsh.getLastExecutionStatus();
    int expectedStatus = 0;
    assertEquals(""Status 0==success"", expectedStatus, actualStatus);

    int expectedLogCount = BANNER_LINES + INIT_FILE_CITATION_LINES + 1;
    assertEquals(""Log records written"", expectedLogCount,
        this.junitLoggerHandler.getLog().size());
    for (LogRecord logRecord : this.junitLoggerHandler.getLog()) {
      assertNull(""No exceptions in log"", logRecord.getThrown());
    }
  }",False
"  public void testInitFile_NotProvided() throws Exception {
    /*
     * String historyFileName, String defaultPrompt, int historySize, String
     * logDir, Level logLevel, Integer logLimit, Integer logCount, String
     * initFileName
     */
    GfshConfig gfshConfig = new GfshConfig(this.gfshHistoryFileName, """", 0,
        temporaryFolder_CurrentDirectory.getRoot().getAbsolutePath(), null,
        null, null, null);
    assertNull(INIT_FILE_NAME, gfshConfig.getInitFileName());

    /*
     * boolean launchShell, String[] args, GfshConfig gfshConfig
     */
    Gfsh gfsh = Gfsh.getInstance(false, new String[] {}, gfshConfig);

    int actualStatus = gfsh.getLastExecutionStatus();
    int expectedStatus = 0;
    assertEquals(""Status 0==success"", expectedStatus, actualStatus);

    int expectedLogCount = BANNER_LINES;
    assertEquals(""Log records written"", expectedLogCount,
        this.junitLoggerHandler.getLog().size());
    for (LogRecord logRecord : this.junitLoggerHandler.getLog()) {
      assertNull(""No exceptions in log"", logRecord.getThrown());
    }
  }",False
"    public void publish(LogRecord record) {
      log.add(record);
    }",False
"  public void testInitFile_Empty() throws Exception {
    File initFile = temporaryFolder_CurrentDirectory.newFile(INIT_FILE_NAME);

    /*
     * String historyFileName, String defaultPrompt, int historySize, String
     * logDir, Level logLevel, Integer logLimit, Integer logCount, String
     * initFileName
     */
    GfshConfig gfshConfig = new GfshConfig(this.gfshHistoryFileName, """", 0,
        temporaryFolder_CurrentDirectory.getRoot().getAbsolutePath(), null,
        null, null, initFile.getAbsolutePath());
    assertNotNull(INIT_FILE_NAME, gfshConfig.getInitFileName());

    /*
     * boolean launchShell, String[] args, GfshConfig gfshConfig
     */
    Gfsh gfsh = Gfsh.getInstance(false, new String[] {}, gfshConfig);

    int actualStatus = gfsh.getLastExecutionStatus();
    int expectedStatus = 0;
    assertEquals(""Status 0==success"", expectedStatus, actualStatus);

    int expectedLogCount = BANNER_LINES + INIT_FILE_CITATION_LINES + 1;
    assertEquals(""Log records written"", expectedLogCount,
        this.junitLoggerHandler.getLog().size());
    for (LogRecord logRecord : this.junitLoggerHandler.getLog()) {
      assertNull(""No exceptions in log"", logRecord.getThrown());
    }
  }",False
"  public void testInitFile_OneBadCommand() throws Exception {
    File initFile = temporaryFolder_CurrentDirectory.newFile(INIT_FILE_NAME);
    FileUtils.writeStringToFile(initFile, ""fail"" + Gfsh.LINE_SEPARATOR, APPEND);

    /*
     * String historyFileName, String defaultPrompt, int historySize, String
     * logDir, Level logLevel, Integer logLimit, Integer logCount, String
     * initFileName
     */
    GfshConfig gfshConfig = new GfshConfig(this.gfshHistoryFileName, """", 0,
        temporaryFolder_CurrentDirectory.getRoot().getAbsolutePath(), null,
        null, null, initFile.getAbsolutePath());
    assertNotNull(INIT_FILE_NAME, gfshConfig.getInitFileName());

    /*
     * boolean launchShell, String[] args, GfshConfig gfshConfig
     */
    Gfsh gfsh = Gfsh.getInstance(false, new String[] {}, gfshConfig);

    int actualStatus = gfsh.getLastExecutionStatus();
    int expectedStatus = 0;
    assertNotEquals(""Status <0==failure"", expectedStatus, actualStatus);

    int expectedLogCount = BANNER_LINES + INIT_FILE_CITATION_LINES + 1;
    assertEquals(""Log records written"", expectedLogCount,
        this.junitLoggerHandler.getLog().size());
    for (LogRecord logRecord : this.junitLoggerHandler.getLog()) {
      assertNull(""No exceptions in log"", logRecord.getThrown());
    }
  }",False
"  public void testInitFile_NotFound() throws Exception {
    // Construct the file name but not the file
    String initFileName = temporaryFolder_CurrentDirectory.getRoot()
        .getAbsolutePath() + File.separator + INIT_FILE_NAME;

    /*
     * String historyFileName, String defaultPrompt, int historySize, String
     * logDir, Level logLevel, Integer logLimit, Integer logCount, String
     * initFileName
     */
    GfshConfig gfshConfig = new GfshConfig(this.gfshHistoryFileName, """", 0,
        temporaryFolder_CurrentDirectory.getRoot().getAbsolutePath(), null,
        null, null, initFileName);
    assertNotNull(INIT_FILE_NAME, gfshConfig.getInitFileName());

    /*
     * boolean launchShell, String[] args, GfshConfig gfshConfig
     */
    Gfsh gfsh = Gfsh.getInstance(false, new String[] {}, gfshConfig);

    int actualStatus = gfsh.getLastExecutionStatus();
    int expectedStatus = 0;
    assertNotEquals(""Status <0==failure"", expectedStatus, actualStatus);

    int expectedLogCount = BANNER_LINES + INIT_FILE_CITATION_LINES + 1;
    assertEquals(""Log records written"", expectedLogCount,
        this.junitLoggerHandler.getLog().size());
    Throwable exception = null;
    for (LogRecord logRecord : this.junitLoggerHandler.getLog()) {
      if (logRecord.getThrown() != null) {
        exception = logRecord.getThrown();
        break;
      }
    }
    assertNotNull(""Exceptions in log"", exception);
  }",False
"  public void setUp() throws Exception {
    // Fake running from home directory
    String userDir = temporaryFolder_CurrentDirectory.getRoot()
        .getAbsolutePath();
    String userHome = userDir;

    System.setProperty(""user.dir"", userDir);
    System.setProperty(""user.home"", userHome);

    // Abort all tests if system properties cannot be overridden
    assertEquals(""user.dir"", System.getProperty(""user.dir""), userDir);
    assertEquals(""user.home"", System.getProperty(""user.home""), userHome);
  }",False
"  public static void setUpBeforeClass() throws Exception {
    saveLog4j2Config = System
        .getProperty(ConfigurationFactory.CONFIGURATION_FILE_PROPERTY);
    saveUserDir = System.getProperty(""user.dir"");
    saveUserHome = System.getProperty(""user.home"");

    julLogger = java.util.logging.Logger.getLogger("""");
    saveHandlers = julLogger.getHandlers();
    for (Handler handler : saveHandlers) {
      julLogger.removeHandler(handler);
    }

    File log4j2XML = temporaryFolder_Config.newFile(""log4j2.xml"");
    FileUtils.writeStringToFile(log4j2XML, ""<Configuration/>"", APPEND);
    System.setProperty(ConfigurationFactory.CONFIGURATION_FILE_PROPERTY,
        log4j2XML.toURI().toString());
  }",False
"  public void setUp2() throws Exception {

    // Null out static instance so can reinitialise
    Field gfsh_instance = Gfsh.class.getDeclaredField(""instance"");
    gfsh_instance.setAccessible(true);
    gfsh_instance.set(null, null);

    this.junitLoggerHandler = new JUnitLoggerHandler();

    this.gfshFileLogger = LogWrapper.getInstance();
    Field logWrapper_INSTANCE = LogWrapper.class.getDeclaredField(""INSTANCE"");
    logWrapper_INSTANCE.setAccessible(true);
    logWrapper_INSTANCE.set(null, this.gfshFileLogger);

    Field logWrapper_logger = LogWrapper.class.getDeclaredField(""logger"");
    logWrapper_logger.setAccessible(true);
    julLogger.addHandler(this.junitLoggerHandler);
    logWrapper_logger.set(this.gfshFileLogger, julLogger);

    Gfsh.gfshout = new PrintStream(sysout);
    this.gfshHistoryFileName = temporaryFolder_CurrentDirectory.newFile(
        ""historyFile"").getAbsolutePath();
  }",False
"  public static void tearDownAfterClass() throws Exception {
    for (Handler handler : saveHandlers) {
      julLogger.addHandler(handler);
    }

    if (saveLog4j2Config == null) {
      System.clearProperty(ConfigurationFactory.CONFIGURATION_FILE_PROPERTY);
    } else {
      System.setProperty(ConfigurationFactory.CONFIGURATION_FILE_PROPERTY,
          saveLog4j2Config);
      ((LoggerContext) LogManager.getContext(false)).reconfigure();
    }

    if (saveUserDir == null) {
      System.clearProperty(""user.dir"");
    } else {
      System.setProperty(""user.dir"", saveUserDir);
    }
    if (saveUserHome == null) {
      System.clearProperty(""user.home"");
    } else {
      System.setProperty(""user.home"", saveUserHome);
    }
  }",False
"  public void tearDown() throws Exception {
    julLogger.removeHandler(this.junitLoggerHandler);
  }",False
"    public void flush() {
    }",False
"    public JUnitLoggerHandler() {
      log = new ArrayList<>();
    }",False
"  private PoolFactory add(String host, int port, List l) {
    if (port == 0) {
      throw new IllegalArgumentException(""port must be greater than 0 but was "" + port);
      // the rest of the port validation is done by InetSocketAddress
    }
    try {
      InetAddress hostAddr = InetAddress.getByName(host);
      InetSocketAddress sockAddr = new InetSocketAddress(hostAddr, port);
      l.add(sockAddr);
    } catch (UnknownHostException cause) {
//      IllegalArgumentException ex = new IllegalArgumentException(""Unknown host "" + host);
//      ex.initCause(cause);
//      throw ex;
      // Fix for #45348
      GemFireCacheImpl cache =GemFireCacheImpl.getInstance();
      logger.fatal(LocalizedMessage.create(LocalizedStrings.PoolFactoryImpl_HOSTNAME_UNKNOWN, host));
      InetSocketAddress sockAddr = new InetSocketAddress(host, port);
      l.add(sockAddr);
    }
    return this;
  }",True
"  private PoolFactory add(String host, int port, List l) {
    if (port == 0) {
      throw new IllegalArgumentException(""port must be greater than 0 but was "" + port);
      // the rest of the port validation is done by InetSocketAddress
    }
    try {
      InetAddress hostAddr = InetAddress.getByName(host);
      InetSocketAddress sockAddr = new InetSocketAddress(hostAddr, port);
      l.add(sockAddr);
    } catch (UnknownHostException cause) {
//      IllegalArgumentException ex = new IllegalArgumentException(""Unknown host "" + host);
//      ex.initCause(cause);
//      throw ex;
      // Fix for #45348
      logger.warn(LocalizedMessage.create(LocalizedStrings.PoolFactoryImpl_HOSTNAME_UNKNOWN, host));
      InetSocketAddress sockAddr = new InetSocketAddress(host, port);
      l.add(sockAddr);
    }
    return this;
  }",False
"  public DistTXAdjunctCommitMessage(TXId txIdent, DM dm, TXState txState) {
    super(txIdent, dm, txState);
  }",False
"  public void basicProcessOps() {
    Collections.sort(this.farSideEntryOps);
    Iterator it = this.farSideEntryOps.iterator();
    while (it.hasNext()) {
      try {
        RegionCommit.FarSideEntryOp entryOp = (RegionCommit.FarSideEntryOp) it
            .next();
        entryOp.processAdjunctOnly();
      } catch (CacheRuntimeException problem) {
        processCacheRuntimeException(problem);
      } catch (Exception e) {
        addProcessingException(e);
      }
    }
  }  ",False
"  protected boolean operateOnTx(TXId txId, DistributionManager dm)
      throws RemoteOperationException {
    if (logger.isDebugEnabled()) {
      logger.debug(""DistTXCommitMessage.operateOnTx: Tx {}"", txId);
    }

    GemFireCacheImpl cache = GemFireCacheImpl.getInstance();
    TXManagerImpl txMgr = cache.getTXMgr();
    final TXStateProxy txStateProxy = txMgr.getTXState();
    boolean commitSuccessful = false;
    TXCommitMessage cmsg = null;
    try {
      // do the actual commit, only if it was not done before
      if (txMgr.isHostedTxRecentlyCompleted(txId)) {
        if (logger.isDebugEnabled()) {
          logger
              .debug(
                  ""DistTXCommitMessage.operateOnTx: found a previously committed transaction:{}"",
                  txId);
        }
        cmsg = txMgr.getRecentlyCompletedMessage(txId);
        if (txMgr.isExceptionToken(cmsg)) {
          throw txMgr.getExceptionForToken(cmsg, txId);
        }
        commitSuccessful = true;
      } else {
        // [DISTTX] TODO - Handle scenarios of no txState
        // if no TXState was created (e.g. due to only getEntry/size operations
        // that don't start remote TX) then ignore
        if (txStateProxy != null) {
          /*
           * [DISTTX] TODO See how other exceptions are caught and send on wire,
           * than throwing?
           * 
           * This can be spared since it will be programming bug
           */
          if (!txStateProxy.isDistTx()
              || txStateProxy.isCreatedOnDistTxCoordinator()) {
            throw new UnsupportedOperationInTransactionException(
                LocalizedStrings.DISTTX_TX_EXPECTED.toLocalizedString(
                    ""DistTXStateProxyImplOnDatanode"", txStateProxy.getClass()
                        .getSimpleName()));
          }
          if (logger.isDebugEnabled()) {
            logger.debug(""DistTXCommitMessage.operateOnTx Commiting {} ""
                + "" incoming entryEventList:{} coming from {} "", txId,
                DistTXStateProxyImplOnCoordinator
                    .printEntryEventList(this.entryStateList), this.getSender()
                    .getId());
          }
          
          // Set Member's ID to all entry states
          String memberID = this.getSender().getId();
          for (ArrayList<DistTxThinEntryState> esList : this.entryStateList) {
            for (DistTxThinEntryState es : esList) {
              es.setMemberID(memberID);
            }
          }
          
          ((DistTXStateProxyImplOnDatanode) txStateProxy)
              .populateDistTxEntryStates(this.entryStateList);
          txStateProxy.setCommitOnBehalfOfRemoteStub(true);
          txMgr.commit();
          commitSuccessful = true;
          cmsg = txStateProxy.getCommitMessage();
        }
      }
    } finally {
      if (commitSuccessful) {
        txMgr.removeHostedTXState(txId);
      }
    }
    DistTXCommitReplyMessage.send(getSender(), getProcessorId(), cmsg,
        getReplySender(dm));

    /*
     * return false so there isn't another reply
     */
    return false;
  }",True
"  protected boolean operateOnTx(TXId txId, DistributionManager dm)
      throws RemoteOperationException {
    if (logger.isDebugEnabled()) {
      logger.debug(""DistTXCommitMessage.operateOnTx: Tx {}"", txId);
    }

    GemFireCacheImpl cache = GemFireCacheImpl.getInstance();
    TXManagerImpl txMgr = cache.getTXMgr();
    final TXStateProxy txStateProxy = txMgr.getTXState();
    TXCommitMessage cmsg = null;
    try {
      // do the actual commit, only if it was not done before
      if (txMgr.isHostedTxRecentlyCompleted(txId)) {
        if (logger.isDebugEnabled()) {
          logger
              .debug(
                  ""DistTXCommitMessage.operateOnTx: found a previously committed transaction:{}"",
                  txId);
        }
        cmsg = txMgr.getRecentlyCompletedMessage(txId);
        if (txMgr.isExceptionToken(cmsg)) {
          throw txMgr.getExceptionForToken(cmsg, txId);
        }
      } else {
        // [DISTTX] TODO - Handle scenarios of no txState
        // if no TXState was created (e.g. due to only getEntry/size operations
        // that don't start remote TX) then ignore
        if (txStateProxy != null) {
          /*
           * [DISTTX] TODO See how other exceptions are caught and send on wire,
           * than throwing?
           * 
           * This can be spared since it will be programming bug
           */
          if (!txStateProxy.isDistTx()
              || txStateProxy.isCreatedOnDistTxCoordinator()) {
            throw new UnsupportedOperationInTransactionException(
                LocalizedStrings.DISTTX_TX_EXPECTED.toLocalizedString(
                    ""DistTXStateProxyImplOnDatanode"", txStateProxy.getClass()
                        .getSimpleName()));
          }
          if (logger.isDebugEnabled()) {
            logger.debug(""DistTXCommitMessage.operateOnTx Commiting {} ""
                + "" incoming entryEventList:{} coming from {} "", txId,
                DistTXStateProxyImplOnCoordinator
                    .printEntryEventList(this.entryStateList), this.getSender()
                    .getId());
          }
          
          // Set Member's ID to all entry states
          String memberID = this.getSender().getId();
          for (ArrayList<DistTxThinEntryState> esList : this.entryStateList) {
            for (DistTxThinEntryState es : esList) {
              es.setMemberID(memberID);
            }
          }
          
          ((DistTXStateProxyImplOnDatanode) txStateProxy)
              .populateDistTxEntryStates(this.entryStateList);
          txStateProxy.setCommitOnBehalfOfRemoteStub(true);
          
          txMgr.commit();

          cmsg = txStateProxy.getCommitMessage();
        }
      }
    } finally {
        txMgr.removeHostedTXState(txId);
    }
    DistTXCommitReplyMessage.send(getSender(), getProcessorId(), cmsg,
        getReplySender(dm));

    /*
     * return false so there isn't another reply
     */
    return false;
  }",False
"  protected TXCommitMessage buildMessageForAdjunctReceivers() {
    TXCommitMessage msg = new DistTXAdjunctCommitMessage(this.proxy.getTxId(), this.proxy.getTxMgr().getDM(), this);
    Iterator<Map.Entry<LocalRegion, TXRegionState>> it = this.regions.entrySet().iterator();
    while (it.hasNext()) {
      Map.Entry<LocalRegion, TXRegionState> me = it.next();
      LocalRegion r = me.getKey();
      TXRegionState txrs = me.getValue();
      
      // only on the primary
      if (r.isUsedForPartitionedRegionBucket() && !txrs.isCreatedDuringCommit()) {
        txrs.buildMessageForAdjunctReceivers(r, msg);  
      }
    }
    return msg;
  }",False
"  public void postPutAll(final DistributedPutAllOperation putallOp,
      final VersionedObjectList successfulPuts, LocalRegion reg) {

    final LocalRegion theRegion;
    if (reg instanceof BucketRegion) {
      theRegion = ((BucketRegion) reg).getPartitionedRegion();
    } else {
      theRegion = reg;
    }
    /*
     * Don't fire events here.
     */
    /*
     * We are on the data store, we don't need to do anything here. Commit will
     * push them out.
     */
    /*
     * We need to put this into the tx state.
     */
    theRegion.syncBulkOp(new Runnable() {
      public void run() {
        // final boolean requiresRegionContext =
        // theRegion.keyRequiresRegionContext();
        InternalDistributedMember myId = theRegion.getDistributionManager()
            .getDistributionManagerId();
        for (int i = 0; i < putallOp.putAllDataSize; ++i) {
          EntryEventImpl ev = PutAllPRMessage.getEventFromEntry(theRegion,
              myId, myId, i, putallOp.putAllData, false, putallOp
                  .getBaseEvent().getContext(), false, !putallOp.getBaseEvent()
                  .isGenerateCallbacks(), false);
          try {
//            ev.setPutAllOperation(putallOp);
            
            // below if condition returns true on secondary when TXState is
            // updated in preCommit only on secondary
            // In this case disable the primary check by calling
            // distKeyInfo.setCheckPrimary(false);
            if (isUpdatingTxStateDuringPreCommit()) {
              KeyInfo keyInfo = ev.getKeyInfo();
              DistTxKeyInfo distKeyInfo = new DistTxKeyInfo(keyInfo);
              distKeyInfo.setCheckPrimary(false);
              ev.setKeyInfo(distKeyInfo);
            }
            if (theRegion.basicPut(ev, false, false, null, false)) {
              successfulPuts.addKeyAndVersion(putallOp.putAllData[i].key, null);
            }
          } finally {
            ev.release();
          }
        }
      }
    }, putallOp.getBaseEvent().getEventId());

  }",True
"  public void postPutAll(final DistributedPutAllOperation putallOp,
      final VersionedObjectList successfulPuts, LocalRegion reg) {

    final LocalRegion theRegion;
    if (reg instanceof BucketRegion) {
      theRegion = ((BucketRegion) reg).getPartitionedRegion();
    } else {
      theRegion = reg;
    }
    /*
     * Don't fire events here.
     */
    /*
     * We are on the data store, we don't need to do anything here. Commit will
     * push them out.
     */
    /*
     * We need to put this into the tx state.
     */
    theRegion.syncBulkOp(new Runnable() {
      public void run() {
        // final boolean requiresRegionContext =
        // theRegion.keyRequiresRegionContext();
        InternalDistributedMember myId = theRegion.getDistributionManager()
            .getDistributionManagerId();
        for (int i = 0; i < putallOp.putAllDataSize; ++i) {
          EntryEventImpl ev = PutAllPRMessage.getEventFromEntry(theRegion,
              myId, myId, i, putallOp.putAllData, false, putallOp
                  .getBaseEvent().getContext(), false, !putallOp.getBaseEvent()
                  .isGenerateCallbacks(), false);
          try {
//            ev.setPutAllOperation(putallOp);
            
            // below if condition returns true on secondary when TXState is
            // updated in preCommit only on secondary
            // In this case disable the primary check by calling
            // distKeyInfo.setCheckPrimary(false);
            if (isUpdatingTxStateDuringPreCommit()) {
              KeyInfo keyInfo = ev.getKeyInfo();
              DistTxKeyInfo distKeyInfo = new DistTxKeyInfo(keyInfo);
              distKeyInfo.setCheckPrimary(false);
              ev.setKeyInfo(distKeyInfo);
            }
            /*
             * Whenever commit is called, especially when its a
             * DistTxStateOnCoordinator the txState is set to null in @see
             * TXManagerImpl.commit() and thus when @see LocalRegion.basicPut
             * will be called as in this function, they will not found a TxState
             * with call for getDataView()
             */
            if (!(theRegion.getDataView() instanceof TXStateInterface)) {
              if (putEntry(ev, false, false, null, false, 0L, false)) {
                successfulPuts.addKeyAndVersion(putallOp.putAllData[i].key,
                    null);
              }
            } else if (theRegion.basicPut(ev, false, false, null, false)) {
              successfulPuts.addKeyAndVersion(putallOp.putAllData[i].key, null);
            }
          } finally {
            ev.release();
          }
        }
      }
    }, putallOp.getBaseEvent().getEventId());

  }",False
"  public void precommit() throws CommitConflictException,
      UnsupportedOperationInTransactionException {
    if (logger.isDebugEnabled()) {
      logger.debug(""DistTXState.precommit transaction {} is closed {} "",
          getTransactionId(), this.closed, new Throwable());
    }

    if (this.closed) {
      return;
    }

    synchronized (this.completionGuard) {
      this.completionStarted = true;
    }

    if (onBehalfOfRemoteStub && !proxy.isCommitOnBehalfOfRemoteStub()) {
      throw new UnsupportedOperationInTransactionException(
          LocalizedStrings.TXState_CANNOT_COMMIT_REMOTED_TRANSACTION
              .toLocalizedString());
    }

    cleanupNonDirtyRegions();

    /*
     * Lock buckets so they can't be rebalanced then perform the conflict check
     * to fix #43489
     */
    try {
      lockBucketRegions();
    } catch (PrimaryBucketException pbe) {
      // not sure what to do here yet
      RuntimeException re = new TransactionDataRebalancedException(
          LocalizedStrings.PartitionedRegion_TRANSACTIONAL_DATA_MOVED_DUE_TO_REBALANCING
              .toLocalizedString());
      re.initCause(pbe);
      throw re;
    }

    if (this.locks == null) {
      reserveAndCheck();
    }

    // For internal testing
    if (this.internalAfterConflictCheck != null) {
      this.internalAfterConflictCheck.run();
    }
    
    updateRegionVersions();
    
    generateTailKeysForParallelDispatcherEvents();
    
    /*
     * If there is a TransactionWriter plugged in, we need to to give it an
     * opportunity to abort the transaction.
     */
    TransactionWriter writer = this.proxy.getTxMgr().getWriter();
    if (!firedWriter && writer != null) {
      try {
        firedWriter = true;
        writer.beforeCommit(getEvent());
      } catch (TransactionWriterException twe) {
        cleanup();
        throw new CommitConflictException(twe);
      } catch (VirtualMachineError err) {
        // cleanup(); this allocates objects so I don't think we can do it -
        // that leaves the TX open, but we are poison pilling so we should be
        // ok??

        SystemFailure.initiateFailure(err);
        // If this ever returns, rethrow the error. We're poisoned
        // now, so don't let this thread continue.
        throw err;
      } catch (Throwable t) {
        cleanup(); // rollback the transaction!
        // Whenever you catch Error or Throwable, you must also
        // catch VirtualMachineError (see above). However, there is
        // _still_ a possibility that you are dealing with a cascading
        // error condition, so you also need to check to see if the JVM
        // is still usable:
        SystemFailure.checkFailure();
        throw new CommitConflictException(t);
      }
    }
  }",True
"  public void precommit() throws CommitConflictException,
      UnsupportedOperationInTransactionException {
    if (logger.isDebugEnabled()) {
      logger.debug(""DistTXState.precommit transaction {} is closed {} "",
          getTransactionId(), this.closed, new Throwable());
    }

    if (this.closed) {
      return;
    }
    
    synchronized (this.completionGuard) {
      this.completionStarted = true;
    }

    if (onBehalfOfRemoteStub && !proxy.isCommitOnBehalfOfRemoteStub()) {
      throw new UnsupportedOperationInTransactionException(
          LocalizedStrings.TXState_CANNOT_COMMIT_REMOTED_TRANSACTION
              .toLocalizedString());
    }

    cleanupNonDirtyRegions();

    /*
     * Lock buckets so they can't be rebalanced then perform the conflict check
     * to fix #43489
     */
    try {
      lockBucketRegions();
    } catch (PrimaryBucketException pbe) {
      // not sure what to do here yet
      RuntimeException re = new TransactionDataRebalancedException(
          LocalizedStrings.PartitionedRegion_TRANSACTIONAL_DATA_MOVED_DUE_TO_REBALANCING
              .toLocalizedString());
      re.initCause(pbe);
      throw re;
    }

    if (this.locks == null) {
      reserveAndCheck();
    }

    // For internal testing
    if (this.internalAfterConflictCheck != null) {
      this.internalAfterConflictCheck.run();
    }
    
    updateRegionVersions();
    
    generateTailKeysForParallelDispatcherEvents();
    
    /*
     * If there is a TransactionWriter plugged in, we need to to give it an
     * opportunity to abort the transaction.
     */
    TransactionWriter writer = this.proxy.getTxMgr().getWriter();
    if (!firedWriter && writer != null) {
      try {
        firedWriter = true;
        writer.beforeCommit(getEvent());
      } catch (TransactionWriterException twe) {
        cleanup();
        throw new CommitConflictException(twe);
      } catch (VirtualMachineError err) {
        // cleanup(); this allocates objects so I don't think we can do it -
        // that leaves the TX open, but we are poison pilling so we should be
        // ok??

        SystemFailure.initiateFailure(err);
        // If this ever returns, rethrow the error. We're poisoned
        // now, so don't let this thread continue.
        throw err;
      } catch (Throwable t) {
        cleanup(); // rollback the transaction!
        // Whenever you catch Error or Throwable, you must also
        // catch VirtualMachineError (see above). However, there is
        // _still_ a possibility that you are dealing with a cascading
        // error condition, so you also need to check to see if the JVM
        // is still usable:
        SystemFailure.checkFailure();
        throw new CommitConflictException(t);
      }
    }
  }",False
"  public void commit() throws CommitConflictException {
    if (logger.isDebugEnabled()) {
      logger.debug(
          ""DistTXState.commit transaction {} is closed {} "",
          getTransactionId(), this.closed, new Throwable());
    }

    if (this.closed) {
      return;
    }

    try {
      List/* <TXEntryStateWithRegionAndKey> */entries = generateEventOffsets();
      if (logger.isDebugEnabled()) {
        logger.debug(""commit entries "" + entries);
      }
      TXCommitMessage msg = null;
      try {
        attachFilterProfileInformation(entries);

        // apply changes to the cache
        applyChanges(entries);
        // For internal testing
        if (this.internalAfterApplyChanges != null) {
          this.internalAfterApplyChanges.run();
        }

        this.commitMessage = buildCompleteMessage();

      } finally {
        if (msg != null) {
          msg.releaseViewVersions();
        }
        this.locks.releaseLocal();
        // For internal testing
        if (this.internalAfterReleaseLocalLocks != null) {
          this.internalAfterReleaseLocalLocks.run();
        }
      }
    } finally {
      cleanup();
    }
  }",True
"  public void commit() throws CommitConflictException {
    if (logger.isDebugEnabled()) {
      logger.debug(
          ""DistTXState.commit transaction {} is closed {} "",
          getTransactionId(), this.closed, new Throwable());
    }

    if (this.closed) {
      return;
    }

    try {
      List/* <TXEntryStateWithRegionAndKey> */entries = generateEventOffsets();
      if (logger.isDebugEnabled()) {
        logger.debug(""commit entries "" + entries);
      }
      TXCommitMessage msg = null;
      try {
        attachFilterProfileInformation(entries);

        if (GemFireCacheImpl.internalBeforeApplyChanges != null) {
          GemFireCacheImpl.internalBeforeApplyChanges.run();
        }
        
        // apply changes to the cache
        applyChanges(entries);
        
        // For internal testing
        if (this.internalAfterApplyChanges != null) {
          this.internalAfterApplyChanges.run();
        }

        // [DISTTX]TODO:
        // Build a message specifically for those nodes who
        // hold gateway senders and listeners but not a copy of the buckets
        // on which changes in this tx are done.
        // This is applicable only for partitioned regions and 
        // serial gateway senders.
        // This works only if the coordinator and sender are not the same node.
        // For same sender as coordinator, this results in a hang, which needs to be addressed.
        // If an another method of notifying adjunct receivers is implemented, 
        // the following two lines should be commented out.
        msg = buildMessageForAdjunctReceivers();
        msg.send(this.locks.getDistributedLockId());

        // Fire callbacks collected in the local txApply* executions
        firePendingCallbacks();
        
        this.commitMessage = buildCompleteMessage();

      } finally {
        if (msg != null) {
          msg.releaseViewVersions();
        }
        this.locks.releaseLocal();
        // For internal testing
        if (this.internalAfterReleaseLocalLocks != null) {
          this.internalAfterReleaseLocalLocks.run();
        }
      }
    } finally {
      cleanup();
    }
  }",False
"  public void postRemoveAll(final DistributedRemoveAllOperation op,
      final VersionedObjectList successfulOps, LocalRegion reg) {
    final LocalRegion theRegion;
    if (reg instanceof BucketRegion) {
      theRegion = ((BucketRegion) reg).getPartitionedRegion();
    } else {
      theRegion = reg;
    }
    /*
     * Don't fire events here. We are on the data store, we don't need to do
     * anything here. Commit will push them out. We need to put this into the tx
     * state.
     */
    theRegion.syncBulkOp(new Runnable() {
      public void run() {
        InternalDistributedMember myId = theRegion.getDistributionManager()
            .getDistributionManagerId();
        for (int i = 0; i < op.removeAllDataSize; ++i) {
          EntryEventImpl ev = RemoveAllPRMessage.getEventFromEntry(theRegion,
              myId, myId, i, op.removeAllData, false, op.getBaseEvent()
                  .getContext(), false, !op.getBaseEvent()
                  .isGenerateCallbacks());
          ev.setRemoveAllOperation(op);
          // below if condition returns true on secondary when TXState is
          // updated in preCommit only on secondary
          // In this case disable the primary check by calling
          // distKeyInfo.setCheckPrimary(false);
          if (isUpdatingTxStateDuringPreCommit()) {
            KeyInfo keyInfo = ev.getKeyInfo();
            DistTxKeyInfo distKeyInfo = new DistTxKeyInfo(keyInfo);
            distKeyInfo.setCheckPrimary(false);
            ev.setKeyInfo(distKeyInfo);
          }
          try {
            theRegion.basicDestroy(ev, true/* should we invoke cacheWriter? */,
                null);
          } catch (EntryNotFoundException ignore) {
          }
          successfulOps.addKeyAndVersion(op.removeAllData[i].key, null);
        }
      }
    }, op.getBaseEvent().getEventId());

  }",True
"  public void postRemoveAll(final DistributedRemoveAllOperation op,
      final VersionedObjectList successfulOps, LocalRegion reg) {
    final LocalRegion theRegion;
    if (reg instanceof BucketRegion) {
      theRegion = ((BucketRegion) reg).getPartitionedRegion();
    } else {
      theRegion = reg;
    }
    /*
     * Don't fire events here. We are on the data store, we don't need to do
     * anything here. Commit will push them out. We need to put this into the tx
     * state.
     */
    theRegion.syncBulkOp(new Runnable() {
      public void run() {
        InternalDistributedMember myId = theRegion.getDistributionManager()
            .getDistributionManagerId();
        for (int i = 0; i < op.removeAllDataSize; ++i) {
          EntryEventImpl ev = RemoveAllPRMessage.getEventFromEntry(theRegion,
              myId, myId, i, op.removeAllData, false, op.getBaseEvent()
                  .getContext(), false, !op.getBaseEvent()
                  .isGenerateCallbacks());
          ev.setRemoveAllOperation(op);
          // below if condition returns true on secondary when TXState is
          // updated in preCommit only on secondary
          // In this case disable the primary check by calling
          // distKeyInfo.setCheckPrimary(false);
          if (isUpdatingTxStateDuringPreCommit()) {
            KeyInfo keyInfo = ev.getKeyInfo();
            DistTxKeyInfo distKeyInfo = new DistTxKeyInfo(keyInfo);
            distKeyInfo.setCheckPrimary(false);
            ev.setKeyInfo(distKeyInfo);
          }
          /*
           * Whenever commit is called, especially when its a
           * DistTxStateOnCoordinator the txState is set to null in @see
           * TXManagerImpl.commit() and thus when basicDestroy will be called
           * will be called as in i.e. @see LocalRegion.basicDestroy, they will
           * not found a TxState with call for getDataView()
           * 
           * [DISTTX] TODO verify if this is correct to call
           * destroyExistingEntry directly?
           */
          try {
            if (!(theRegion.getDataView() instanceof TXStateInterface)) {
              destroyExistingEntry(ev, true/* should we invoke cacheWriter? */,
                  null);
            } else {
              theRegion.basicDestroy(ev,
                  true/* should we invoke cacheWriter? */, null);
            }
          } catch (EntryNotFoundException ignore) {
          }
          successfulOps.addKeyAndVersion(op.removeAllData[i].key, null);
        }
      }
    }, op.getBaseEvent().getEventId());

  }",False
"  public void postRemoveAll(DistributedRemoveAllOperation op,
      VersionedObjectList successfulOps, LocalRegion region) {
    if (op.removeAllData.length == 0) {
      return;
    }
    if (region instanceof DistributedRegion) {
      super.postRemoveAll(op, successfulOps, region);
    } else {
      region.getCancelCriterion().checkCancelInProgress(null); // fix for bug
                                                               // #43651
      if (logger.isDebugEnabled()) {
        logger.debug(""DistTXStateProxyImplOnCoordinator.postRemoveAll ""
            + ""processing removeAll op for region {}, size of removeAll ""
            + ""is {}"", region, op.removeAllDataSize);
      }
      
      //map of bucketId to removeAll op for this bucket
      HashMap<Integer, DistributedRemoveAllOperation> bucketToRemoveAllMap = 
          new HashMap<Integer, DistributedRemoveAllOperation>();
      //map of bucketId to TXStateStub for target that hosts this bucket
      HashMap<Integer, DistTXCoordinatorInterface> bucketToTxStateStubMap = 
          new HashMap<Integer, DistTXCoordinatorInterface>();
      
      //separate the removeAll op per bucket
      for (int i=0; i<op.removeAllData.length; i++) {
        assert (op.removeAllData[i] != null);
        Object key = op.removeAllData[i].key;
        int bucketId = op.removeAllData[i].getBucketId();
        
        DistributedRemoveAllOperation removeAllForBucket = 
            bucketToRemoveAllMap.get(bucketId);
        if (removeAllForBucket == null) {
          EntryEventImpl event = EntryEventImpl.createPutAllEvent(null, region,
              Operation.REMOVEALL_DESTROY, key, null);
          removeAllForBucket = new DistributedRemoveAllOperation(
              event, op.removeAllDataSize, op.isBridgeOp);
          bucketToRemoveAllMap.put(bucketId, removeAllForBucket);
        } 
        removeAllForBucket.addEntry(op.removeAllData[i]);

        KeyInfo ki = new KeyInfo(key, null, null);
        DistTXCoordinatorInterface tsi = (DistTXCoordinatorInterface) getRealDeal(ki, region);
        bucketToTxStateStubMap.put(bucketId, tsi);
      }
      
      // fire a removeAll operation for each bucket using appropriate TXStateStub
      // (for target that host this bucket)

      // [DISTTX] [TODO] Perf: Can this be further optimized?
      // This sends putAll in a loop to each target bucket (and waits for ack)
      // one after another.Could we send respective putAll messages to all
      // targets using same reply processor and wait on it?
      for (Entry<Integer, DistTXCoordinatorInterface> e : bucketToTxStateStubMap
          .entrySet()) {
        Integer bucketId = e.getKey();
        DistTXCoordinatorInterface dtsi = e.getValue();
        DistributedRemoveAllOperation removeAllForBucket = bucketToRemoveAllMap
            .get(bucketId);
        
        if (logger.isDebugEnabled()) {
          logger.debug(""DistTXStateProxyImplOnCoordinator.postRemoveAll processing""
              + "" removeAll for ##bucketId = {}, ##txStateStub = {}, ""
              + ""##removeAllOp = {}""
              , bucketId, dtsi, removeAllForBucket);
        }
        dtsi.postRemoveAll(removeAllForBucket, successfulOps, region);
      }

    }
  }",True
"  public void postRemoveAll(DistributedRemoveAllOperation op,
      VersionedObjectList successfulOps, LocalRegion region) {
    if (op.removeAllData.length == 0) {
      return;
    }
    if (region instanceof DistributedRegion) {
      super.postRemoveAll(op, successfulOps, region);
    } else {
      region.getCancelCriterion().checkCancelInProgress(null); // fix for bug
                                                               // #43651
      if (logger.isDebugEnabled()) {
        logger.debug(""DistTXStateProxyImplOnCoordinator.postRemoveAll ""
            + ""processing removeAll op for region {}, size of removeAll ""
            + ""is {}"", region, op.removeAllDataSize);
      }
      
      //map of bucketId to removeAll op for this bucket
      HashMap<Integer, DistributedRemoveAllOperation> bucketToRemoveAllMap = 
          new HashMap<Integer, DistributedRemoveAllOperation>();
      //map of bucketId to TXStateStub for target that hosts this bucket
      HashMap<Integer, DistTXCoordinatorInterface> bucketToTxStateStubMap = 
          new HashMap<Integer, DistTXCoordinatorInterface>();
      
      //separate the removeAll op per bucket
      for (int i=0; i<op.removeAllData.length; i++) {
        assert (op.removeAllData[i] != null);
        Object key = op.removeAllData[i].key;
        int bucketId = op.removeAllData[i].getBucketId();
        
        DistributedRemoveAllOperation removeAllForBucket = 
            bucketToRemoveAllMap.get(bucketId);
        if (removeAllForBucket == null) {
          EntryEventImpl event = EntryEventImpl.createRemoveAllEvent(op, region, key);
          event.setEventId(op.removeAllData[i].getEventID());
          removeAllForBucket = new DistributedRemoveAllOperation(
              event, op.removeAllDataSize, op.isBridgeOp);
          bucketToRemoveAllMap.put(bucketId, removeAllForBucket);
        } 
        removeAllForBucket.addEntry(op.removeAllData[i]);

        KeyInfo ki = new KeyInfo(key, null, null);
        DistTXCoordinatorInterface tsi = (DistTXCoordinatorInterface) getRealDeal(ki, region);
        bucketToTxStateStubMap.put(bucketId, tsi);
      }
      
      // fire a removeAll operation for each bucket using appropriate TXStateStub
      // (for target that host this bucket)

      // [DISTTX] [TODO] Perf: Can this be further optimized?
      // This sends putAll in a loop to each target bucket (and waits for ack)
      // one after another.Could we send respective putAll messages to all
      // targets using same reply processor and wait on it?
      for (Entry<Integer, DistTXCoordinatorInterface> e : bucketToTxStateStubMap
          .entrySet()) {
        Integer bucketId = e.getKey();
        DistTXCoordinatorInterface dtsi = e.getValue();
        DistributedRemoveAllOperation removeAllForBucket = bucketToRemoveAllMap
            .get(bucketId);
        
        if (logger.isDebugEnabled()) {
          logger.debug(""DistTXStateProxyImplOnCoordinator.postRemoveAll processing""
              + "" removeAll for ##bucketId = {}, ##txStateStub = {}, ""
              + ""##removeAllOp = {}""
              , bucketId, dtsi, removeAllForBucket);
        }
        dtsi.postRemoveAll(removeAllForBucket, successfulOps, region);
      }

    }
  }",False
"  private boolean doPrecommit() {
    boolean finalResult = true;
    final GemFireCacheImpl cache = GemFireCacheImpl
        .getExisting(""Applying Dist TX Precommit"");
    final DM dm = cache.getDistributionManager();

    // Create Tx Participants
    Set<DistributedMember> txParticpants = target2realDeals.keySet();
    Set<DistributedMember> txRemoteParticpants = getTxRemoteParticpants(dm);

    // Determine if the set of VMs for any of the Regions for this TX have
    // changed
    DistributedRegion dr = null;
    HashSet<LocalRegion> affectedRegions = new HashSet<LocalRegion>();
    for (DistTXCoordinatorInterface distTXStateStub : target2realDeals.values()) {
      affectedRegions.clear();
      distTXStateStub.gatherAffectedRegions(affectedRegions, true, false);
      for (LocalRegion lr : affectedRegions) {
        if (lr.getScope().isLocal()) {
          continue;
        }
        // [DISTTX] TODO what about PR?
        if (lr instanceof DistributedRegion) {
          dr = (DistributedRegion) lr;
          CacheDistributionAdvisor adv = dr.getCacheDistributionAdvisor();
          Set newRegionMemberView = adv.adviseTX();

          if (!txParticpants.containsAll(newRegionMemberView)) {
            logger
                .warn(LocalizedMessage
                    .create(
                        LocalizedStrings.TXCommitMessage_NEW_MEMBERS_FOR_REGION_0_ORIG_LIST_1_NEW_LIST_2,
                        new Object[] { dr, txParticpants, newRegionMemberView }));
          }
        }
      }
    }

    // create processor and precommit message
    DistTXPrecommitMessage.DistTxPrecommitReplyProcessor processor = new DistTXPrecommitMessage.DistTxPrecommitReplyProcessor(
        this.getTxId(), dm, txRemoteParticpants, target2realDeals);
    // TODO [DISTTX} whats ack threshold?
    processor.enableSevereAlertProcessing();
    final DistTXPrecommitMessage precommitMsg = new DistTXPrecommitMessage(
        this.getTxId(), this.onBehalfOfClientMember, processor);

    // send precommit message to remote nodes
    for (DistributedMember remoteNode : txRemoteParticpants) {
      DistTXCoordinatorInterface remoteTXStateStub = target2realDeals
          .get(remoteNode);
      if (remoteTXStateStub.isTxState()) {
        throw new UnsupportedOperationInTransactionException(
            LocalizedStrings.DISTTX_TX_EXPECTED.toLocalizedString(
                ""DistPeerTXStateStub"", remoteTXStateStub.getClass()
                    .getSimpleName()));
      }
      try {
        remoteTXStateStub.setPrecommitMessage(precommitMsg, dm);
        remoteTXStateStub.precommit();
      } finally {
        remoteTXStateStub.setPrecommitMessage(null, null);
      }
      if (logger.isDebugEnabled()) {
        logger.debug(""DistTXStateProxyImplOnCoordinator.doPrecommit Sent Message to target = ""
            + remoteNode);
      }
    }

    // Do precommit on local node
    TreeSet<String> sortedRegionName = new TreeSet<>();
    DistTXCoordinatorInterface localTXState = target2realDeals.get(dm.getId());
    if (localTXState != null) {
      if (!localTXState.isTxState()) {
        throw new UnsupportedOperationInTransactionException(
            LocalizedStrings.DISTTX_TX_EXPECTED.toLocalizedString(
                ""DistTXStateOnCoordinator"", localTXState.getClass()
                    .getSimpleName()));
      }
      localTXState.precommit();
      boolean localResult = localTXState.getPreCommitResponse();
      TreeMap<String, ArrayList<DistTxThinEntryState>> entryStateSortedMap = new TreeMap<String, ArrayList<DistTxThinEntryState>>();
      ArrayList<ArrayList<DistTxThinEntryState>> entryEventList = null;
      if (localResult) {
        localResult = ((DistTXStateOnCoordinator) localTXState)
            .populateDistTxEntryStateList(entryStateSortedMap);
        if (localResult) {
          entryEventList = new ArrayList<ArrayList<DistTxThinEntryState>>(
              entryStateSortedMap.values());
          populateEntryEventMap(dm.getId(), entryEventList, sortedRegionName);
        }
      }

      if (logger.isDebugEnabled()) {
        logger.debug(""DistTXStateProxyImplOnCoordinator.doPrecommit local = ""
            + dm.getId() + "" ,entryEventList=""
            + printEntryEventList(entryEventList) + "" ,txRegionVersionsMap=""
            + printEntryEventMap(this.txEntryEventMap) + "" ,result= ""
            + localResult + "" ,finalResult-old= "" + finalResult);
      }
      finalResult = finalResult && localResult;
    }

    /*
     * [DISTTX] TODO Any test hooks
     */
    // if (internalAfterIndividualSend != null) {
    // internalAfterIndividualSend.run();
    // }

    /*
     * [DISTTX] TODO see how to handle exception
     */

    /*
     * [DISTTX] TODO Any test hooks
     */
    // if (internalAfterIndividualCommitProcess != null) {
    // // Testing callback
    // internalAfterIndividualCommitProcess.run();
    // }

    { // Wait for results
      dm.getCancelCriterion().checkCancelInProgress(null);
      processor.waitForPrecommitCompletion();

      // [DISTTX} TODO Handle stats
      // dm.getStats().incCommitWaits();

      Map<DistributedMember, DistTxPrecommitResponse> remoteResults = processor
          .getCommitResponseMap();
      for (Entry<DistributedMember, DistTxPrecommitResponse> e : remoteResults
          .entrySet()) {
        DistributedMember target = e.getKey();
        DistTxPrecommitResponse remoteResponse = e.getValue();
        ArrayList<ArrayList<DistTxThinEntryState>> entryEventList = remoteResponse.getDistTxEntryEventList();
        populateEntryEventMap(target, entryEventList, sortedRegionName);
        if (logger.isDebugEnabled()) {
          logger
              .debug(""DistTXStateProxyImplOnCoordinator.doPrecommit got reply from target = ""
                  + target
                  + "" ,sortedRegions""
                  + sortedRegionName
                  + "" ,entryEventList=""
                  + printEntryEventList(entryEventList)
                  + "" ,txEntryEventMap=""
                  + printEntryEventMap(this.txEntryEventMap)
                  + "" ,result= ""
                  + remoteResponse.getCommitState()
                  + "" ,finalResult-old= ""
                  + finalResult);
        }
        finalResult = finalResult && remoteResponse.getCommitState();
      }
    }

    /*
     * [DISTTX] TODO Write similar method to take out exception
     * 
     * [DISTTX] TODO Handle Reliable regions
     */
    // if (this.hasReliableRegions) {
    // checkDistributionReliability(distMap, processor);
    // }

    if (logger.isDebugEnabled()) {
      logger
          .debug(""DistTXStateProxyImplOnCoordinator.doPrecommit finalResult= ""
              + finalResult);
    }
    return finalResult;
  }",True
"  private boolean doPrecommit() {
    boolean finalResult = true;
    final GemFireCacheImpl cache = GemFireCacheImpl
        .getExisting(""Applying Dist TX Precommit"");
    final DM dm = cache.getDistributionManager();

    // Create Tx Participants
    Set<DistributedMember> txParticpants = target2realDeals.keySet();
    Set<DistributedMember> txRemoteParticpants = getTxRemoteParticpants(dm);

    // Determine if the set of VMs for any of the Regions for this TX have
    // changed
    HashSet<LocalRegion> affectedRegions = new HashSet<LocalRegion>();
    for (DistTXCoordinatorInterface distTXStateStub : target2realDeals.values()) {
      affectedRegions.clear();
      distTXStateStub.gatherAffectedRegions(affectedRegions, true, false);
      for (LocalRegion lr : affectedRegions) {
        if (lr.getScope().isLocal()) {
          continue;
        }
        if (lr instanceof DistributedRegion) {
          DistributedRegion dr = (DistributedRegion) lr;
          CacheDistributionAdvisor adv = dr.getCacheDistributionAdvisor();
          Set newRegionMemberView = adv.adviseTX();

          if (!txParticpants.containsAll(newRegionMemberView)) {
            logger
                .warn(LocalizedMessage
                    .create(
                        LocalizedStrings.TXCommitMessage_NEW_MEMBERS_FOR_REGION_0_ORIG_LIST_1_NEW_LIST_2,
                        new Object[] { dr, txParticpants, newRegionMemberView }));
          }
        } else if (lr instanceof PartitionedRegion
            || lr instanceof BucketRegion) {
          final PartitionedRegion pr;
          if (lr instanceof BucketRegion) {
            pr = ((BucketRegion) lr).getPartitionedRegion();
          } else {
            pr = (PartitionedRegion) lr;
          }
          CacheDistributionAdvisor adv = pr.getCacheDistributionAdvisor();
          Set newRegionMemberView = adv.adviseTX();

          if (!txParticpants.containsAll(newRegionMemberView)) {
            logger
                .warn(LocalizedMessage
                    .create(
                        LocalizedStrings.TXCommitMessage_NEW_MEMBERS_FOR_REGION_0_ORIG_LIST_1_NEW_LIST_2,
                        new Object[] { pr, txParticpants, newRegionMemberView }));
          }
        }
      }
    }

    // create processor and precommit message
    DistTXPrecommitMessage.DistTxPrecommitReplyProcessor processor = new DistTXPrecommitMessage.DistTxPrecommitReplyProcessor(
        this.getTxId(), dm, txRemoteParticpants, target2realDeals);
    // TODO [DISTTX} whats ack threshold?
    processor.enableSevereAlertProcessing();
    final DistTXPrecommitMessage precommitMsg = new DistTXPrecommitMessage(
        this.getTxId(), this.onBehalfOfClientMember, processor);

    // send precommit message to remote nodes
    for (DistributedMember remoteNode : txRemoteParticpants) {
      DistTXCoordinatorInterface remoteTXStateStub = target2realDeals
          .get(remoteNode);
      if (remoteTXStateStub.isTxState()) {
        throw new UnsupportedOperationInTransactionException(
            LocalizedStrings.DISTTX_TX_EXPECTED.toLocalizedString(
                ""DistPeerTXStateStub"", remoteTXStateStub.getClass()
                    .getSimpleName()));
      }
      try {
        remoteTXStateStub.setPrecommitMessage(precommitMsg, dm);
        remoteTXStateStub.precommit();
      } finally {
        remoteTXStateStub.setPrecommitMessage(null, null);
      }
      if (logger.isDebugEnabled()) {
        logger.debug(""DistTXStateProxyImplOnCoordinator.doPrecommit Sent Message to target = ""
            + remoteNode);
      }
    }

    // Do precommit on local node
    TreeSet<String> sortedRegionName = new TreeSet<>();
    DistTXCoordinatorInterface localTXState = target2realDeals.get(dm.getId());
    if (localTXState != null) {
      if (!localTXState.isTxState()) {
        throw new UnsupportedOperationInTransactionException(
            LocalizedStrings.DISTTX_TX_EXPECTED.toLocalizedString(
                ""DistTXStateOnCoordinator"", localTXState.getClass()
                    .getSimpleName()));
      }
      localTXState.precommit();
      boolean localResult = localTXState.getPreCommitResponse();
      TreeMap<String, ArrayList<DistTxThinEntryState>> entryStateSortedMap = new TreeMap<String, ArrayList<DistTxThinEntryState>>();
      ArrayList<ArrayList<DistTxThinEntryState>> entryEventList = null;
      if (localResult) {
        localResult = ((DistTXStateOnCoordinator) localTXState)
            .populateDistTxEntryStateList(entryStateSortedMap);
        if (localResult) {
          entryEventList = new ArrayList<ArrayList<DistTxThinEntryState>>(
              entryStateSortedMap.values());
          populateEntryEventMap(dm.getId(), entryEventList, sortedRegionName);
        }
      }

      if (logger.isDebugEnabled()) {
        logger.debug(""DistTXStateProxyImplOnCoordinator.doPrecommit local = ""
            + dm.getId() + "" ,entryEventList=""
            + printEntryEventList(entryEventList) + "" ,txRegionVersionsMap=""
            + printEntryEventMap(this.txEntryEventMap) + "" ,result= ""
            + localResult + "" ,finalResult-old= "" + finalResult);
      }
      finalResult = finalResult && localResult;
    }

    /*
     * [DISTTX] TODO Any test hooks
     */
    // if (internalAfterIndividualSend != null) {
    // internalAfterIndividualSend.run();
    // }

    /*
     * [DISTTX] TODO see how to handle exception
     */

    /*
     * [DISTTX] TODO Any test hooks
     */
    // if (internalAfterIndividualCommitProcess != null) {
    // // Testing callback
    // internalAfterIndividualCommitProcess.run();
    // }

    { // Wait for results
      dm.getCancelCriterion().checkCancelInProgress(null);
      processor.waitForPrecommitCompletion();

      // [DISTTX} TODO Handle stats
      // dm.getStats().incCommitWaits();

      Map<DistributedMember, DistTxPrecommitResponse> remoteResults = processor
          .getCommitResponseMap();
      for (Entry<DistributedMember, DistTxPrecommitResponse> e : remoteResults
          .entrySet()) {
        DistributedMember target = e.getKey();
        DistTxPrecommitResponse remoteResponse = e.getValue();
        ArrayList<ArrayList<DistTxThinEntryState>> entryEventList = remoteResponse.getDistTxEntryEventList();
        populateEntryEventMap(target, entryEventList, sortedRegionName);
        if (logger.isDebugEnabled()) {
          logger
              .debug(""DistTXStateProxyImplOnCoordinator.doPrecommit got reply from target = ""
                  + target
                  + "" ,sortedRegions""
                  + sortedRegionName
                  + "" ,entryEventList=""
                  + printEntryEventList(entryEventList)
                  + "" ,txEntryEventMap=""
                  + printEntryEventMap(this.txEntryEventMap)
                  + "" ,result= ""
                  + remoteResponse.getCommitState()
                  + "" ,finalResult-old= ""
                  + finalResult);
        }
        finalResult = finalResult && remoteResponse.getCommitState();
      }
    }

    /*
     * [DISTTX] TODO Write similar method to take out exception
     * 
     * [DISTTX] TODO Handle Reliable regions
     */
    // if (this.hasReliableRegions) {
    // checkDistributionReliability(distMap, processor);
    // }

    if (logger.isDebugEnabled()) {
      logger
          .debug(""DistTXStateProxyImplOnCoordinator.doPrecommit finalResult= ""
              + finalResult);
    }
    return finalResult;
  }",False
"  String getShortClassName() {
    String cname = getClass().getName();
    return cname.substring(getClass().getPackage().getName().length()+1);
  }",True
"  protected String getShortClassName() {
    String cname = getClass().getName();
    return cname.substring(getClass().getPackage().getName().length()+1);
  }",False
"  protected RegionEntry basicPutEntry(final EntryEventImpl event,
                                            final long lastModified)
  throws TimeoutException, CacheWriterException {
    discoverJTA();
    TXStateInterface tx = getTXState();
    // Note we are doing a load or netsearch result so it seems like
    // we should set ifNew to true. The entry should not yet exist.
    // However since the non-tx code sets ifNew to false this code will also.
    final boolean ifNew = false;

    if (isTX()) {
      tx.txPutEntry(event, ifNew, false, false, null);
      return null;
    }
    else {
      RegionEntry oldEntry = this.entries.basicPut(event,
                                   lastModified,
                                   ifNew,
                                   false,  // ifOld
                                   null,   // expectedOldValue
                                   false,  // requireOldValue
                                   false); // overwriteDestroyed
      return oldEntry;
    }
  }",True
"  protected RegionEntry basicPutEntry(final EntryEventImpl event,
                                            final long lastModified)
  throws TimeoutException, CacheWriterException {
    discoverJTA();
    TXStateInterface tx = getTXState();
    // Note we are doing a load or netsearch result so it seems like
    // we should set ifNew to true. The entry should not yet exist.
    // However since the non-tx code sets ifNew to false this code will also.
    final boolean ifNew = false;

    if (isTX()) {
      tx.txPutEntry(event, ifNew, false, false, null);
      return null;
    }
    else {
      if (GemFireCacheImpl.internalBeforeNonTXBasicPut != null) {
        GemFireCacheImpl.internalBeforeNonTXBasicPut.run();
      }
      
      RegionEntry oldEntry = this.entries.basicPut(event,
                                   lastModified,
                                   ifNew,
                                   false,  // ifOld
                                   null,   // expectedOldValue
                                   false,  // requireOldValue
                                   false); // overwriteDestroyed
      return oldEntry;
    }
  }",False
"  public String toString()
  {
    StringBuffer buff = new StringBuffer();
    String className = getClass().getName();
//    className.substring(className.lastIndexOf('.', className.lastIndexOf('.') - 1) + 1);  // partition.<foo> more generic version 
    buff.append(className.substring(className.indexOf(PN_TOKEN) + PN_TOKEN.length())); // partition.<foo>
    buff.append(""(regionPath=""); // make sure this is the first one
    buff.append(this.regionPath);
    appendFields(buff);
    buff.append("")"");
    return buff.toString();
  }",True
"  public String toString()
  {
    StringBuffer buff = new StringBuffer();
    String className = getClass().getName();
//    className.substring(className.lastIndexOf('.', className.lastIndexOf('.') - 1) + 1);  // partition.<foo> more generic version 
    buff.append(className.substring(className.indexOf(PN_TOKEN) + PN_TOKEN.length())); // partition.<foo>
    buff.append(""(regionPath=""); // make sure this is the first one
    buff.append(this.regionPath);
    appendFields(buff);
    buff.append("" ,distTx="");
    buff.append(this.isTransactionDistributed);
    buff.append("")"");
    return buff.toString();
  }",False
"      public void processAdjunctOnly() {
        txApplyEntryOpAdjunctOnly(this);
      }",False
"  private void processCacheRuntimeException(CacheRuntimeException problem) {
    if (problem instanceof RegionDestroyedException) { // catch RegionDestroyedException
      addProcessingException(problem);
    } else if (problem instanceof CancelException) { // catch CacheClosedException
      addProcessingException(problem);
      throw problem;
    } else { // catch CacheRuntimeException
      addProcessingException(problem);      
      logger.error(LocalizedMessage.create(
          LocalizedStrings.TXCommitMessage_TRANSACTION_MESSAGE_0_FROM_SENDER_1_FAILED_PROCESSING_UNKNOWN_TRANSACTION_STATE_2,
          new Object[] { this, getSender(), problem}));
    }
  }",True
"  protected void processCacheRuntimeException(CacheRuntimeException problem) {
    if (problem instanceof RegionDestroyedException) { // catch RegionDestroyedException
      addProcessingException(problem);
    } else if (problem instanceof CancelException) { // catch CacheClosedException
      addProcessingException(problem);
      throw problem;
    } else { // catch CacheRuntimeException
      addProcessingException(problem);      
      logger.error(LocalizedMessage.create(
          LocalizedStrings.TXCommitMessage_TRANSACTION_MESSAGE_0_FROM_SENDER_1_FAILED_PROCESSING_UNKNOWN_TRANSACTION_STATE_2,
          new Object[] { this, getSender(), problem}));
    }
  }",False
"    protected void txApplyEntryOpAdjunctOnly(FarSideEntryOp entryOp)
    {
      if (this.r == null) {
        return;
      }
      EventID eventID = getEventId(entryOp);
      boolean isDuplicate = this.r.hasSeenEvent(eventID);
      boolean callbacksOnly = (this.r.getDataPolicy() == DataPolicy.PARTITION)
          || isDuplicate;
      if (this.r instanceof PartitionedRegion) {
        
        PartitionedRegion pr = (PartitionedRegion)r;
        BucketRegion br = pr.getBucketRegion(entryOp.key);
        Set bucketOwners = br.getBucketOwners();
        InternalDistributedMember thisMember = GemFireCacheImpl.getExisting().getDistributionManager().getId();
        if (bucketOwners.contains(thisMember)) {
          return;
        }
        
        /*
         * This happens when we don't have the bucket and are getting adjunct notification
         */
        EntryEventImpl eei = AbstractRegionMap.createCBEvent(this.r, entryOp.op, entryOp.key, entryOp.value, this.msg.txIdent, txEvent, getEventId(entryOp), entryOp.callbackArg,entryOp.filterRoutingInfo,this.msg.bridgeContext, null, entryOp.versionTag, entryOp.tailKey);
        try {
        if(entryOp.filterRoutingInfo!=null) {
          eei.setLocalFilterInfo(entryOp.filterRoutingInfo.getFilterInfo(this.r.getCache().getMyId()));
        }
        if (isDuplicate) {
          eei.setPossibleDuplicate(true);
        }
        if (logger.isDebugEnabled()) {
          logger.debug(""invoking transactional callbacks for {} key={} needsUnlock={} event={}"", entryOp.op, entryOp.key, this.needsUnlock, eei);
        }
        // we reach this spot because the event is either delivered to this member
        // as an ""adjunct"" message or because the bucket was being created when
        // the message was sent and already reflects the change caused by this event.
        // In the latter case we need to invoke listeners
        final boolean skipListeners = !isDuplicate;
        eei.invokeCallbacks(this.r, skipListeners, true);
        } finally {
          eei.release();
        }
        return;
      }
    }",False
"  void buildMessageForAdjunctReceivers(LocalRegion r, TXCommitMessage msg) {
    try {
      if (!r.getScope().isLocal() && !this.entryMods.isEmpty()) {
        
        msg.startRegion(r, entryMods.size());
        Iterator it = this.entryMods.entrySet().iterator();
        Set<InternalDistributedMember> newMemberSet = new HashSet<InternalDistributedMember>();
        
        while (it.hasNext()) {
          Map.Entry me = (Map.Entry)it.next();
          Object eKey = me.getKey();
          TXEntryState txes = (TXEntryState)me.getValue();
          txes.buildMessage(r, eKey, msg,this.otherMembers);
          if(txes.getFilterRoutingInfo()!=null) {
            newMemberSet.addAll(txes.getFilterRoutingInfo().getMembers());
          }
          if(txes.getAdjunctRecipients()!=null) {
            
            Set adjunctRecipients = txes.getAdjunctRecipients();
            newMemberSet.addAll(adjunctRecipients);  
          }
        }
        
        
        if (!newMemberSet.equals(this.otherMembers)) 
        { 
          // r.getCache().getLogger().info(""DEBUG: participants list has changed! bug 32999.""); 
          // Flag the message that the lock manager needs to be updated with the new member set
          msg.setUpdateLockMembers();
          this.otherMembers = newMemberSet;
        }
        
        msg.finishRegion(this.otherMembers);
      }
    }
    catch (RegionDestroyedException ex) {
      // region was destroyed out from under us; after conflict checking
      // passed. So act as if the region destroy happened right after the
      // commit. We act this way by doing nothing; including distribution
      // of this region's commit data.
    }
    catch (CancelException ex) {
      // cache was closed out from under us; after conflict checking
      // passed. So do nothing.
    }
  }",False
"  private void removeAllFromData(DataInput in, int removeAllSize)
      throws IOException, ClassNotFoundException {
    final RemoveAllEntryData[] removeAllData = new RemoveAllEntryData[removeAllSize];
    final Version version = InternalDataSerializer
        .getVersionForDataStreamOrNull(in);
    final ByteArrayDataInput bytesIn = new ByteArrayDataInput();
    for (int i = 0; i < removeAllSize; i++) {
      removeAllData[i] = new RemoveAllEntryData(in, this.eventID, i, version,
          bytesIn);
    }
  
    boolean hasTags = in.readBoolean();
    if (hasTags) {
      EntryVersionsList versionTags = EntryVersionsList.create(in);
      for (int i = 0; i < removeAllSize; i++) {
        removeAllData[i].versionTag = versionTags.get(i);
      }
    }
    
    EntryEventImpl e = EntryEventImpl.create(
        this.region, Operation.REMOVEALL_DESTROY,
        null, null, null, true, this.getDistributedMember(), true, true);
    this.removeAllOp = new DistributedRemoveAllOperation(e, removeAllSize, false /*[DISTTX] TODO*/);
    this.removeAllOp.setRemoveAllEntryData(removeAllData);
  }",True
"  private void removeAllFromData(DataInput in)
      throws IOException, ClassNotFoundException {
    int removeAllSize = DataSerializer.readInteger(in);
    final RemoveAllEntryData[] removeAllData = new RemoveAllEntryData[removeAllSize];
    final Version version = InternalDataSerializer
        .getVersionForDataStreamOrNull(in);
    final ByteArrayDataInput bytesIn = new ByteArrayDataInput();
    for (int i = 0; i < removeAllSize; i++) {
      removeAllData[i] = new RemoveAllEntryData(in, this.eventID, i, version,
          bytesIn);
    }
  
    boolean hasTags = in.readBoolean();
    if (hasTags) {
      EntryVersionsList versionTags = EntryVersionsList.create(in);
      for (int i = 0; i < removeAllSize; i++) {
        removeAllData[i].versionTag = versionTags.get(i);
      }
    }
    
    EntryEventImpl e = EntryEventImpl.create(
        this.region, Operation.REMOVEALL_DESTROY,
        null, null, null, true, this.getDistributedMember(), true, true);
    this.removeAllOp = new DistributedRemoveAllOperation(e, removeAllSize, false /*[DISTTX] TODO*/);
    this.removeAllOp.setRemoveAllEntryData(removeAllData);
  }",False
"  private void putAllFromData(DataInput in, int putAllSize)
      throws IOException, ClassNotFoundException {
    PutAllEntryData[] putAllEntries = new PutAllEntryData[putAllSize];
    if (putAllSize > 0) {
      final Version version = InternalDataSerializer
          .getVersionForDataStreamOrNull(in);
      final ByteArrayDataInput bytesIn = new ByteArrayDataInput();
      for (int i = 0; i < putAllSize; i++) {
        putAllEntries[i] = new PutAllEntryData(in, this.eventID, i, version,
            bytesIn);
      }

      boolean hasTags = in.readBoolean();
      if (hasTags) {
        EntryVersionsList versionTags = EntryVersionsList.create(in);
        for (int i = 0; i < putAllSize; i++) {
          putAllEntries[i].versionTag = versionTags.get(i);
        }
      }
    }
    
    EntryEventImpl e = EntryEventImpl.create(
        this.region, Operation.PUTALL_CREATE,
        null, null, null, true, this.getDistributedMember(), true, true);
    
    this.putAllOp = new DistributedPutAllOperation(e, putAllSize, false /*[DISTTX] TODO*/);
    this.putAllOp.setPutAllEntryData(putAllEntries);
  }",True
"  private void putAllFromData(DataInput in)
      throws IOException, ClassNotFoundException {
    int putAllSize = DataSerializer.readInteger(in);
    PutAllEntryData[] putAllEntries = new PutAllEntryData[putAllSize];
    if (putAllSize > 0) {
      final Version version = InternalDataSerializer
          .getVersionForDataStreamOrNull(in);
      final ByteArrayDataInput bytesIn = new ByteArrayDataInput();
      for (int i = 0; i < putAllSize; i++) {
        putAllEntries[i] = new PutAllEntryData(in, this.eventID, i, version,
            bytesIn);
      }

      boolean hasTags = in.readBoolean();
      if (hasTags) {
        EntryVersionsList versionTags = EntryVersionsList.create(in);
        for (int i = 0; i < putAllSize; i++) {
          putAllEntries[i].versionTag = versionTags.get(i);
        }
      }
    }
    
    EntryEventImpl e = EntryEventImpl.create(
        this.region, Operation.PUTALL_CREATE,
        null, null, null, true, this.getDistributedMember(), true, true);
    
    this.putAllOp = new DistributedPutAllOperation(e, putAllSize, false /*[DISTTX] TODO*/);
    this.putAllOp.setPutAllEntryData(putAllEntries);
  }",False
"  public String toString() {
    StringBuilder buf = new StringBuilder();
    if (this.putAllOp != null) {
      buf.append(""putAllDataSize :"" + this.putAllOp.putAllDataSize);
    }
    if (this.removeAllOp != null) {
      buf.append(""removeAllDataSize :"" + this.removeAllOp.removeAllDataSize);
    }
    return buf.toString(); 
  }",True
"  public String toString() {
    StringBuilder buf = new StringBuilder();
    buf.append(getShortClassName());
    buf.append(""["");
    buf.append(""eventID="");
    buf.append(this.eventID);
    if (this.region != null) {
      buf.append("";r="").append(this.region.getName());
    }
    buf.append("";op="");
    buf.append(getOperation());
    buf.append("";key="");
    buf.append(this.getKey());
    buf.append("";bucket="");
    buf.append(this.getKeyInfo().getBucketId());
    buf.append("";oldValue="");
    if (this.putAllOp != null) {
      buf.append("";putAllDataSize :"" + this.putAllOp.putAllDataSize);
    }
    if (this.removeAllOp != null) {
      buf.append("";removeAllDataSize :"" + this.removeAllOp.removeAllDataSize);
    }
    buf.append(""]"");
    return buf.toString();
  }",False
"  private void removeAllFromData(DataInput in)
      throws IOException, ClassNotFoundException {
    int removeAllSize = DataSerializer.readInteger(in);
    final RemoveAllEntryData[] removeAllData = new RemoveAllEntryData[removeAllSize];
    final Version version = InternalDataSerializer
        .getVersionForDataStreamOrNull(in);
    final ByteArrayDataInput bytesIn = new ByteArrayDataInput();
    for (int i = 0; i < removeAllSize; i++) {
      removeAllData[i] = new RemoveAllEntryData(in, this.eventID, i, version,
          bytesIn);
    }
  
    boolean hasTags = in.readBoolean();
    if (hasTags) {
      EntryVersionsList versionTags = EntryVersionsList.create(in);
      for (int i = 0; i < removeAllSize; i++) {
        removeAllData[i].versionTag = versionTags.get(i);
      }
    }
    
    EntryEventImpl e = EntryEventImpl.create(
        this.region, Operation.REMOVEALL_DESTROY,
        null, null, null, true, this.getDistributedMember(), true, true);
    this.removeAllOp = new DistributedRemoveAllOperation(e, removeAllSize, false /*[DISTTX] TODO*/);
    this.removeAllOp.setRemoveAllEntryData(removeAllData);",False
"  public void fromData(DataInput in) throws IOException, ClassNotFoundException {
    this.eventID = (EventID) DataSerializer.readObject(in);
    String regionName = DataSerializer.readString(in);
    GemFireCacheImpl cache = GemFireCacheImpl.getInstance();
    this.region = (LocalRegion) cache.getRegion(regionName);
    this.op = Operation.fromOrdinal(in.readByte());
    Object key = DataSerializer.readObject(in);
    Integer bucketId = DataSerializer.readInteger(in);
    this.keyInfo = new DistTxKeyInfo(key, null/*
                                             * value [DISTTX} TODO see if
                                             * required
                                             */, null/*
                                                      * callbackarg [DISTTX]
                                                      * TODO
                                                      */, bucketId);
    basicSetNewValue(DataSerializer.readObject(in));
    int putAllSize = DataSerializer.readInteger(in);
    if (putAllSize > 0) {
      putAllFromData(in, putAllSize);
    }
    int removeAllSize = DataSerializer.readInteger(in);
    if (removeAllSize > 0) {
      removeAllFromData(in, removeAllSize);
    }
  }",True
"  public void fromData(DataInput in) throws IOException, ClassNotFoundException {
    this.eventID = (EventID) DataSerializer.readObject(in);
    String regionName = DataSerializer.readString(in);
    GemFireCacheImpl cache = GemFireCacheImpl.getInstance();
    this.region = (LocalRegion) cache.getRegion(regionName);
    this.op = Operation.fromOrdinal(in.readByte());
    Object key = DataSerializer.readObject(in);
    Integer bucketId = DataSerializer.readInteger(in);
    this.keyInfo = new DistTxKeyInfo(key, null/*
                                             * value [DISTTX} TODO see if
                                             * required
                                             */, null/*
                                                      * callbackarg [DISTTX]
                                                      * TODO
                                                      */, bucketId);
    basicSetNewValue(DataSerializer.readObject(in));
    
    byte flags = DataSerializer.readByte(in);
    if ((flags & HAS_PUTALL_OP) != 0 ) {
      putAllFromData(in);
    }
    
    if ((flags & HAS_REMOVEALL_OP) != 0 ) {
      removeAllFromData(in);
    }
  }",False
"  private void putAllFromData(DataInput in)
      throws IOException, ClassNotFoundException {
    int putAllSize = DataSerializer.readInteger(in);
    PutAllEntryData[] putAllEntries = new PutAllEntryData[putAllSize];
    if (putAllSize > 0) {
      final Version version = InternalDataSerializer
          .getVersionForDataStreamOrNull(in);
      final ByteArrayDataInput bytesIn = new ByteArrayDataInput();
      for (int i = 0; i < putAllSize; i++) {
        putAllEntries[i] = new PutAllEntryData(in, this.eventID, i, version,
            bytesIn);
      }

      boolean hasTags = in.readBoolean();
      if (hasTags) {
        EntryVersionsList versionTags = EntryVersionsList.create(in);
        for (int i = 0; i < putAllSize; i++) {
          putAllEntries[i].versionTag = versionTags.get(i);
        }
      }
    }
    
    EntryEventImpl e = EntryEventImpl.create(
        this.region, Operation.PUTALL_CREATE,
        null, null, null, true, this.getDistributedMember(), true, true);
    
    this.putAllOp = new DistributedPutAllOperation(e, putAllSize, false /*[DISTTX] TODO*/);
    this.putAllOp.setPutAllEntryData(putAllEntries);",False
"  public void toData(DataOutput out) throws IOException {
    DataSerializer.writeObject(this.eventID, out);
    DataSerializer.writeObject(this.region.getFullPath(), out);
    out.writeByte(this.op.ordinal);
    DataSerializer.writeObject(this.getKey(), out);
    DataSerializer.writeInteger(this.keyInfo.getBucketId(), out);
    DataSerializer.writeObject(this.basicGetNewValue(), out);

    // handle putAll
    if (this.putAllOp != null) {
      putAllToData(out);
    } else {
      DataSerializer.writeInteger(0, out);
    }

    // handle removeAll
    if (this.removeAllOp != null) {
      removeAllToData(out);
    } else {
      DataSerializer.writeInteger(0, out);
    }
  }",True
"  public void toData(DataOutput out) throws IOException {
    DataSerializer.writeObject(this.eventID, out);
    DataSerializer.writeObject(this.region.getFullPath(), out);
    out.writeByte(this.op.ordinal);
    DataSerializer.writeObject(this.getKey(), out);
    DataSerializer.writeInteger(this.keyInfo.getBucketId(), out);
    DataSerializer.writeObject(this.basicGetNewValue(), out);

    byte flags = 0;
    if (this.putAllOp != null) {
      flags |= HAS_PUTALL_OP;
    }
    if (this.removeAllOp != null) {
      flags |= HAS_REMOVEALL_OP;
    }
    DataSerializer.writeByte(flags, out);
    
    // handle putAll
    if (this.putAllOp != null) {
      putAllToData(out);
    } 
    // handle removeAll
    if (this.removeAllOp != null) {
      removeAllToData(out);
    } 
  }",False
"  public void testCommitTxn() {
    // [DISTTX] TODO test overridden and added @Ignore as it fails
    // fix this 
  }",True
"  public void testCommitTxn() {
    // [DISTTX] TODO test overridden intentionally and left blank as it fails
    // fix this 
  }",False
"  public void testFarSideOrder() throws CacheException {
    //[DISTTX] TODO fix this test
  }",True
"  public void testFarSideOrder() throws CacheException {
    // [DISTTX] TODO test overridden intentionally and left blank as it fails
    // fix this 
  }",False
"  public void testInternalRegionNotExposed() {
    //[DISTTX] TODO fix this test
  }",True
"  public void testInternalRegionNotExposed() {
    // [DISTTX] TODO test overridden intentionally and left blank as it fails
    // fix this 
  }",False
"  public DistTXWithDeltaDUnitTest(String name) {
    super(name);
  }",False
"  public Properties getDistributedSystemProperties() {
    Properties props = super.getDistributedSystemProperties();
    props.setProperty(DistributionConfig.DISTRIBUTED_TRANSACTIONS_NAME, ""true"");
    // props.setProperty(DistributionConfig.LOG_LEVEL_NAME, ""fine"");
    return props;
  }",False
"    public TxOps_no_conflicts(String regionName) {
      this.regionName = regionName;
    }",False
"    public Object call() throws Exception {
      CacheTransactionManager mgr = getGemfireCache().getTxManager();
      mgr.setDistributed(true);
      mgr.begin();

      // Perform a put
      Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER_PR);
      
      CustId custIdOne = new CustId(1);
      Customer customerOne = new Customer(""name1"", ""addr1"");
      CustId custIdTwo = new CustId(2);
      Customer customerTwo = new Customer(""name2"", ""addr2"");
      CustId custIdThree = new CustId(3);
      Customer customerThree = new Customer(""name3"", ""addr3"");
      custRegion.put(custIdOne, customerOne);
      custRegion.put(custIdTwo, customerTwo);
      custRegion.put(custIdThree, customerThree);
      
      final class TxThread extends Thread {
        public boolean gotConflict = false;
        public void run() {
          CacheTransactionManager mgr = getGemfireCache().getTxManager();
          mgr.setDistributed(true);
          mgr.begin();
          CustId custIdOne = new CustId(1);
          Customer customerOne = new Customer(""name1"", ""addr1"");
          Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER_PR);
          
          // This should give a commit conflict/
          // [sjigyasu] Not sure at this point what the exception will be.
          // TODO: Check for the correct exception when the merge is over.
          try {
            custRegion.put(custIdOne, customerOne);
          } catch (Exception e) {
            // Assuming there is conflict exception.
            gotConflict = true;
            mgr.rollback();
          }
        }
      }
      
      TxThread txThread = new TxThread();
      txThread.start();
      txThread.join();
      assertTrue(txThread.gotConflict);
      return null;
    }",True
"    public Object call() throws Exception {
      CacheTransactionManager mgr = getGemfireCache().getTxManager();
      mgr.setDistributed(true);
      mgr.begin();

      // Perform a put
      Region<CustId, Customer> custRegion = getCache().getRegion(this.regionName);
      
      CustId custIdOne = new CustId(1);
      Customer customerOne = new Customer(""name1"", ""addr1"");
      CustId custIdTwo = new CustId(2);
      Customer customerTwo = new Customer(""name2"", ""addr2"");
      CustId custIdThree = new CustId(3);
      Customer customerThree = new Customer(""name3"", ""addr3"");
      custRegion.put(custIdOne, customerOne);
      custRegion.put(custIdTwo, customerTwo);
      custRegion.put(custIdThree, customerThree);
      
      // spawn a new thread modify and custIdOne in another tx
      // so that outer thread fails
      final class TxThread extends Thread {
        public void run() {
          CacheTransactionManager mgr = getGemfireCache().getTxManager();
          mgr.setDistributed(true);
          mgr.begin();
          CustId custIdOne = new CustId(1);
          Customer customerOne = new Customer(""name1"", ""addr11"");
          Region<CustId, Customer> custRegion = getCache().getRegion(regionName);
          custRegion.put(custIdOne, customerOne);
          mgr.commit();
        }
      }
      
      TxThread txThread = new TxThread(); 
      txThread.start();
      txThread.join(); //let the tx commit
      
      try {
        mgr.commit();
        fail(""this test should have failed with CommitConflictException"");
        // [DISTTX] TODO after conflict detection either  
        // CommitIncompleteException or CommitConflictException is thrown. 
        // Should it always be CommitConflictException?
      } catch (CommitIncompleteException cie) {
      } 
      catch (CommitConflictException ce) {
      }
      
      //verify data
      assertEquals(new Customer(""name1"", ""addr11""), custRegion.get(custIdOne));
      assertEquals(null, custRegion.get(custIdTwo));
      assertEquals(null, custRegion.get(custIdThree));
      
      //clearing the region
      custRegion.remove(custIdOne);
      return null;
    }",False
"  public void testCommitConflicts_PR_after_locks_acquired() throws Exception {
    Host host = Host.getHost(0);
    VM server1 = host.getVM(0);
    VM server2 = host.getVM(1);

//    createPRwithRedundanyCopies(new VM[] { server1, server2 }, 1);
    
    createPRwithRedundanyCopies(new VM[] { server1 }, 0);

    server1.invoke(new TxOps_conflicts_after_locks_acquired(CUSTOMER_PR));
  }",False
"  public Properties getDistributedSystemProperties() {
    Properties props = super.getDistributedSystemProperties();
    //props.put(""distributed-transactions"", ""true"");
    return props;
  }",True
"  public Properties getDistributedSystemProperties() {
    Properties props = super.getDistributedSystemProperties();
    //props.put(""distributed-transactions"", ""true"");
//    props.setProperty(DistributionConfig.LOG_LEVEL_NAME, ""fine"");
    return props;
  }",False
"public void testCommitNoConflicts_PR() throws Exception {
  Host host = Host.getHost(0);
  VM server1 = host.getVM(0);
  VM server2 = host.getVM(1);

  createPRwithRedundanyCopies(new VM[] { server1, server2 }, 1);

  server1.invoke(new TxOps_no_conflicts(CUSTOMER_PR));
}",False
"  public void createRRonAccessor(VM accessor) {
    accessor.invoke(new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        createRR(true);
        return null;
      }
    });
  }",False
"  public void testCommitConflicts_RR_after_locks_acquired() throws Exception {
    Host host = Host.getHost(0);
    VM server1 = host.getVM(0);
    VM server2 = host.getVM(1);

    createRR(new VM[] { server1, server2 });

    server1.invoke(new TxOps_conflicts_after_locks_acquired(CUSTOMER_RR));
  }",False
"    public Object call() throws Exception {
      CacheTransactionManager mgr = getGemfireCache().getTxManager();
      mgr.setDistributed(true);
      mgr.begin();
      
      //set up a callback to be invoked after locks are acquired at commit time
      ((TXStateProxyImpl)((TXManagerImpl)mgr).getTXState()).forceLocalBootstrap();
      TXStateInterface txp = ((TXManagerImpl)mgr).getTXState();
      DistTXState tx = (DistTXState)((TXStateProxyImpl)txp).getRealDeal(null, null);
      tx.setAfterReservation(new TxConflictRunnable(this.regionName)); //callback

      // Perform a put
      Region<CustId, Customer> custRegion = getCache().getRegion(this.regionName);
      
      CustId custIdOne = new CustId(1);
      Customer customerOne = new Customer(""name1"", ""addr1"");
      CustId custIdTwo = new CustId(2);
      Customer customerTwo = new Customer(""name2"", ""addr2"");
      CustId custIdThree = new CustId(3);
      Customer customerThree = new Customer(""name3"", ""addr3"");
      CustId custIdFour = new CustId(4);
      Customer customerFour = new Customer(""name4"", ""addr4"");
      custRegion.put(custIdOne, customerOne);
      custRegion.put(custIdTwo, customerTwo);
      custRegion.put(custIdThree, customerThree);
      custRegion.put(custIdFour, customerFour);
      
      // will invoke the callback that spawns a new thread and another
      // transaction
      mgr.commit(); 

      //verify data
      assertEquals(new Customer(""name1"", ""addr1""), custRegion.get(custIdOne));
      assertEquals(new Customer(""name2"", ""addr2""), custRegion.get(custIdTwo));
      assertEquals(new Customer(""name3"", ""addr3""), custRegion.get(custIdThree));
      assertEquals(new Customer(""name4"", ""addr4""), custRegion.get(custIdFour));

      return null;
    }",False
"    public Object call() throws Exception {
      CacheTransactionManager mgr = getGemfireCache().getTxManager();
      mgr.setDistributed(true);
      mgr.begin();
      
      //set up a callback to be invoked after locks are acquired at commit time
      ((TXStateProxyImpl)((TXManagerImpl)mgr).getTXState()).forceLocalBootstrap();
      TXStateInterface txp = ((TXManagerImpl)mgr).getTXState();
      DistTXState tx = (DistTXState)((TXStateProxyImpl)txp).getRealDeal(null, null);
      tx.setAfterReservation(new TxRunnable(this.regionName)); //callback

      // Perform a put
      Region<CustId, Customer> custRegion = getCache().getRegion(this.regionName);
      
      CustId custIdOne = new CustId(1);
      Customer customerOne = new Customer(""name1"", ""addr1"");
      CustId custIdTwo = new CustId(2);
      Customer customerTwo = new Customer(""name2"", ""addr2"");
      CustId custIdThree = new CustId(3);
      Customer customerThree = new Customer(""name3"", ""addr3"");
      CustId custIdFour = new CustId(4);
      Customer customerFour = new Customer(""name4"", ""addr4"");
      custRegion.put(custIdOne, customerOne);
      custRegion.put(custIdTwo, customerTwo);
      custRegion.put(custIdThree, customerThree);
      custRegion.put(custIdFour, customerFour);
      
      // will invoke the callback that spawns a new thread and another
      // transaction that does puts of 10 entries
      mgr.commit(); 

      //verify data
      assertEquals(14, custRegion.size());

      return null;
    }",False
"  public void DISABLED_testConcurrentTXAndNonTXOperations() throws Exception {
    Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    
    createPersistentPR(new VM[]{server1});

    execute(server1, new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        Region<CustId, Customer> prRegion = getCache().getRegion(
            PERSISTENT_CUSTOMER_PR);

        CustId custIdOne = new CustId(1);
        Customer customerOne = new Customer(""name1"", ""addr1"");
        prRegion.put(custIdOne, customerOne);
        
        BucketRegion br = ((PartitionedRegion) prRegion)
            .getBucketRegion(custIdOne);
        
        String primaryMember = br.getBucketAdvisor().getPrimary().toString();
        getGemfireCache().getLoggerI18n().fine(""TEST:PRIMARY:"" + primaryMember);
        
        String memberId = getGemfireCache().getDistributedSystem().getMemberId();
        getGemfireCache().getLoggerI18n().fine(""TEST:MEMBERID:""+memberId);
        
        return null;
      }
    });    
    
    createPersistentPR(new VM[]{server2});
    
    Boolean isPrimary = (Boolean)execute(server1, new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        Region<CustId, Customer> prRegion = getCache().getRegion(
            PERSISTENT_CUSTOMER_PR);
        CustId custIdOne = new CustId(1);
        BucketRegion br = ((PartitionedRegion) prRegion)
            .getBucketRegion(custIdOne);
        
        String primaryMember = br.getBucketAdvisor().getPrimary().toString();
        getGemfireCache().getLoggerI18n().fine(""TEST:PRIMARY:"" + primaryMember);
        
        String memberId = getGemfireCache().getDistributedSystem().getMemberId();
        getGemfireCache().getLoggerI18n().fine(""TEST:MEMBERID:""+memberId);

        return memberId.equals(primaryMember);
      }
    });
    
    final VM primary = isPrimary.booleanValue() ? server1 : server2;
    final VM secondary = !isPrimary.booleanValue() ? server1 : server2;
    
    System.out.println(""TEST:SERVER-1:VM-""+server1.getPid());
    System.out.println(""TEST:SERVER-2:VM-""+server2.getPid());
    System.out.println(""TEST:PRIMARY=VM-""+primary.getPid());
    System.out.println(""TEST:SECONDARY=VM-""+secondary.getPid());
    
    class WaitRelease implements Runnable {
      CountDownLatch cdl;
      String op;
      public WaitRelease(CountDownLatch cdl, String member) {
        this.cdl = cdl;
      }
      @Override
      public void run() {
        try {
          GemFireCacheImpl.getExisting().getLoggerI18n().fine(""TEST:TX WAITING - "" + op);
          cdl.await();  
          GemFireCacheImpl.getExisting().getLoggerI18n().fine(""TEST:TX END WAITING"");
        } catch (InterruptedException e) {
        }
      }
      public void release() {
        GemFireCacheImpl.getExisting().getLoggerI18n().fine(""TEST:TX COUNTDOWN - "" + op);
        cdl.countDown();
      }
    }

    // Install TX hook
    SerializableCallable txHook = new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        CountDownLatch cdl = new CountDownLatch(1);
        GemFireCacheImpl.internalBeforeApplyChanges = new WaitRelease(cdl, ""TX OP"");
        return null;
      }
    };
    
    execute(secondary, txHook);


    // Install non-TX hook
    SerializableCallable nontxHook = new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        CountDownLatch cdl = new CountDownLatch(1);
        GemFireCacheImpl.internalBeforeNonTXBasicPut = new WaitRelease(cdl, ""NON TX OP"");
        return null;
      }
    };
    
    // Install the wait-release hook on the secondary
    execute(secondary, nontxHook);

    
    // Start a tx operation on primary
        
    execute(primary, new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        // The reason this is run in a separate thread instead of controller thread
        // is that this is going to block because the secondary is going to wait.
        new Thread() {
          public void run() {
            CacheTransactionManager mgr = getGemfireCache().getTxManager();
            mgr.setDistributed(true);
            getGemfireCache().getLoggerI18n().fine(
                ""TEST:DISTTX="" + mgr.isDistributed());
            mgr.begin();
            Region<CustId, Customer> prRegion = getCache().getRegion(
                PERSISTENT_CUSTOMER_PR);

            CustId custIdOne = new CustId(1);
            Customer customerOne = new Customer(""name1_tx"", ""addr1"");
            getGemfireCache().getLoggerI18n().fine(""TEST:TX UPDATE"");
            prRegion.put(custIdOne, customerOne);
            getGemfireCache().getLoggerI18n().fine(""TEST:TX COMMIT"");
            mgr.commit();
          }
        }.start();
        return null;
      }
    });    
    
    // Let the TX op be applied on primary first
    Thread.currentThread().sleep(200);
    
    // Perform a non-tx op on the same key on primary
    execute(primary, new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        Region<CustId, Customer> prRegion = getCache().getRegion(PERSISTENT_CUSTOMER_PR);

        CustId custIdOne = new CustId(1);
        Customer customerOne = new Customer(""name1_nontx"", ""addr1"");
        getGemfireCache().getLoggerI18n().fine(""TEST:TX NONTXUPDATE"");
        prRegion.put(custIdOne, customerOne);
        return null;
      }
    });
   
    
    // Wait for a few milliseconds
    Thread.currentThread().sleep(200);
    
    // Release the waiting non-tx op first, on secondary 
    execute(secondary, new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        Runnable r = GemFireCacheImpl.internalBeforeNonTXBasicPut;
        assert(r != null && r instanceof WaitRelease);
        WaitRelease e = (WaitRelease)r;
        e.release();
        return null;
      }
    });
    
    // Now release the waiting commit on secondary
    execute(secondary, new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        Runnable r = GemFireCacheImpl.internalBeforeApplyChanges;
        assert(r != null && r instanceof WaitRelease);
        WaitRelease e = (WaitRelease)r;
        e.release();
        return null;
      }
    });
    
    // Verify region and entry versions on primary and secondary
    SerializableCallable verifyPrimary = new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        Region<CustId, Customer> prRegion = getCache().getRegion(PERSISTENT_CUSTOMER_PR);
        
        CustId custId = new CustId(1);
        Customer customer = prRegion.get(custId);
        
        BucketRegion br = ((PartitionedRegion)prRegion).getBucketRegion(custId);
        RegionEntry re = br.getRegionEntry(custId);
        
        getGemfireCache().getLoggerI18n().fine(""TEST:TX PRIMARY CUSTOMER=""+customer);
        
        getGemfireCache().getLoggerI18n().fine(""TEST:TX PRIMARY REGION VERSION=""+re.getVersionStamp().getRegionVersion());
        getGemfireCache().getLoggerI18n().fine(""TEST:TX PRIMARY ENTRY VERSION=""+re.getVersionStamp().getEntryVersion());
        return null;
      }
    };
    execute(primary, verifyPrimary);
    SerializableCallable verifySecondary = new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        Region<CustId, Customer> prRegion = getCache().getRegion(PERSISTENT_CUSTOMER_PR);
        
        CustId custId = new CustId(1);
        Customer customer = prRegion.get(custId);
        
        BucketRegion br = ((PartitionedRegion)prRegion).getBucketRegion(custId);
        RegionEntry re = br.getRegionEntry(custId);
        
        getGemfireCache().getLoggerI18n().fine(""TEST:TX SECONDARY CUSTOMER=""+customer);
        
        getGemfireCache().getLoggerI18n().fine(""TEST:TX SECONDARY REGION VERSION=""+re.getVersionStamp().getRegionVersion());
        getGemfireCache().getLoggerI18n().fine(""TEST:TX SECONDARY ENTRY VERSION=""+re.getVersionStamp().getEntryVersion());
        return null;
      }
    };
    
    execute(secondary, verifySecondary);
  }",False
"    public void run() {
      final class TxThread extends Thread {
        public boolean gotException = false;
        public Exception ex = new Exception();

        public void run() {
          getLogWriter()
              .info(""Inside TxRunnable.TxThread after aquiring locks"");
          CacheTransactionManager mgr = getGemfireCache().getTxManager();
          mgr.setDistributed(true);
          mgr.begin();
          Region<CustId, Customer> custRegion = getCache()
              .getRegion(regionName);
          for (int i=11; i<=20; i++) {
            custRegion.put(new CustId(i), new Customer(""name"" + i, ""addr"" + i));
          }
          try {
            mgr.commit();
          } catch (Exception e) {
            gotException = true;
            getLogWriter().info(""Received exception "", e);
            ex.initCause(e);
          }
        }
      }

      TxThread txThread = new TxThread();
      txThread.start();
      try {
        txThread.join(); // let the tx commit
      } catch (InterruptedException e) {
        // TODO Auto-generated catch block
        e.printStackTrace();
      }
      if (txThread.gotException) {
        fail(""Received exception "", txThread.ex);
      }
    }",False
"  public void testRemoveAllWithTransactions() throws Exception {
    Host host = Host.getHost(0);
    VM server1 = host.getVM(0); 
    VM server2 = host.getVM(1); 
    VM server3 = host.getVM(2);
    
    createRegions(new VM[]{server1, server2, server3});
    
    execute(server1, new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        Region custRegion = getCache().getRegion(CUSTOMER_PR);
        Region orderRegion = getCache().getRegion(ORDER_PR);
        
        Map custMap = new HashMap();
        Map orderMap = new HashMap();
        for (int i = 0; i < 15; i++) {
          CustId custId = new CustId(i);
          Customer customer = new Customer(""customer"" + i, ""address"" + i);
          OrderId orderId = new OrderId(i, custId);
          Order order = new Order(""order"" + i);
          custMap.put(custId, customer);
          orderMap.put(orderId, order);
        }
  
        CacheTransactionManager mgr = getGemfireCache().getTxManager();
        mgr.setDistributed(true);
        mgr.begin();
        custRegion.putAll(custMap);
        orderRegion.putAll(orderMap);
        mgr.commit();
        
        mgr.begin(); 
        assertEquals(15, custRegion.size());
        assertEquals(15, orderRegion.size());
  
        custMap = new HashMap();
        orderMap = new HashMap();
        for (int i = 5; i < 10; i++) {
          CustId custId = new CustId(i);
          Customer customer = new Customer(""customer"" + i, ""address"" + i);
          OrderId orderId = new OrderId(i, custId);
          Order order = new Order(""order"" + i);
          custMap.put(custId, customer);
          orderMap.put(orderId, order);
        }
        custRegion.removeAll(custMap.keySet());
        orderRegion.removeAll(orderMap.keySet());
        mgr.rollback();
  
        mgr.begin();        
        assertEquals(15, custRegion.size());
        assertEquals(15, orderRegion.size());
  
        custRegion.removeAll(custMap.keySet());
        orderRegion.removeAll(orderMap.keySet());
  
        assertEquals(10, custRegion.size());
        assertEquals(10, orderRegion.size());
        mgr.commit();
        
        assertEquals(10, custRegion.size());
        assertEquals(10, orderRegion.size());
        
        return null;
      }
    });
  }",False
"  public void setUp() throws Exception{
    super.setUp();
    this.invokeInEveryVM(new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        System.setProperty(""gemfire.sync-commits"", ""true"");
        return null;
      }
    });
    
    this.invokeInEveryVM(new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        //System.setProperty(""gemfire.log-level"", ""fine"");
        return null;
      }
    }); 

    this.invokeInEveryVM(new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        //System.setProperty(""gemfire.ALLOW_PERSISTENT_TRANSACTIONS"", ""true"");
        TXManagerImpl.ALLOW_PERSISTENT_TRANSACTIONS = true;
        return null;
      }
    }); 
  }",True
"  public void setUp() throws Exception{
    super.setUp();
    this.invokeInEveryVM(new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        System.setProperty(""gemfire.sync-commits"", ""true"");
        return null;
      }
    });
    
    this.invokeInEveryVM(new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        System.setProperty(""gemfire.log-level"", ""fine"");
        return null;
      }
    }); 

    this.invokeInEveryVM(new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        //System.setProperty(""gemfire.ALLOW_PERSISTENT_TRANSACTIONS"", ""true"");
        TXManagerImpl.ALLOW_PERSISTENT_TRANSACTIONS = true;
        return null;
      }
    }); 
  }",False
"  public void execute(VM vm, SerializableCallable c) {
    vm.invoke(c);
  }",True
"  public Object execute(VM vm, SerializableCallable c) {
    return vm.invoke(c);
  }",False
"  void createRR() {
    AttributesFactory af = new AttributesFactory();
    af.setScope(Scope.DISTRIBUTED_ACK);
    af.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);
    af.setConcurrencyChecksEnabled(getConcurrencyChecksEnabled());
    getCache().createRegion(CUSTOMER_RR, af.create());
  }",True
"  void createRR(boolean isEmpty) {
    AttributesFactory af = new AttributesFactory();
    af.setScope(Scope.DISTRIBUTED_ACK);
    if (!isEmpty) {
      af.setDataPolicy(DataPolicy.PERSISTENT_REPLICATE);
    } else {
      af.setDataPolicy(DataPolicy.EMPTY); //for accessor
    }
    af.setConcurrencyChecksEnabled(getConcurrencyChecksEnabled());
    getCache().createRegion(CUSTOMER_RR, af.create());
  }",False
"    public TxRunnable(String regionName) {
      this.regionName = regionName;
    }",False
"
  protected boolean getConcurrencyChecksEnabled() {
    return true;
  }

  void createRR(boolean isEmpty) {
    AttributesFactory af = new AttributesFactory();",False
"  public void DISABLED_testPutAllWithTransactions() throws Exception {
    Host host = Host.getHost(0);
    VM server1 = host.getVM(0); 
    VM server2 = host.getVM(1); 
    VM server3 = host.getVM(2);
    
    createRegions(new VM[]{server1, server2, server3});

    execute(new VM[]{server1, server2, server3}, new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        AttributesFactory af = new AttributesFactory();
        af.setConcurrencyChecksEnabled(getConcurrencyChecksEnabled());
        af.setPartitionAttributes(new PartitionAttributesFactory<CustId, Customer>()
            .setTotalNumBuckets(4).setLocalMaxMemory(1)
            .setPartitionResolver(new CustomerIDPartitionResolver(""resolver1""))
            .setRedundantCopies(0).create());
        getCache().createRegion(""NONCOLOCATED_PR"", af.create());
        return null;
      }
    });
    
    execute(server1, new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        Region custRegion = getCache().getRegion(CUSTOMER_PR);
        Region orderRegion = getCache().getRegion(ORDER_PR);
        
        Map custMap = new HashMap();
        Map orderMap = new HashMap();
        for (int i = 0; i < 5; i++) {
          CustId custId = new CustId(i);
          Customer customer = new Customer(""customer"" + i, ""address"" + i);
          OrderId orderId = new OrderId(i, custId);
          Order order = new Order(""order"" + i);
          custMap.put(custId, customer);
          orderMap.put(orderId, order);
        }

        CacheTransactionManager mgr = getGemfireCache().getTxManager();
        mgr.setDistributed(true);
        mgr.begin();
        custRegion.putAll(custMap);
        orderRegion.putAll(orderMap);
        mgr.commit();
        
        mgr.begin(); 
        assertEquals(5, custRegion.size());
        assertEquals(5, orderRegion.size());

        custMap = new HashMap();
        orderMap = new HashMap();
        for (int i = 5; i < 10; i++) {
          CustId custId = new CustId(i);
          Customer customer = new Customer(""customer"" + i, ""address"" + i);
          OrderId orderId = new OrderId(i, custId);
          Order order = new Order(""order"" + i);
          custMap.put(custId, customer);
          orderMap.put(orderId, order);
        }
        custRegion.putAll(custMap);
        orderRegion.putAll(orderMap);
        mgr.rollback();

        mgr.begin();        
        assertEquals(5, custRegion.size());
        assertEquals(5, orderRegion.size());

        custRegion.putAll(custMap);
        orderRegion.putAll(orderMap);

        assertEquals(10, custRegion.size());
        assertEquals(10, orderRegion.size());

        // Verify operations involving non colocated PR
        Map map = new HashMap();
        custMap.clear();
        for (int i = 10; i < 15; i++) {
          CustId custId = new CustId(i);
          Customer customer = new Customer(""customer"" + i, ""address"" + i);
          OrderId orderId = new OrderId(i, custId);
          Order order = new Order(""order"" + i);
          custMap.put(custId, customer);
          map.put(custId, customer);
        }
        custRegion.putAll(custMap);
        Region nonColocatedRegion = getCache().getRegion(""NONCOLOCATED_PR"");
        nonColocatedRegion.putAll(orderMap);


        mgr.commit();
        mgr.begin();
        assertEquals(15, custRegion.size());
        assertEquals(5, nonColocatedRegion.size());
        
        custMap.clear();
        map.clear();
        for (int i = 15; i < 20; i++) {
          CustId custId = new CustId(i);
          Customer customer = new Customer(""customer"" + i, ""address"" + i);
          OrderId orderId = new OrderId(i, custId);
          Order order = new Order(""order"" + i);
          custMap.put(custId, customer);
          map.put(custId, customer);
        }
        custRegion.putAll(custMap);
        nonColocatedRegion.putAll(orderMap);
         
        mgr.rollback();
        assertEquals(15, custRegion.size());
        assertEquals(5, nonColocatedRegion.size());
        
        return null;
      }
    });
  }",True
"        af.setConcurrencyChecksEnabled(getConcurrencyChecksEnabled());
        af.setPartitionAttributes(new PartitionAttributesFactory<CustId, Customer>()
            .setTotalNumBuckets(4).setLocalMaxMemory(1)
            .setPartitionResolver(new CustomerIDPartitionResolver(""resolver1""))
            .setRedundantCopies(0).create());
        getCache().createRegion(""NONCOLOCATED_PR"", af.create());
        return null;
      }
    });
    
    execute(server1, new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        Region custRegion = getCache().getRegion(CUSTOMER_PR);
        Region orderRegion = getCache().getRegion(ORDER_PR);
        
        Map custMap = new HashMap();
        Map orderMap = new HashMap();
        for (int i = 0; i < 5; i++) {
          CustId custId = new CustId(i);
          Customer customer = new Customer(""customer"" + i, ""address"" + i);
          OrderId orderId = new OrderId(i, custId);
          Order order = new Order(""order"" + i);
          custMap.put(custId, customer);
          orderMap.put(orderId, order);
        }

        CacheTransactionManager mgr = getGemfireCache().getTxManager();
        mgr.setDistributed(true);
        mgr.begin();
        custRegion.putAll(custMap);
        orderRegion.putAll(orderMap);
        mgr.commit();
        
        mgr.begin(); 
        assertEquals(5, custRegion.size());
        assertEquals(5, orderRegion.size());

        custMap = new HashMap();
        orderMap = new HashMap();
        for (int i = 5; i < 10; i++) {
          CustId custId = new CustId(i);
          Customer customer = new Customer(""customer"" + i, ""address"" + i);
          OrderId orderId = new OrderId(i, custId);
          Order order = new Order(""order"" + i);
          custMap.put(custId, customer);
          orderMap.put(orderId, order);
        }
        custRegion.putAll(custMap);
        orderRegion.putAll(orderMap);
        mgr.rollback();

        mgr.begin();        
        assertEquals(5, custRegion.size());
        assertEquals(5, orderRegion.size());

        custRegion.putAll(custMap);
        orderRegion.putAll(orderMap);

        assertEquals(10, custRegion.size());
        assertEquals(10, orderRegion.size());

        // Verify operations involving non colocated PR
        Map map = new HashMap();
        custMap.clear();
        for (int i = 10; i < 15; i++) {
          CustId custId = new CustId(i);
          Customer customer = new Customer(""customer"" + i, ""address"" + i);
          OrderId orderId = new OrderId(i, custId);
          Order order = new Order(""order"" + i);
          custMap.put(custId, customer);
          map.put(custId, customer);
        }
        custRegion.putAll(custMap);
        Region nonColocatedRegion = getCache().getRegion(""NONCOLOCATED_PR"");
        nonColocatedRegion.putAll(orderMap);


        mgr.commit();
        mgr.begin();
        assertEquals(15, custRegion.size());
        assertEquals(5, nonColocatedRegion.size());
        
        custMap.clear();
        map.clear();
        for (int i = 15; i < 20; i++) {
          CustId custId = new CustId(i);
          Customer customer = new Customer(""customer"" + i, ""address"" + i);
          OrderId orderId = new OrderId(i, custId);
          Order order = new Order(""order"" + i);
          custMap.put(custId, customer);
          map.put(custId, customer);
        }
        custRegion.putAll(custMap);
        nonColocatedRegion.putAll(orderMap);
         
        mgr.rollback();
        assertEquals(15, custRegion.size());
        assertEquals(5, nonColocatedRegion.size());
        
        return null;
      }
    });
  }
  
  public void testRemoveAllWithTransactions() throws Exception {
    Host host = Host.getHost(0);
    VM server1 = host.getVM(0); 
    VM server2 = host.getVM(1); 
    VM server3 = host.getVM(2);
    
    createRegions(new VM[]{server1, server2, server3});
    
    execute(server1, new SerializableCallable() {
      @Override
      public Object call() throws Exception {",False
"    public TxOps_Conflicts(String regionName) {
      this.regionName = regionName;
    }",False
"    public TxOps_conflicts_after_locks_acquired(String regionName) {
      this.regionName = regionName;
    }",False
"  public void createPRonAccessor(VM accessor, final int redundency) {
    accessor.invoke(new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        createPR(true, redundency, null);
        return null;
      }
    });
  }",False
"  public void testCommitConflicts_PR() throws Exception {
    Host host = Host.getHost(0);
    VM server1 = host.getVM(0);
    VM server2 = host.getVM(1);
    VM server3 = host.getVM(2);
    VM accessor = host.getVM(3);

    createPRwithRedundanyCopies(new VM[] { server1, server2, server3 }, 1);
    createPRonAccessor(accessor, 1);
    
    server1.invoke(new TxOps_Conflicts(CUSTOMER_PR));
    
    //test thru accessor as well
    accessor.invoke(new TxOps_Conflicts(CUSTOMER_PR));
  }",False
"  public void createRR(VM[] vms) {
    for (VM vm : vms) {
      vm.invoke(new SerializableCallable() {
        @Override
        public Object call() throws Exception {
          createRR(false);
          return null;
        }
      });
    }
  }",False
"  public void testPutAllWithTransactions() throws Exception {
    Host host = Host.getHost(0);
    VM server1 = host.getVM(0); 
    VM server2 = host.getVM(1); 
    VM server3 = host.getVM(2);
    
    createRegions(new VM[]{server1, server2, server3});

    execute(new VM[]{server1, server2, server3}, new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        AttributesFactory af = new AttributesFactory();
        af.setConcurrencyChecksEnabled(getConcurrencyChecksEnabled());
        af.setPartitionAttributes(new PartitionAttributesFactory<CustId, Customer>()
            .setTotalNumBuckets(4).setLocalMaxMemory(1)
            .setPartitionResolver(new CustomerIDPartitionResolver(""resolver1""))
            .setRedundantCopies(0).create());
        getCache().createRegion(""NONCOLOCATED_PR"", af.create());
        return null;
      }
    });
    
    execute(server1, new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        Region custRegion = getCache().getRegion(CUSTOMER_PR);
        Region orderRegion = getCache().getRegion(ORDER_PR);
        
        Map custMap = new HashMap();
        Map orderMap = new HashMap();
        for (int i = 0; i < 5; i++) {
          CustId custId = new CustId(i);
          Customer customer = new Customer(""customer"" + i, ""address"" + i);
          OrderId orderId = new OrderId(i, custId);
          Order order = new Order(""order"" + i);
          custMap.put(custId, customer);
          orderMap.put(orderId, order);
        }

        CacheTransactionManager mgr = getGemfireCache().getTxManager();
        mgr.setDistributed(true);
        mgr.begin();
        custRegion.putAll(custMap);
        orderRegion.putAll(orderMap);
        mgr.commit();
        
        mgr.begin(); 
        assertEquals(5, custRegion.size());
        assertEquals(5, orderRegion.size());

        custMap = new HashMap();
        orderMap = new HashMap();
        for (int i = 5; i < 10; i++) {
          CustId custId = new CustId(i);
          Customer customer = new Customer(""customer"" + i, ""address"" + i);
          OrderId orderId = new OrderId(i, custId);
          Order order = new Order(""order"" + i);
          custMap.put(custId, customer);
          orderMap.put(orderId, order);
        }
        custRegion.putAll(custMap);
        orderRegion.putAll(orderMap);
        mgr.rollback();

        mgr.begin();        
        assertEquals(5, custRegion.size());
        assertEquals(5, orderRegion.size());

        custRegion.putAll(custMap);
        orderRegion.putAll(orderMap);

        assertEquals(10, custRegion.size());
        assertEquals(10, orderRegion.size());

        // Verify operations involving non colocated PR
        Map map = new HashMap();
        custMap.clear();
        for (int i = 10; i < 15; i++) {
          CustId custId = new CustId(i);
          Customer customer = new Customer(""customer"" + i, ""address"" + i);
          OrderId orderId = new OrderId(i, custId);
          Order order = new Order(""order"" + i);
          custMap.put(custId, customer);
          map.put(custId, customer);
        }
        custRegion.putAll(custMap);
        Region nonColocatedRegion = getCache().getRegion(""NONCOLOCATED_PR"");
        nonColocatedRegion.putAll(orderMap);


        mgr.commit();
        mgr.begin();
        assertEquals(15, custRegion.size());
        assertEquals(5, nonColocatedRegion.size());
        
        custMap.clear();
        map.clear();
        for (int i = 15; i < 20; i++) {
          CustId custId = new CustId(i);
          Customer customer = new Customer(""customer"" + i, ""address"" + i);
          OrderId orderId = new OrderId(i, custId);
          Order order = new Order(""order"" + i);
          custMap.put(custId, customer);
          map.put(custId, customer);
        }
        custRegion.putAll(custMap);
        nonColocatedRegion.putAll(orderMap);
         
        mgr.rollback();
        assertEquals(15, custRegion.size());
        assertEquals(5, nonColocatedRegion.size());
        
        return null;
      }
    });
  }",False
"public void testCommitNoConflicts_RR() throws Exception {
  Host host = Host.getHost(0);
  VM server1 = host.getVM(0);
  VM server2 = host.getVM(1);

  createRR(new VM[] { server1, server2 });

  server1.invoke(new TxOps_no_conflicts(CUSTOMER_RR));
}",False
"    public void run() {
      // spawn a new thread modify and custIdOne in another tx
      // so that outer thread fails
      final class TxThread extends Thread {
        public boolean gotConflict = false;
        public boolean gotOtherException = false;
        public Exception ex = new Exception();
        
        public void run() {
          getLogWriter().info(""Inside TxConflictRunnable.TxThread after aquiring locks"");
          CacheTransactionManager mgr = getGemfireCache().getTxManager();
          mgr.setDistributed(true);
          mgr.begin();
          CustId custIdOne = new CustId(1);
          Customer customerOne = new Customer(""name1"", ""addr11"");
          Region<CustId, Customer> custRegion = getCache()
              .getRegion(regionName);
          custRegion.put(custIdOne, customerOne);
          try {
            mgr.commit();
          } catch (CommitConflictException ce) {
            gotConflict = true;
            getLogWriter().info(""Received exception "", ce);
          } catch (Exception e) {
            gotOtherException = true;
            getLogWriter().info(""Received exception "", e);
            ex.initCause(e);
          }
        }
      }

      TxThread txThread = new TxThread();
      txThread.start();
      try {
        txThread.join(); // let the tx commit
      } catch (InterruptedException e) {
        // TODO Auto-generated catch block
        e.printStackTrace();
      } 
      
      assertTrue(""This test should fail with CommitConflictException"",
          txThread.gotConflict);
      if (txThread.gotOtherException) {
        fail(""Received unexpected exception "", txThread.ex);
      }
    }",False
"  public void createPRwithRedundanyCopies(VM[] vms, final int redundency) {
    for (VM vm : vms) {
      vm.invoke(new SerializableCallable() {
        @Override
        public Object call() throws Exception {
          createPR(false, redundency, null);
          return null;
        }
      });
    }
  }",False
"  public void testCommitConflicts_RR() throws Exception {
    Host host = Host.getHost(0);
    VM server1 = host.getVM(0);
    VM server2 = host.getVM(1);
    VM server3 = host.getVM(2);
    VM accessor = host.getVM(3);

    createRR(new VM[] { server1, server2, server3 });
    createRRonAccessor(accessor);
    
    server1.invoke(new TxOps_Conflicts(CUSTOMER_RR));
    
    //test thru accessor as well
    accessor.invoke(new TxOps_Conflicts(CUSTOMER_RR));
  }",False
"    public TxConflictRunnable(String regionName) {
      this.regionName = regionName;
    }",False
"  public Properties getDistributedSystemProperties() {
    Properties props = super.getDistributedSystemProperties();
    props.setProperty(DistributionConfig.DISTRIBUTED_TRANSACTIONS_NAME, ""true"");
//    props.setProperty(DistributionConfig.LOG_LEVEL_NAME, ""fine"");
    return props;
  }",False
"  public void testBasicPRTransactionRedundancy0() {
  }",False
"  public PRDistTXDUnitTest(String name) {
    super(name);
  }",False
"  public void testBasicPRTransactionNoDataRedundancy2() {
  }",False
"  public void testBasicPRTransactionRedundancy1() {
  }",False
"  public void testBasicPRTransactionNoDataRedundancy0() {
  }",False
"  public void testBasicPRTransactionRedundancy2() {
  }",False
"  public void testBasicPRTransactionNoDataRedundancy1() {
  }",False
"  public PRDistTXWithVersionsDUnitTest(String name) {
    super(name);
  }",False
"  public void testServerGetAllFunction(){
    createScenario();
    client.invoke(SingleHopGetAllPutAllDUnitTest.class,
        ""getAll"");
  }  ",False
"  public static void getAll() {
    Region region = cache.getRegion(PartitionedRegionName);
    assertNotNull(region);
    final List testKeysList = new ArrayList();
    for (int i = (totalNumBuckets.intValue() * 3); i > 0; i--) {
      testKeysList.add(""execKey-"" + i);
    }
    DistributedSystem.setThreadsSocketPolicy(false);
    try {
      int j = 0;
      Map origVals = new HashMap();
      for (Iterator i = testKeysList.iterator(); i.hasNext();) {
        Integer val = new Integer(j++);
        Object key = i.next();
        origVals.put(key, val);
        region.put(key, val);
      }

      // check if the client meta-data is in synch
      verifyMetadata();
      
      // check if the function was routed to pruned nodes
      Map resultMap = region.getAll(testKeysList);
      assertTrue(resultMap.equals(origVals));
      pause(2000);
      Map secondResultMap = region.getAll(testKeysList);
      assertTrue(secondResultMap.equals(origVals));
    }
    catch (Exception e) {
      fail(""Test failed after the getAll operation"", e);
    }
  }",True
"  public static void getAll() {
    Region region = cache.getRegion(PartitionedRegionName);
    assertNotNull(region);
    final List testValueList = new ArrayList();
    final List testKeyList = new ArrayList();
    for (int i = (totalNumBuckets.intValue() * 3); i > 0; i--) {
      testValueList.add(""execKey-"" + i);    
    }
    DistributedSystem.setThreadsSocketPolicy(false);
    try {
      int j = 0;
      Map origVals = new HashMap();
      for (Iterator i = testValueList.iterator(); i.hasNext();) {
        testKeyList.add(j);
        Integer key = new Integer(j++);
        Object val = i.next();
        origVals.put(key, val);
        region.put(key, val);
      }

      // check if the client meta-data is in synch
      verifyMetadata();
      
      // check if the function was routed to pruned nodes
      Map resultMap = region.getAll(testKeyList);
      assertTrue(resultMap.equals(origVals));
      pause(2000);
      Map secondResultMap = region.getAll(testKeyList);
      assertTrue(secondResultMap.equals(origVals));
    }
    catch (Exception e) {
      fail(""Test failed after the getAll operation"", e);
    }
  }",False
"  public void DISABLED_testServerGetAllFunction(){
    createScenario();
    client.invoke(SingleHopGetAllPutAllDUnitTest.class,
        ""getAll"");
  }  ",True
"  private void doClientServerTest(final String regionName, boolean createPR)
      throws Exception {
    //create region on the server
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);

    final int port = AvailablePortHelper.getRandomAvailableTCPPort();
    final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
    startCacheServer(server, port, mcastPort, 0f, 90f,
        regionName, createPR, false, 0);
    startClient(client, server, port, regionName);
    doPuts(client, regionName, false/*catchServerException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(client, regionName, false/*catchServerException*/,
        false/*catchLowMemoryException*/, Range.DEFAULT);

    //make the region sick in the server
    server.invoke(new SerializableRunnable() {
      public void run() {
        InternalResourceManager irm = ((GemFireCacheImpl)getCache()).getResourceManager();
        final OffHeapMemoryMonitor ohm = irm.getOffHeapMonitor();
        assertTrue(ohm.getState().isNormal());
        getCache().getLoggerI18n().fine(addExpectedExString);
        getRootRegion().getSubregion(regionName).put(1, new byte[943720]);
        WaitCriterion wc = new WaitCriterion() {
          @Override
          public String description() {
            return ""Expected to go critical"";
          }

          @Override
          public boolean done() {
            return ohm.getState().isCritical();
          }
        };
        waitForCriterion(wc, 5000, 100, true);
        getCache().getLoggerI18n().fine(removeExpectedExString);
        return;
      }
    });

    //make sure client puts are rejected
    doPuts(client, regionName, true/*catchServerException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(client, regionName, true/*catchServerException*/,
        false/*catchLowMemoryException*/, new Range(Range.DEFAULT, Range.DEFAULT.width()+1));
    
    //make the region healthy in the server
    server.invoke(new SerializableRunnable() {
      public void run() {
        InternalResourceManager irm = ((GemFireCacheImpl)getCache()).getResourceManager();
        final OffHeapMemoryMonitor ohm = irm.getOffHeapMonitor();
        assertTrue(ohm.getState().isCritical());
        getCache().getLogger().fine(MemoryThresholdsOffHeapDUnitTest.this.addExpectedBelow);
        getRootRegion().getSubregion(regionName).destroy(1);
        WaitCriterion wc = new WaitCriterion() {
          @Override
          public String description() {
            return ""Expected to go normal"";
          }

          @Override
          public boolean done() {
            return ohm.getState().isNormal();
          }
        };
        waitForCriterion(wc, 5000, 100, true);
        getCache().getLogger().fine(MemoryThresholdsOffHeapDUnitTest.this.removeExpectedBelow);
        return;
      }
    });
  }",True
"  private void doClientServerTest(final String regionName, boolean createPR)
      throws Exception {
    //create region on the server
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);

    final int port = AvailablePortHelper.getRandomAvailableTCPPort();
    final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
    startCacheServer(server, port, mcastPort, 0f, 90f,
        regionName, createPR, false, 0);
    startClient(client, server, port, regionName);
    doPuts(client, regionName, false/*catchServerException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(client, regionName, false/*catchServerException*/,
        false/*catchLowMemoryException*/, Range.DEFAULT);

    //make the region sick in the server
    server.invoke(new SerializableRunnable() {
      public void run() {
        InternalResourceManager irm = ((GemFireCacheImpl)getCache()).getResourceManager();
        final OffHeapMemoryMonitor ohm = irm.getOffHeapMonitor();
        assertTrue(ohm.getState().isNormal());
        getCache().getLoggerI18n().fine(addExpectedExString);
        final LocalRegion r = (LocalRegion) getRootRegion().getSubregion(regionName);
        final Object key = 1;
        r.put(key, new byte[943720]);
        WaitCriterion wc;
        if (r instanceof PartitionedRegion) {
          final PartitionedRegion pr = (PartitionedRegion) r;
          final int bucketId = PartitionedRegionHelper.getHashKey(pr, null, key, null, null);
          wc = new WaitCriterion() {
            @Override
            public String description() {
              return ""Expected to go critical: isCritical="" + ohm.getState().isCritical();
            }

            @Override
            public boolean done() {
              if (!ohm.getState().isCritical()) return false;
              // Only done once the bucket has been marked sick
              try {
                pr.getRegionAdvisor().checkIfBucketSick(bucketId, key);
                return false;
              } catch (LowMemoryException ignore) {
                return true;
              }
            }
          };
        } else {
          wc = new WaitCriterion() {
            @Override
            public String description() {
              return ""Expected to go critical: isCritical="" + ohm.getState().isCritical() + "" memoryThresholdReached="" + r.memoryThresholdReached.get();
            }

            @Override
            public boolean done() {
              return ohm.getState().isCritical() && r.memoryThresholdReached.get();
            }
          };
        }
        waitForCriterion(wc, 5000, 100, true);
        getCache().getLoggerI18n().fine(removeExpectedExString);
        return;
      }
    });

    //make sure client puts are rejected
    doPuts(client, regionName, true/*catchServerException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(client, regionName, true/*catchServerException*/,
        false/*catchLowMemoryException*/, new Range(Range.DEFAULT, Range.DEFAULT.width()+1));
    
    //make the region healthy in the server
    server.invoke(new SerializableRunnable() {
      public void run() {
        InternalResourceManager irm = ((GemFireCacheImpl)getCache()).getResourceManager();
        final OffHeapMemoryMonitor ohm = irm.getOffHeapMonitor();
        assertTrue(ohm.getState().isCritical());
        getCache().getLogger().fine(MemoryThresholdsOffHeapDUnitTest.this.addExpectedBelow);
        getRootRegion().getSubregion(regionName).destroy(1);
        WaitCriterion wc = new WaitCriterion() {
          @Override
          public String description() {
            return ""Expected to go normal"";
          }

          @Override
          public boolean done() {
            return ohm.getState().isNormal();
          }
        };
        waitForCriterion(wc, 5000, 100, true);
        getCache().getLogger().fine(MemoryThresholdsOffHeapDUnitTest.this.removeExpectedBelow);
        return;
      }
    });
  }",False
"  protected LocalRegion(String regionName, RegionAttributes attrs,
      LocalRegion parentRegion, GemFireCacheImpl cache,
      InternalRegionArguments internalRegionArgs) throws DiskAccessException {
    super(cache, attrs,regionName, internalRegionArgs);
    Assert.assertTrue(regionName != null, ""regionName must not be null"");
    this.sharedDataView = buildDataView();
    this.regionName = regionName;
    this.parentRegion = parentRegion;
    this.fullPath = calcFullPath(regionName, parentRegion);

    String myName = getFullPath();
    if (internalRegionArgs.getPartitionedRegion() != null) {
      myName = internalRegionArgs.getPartitionedRegion().getFullPath();
    }
    this.offHeap = attrs.getOffHeap() || Boolean.getBoolean(myName+"":OFF_HEAP"");
    if (getOffHeap()) {
      if (cache.getOffHeapStore() == null) {
        throw new IllegalStateException(""The region "" + myName + "" was configured to use off heap memory but no off heap memory was configured."");
      }
    }
    
    this.initializationLatchBeforeGetInitialImage = new StoppableCountDownLatch(this.stopper, 1);
    this.initializationLatchAfterGetInitialImage = new StoppableCountDownLatch(this.stopper, 1);
    this.afterRegionCreateEventLatch = new StoppableCountDownLatch(this.stopper, 1);

    // set the user-attribute object upfront for SQLFabric
    if (internalRegionArgs.getUserAttribute() != null) {
      setUserAttribute(internalRegionArgs.getUserAttribute());
    }
    setKeyRequiresRegionContext(internalRegionArgs.keyRequiresRegionContext());
    initializingRegion.set(this);

    if (internalRegionArgs.getCachePerfStatsHolder() != null) {
      this.hasOwnStats = false;
      this.cachePerfStats = internalRegionArgs.getCachePerfStatsHolder()
          .getCachePerfStats();
    }
    else {
      if (attrs.getPartitionAttributes() != null || isInternalRegion()
          || internalRegionArgs.isUsedForMetaRegion()) {
        this.hasOwnStats = false;
        this.cachePerfStats = cache.getCachePerfStats();
      }
      else {
        this.hasOwnStats = true;
        this.cachePerfStats = new RegionPerfStats(cache, cache.getCachePerfStats(), regionName);
      }
    }

    this.hdfsManager = initHDFSManager();
    this.dsi = findDiskStore(attrs, internalRegionArgs);
    this.diskRegion = createDiskRegion(internalRegionArgs);
    this.entries = createRegionMap(internalRegionArgs);
    this.entriesInitialized = true;
    this.subregions = new ConcurrentHashMap();
    // we only need a destroy lock if this is a root
    if (parentRegion == null) {
      initRoot();
    }
    if (internalRegionArgs.getLoaderHelperFactory() != null) {
      this.loaderHelperFactory = internalRegionArgs.getLoaderHelperFactory();
    }
    else {
      this.loaderHelperFactory = this;
    }

    this.isUsedForPartitionedRegionAdmin = internalRegionArgs
        .isUsedForPartitionedRegionAdmin();
    this.isUsedForPartitionedRegionBucket = internalRegionArgs
        .isUsedForPartitionedRegionBucket();
    this.isUsedForMetaRegion = internalRegionArgs
        .isUsedForMetaRegion();
    this.isMetaRegionWithTransactions = internalRegionArgs.isMetaRegionWithTransactions();
    this.isUsedForSerialGatewaySenderQueue = internalRegionArgs.isUsedForSerialGatewaySenderQueue();
    this.isUsedForParallelGatewaySenderQueue = internalRegionArgs.isUsedForParallelGatewaySenderQueue();
    this.serialGatewaySender = internalRegionArgs.getSerialGatewaySender();
    
    if (!isUsedForMetaRegion && !isUsedForPartitionedRegionAdmin
        && !isUsedForPartitionedRegionBucket
        && !isUsedForSerialGatewaySenderQueue
        && !isUsedForParallelGatewaySenderQueue) {
      this.filterProfile = new FilterProfile(this);
    }
    
    // initialize client to server proxy
    this.srp = ((this.getPoolName() != null)
                || isBridgeLoader(this.getCacheLoader())
                || isBridgeWriter(this.getCacheWriter()))
      ? new ServerRegionProxy(this)
      : null;
    this.imageState =
      new UnsharedImageState(this.srp != null,
                             getDataPolicy().withReplication() || getDataPolicy().isPreloaded(),
                             getAttributes().getDataPolicy().withPersistence(),
                             this.stopper);

    createEventTracker();

    // prevent internal regions from participating in a TX, bug 38709
    this.supportsTX = !isSecret() && !isUsedForPartitionedRegionAdmin()
        && !isUsedForMetaRegion() || isMetaRegionWithTransactions();

    this.testCallable = internalRegionArgs.getTestCallable();
    
  }",True
"  protected LocalRegion(String regionName, RegionAttributes attrs,
      LocalRegion parentRegion, GemFireCacheImpl cache,
      InternalRegionArguments internalRegionArgs) throws DiskAccessException {
    super(cache, attrs,regionName, internalRegionArgs);
    // Initialized here (and defers to parent) to fix GEODE-128
    this.EXPIRY_UNITS_MS = parentRegion != null ? parentRegion.EXPIRY_UNITS_MS : Boolean.getBoolean(EXPIRY_MS_PROPERTY);

    Assert.assertTrue(regionName != null, ""regionName must not be null"");
    this.sharedDataView = buildDataView();
    this.regionName = regionName;
    this.parentRegion = parentRegion;
    this.fullPath = calcFullPath(regionName, parentRegion);

    String myName = getFullPath();
    if (internalRegionArgs.getPartitionedRegion() != null) {
      myName = internalRegionArgs.getPartitionedRegion().getFullPath();
    }
    this.offHeap = attrs.getOffHeap() || Boolean.getBoolean(myName+"":OFF_HEAP"");
    if (getOffHeap()) {
      if (cache.getOffHeapStore() == null) {
        throw new IllegalStateException(""The region "" + myName + "" was configured to use off heap memory but no off heap memory was configured."");
      }
    }
    
    this.initializationLatchBeforeGetInitialImage = new StoppableCountDownLatch(this.stopper, 1);
    this.initializationLatchAfterGetInitialImage = new StoppableCountDownLatch(this.stopper, 1);
    this.afterRegionCreateEventLatch = new StoppableCountDownLatch(this.stopper, 1);

    // set the user-attribute object upfront for SQLFabric
    if (internalRegionArgs.getUserAttribute() != null) {
      setUserAttribute(internalRegionArgs.getUserAttribute());
    }
    setKeyRequiresRegionContext(internalRegionArgs.keyRequiresRegionContext());
    initializingRegion.set(this);

    if (internalRegionArgs.getCachePerfStatsHolder() != null) {
      this.hasOwnStats = false;
      this.cachePerfStats = internalRegionArgs.getCachePerfStatsHolder()
          .getCachePerfStats();
    }
    else {
      if (attrs.getPartitionAttributes() != null || isInternalRegion()
          || internalRegionArgs.isUsedForMetaRegion()) {
        this.hasOwnStats = false;
        this.cachePerfStats = cache.getCachePerfStats();
      }
      else {
        this.hasOwnStats = true;
        this.cachePerfStats = new RegionPerfStats(cache, cache.getCachePerfStats(), regionName);
      }
    }

    this.hdfsManager = initHDFSManager();
    this.dsi = findDiskStore(attrs, internalRegionArgs);
    this.diskRegion = createDiskRegion(internalRegionArgs);
    this.entries = createRegionMap(internalRegionArgs);
    this.entriesInitialized = true;
    this.subregions = new ConcurrentHashMap();
    // we only need a destroy lock if this is a root
    if (parentRegion == null) {
      initRoot();
    }
    if (internalRegionArgs.getLoaderHelperFactory() != null) {
      this.loaderHelperFactory = internalRegionArgs.getLoaderHelperFactory();
    }
    else {
      this.loaderHelperFactory = this;
    }

    this.isUsedForPartitionedRegionAdmin = internalRegionArgs
        .isUsedForPartitionedRegionAdmin();
    this.isUsedForPartitionedRegionBucket = internalRegionArgs
        .isUsedForPartitionedRegionBucket();
    this.isUsedForMetaRegion = internalRegionArgs
        .isUsedForMetaRegion();
    this.isMetaRegionWithTransactions = internalRegionArgs.isMetaRegionWithTransactions();
    this.isUsedForSerialGatewaySenderQueue = internalRegionArgs.isUsedForSerialGatewaySenderQueue();
    this.isUsedForParallelGatewaySenderQueue = internalRegionArgs.isUsedForParallelGatewaySenderQueue();
    this.serialGatewaySender = internalRegionArgs.getSerialGatewaySender();
    
    if (!isUsedForMetaRegion && !isUsedForPartitionedRegionAdmin
        && !isUsedForPartitionedRegionBucket
        && !isUsedForSerialGatewaySenderQueue
        && !isUsedForParallelGatewaySenderQueue) {
      this.filterProfile = new FilterProfile(this);
    }
    
    // initialize client to server proxy
    this.srp = ((this.getPoolName() != null)
                || isBridgeLoader(this.getCacheLoader())
                || isBridgeWriter(this.getCacheWriter()))
      ? new ServerRegionProxy(this)
      : null;
    this.imageState =
      new UnsharedImageState(this.srp != null,
                             getDataPolicy().withReplication() || getDataPolicy().isPreloaded(),
                             getAttributes().getDataPolicy().withPersistence(),
                             this.stopper);

    createEventTracker();

    // prevent internal regions from participating in a TX, bug 38709
    this.supportsTX = !isSecret() && !isUsedForPartitionedRegionAdmin()
        && !isUsedForMetaRegion() || isMetaRegionWithTransactions();

    this.testCallable = internalRegionArgs.getTestCallable();
    
  }",False
"  protected void waitForInvalidate(Region.Entry entry, long p_tilt) {
    long tilt = p_tilt;
    // up until the time that the expiry fires, the entry
    // better not be null...
    if (entry == null) {
      // the entire wait routine was called very late, and
      // we have no entry?  That's ok.
      return;
    }
    for (;;) {
      boolean wasInvalidated = fetchEntryValue(entry) == null; // do this 1st
      long now = System.currentTimeMillis(); // do this 2nd
      if (now >= tilt) {
        // once this is true it is ok if it was invalidated
        break;
      }
      if (!wasInvalidated) {
        pause(100);
        continue;
      }
      if (now >= tilt - SLOP) {
        getLogWriter().warning(""Entry invalidated sloppily ""
            + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
        break;
      }
      fail(""Entry invalidated prematurely ""
           + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
    }

    // After the timeout passes, we will tolerate a slight
    // lag before the invalidate becomes visible (due to
    // system loading)
    final int maxWaitTime = Integer.getInteger(WAIT_PROPERTY, WAIT_DEFAULT).intValue();
    tilt += maxWaitTime;
    for (;;) {
      if (fetchEntryValue(entry) == null) break;
      if (System.currentTimeMillis() > tilt) {
        if (fetchEntryValue(entry) == null) break;
        fail(""Entry failed to invalidate"");
      }
      pause(1000);
    }
  }",True
"  protected void waitForInvalidate(Region.Entry entry, long p_tilt) {
    long tilt = p_tilt;
    // up until the time that the expiry fires, the entry
    // better not be null...
    if (entry == null) {
      // the entire wait routine was called very late, and
      // we have no entry?  That's ok.
      return;
    }
    for (;;) {
      boolean wasInvalidated = fetchEntryValue(entry) == null; // do this 1st
      long now = System.currentTimeMillis(); // do this 2nd
      if (now >= tilt) {
        // once this is true it is ok if it was invalidated
        break;
      }
      if (!wasInvalidated) {
        pause(100);
        continue;
      }
      if (now >= tilt - SLOP) {
        getLogWriter().warning(""Entry invalidated sloppily ""
            + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
        break;
      }
      fail(""Entry invalidated prematurely ""
           + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
    }

    // After the timeout passes, we will tolerate a slight
    // lag before the invalidate becomes visible (due to
    // system loading)
    // Slight lag? WAIT_DEFAULT is 60,000 ms. Many of our tests configure 20ms expiration.
    final int maxWaitTime = Integer.getInteger(WAIT_PROPERTY, WAIT_DEFAULT).intValue();
    tilt += maxWaitTime;
    for (;;) {
      if (fetchEntryValue(entry) == null) break;
      if (System.currentTimeMillis() > tilt) {
        if (fetchEntryValue(entry) == null) break;
        fail(""Entry failed to invalidate"");
      }
      pause(100);
    }
  }",False
"  public void testCustomEntryTtl1() {

    final String name = this.getUniqueName();
    final int timeout = 20; // ms!
    final String key1 = ""KEY1"";
    final String key2 = ""KEY2"";
    final String value = ""VALUE"";
    
    AttributesFactory factory = new AttributesFactory(getRegionAttributes());
    ExpirationAttributes expire =
            new ExpirationAttributes(timeout, ExpirationAction.INVALIDATE);
//    factory.setEntryTimeToLive(expire);
    factory.setCustomEntryTimeToLive(new TestExpiry(key2, expire));
    factory.setStatisticsEnabled(true);
    RegionAttributes attrs = factory.create();

    Region region = null;
    /**
             * Crank up the expiration so test runs faster.
             * This property only needs to be set while the region is created
             */
    System.setProperty(LocalRegion.EXPIRY_MS_PROPERTY, ""true"");
    try {
      region = createRegion(name, attrs);
    } 
    finally {
      System.getProperties().remove(LocalRegion.EXPIRY_MS_PROPERTY);
    }
    
    // Random values should not expire
    region.put(key1, value);
    pause(timeout * 2);
    assert(region.get(key1).equals(value));
    
    // key2 *should* expire
    ExpiryTask.suspendExpiration();
    Region.Entry entry = null;
    long tilt;
    try {
      region.put(key2, value);
      tilt = System.currentTimeMillis() + timeout;
      entry = region.getEntry(key2);
      assertNotNull(entry.getValue());
    } 
    finally {
      ExpiryTask.permitExpiration();
    }
    waitForInvalidate(entry, tilt);
    
    assert(region.get(key1).equals(value));
  }",True
"  public void testCustomEntryTtl1() {

    final String name = this.getUniqueName();
    final int timeout = 20; // ms!
    final String key1 = ""KEY1"";
    final String key2 = ""KEY2"";
    final String value = ""VALUE"";
    
    AttributesFactory factory = new AttributesFactory(getRegionAttributes());
    ExpirationAttributes expire =
            new ExpirationAttributes(timeout, ExpirationAction.INVALIDATE);
//    factory.setEntryTimeToLive(expire);
    factory.setCustomEntryTimeToLive(new TestExpiry(key2, expire));
    factory.setStatisticsEnabled(true);
    RegionAttributes attrs = factory.create();

    Region region = null;
    /**
     * Crank up the expiration so test runs faster.
     * This property only needs to be set while the region is created
     */
    System.setProperty(LocalRegion.EXPIRY_MS_PROPERTY, ""true"");
    try {
      region = createRegion(name, attrs);
    } 
    finally {
      System.getProperties().remove(LocalRegion.EXPIRY_MS_PROPERTY);
    }
    
    // Random values should not expire
    region.put(key1, value);
    pause(timeout * 2);
    assert(region.get(key1).equals(value));
    
    // key2 *should* expire
    ExpiryTask.suspendExpiration();
    Region.Entry entry = null;
    long tilt;
    try {
      region.put(key2, value);
      tilt = System.currentTimeMillis() + timeout;
      entry = region.getEntry(key2);
      assertNotNull(entry.getValue());
    } 
    finally {
      ExpiryTask.permitExpiration();
    }
    waitForInvalidate(entry, tilt);
    
    assert(region.get(key1).equals(value));
  }",False
"  protected void waitForRegionDestroy(Region region, long p_tilt) {
    long tilt = p_tilt;
    // up until the time that the expiry fires, the entry
    // better not be null...
    for (;;) {
      long now = System.currentTimeMillis();
      if (now >= tilt)
        break;
      if (!region.isDestroyed()) {
        pause(100);
        continue;
      }
      if (now >= tilt - SLOP) {
        getLogWriter().warning(""Region destroyed sloppily ""
            + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
        break;
      }
      fail(""Region destroyed prematurely""
          + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
    }

    // After the timeout passes, we will tolerate a slight
    // lag before the destroy becomes visible (due to
    // system loading)
    final int maxWaitTime = Integer.getInteger(WAIT_PROPERTY, WAIT_DEFAULT).intValue();
    tilt += maxWaitTime;
    for (;;) {
      if (region.isDestroyed())
        break;
      Assert.assertTrue(System.currentTimeMillis() <= tilt,
          ""Region failed to destroy"");
      pause(1000);
    }
  }  ",True
"  protected void waitForRegionDestroy(Region region, long p_tilt) {
    long tilt = p_tilt;
    // up until the time that the expiry fires, the entry
    // better not be null...
    for (;;) {
      long now = System.currentTimeMillis();
      if (now >= tilt)
        break;
      if (!region.isDestroyed()) {
        pause(100);
        continue;
      }
      if (now >= tilt - SLOP) {
        getLogWriter().warning(""Region destroyed sloppily ""
            + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
        break;
      }
      fail(""Region destroyed prematurely""
          + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
    }

    // After the timeout passes, we will tolerate a slight
    // lag before the destroy becomes visible (due to
    // system loading)
    final int maxWaitTime = Integer.getInteger(WAIT_PROPERTY, WAIT_DEFAULT).intValue();
    tilt += maxWaitTime;
    for (;;) {
      if (region.isDestroyed())
        break;
      Assert.assertTrue(System.currentTimeMillis() <= tilt,
          ""Region failed to destroy"");
      pause(100);
    }
  }  ",False
"  protected void waitForDestroy(Region.Entry entry, long p_tilt) {
    long tilt = p_tilt;
    // up until the time that the expiry fires, the entry
    // better not be null...
    for (;;) {
      long now = System.currentTimeMillis();
      if (now >= tilt)
        break;
      if (!isEntryDestroyed(entry)) {
        pause(100);
        continue;
      }
      if (now >= tilt - SLOP) {
        getLogWriter().warning(""Entry destroyed sloppily ""
            + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
        break;
      }
      fail(""Entry destroyed prematurely""
          + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
    }

    // After the timeout passes, we will tolerate a slight
    // lag before the destroy becomes visible (due to
    // system loading)
    final int maxWaitTime = Integer.getInteger(WAIT_PROPERTY, WAIT_DEFAULT).intValue();
    tilt += maxWaitTime;
    for (;;) {
      if (isEntryDestroyed(entry))
        break;
      Assert.assertTrue(System.currentTimeMillis() <= tilt,
          ""Entry failed to destroy"");
      pause(1000);
    }
  }",True
"  protected void waitForDestroy(Region.Entry entry, long p_tilt) {
    long tilt = p_tilt;
    // up until the time that the expiry fires, the entry
    // better not be null...
    for (;;) {
      long now = System.currentTimeMillis();
      if (now >= tilt)
        break;
      if (!isEntryDestroyed(entry)) {
        pause(100);
        continue;
      }
      if (now >= tilt - SLOP) {
        getLogWriter().warning(""Entry destroyed sloppily ""
            + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
        break;
      }
      fail(""Entry destroyed prematurely""
          + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
    }

    // After the timeout passes, we will tolerate a slight
    // lag before the destroy becomes visible (due to
    // system loading)
    final int maxWaitTime = Integer.getInteger(WAIT_PROPERTY, WAIT_DEFAULT).intValue();
    tilt += maxWaitTime;
    for (;;) {
      if (isEntryDestroyed(entry))
        break;
      Assert.assertTrue(System.currentTimeMillis() <= tilt,
          ""Entry failed to destroy"");
      pause(100);
    }
  }",False
"  public static void createClientPoolCache(String testName,String host) throws Exception
  {
    Properties props = new Properties();
    props.setProperty(DistributionConfig.MCAST_PORT_NAME, ""0"");
    props.setProperty(DistributionConfig.LOCATORS_NAME, """");
    new HAInterestBaseTest(""temp"").createCache(props);
    CacheServerTestUtil.disableShufflingOfEndpoints();
    PoolImpl p;
    try {
      p = (PoolImpl)PoolManager.createFactory()
        .addServer(host, PORT1)
        .addServer(host, PORT2)
        .addServer(host, PORT3)
        .setSubscriptionEnabled(true)
        .setSubscriptionRedundancy(-1)
        .setReadTimeout(1000)
        .setPingInterval(1000)
        // retryInterval should be more so that only registerInterste thread will initiate failover
        // .setRetryInterval(20000)
        .create(""HAInterestBaseTestPool"");
    } finally {
      CacheServerTestUtil.enableShufflingOfEndpoints();
    }
    AttributesFactory factory = new AttributesFactory();
    factory.setScope(Scope.LOCAL);
    factory.setConcurrencyChecksEnabled(true);
    factory.setPoolName(p.getName());

    cache.createRegion(REGION_NAME, factory.create());
    pool = p;
    conn = pool.acquireConnection();
    assertNotNull(conn);
  }",True
"  public static void createClientPoolCache(String testName, String host) throws Exception {
    Properties props = new Properties();
    props.setProperty(DistributionConfig.MCAST_PORT_NAME, ""0"");
    props.setProperty(DistributionConfig.LOCATORS_NAME, """");
    new HAInterestBaseTest(""temp"").createCache(props);
    CacheServerTestUtil.disableShufflingOfEndpoints();
    PoolImpl p;
    try {
      p = (PoolImpl) PoolManager.createFactory()
          .addServer(host, PORT1)
          .addServer(host, PORT2)
          .addServer(host, PORT3)
          .setSubscriptionEnabled(true)
          .setSubscriptionRedundancy(-1)
          .setReadTimeout(1000)
          .setPingInterval(1000)
          // retryInterval should be more so that only registerInterste thread
          // will initiate failover
          // .setRetryInterval(20000)
          .create(""HAInterestBaseTestPool"");
    } finally {
      CacheServerTestUtil.enableShufflingOfEndpoints();
    }
    AttributesFactory factory = new AttributesFactory();
    factory.setScope(Scope.LOCAL);
    factory.setConcurrencyChecksEnabled(true);
    factory.setPoolName(p.getName());

    cache.createRegion(REGION_NAME, factory.create());
    pool = p;
    conn = pool.acquireConnection();
    assertNotNull(conn);
  }",False
" public static void putK1andK2()
  {
    Region r1 = cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r1);
    try {
      r1.put(k1, server_k1);
      r1.put(k2, server_k2);
    }
    catch (Exception e) {
      fail(""Test failed due to Exception in putK1andK2 ::"" + e);
    }
  }",True
"  public static void putK1andK2() {
    Region r1 = cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r1);
    r1.put(k1, server_k1);
    r1.put(k2, server_k2);
  }",False
"public static void setBridgeObserverForAfterRegistration(final VM vm)
{
  PoolImpl.AFTER_REGISTER_CALLBACK_FLAG = true;
  BridgeObserverHolder.setInstance(new BridgeObserverAdapter() {
    public void afterInterestRegistration()
    {
      synchronized (HAInterestBaseTest.class) {
        vm.invoke(HAInterestBaseTest.class, ""startServer"");
        HAInterestBaseTest.isAfterRegistrationCallbackCalled = true;
        HAInterestBaseTest.class.notify();
        PoolImpl.AFTER_REGISTER_CALLBACK_FLAG = false;
      }
    }
  });
}",True
"  public static void setBridgeObserverForAfterRegistration(final VM vm) {
    PoolImpl.AFTER_REGISTER_CALLBACK_FLAG = true;
    BridgeObserverHolder.setInstance(new BridgeObserverAdapter() {
      public void afterInterestRegistration() {
        synchronized (HAInterestBaseTest.class) {
          vm.invoke(HAInterestBaseTest.class, ""startServer"");
          HAInterestBaseTest.isAfterRegistrationCallbackCalled = true;
          HAInterestBaseTest.class.notify();
          PoolImpl.AFTER_REGISTER_CALLBACK_FLAG = false;
        }
      }
    });
  }",False
"      public static void verifyInterestUNRegistration()
      {
    try {
      WaitCriterion wc = new WaitCriterion() {
        String excuse;
        public boolean done() {
          return cache.getBridgeServers().size() == 1;
        }
        public String description() {
          return excuse;
        }
      };
      DistributedTestCase.waitForCriterion(wc, MAX_WAIT, 1000, true);
      
      BridgeServerImpl bs = (BridgeServerImpl)cache.getBridgeServers()
          .iterator().next();
      assertNotNull(bs);
      assertNotNull(bs.getAcceptor());
      assertNotNull(bs.getAcceptor().getCacheClientNotifier());
      final CacheClientNotifier ccn = bs.getAcceptor().getCacheClientNotifier();
      wc = new WaitCriterion() {
        String excuse;
        public boolean done() {
          return ccn.getClientProxies().size() > 0;
        }
        public String description() {
          return excuse;
        }
      };
      DistributedTestCase.waitForCriterion(wc, MAX_WAIT, 1000, true);
      
      Iterator iter_prox = ccn.getClientProxies().iterator();
      if (iter_prox.hasNext()) {
        final CacheClientProxy ccp =(CacheClientProxy)iter_prox.next();
        wc = new WaitCriterion() {
          String excuse;
          public boolean done() {
            Set keysMap = (Set)ccp.cils[RegisterInterestTracker.interestListIndex]
              .getProfile(Region.SEPARATOR + REGION_NAME)
              .getKeysOfInterestFor(ccp.getProxyID());
            return keysMap != null;
          }
          public String description() {
            return excuse;
          }
        };
        DistributedTestCase.waitForCriterion(wc, MAX_WAIT, 1000, true);
        
        Set keysMap = (Set)ccp.cils[RegisterInterestTracker.interestListIndex]
          .getProfile(Region.SEPARATOR + REGION_NAME)
          .getKeysOfInterestFor(ccp.getProxyID());
        assertNotNull(keysMap);
        assertEquals(1, keysMap.size());
        assertFalse(keysMap.contains(k1));
        assertTrue(keysMap.contains(k2));
      }
    }
    catch (Exception ex) {
      fail(""while setting verifyInterestUNRegistration  "" + ex);
    }
  }",True
"  public static void verifyInterestUNRegistration() {
    WaitCriterion wc = new WaitCriterion() {
      @Override
      public boolean done() {
        return cache.getBridgeServers().size() == 1;
      }
      @Override
      public String description() {
        return ""waiting for cache.getBridgeServers().size() == 1"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);

    BridgeServerImpl bs = (BridgeServerImpl) cache.getBridgeServers().iterator().next();
    assertNotNull(bs);
    assertNotNull(bs.getAcceptor());
    assertNotNull(bs.getAcceptor().getCacheClientNotifier());
    final CacheClientNotifier ccn = bs.getAcceptor().getCacheClientNotifier();
    
    wc = new WaitCriterion() {
      @Override
      public boolean done() {
        return ccn.getClientProxies().size() > 0;
      }
      @Override
      public String description() {
        return ""waiting for ccn.getClientProxies().size() > 0"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);

    Iterator iter_prox = ccn.getClientProxies().iterator();
    if (iter_prox.hasNext()) {
      final CacheClientProxy ccp = (CacheClientProxy) iter_prox.next();
      
      wc = new WaitCriterion() {
        @Override
        public boolean done() {
          Set keysMap = (Set) ccp.cils[RegisterInterestTracker.interestListIndex]
              .getProfile(Region.SEPARATOR + REGION_NAME)
              .getKeysOfInterestFor(ccp.getProxyID());
          return keysMap != null;
        }
        @Override
        public String description() {
          return ""waiting for keys of interest to not be null"";
        }
      };
      DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);

      Set keysMap = (Set) ccp.cils[RegisterInterestTracker.interestListIndex]
          .getProfile(Region.SEPARATOR + REGION_NAME)
          .getKeysOfInterestFor(ccp.getProxyID());
      assertNotNull(keysMap);
      assertEquals(1, keysMap.size());
      assertFalse(keysMap.contains(k1));
      assertTrue(keysMap.contains(k2));
    }
  }",False
"    public static VM stopSecondaryAndUNregisterK1()
    {
      try {
        LocalRegion r = (LocalRegion)cache.getRegion(Region.SEPARATOR+REGION_NAME);
        assertNotNull(r);
        ServerRegionProxy srp = new ServerRegionProxy(r);

        WaitCriterion wc = new WaitCriterion() {
          public boolean done() {
            return pool.getConnectedServerCount() == 3;
          }
          public String description() {
            return ""connected server count never became 3"";
          }
        };
        DistributedTestCase.waitForCriterion(wc, 30 * 1000, 1000, true);

        // close secondary EP
        VM result = getBackupVM();
        result.invoke(HAInterestBaseTest.class, ""stopServer"");
        List list = new ArrayList();
        list.add(k1);
        srp.unregisterInterest(list, InterestType.KEY,false,false);
        return result;
      }
      catch (Exception ex) {
        fail(""failed while region.stopSecondaryAndUNregisterK1()"", ex);
        return null;
      }
    }",True
"  public static VM stopSecondaryAndUNregisterK1() {
    LocalRegion r = (LocalRegion) cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r);
    ServerRegionProxy srp = new ServerRegionProxy(r);

    WaitCriterion wc = new WaitCriterion() {
      @Override
      public boolean done() {
        return pool.getConnectedServerCount() == 3;
      }
      @Override
      public String description() {
        return ""connected server count never became 3"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);

    // close secondary EP
    VM result = getBackupVM();
    result.invoke(HAInterestBaseTest.class, ""stopServer"");
    List list = new ArrayList();
    list.add(k1);
    srp.unregisterInterest(list, InterestType.KEY, false, false);
    return result;
  }",False
"    public static void reRegisterK1AndK2()
    {
      try {
        Region r = cache.getRegion(Region.SEPARATOR+REGION_NAME);
        assertNotNull(r);
        List list = new ArrayList();
        list.add(k1);
        list.add(k2);
        r.registerInterest(list);

      }
      catch (Exception ex) {
        fail(""failed while region.reRegisterK1AndK2()"", ex);
      }
    }",True
"  public static void reRegisterK1AndK2() {
    Region r = cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r);
    List list = new ArrayList();
    list.add(k1);
    list.add(k2);
    r.registerInterest(list);
  }",False
"  public static VM getPrimaryVM() {
    return getPrimaryVM(null);
  }",True
"  public static VM getPrimaryVM(final VM oldPrimary) {
    WaitCriterion wc = new WaitCriterion() {
      @Override
      public boolean done() {
        int primaryPort = pool.getPrimaryPort();
        if (primaryPort == -1) {
          return false;
        }
        // we have a primary
        VM currentPrimary = getServerVM(primaryPort);
        if (currentPrimary != oldPrimary) {
          return true;
        }
        return false;
      }
      @Override
      public String description() {
        return ""waiting for primary"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);

    int primaryPort = pool.getPrimaryPort();
    assertTrue(primaryPort != -1);
    VM currentPrimary = getServerVM(primaryPort);
    assertTrue(currentPrimary != oldPrimary);
    return currentPrimary;
  }",False
" public static void verifyRefreshedEntriesFromServer()
  {
    final Region r1 = cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r1);
    
    WaitCriterion wc = new WaitCriterion() {
      String excuse;
      public boolean done() {
        Region.Entry re = r1.getEntry(k1);
        if (re == null) return false;
        Object val = re.getValue();
        return client_k1.equals(val);
      }
      public String description() {
        return excuse;
      }
    };
    DistributedTestCase.waitForCriterion(wc, MAX_WAIT, 1000, true);

    wc = new WaitCriterion() {
      String excuse;
      public boolean done() {
        Region.Entry re = r1.getEntry(k2);
        if (re == null) return false;
        Object val = re.getValue();
        return client_k2.equals(val);
      }
      public String description() {
        return excuse;
      }
    };
    DistributedTestCase.waitForCriterion(wc, MAX_WAIT, 1000, true);

    // assertEquals(client_k1, r1.getEntry(k1).getValue());
    // assertEquals(client_k2 ,r1.getEntry(k2).getValue());
  }",True
"  public static void verifyRefreshedEntriesFromServer() {
    final Region r1 = cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r1);

    WaitCriterion wc = new WaitCriterion() {
      @Override
      public boolean done() {
        Region.Entry re = r1.getEntry(k1);
        if (re == null)
          return false;
        Object val = re.getValue();
        return client_k1.equals(val);
      }
      @Override
      public String description() {
        return ""waiting for client_k1 refresh from server"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);

    wc = new WaitCriterion() {
      @Override
      public boolean done() {
        Region.Entry re = r1.getEntry(k2);
        if (re == null)
          return false;
        Object val = re.getValue();
        return client_k2.equals(val);
      }
      @Override
      public String description() {
        return ""waiting for client_k2 refresh from server"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);
  }",False
"  public static VM getBackupVM() {
    return getBackupVM(null);
  }",True
"  public static VM getBackupVM(VM stoppedBackup) {
    VM currentPrimary = getPrimaryVM(null);
    if (currentPrimary != server2 && server2 != stoppedBackup) {
      return server2;
    } else if (currentPrimary != server3 && server3 != stoppedBackup) {
      return server3;
    } else if (currentPrimary != server1 && server1 != stoppedBackup) {
      return server1;
    } else {
      fail(""expected currentPrimary "" + currentPrimary + "" to be "" + server1 + "", or "" + server2 + "", or "" + server3);
      return null;
    }
  }",False
" public static void waitForBeforeInterestRecoveryCallBack()
 {

   assertNotNull(cache);
   synchronized (HAInterestBaseTest.class) {
     while (!isBeforeInterestRecoveryCallbackCalled) {
       try {
         HAInterestBaseTest.class.wait();
       }
       catch (InterruptedException e) {
         fail(""Test failed due to InterruptedException in waitForBeforeInterstRecovery()"");
       }
     }
   }

 }",True
"  public static void waitForBeforeInterestRecoveryCallBack() throws InterruptedException {
    assertNotNull(cache);
    synchronized (HAInterestBaseTest.class) {
      while (!isBeforeInterestRecoveryCallbackCalled) {
        HAInterestBaseTest.class.wait();
      }
    }
  }",False
"    public static void stopServer()
    {
    try {
          assertEquals(""More than one BridgeServer"", 1, cache.getBridgeServers().size());
          BridgeServerImpl bs = (BridgeServerImpl) cache.getBridgeServers().iterator().next();
          assertNotNull(bs);
          bs.stop();
    }
      catch (Exception ex) {
        fail(""while setting stopServer  "" + ex);
      }
    }",True
"  public static void stopServer() {
    assertEquals(""More than one BridgeServer"", 1, cache.getBridgeServers().size());
    BridgeServerImpl bs = (BridgeServerImpl) cache.getBridgeServers().iterator().next();
    assertNotNull(bs);
    bs.stop();
  }",False
"    public static void stopPrimaryAndUnregisterRegisterK1()
    {
      try {
        LocalRegion r = (LocalRegion)cache.getRegion(Region.SEPARATOR+REGION_NAME);
        assertNotNull(r);
        ServerRegionProxy srp = new ServerRegionProxy(r);

        WaitCriterion wc = new WaitCriterion() {
          public boolean done() {
            return pool.getConnectedServerCount() == 3;
          }
          public String description() {
            return ""connected server count never became 3"";
          }
        };
        DistributedTestCase.waitForCriterion(wc, 30 * 1000, 1000, true);

        // close primaryEP
        getPrimaryVM().invoke(HAInterestBaseTest.class, ""stopServer"");
        List list = new ArrayList();
        list.add(k1);
        srp.unregisterInterest(list, InterestType.KEY,false,false);
      }
      catch (Exception ex) {
        fail(""failed while region.stopPrimaryAndUnregisterRegisterK1()"", ex);
      }
    }",True
"  public static void stopPrimaryAndUnregisterRegisterK1() {
    LocalRegion r = (LocalRegion) cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r);
    ServerRegionProxy srp = new ServerRegionProxy(r);

    WaitCriterion wc = new WaitCriterion() {
      @Override
      public boolean done() {
        return pool.getConnectedServerCount() == 3;
      }
      @Override
      public String description() {
        return ""connected server count never became 3"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);

    // close primaryEP
    getPrimaryVM().invoke(HAInterestBaseTest.class, ""stopServer"");
    List list = new ArrayList();
    list.add(k1);
    srp.unregisterInterest(list, InterestType.KEY, false, false);
  }",False
" public static void setBridgeObserverForBeforeInterestRecovery()
 {
   PoolImpl.BEFORE_RECOVER_INTEREST_CALLBACK_FLAG = true;
   BridgeObserverHolder.setInstance(new BridgeObserverAdapter() {
     public void beforeInterestRecovery()
     {
       synchronized (HAInterestBaseTest.class) {
         Thread t = new Thread (){
           public void run(){
               Region r1 = cache.getRegion(Region.SEPARATOR + REGION_NAME);
               assertNotNull(r1);
               try {
              r1.put(k1, server_k1_updated);
            } catch (Exception e) {
              e.printStackTrace();
              fail(""Test Failed due to ...""+e);
            }
           }
         };
       t.start();

       HAInterestBaseTest.isBeforeInterestRecoveryCallbackCalled = true;
       HAInterestBaseTest.class.notify();
         PoolImpl.BEFORE_RECOVER_INTEREST_CALLBACK_FLAG = false;
       }
     }
   });
 }",True
"  public static void setBridgeObserverForBeforeInterestRecovery() {
    PoolImpl.BEFORE_RECOVER_INTEREST_CALLBACK_FLAG = true;
    BridgeObserverHolder.setInstance(new BridgeObserverAdapter() {
      public void beforeInterestRecovery() {
        synchronized (HAInterestBaseTest.class) {
          Thread t = new Thread() {
            public void run() {
              Region r1 = cache.getRegion(Region.SEPARATOR + REGION_NAME);
              assertNotNull(r1);
              r1.put(k1, server_k1_updated);
            }
          };
          t.start();

          HAInterestBaseTest.isBeforeInterestRecoveryCallbackCalled = true;
          HAInterestBaseTest.class.notify();
          PoolImpl.BEFORE_RECOVER_INTEREST_CALLBACK_FLAG = false;
        }
      }
    });
  }",False
"    public static VM stopSecondaryAndRegisterK1AndK2AndVerifyResponse()
    {
      try {
        LocalRegion r = (LocalRegion)cache.getRegion(Region.SEPARATOR+REGION_NAME);
        assertNotNull(r);
        ServerRegionProxy srp = new ServerRegionProxy(r);

        WaitCriterion wc = new WaitCriterion() {
          public boolean done() {
            return pool.getConnectedServerCount() == 3;
          }
          public String description() {
            return ""Never got three connected servers"";
          }
        };
        DistributedTestCase.waitForCriterion(wc, 90 * 1000, 1000, true);
        
        // close secondary EP
        VM result = getBackupVM();
        result.invoke(HAInterestBaseTest.class, ""stopServer"");
        List list = new ArrayList();
        list.add(k1);
        list.add(k2);
        List serverKeys = srp.registerInterest(list, InterestType.KEY,
          InterestResultPolicy.KEYS,
          false, r.getAttributes().getDataPolicy().ordinal);

        assertNotNull(serverKeys);
        List resultKeys =(List) serverKeys.get(0) ;
        assertEquals(2,resultKeys.size());
        assertTrue(resultKeys.contains(k1));
        assertTrue(resultKeys.contains(k2));
        return result;
      }
      catch (Exception ex) {
        fail(""failed while region.stopSecondaryAndRegisterK1AndK2AndVerifyResponse()"", ex);
        return null;
      }
    }",True
"  public static VM stopSecondaryAndRegisterK1AndK2AndVerifyResponse() {
    LocalRegion r = (LocalRegion) cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r);
    ServerRegionProxy srp = new ServerRegionProxy(r);

    WaitCriterion wc = new WaitCriterion() {
      @Override
      public boolean done() {
        return pool.getConnectedServerCount() == 3;
      }
      @Override
      public String description() {
        return ""Never got three connected servers"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);

    // close secondary EP
    VM result = getBackupVM();
    result.invoke(HAInterestBaseTest.class, ""stopServer"");
    List list = new ArrayList();
    list.add(k1);
    list.add(k2);
    List serverKeys = srp.registerInterest(list, InterestType.KEY, InterestResultPolicy.KEYS, false, r.getAttributes().getDataPolicy().ordinal);

    assertNotNull(serverKeys);
    List resultKeys = (List) serverKeys.get(0);
    assertEquals(2, resultKeys.size());
    assertTrue(resultKeys.contains(k1));
    assertTrue(resultKeys.contains(k2));
    return result;
  }",False
"    public static void stopPrimaryAndRegisterK1AndK2AndVerifyResponse()
    {
      try {
        LocalRegion r = (LocalRegion)cache.getRegion(Region.SEPARATOR+REGION_NAME);
        assertNotNull(r);
        ServerRegionProxy srp = new ServerRegionProxy(r);

        WaitCriterion wc = new WaitCriterion() {
          public boolean done() {
            return pool.getConnectedServerCount() == 3;
          }
          public String description() {
            return ""connected server count never became 3"";
          }
        };
        DistributedTestCase.waitForCriterion(wc, 30 * 1000, 1000, true);

        // close primaryEP
        getPrimaryVM().invoke(HAInterestBaseTest.class, ""stopServer"");
        List list = new ArrayList();
        list.add(k1);
        list.add(k2);
        List serverKeys = srp.registerInterest(list, InterestType.KEY,
          InterestResultPolicy.KEYS, false,
          r.getAttributes().getDataPolicy().ordinal);
        assertNotNull(serverKeys);
        List resultKeys =(List) serverKeys.get(0) ;
        assertEquals(2,resultKeys.size());
        assertTrue(resultKeys.contains(k1));
        assertTrue(resultKeys.contains(k2));

      }
      catch (Exception ex) {
        fail(""failed while region.stopPrimaryAndRegisterK1AndK2AndVerifyResponse()"", ex);
      }
    }",True
"  public static void stopPrimaryAndRegisterK1AndK2AndVerifyResponse() {
    LocalRegion r = (LocalRegion) cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r);
    ServerRegionProxy srp = new ServerRegionProxy(r);

    WaitCriterion wc = new WaitCriterion() {
      @Override
      public boolean done() {
        return pool.getConnectedServerCount() == 3;
      }
      @Override
      public String description() {
        return ""connected server count never became 3"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);

    // close primaryEP
    getPrimaryVM().invoke(HAInterestBaseTest.class, ""stopServer"");
    List list = new ArrayList();
    list.add(k1);
    list.add(k2);
    List serverKeys = srp.registerInterest(list, InterestType.KEY, InterestResultPolicy.KEYS, false, r.getAttributes().getDataPolicy().ordinal);
    assertNotNull(serverKeys);
    List resultKeys = (List) serverKeys.get(0);
    assertEquals(2, resultKeys.size());
    assertTrue(resultKeys.contains(k1));
    assertTrue(resultKeys.contains(k2));
  }",False
"public static void waitForBeforeRegistrationCallback()
{

  assertNotNull(cache);
  synchronized (HAInterestBaseTest.class) {
    while (!isBeforeRegistrationCallbackCalled) {
      try {
        HAInterestBaseTest.class.wait();
      }
      catch (InterruptedException e) {
        fail(""Test failed due to InterruptedException in waitForBeforeRegistrationCallback()"");
      }
    }
  }
}",True
"  public static void waitForBeforeRegistrationCallback() throws InterruptedException {
    assertNotNull(cache);
    synchronized (HAInterestBaseTest.class) {
      while (!isBeforeRegistrationCallbackCalled) {
        HAInterestBaseTest.class.wait();
      }
    }
  }",False
"  public static void createClientPoolCacheConnectionToSingleServer(String testName,String hostName) throws Exception
  {

    Properties props = new Properties();
    props.setProperty(DistributionConfig.MCAST_PORT_NAME, ""0"");
    props.setProperty(DistributionConfig.LOCATORS_NAME, """");
    new HAInterestBaseTest(""temp"").createCache(props);
    PoolImpl p = (PoolImpl)PoolManager.createFactory()
      .addServer(hostName, PORT1)
      .setSubscriptionEnabled(true)
      .setSubscriptionRedundancy(-1)
      .setReadTimeout(1000)
      // .setRetryInterval(20)
      .create(""HAInterestBaseTestPool"");
    AttributesFactory factory = new AttributesFactory();
    factory.setScope(Scope.LOCAL);
    factory.setConcurrencyChecksEnabled(true);
    factory.setPoolName(p.getName());

    cache.createRegion(REGION_NAME, factory.create());

    pool = p;
    conn = pool.acquireConnection();
    assertNotNull(conn);
  }",True
"  public static void createClientPoolCacheConnectionToSingleServer(String testName, String hostName) throws Exception {
    Properties props = new Properties();
    props.setProperty(DistributionConfig.MCAST_PORT_NAME, ""0"");
    props.setProperty(DistributionConfig.LOCATORS_NAME, """");
    new HAInterestBaseTest(""temp"").createCache(props);
    PoolImpl p = (PoolImpl) PoolManager.createFactory()
        .addServer(hostName, PORT1)
        .setSubscriptionEnabled(true)
        .setSubscriptionRedundancy(-1)
        .setReadTimeout(1000)
        // .setRetryInterval(20)
        .create(""HAInterestBaseTestPool"");
    AttributesFactory factory = new AttributesFactory();
    factory.setScope(Scope.LOCAL);
    factory.setConcurrencyChecksEnabled(true);
    factory.setPoolName(p.getName());

    cache.createRegion(REGION_NAME, factory.create());

    pool = p;
    conn = pool.acquireConnection();
    assertNotNull(conn);
  }",False
"  private  void createCache(Properties props) throws Exception
  {
    DistributedSystem ds = getSystem(props);
    assertNotNull(ds);
    ds.disconnect();
    ds = getSystem(props);
    cache = CacheFactory.create(ds);
    assertNotNull(cache);
  }",True
"  private void createCache(Properties props) throws Exception {
    DistributedSystem ds = getSystem(props);
    assertNotNull(ds);
    ds.disconnect();
    ds = getSystem(props);
    cache = CacheFactory.create(ds);
    assertNotNull(cache);
  }",False
"    public static void registerK1AndK2()
    {
      try {
        Region r = cache.getRegion(Region.SEPARATOR+REGION_NAME);
        assertNotNull(r);
        List list = new ArrayList();
        list.add(k1);
        list.add(k2);
        r.registerInterest(list, InterestResultPolicy.KEYS_VALUES);
      }
      catch (Exception ex) {
        ex.printStackTrace();
        fail(""failed while region.registerK1AndK2()"", ex);
      }
    }",True
"  public static void registerK1AndK2() {
    Region r = cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r);
    List list = new ArrayList();
    list.add(k1);
    list.add(k2);
    r.registerInterest(list, InterestResultPolicy.KEYS_VALUES);
  }",False
"    public static void startServerAndPause()
    {
    try {
      Cache c = CacheFactory.getAnyInstance();
      assertEquals(""More than one BridgeServer"", 1, c.getBridgeServers().size());
      BridgeServerImpl bs = (BridgeServerImpl) c.getBridgeServers().iterator().next();
      assertNotNull(bs);
      bs.start();
      Thread.sleep(10000);
    }
      catch (Exception ex) {
        fail(""while startServer()  "" + ex);
      }
    }",True
"  }

  /**
   * returns the secondary that was stopped
   */
  public static VM stopSecondaryAndRegisterK1AndK2AndVerifyResponse() {
    LocalRegion r = (LocalRegion) cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r);
    ServerRegionProxy srp = new ServerRegionProxy(r);

    WaitCriterion wc = new WaitCriterion() {
      @Override
      public boolean done() {
        return pool.getConnectedServerCount() == 3;",False
"    public static void createServerEntriesK1andK2()
    {
      try {
        Region r1 = cache.getRegion(Region.SEPARATOR+ REGION_NAME);
        assertNotNull(r1);
        if (!r1.containsKey(k1)) {
          r1.create(k1, server_k1);
        }
        if (!r1.containsKey(k2)) {
          r1.create(k2, server_k2);
        }
        assertEquals(r1.getEntry(k1).getValue(), server_k1);
        assertEquals(r1.getEntry(k2).getValue(), server_k2);
      }
      catch (Exception ex) {
        fail(""failed while createEntries()"", ex);
      }
    }",True
"  public static void createServerEntriesK1andK2() {
    Region r1 = cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r1);
    if (!r1.containsKey(k1)) {
      r1.create(k1, server_k1);
    }
    if (!r1.containsKey(k2)) {
      r1.create(k2, server_k2);
    }
    assertEquals(r1.getEntry(k1).getValue(), server_k1);
    assertEquals(r1.getEntry(k2).getValue(), server_k2);
  }",False
" public static void verifyDeadAndLiveServers(final int expectedDeadServers, 
     final int expectedLiveServers)
{
   WaitCriterion wc = new WaitCriterion() {
     String description;
     public boolean done() {
       return pool.getConnectedServerCount() == expectedLiveServers;  
     }
     public String description() {
       return description;
     }
   };
   DistributedTestCase.waitForCriterion(wc, MAX_WAIT, 1000, true);
   
//   while (proxy.getDeadServers().size() != expectedDeadServers) { // wait until condition is met
//     assertTrue(""Waited over "" + maxWaitTime + ""for dead servers to become : "" + expectedDeadServers  + "" This issue can occur on Solaris as DSM thread get stuck in connectForServer() call, and hence not recovering any newly started server This may be beacuase of tcp_ip_abort_cinterval kernal level property on solaris which has 3 minutes as a default value"",
//         (System.currentTimeMillis() - start) < maxWaitTime);
//     try {
//       Thread.yield();
//         synchronized(delayLock) {delayLock.wait(2000);}
//     }
//     catch (InterruptedException ie) {
//       fail(""Interrupted while waiting "", ie);
//     }
//   }
//   start = System.currentTimeMillis();
}",True
"  public static void verifyDeadAndLiveServers(final int expectedDeadServers, final int expectedLiveServers) {
    WaitCriterion wc = new WaitCriterion() {
      @Override
      public boolean done() {
        return pool.getConnectedServerCount() == expectedLiveServers;
      }
      @Override
      public String description() {
        return ""waiting for pool.getConnectedServerCount() == expectedLiveServer"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);
  }",False
"      public static void verifyInterestRegistration()
      {
    try {
      WaitCriterion wc = new WaitCriterion() {
        String excuse;
        public boolean done() {
          return cache.getBridgeServers().size() == 1;
        }
        public String description() {
          return excuse;
        }
      };
      DistributedTestCase.waitForCriterion(wc, MAX_WAIT, 1000, true);

      BridgeServerImpl bs = (BridgeServerImpl)cache.getBridgeServers()
          .iterator().next();
      assertNotNull(bs);
      assertNotNull(bs.getAcceptor());
      assertNotNull(bs.getAcceptor().getCacheClientNotifier());
      final CacheClientNotifier ccn = bs.getAcceptor().getCacheClientNotifier();
      wc = new WaitCriterion() {
        String excuse;
        public boolean done() {
          return ccn.getClientProxies().size() > 0;
        }
        public String description() {
          return excuse;
        }
      };
      DistributedTestCase.waitForCriterion(wc, MAX_WAIT, 1000, true);

      Iterator iter_prox = ccn.getClientProxies().iterator();

      if (iter_prox.hasNext()) {
        final CacheClientProxy ccp =(CacheClientProxy)iter_prox.next();
        wc = new WaitCriterion() {
          String excuse;
          public boolean done() {
            Set keysMap = (Set)ccp.cils[RegisterInterestTracker.interestListIndex]
              .getProfile(Region.SEPARATOR + REGION_NAME)
              .getKeysOfInterestFor(ccp.getProxyID());
            return keysMap != null && keysMap.size() == 2;
          }
          public String description() {
            return excuse;
          }
        };
        DistributedTestCase.waitForCriterion(wc, MAX_WAIT, 1000, true);

        Set keysMap = (Set)ccp.cils[RegisterInterestTracker.interestListIndex]
          .getProfile( Region.SEPARATOR + REGION_NAME)
          .getKeysOfInterestFor(ccp.getProxyID());
        assertNotNull(keysMap);
        assertEquals(2, keysMap.size());
        assertTrue(keysMap.contains(k1));
        assertTrue(keysMap.contains(k2));
      }
    }
    catch (Exception ex) {
      fail(""while setting verifyInterestRegistration  "" + ex);
    }
  }",True
"  public static void verifyInterestRegistration() {
    WaitCriterion wc = new WaitCriterion() {
      @Override
      public boolean done() {
        return cache.getBridgeServers().size() == 1;
      }
      @Override
      public String description() {
        return ""waiting for cache.getBridgeServers().size() == 1"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);

    BridgeServerImpl bs = (BridgeServerImpl) cache.getBridgeServers().iterator().next();
    assertNotNull(bs);
    assertNotNull(bs.getAcceptor());
    assertNotNull(bs.getAcceptor().getCacheClientNotifier());
    final CacheClientNotifier ccn = bs.getAcceptor().getCacheClientNotifier();
    
    wc = new WaitCriterion() {
      @Override
      public boolean done() {
        return ccn.getClientProxies().size() > 0;
      }
      @Override
      public String description() {
        return ""waiting for ccn.getClientProxies().size() > 0"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);

    Iterator iter_prox = ccn.getClientProxies().iterator();

    if (iter_prox.hasNext()) {
      final CacheClientProxy ccp = (CacheClientProxy) iter_prox.next();
      
      wc = new WaitCriterion() {
        @Override
        public boolean done() {
          Set keysMap = (Set) ccp.cils[RegisterInterestTracker.interestListIndex]
              .getProfile(Region.SEPARATOR + REGION_NAME)
              .getKeysOfInterestFor(ccp.getProxyID());
          return keysMap != null && keysMap.size() == 2;
        }
        @Override
        public String description() {
          return ""waiting for keys of interest to include 2 keys"";
        }
      };
      DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);

      Set keysMap = (Set) ccp.cils[RegisterInterestTracker.interestListIndex].getProfile(Region.SEPARATOR + REGION_NAME)
          .getKeysOfInterestFor(ccp.getProxyID());
      assertNotNull(keysMap);
      assertEquals(2, keysMap.size());
      assertTrue(keysMap.contains(k1));
      assertTrue(keysMap.contains(k2));
    }
  }",False
"    public static void createEntriesK1andK2OnServer()
    {
      try {
        Region r1 = cache.getRegion(Region.SEPARATOR+ REGION_NAME);
        assertNotNull(r1);
        if (!r1.containsKey(k1)) {
          r1.create(k1, server_k1);
        }
        if (!r1.containsKey(k2)) {
          r1.create(k2, server_k2);
        }
        assertEquals(r1.getEntry(k1).getValue(), server_k1);
        assertEquals(r1.getEntry(k2).getValue(), server_k2);
      }
      catch (Exception ex) {
        fail(""failed while createEntries()"", ex);
      }
    }",True
"  public static void createEntriesK1andK2OnServer() {
    Region r1 = cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r1);
    if (!r1.containsKey(k1)) {
      r1.create(k1, server_k1);
    }
    if (!r1.containsKey(k2)) {
      r1.create(k2, server_k2);
    }
    assertEquals(r1.getEntry(k1).getValue(), server_k1);
    assertEquals(r1.getEntry(k2).getValue(), server_k2);
  }",False
"  public static Integer createServerCache() throws Exception
  {
    new HAInterestBaseTest(""temp"").createCache(new Properties());
    AttributesFactory factory = new AttributesFactory();
    factory.setScope(Scope.DISTRIBUTED_ACK);
    factory.setEnableBridgeConflation(true);
    factory.setMirrorType(MirrorType.KEYS_VALUES);
    factory.setConcurrencyChecksEnabled(true);
    cache.createRegion(REGION_NAME, factory.create());

    BridgeServer server = cache.addBridgeServer();
    int port = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET) ;
    server.setPort(port);
    server.setMaximumTimeBetweenPings(180000);
    // ensures updates to be sent instead of invalidations
    server.setNotifyBySubscription(true);
    server.start();
    return new Integer(server.getPort());

  }",True
"  public static Integer createServerCache() throws Exception {
    new HAInterestBaseTest(""temp"").createCache(new Properties());
    AttributesFactory factory = new AttributesFactory();
    factory.setScope(Scope.DISTRIBUTED_ACK);
    factory.setEnableBridgeConflation(true);
    factory.setMirrorType(MirrorType.KEYS_VALUES);
    factory.setConcurrencyChecksEnabled(true);
    cache.createRegion(REGION_NAME, factory.create());

    BridgeServer server = cache.addBridgeServer();
    int port = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    server.setPort(port);
    server.setMaximumTimeBetweenPings(180000);
    // ensures updates to be sent instead of invalidations
    server.setNotifyBySubscription(true);
    server.start();
    return new Integer(server.getPort());
  }",False
"  public void tearDown2() throws Exception
  {
        super.tearDown2();
    // close the clients first
    closeCache();

    // then close the servers
    server1.invoke(HAInterestBaseTest.class, ""closeCache"");
    server2.invoke(HAInterestBaseTest.class, ""closeCache"");
    server3.invoke(HAInterestBaseTest.class, ""closeCache"");
    CacheServerTestUtil.resetDisableShufflingOfEndpointsFlag();
  }",True
"  public void tearDown2() throws Exception {
    // close the clients first
    closeCache();

    // then close the servers
    server1.invoke(HAInterestBaseTest.class, ""closeCache"");
    server2.invoke(HAInterestBaseTest.class, ""closeCache"");
    server3.invoke(HAInterestBaseTest.class, ""closeCache"");
    CacheServerTestUtil.resetDisableShufflingOfEndpointsFlag();
  }",False
"    public static void registerK1AndK2OnPrimaryAndSecondaryAndVerifyResponse()
    {
      try {
        ServerLocation primary = pool.getPrimary();
        ServerLocation secondary = (ServerLocation)pool.getRedundants().get(0);
        LocalRegion r = (LocalRegion)cache.getRegion(Region.SEPARATOR+REGION_NAME);
        assertNotNull(r);
        ServerRegionProxy srp = new ServerRegionProxy(r);
        List list = new ArrayList();
        list.add(k1);
        list.add(k2);

        //Primary server
        List serverKeys1 = srp.registerInterestOn(primary, list,
          InterestType.KEY, InterestResultPolicy.KEYS, false, r.getAttributes()
              .getDataPolicy().ordinal);
        assertNotNull(serverKeys1);
        //expect serverKeys in response from primary
        List resultKeys =(List) serverKeys1.get(0) ;
        assertEquals(2,resultKeys.size());
        assertTrue(resultKeys.contains(k1));
        assertTrue(resultKeys.contains(k2));

        //Secondary server
        List serverKeys2 = srp.registerInterestOn(secondary, list,
          InterestType.KEY, InterestResultPolicy.KEYS, false, r.getAttributes()
              .getDataPolicy().ordinal);
        // if the list is null then it is empty
        if (serverKeys2 != null) {
          // no serverKeys in response from secondary
          assertTrue(serverKeys2.isEmpty());
        }


      }
      catch (Exception ex) {
        fail(""failed while region.registerK1AndK2OnPrimaryAndSecondaryAndVerifyResponse()"", ex);
      }
    }",True
"  public static void registerK1AndK2OnPrimaryAndSecondaryAndVerifyResponse() {
    ServerLocation primary = pool.getPrimary();
    ServerLocation secondary = (ServerLocation) pool.getRedundants().get(0);
    LocalRegion r = (LocalRegion) cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r);
    ServerRegionProxy srp = new ServerRegionProxy(r);
    List list = new ArrayList();
    list.add(k1);
    list.add(k2);

    // Primary server
    List serverKeys1 = srp.registerInterestOn(primary, list, InterestType.KEY, InterestResultPolicy.KEYS, false, r.getAttributes().getDataPolicy().ordinal);
    assertNotNull(serverKeys1);
    // expect serverKeys in response from primary
    List resultKeys = (List) serverKeys1.get(0);
    assertEquals(2, resultKeys.size());
    assertTrue(resultKeys.contains(k1));
    assertTrue(resultKeys.contains(k2));

    // Secondary server
    List serverKeys2 = srp.registerInterestOn(secondary, list, InterestType.KEY, InterestResultPolicy.KEYS, false, r.getAttributes().getDataPolicy().ordinal);
    // if the list is null then it is empty
    if (serverKeys2 != null) {
      // no serverKeys in response from secondary
      assertTrue(serverKeys2.isEmpty());
    }
  }",False
"  public void setUp() throws Exception
  {
    super.setUp();
    host = Host.getHost(0);
    server1 = host.getVM(0);
    server2 = host.getVM(1);
    server3 = host.getVM(2);
    CacheServerTestUtil.disableShufflingOfEndpoints();
    // start servers first
    PORT1 =  ((Integer) server1.invoke(HAInterestBaseTest.class, ""createServerCache"")).intValue();
    PORT2 =  ((Integer) server2.invoke(HAInterestBaseTest.class, ""createServerCache"")).intValue();
    PORT3 =  ((Integer) server3.invoke(HAInterestBaseTest.class, ""createServerCache"")).intValue();
    exceptionOccured = false;

  }",True
"  public void setUp() throws Exception {
    super.setUp();
    host = Host.getHost(0);
    server1 = host.getVM(0);
    server2 = host.getVM(1);
    server3 = host.getVM(2);
    CacheServerTestUtil.disableShufflingOfEndpoints();
    // start servers first
    PORT1 = ((Integer) server1.invoke(HAInterestBaseTest.class, ""createServerCache"")).intValue();
    PORT2 = ((Integer) server2.invoke(HAInterestBaseTest.class, ""createServerCache"")).intValue();
    PORT3 = ((Integer) server3.invoke(HAInterestBaseTest.class, ""createServerCache"")).intValue();
    exceptionOccured = false;
    addExpectedException(""java.net.ConnectException: Connection refused: connect"");
  }",False
"public static void waitForAfterRegistrationCallback()
{

  assertNotNull(cache);
  if (!isAfterRegistrationCallbackCalled) {
    synchronized (HAInterestBaseTest.class) {
      while (!isAfterRegistrationCallbackCalled) {
        try {
          HAInterestBaseTest.class.wait();
        }
        catch (InterruptedException e) {
          fail(""Test failed due to InterruptedException in waitForAfterRegistrationCallback()"");
        }
      }
    }
  }

}",True
"  public static void waitForAfterRegistrationCallback() throws InterruptedException {
    assertNotNull(cache);
    if (!isAfterRegistrationCallbackCalled) {
      synchronized (HAInterestBaseTest.class) {
        while (!isAfterRegistrationCallbackCalled) {
          HAInterestBaseTest.class.wait();
        }
      }
    }
  }",False
"  public static VM getServerVM(int port) {
    if (port == PORT1) {
      return server1;
    } else if (port == PORT2) {
      return server2;
    } else if (port == PORT3) {
      return server3;
    } else {
      fail(""expected port "" + port + "" to be ""
           + PORT1
           + "", or ""
           + PORT2
           + "", or ""
           + PORT3);
      return null;
    }
  }",True
"  public static VM getServerVM(int port) {
    if (port == PORT1) {
      return server1;
    } else if (port == PORT2) {
      return server2;
    } else if (port == PORT3) {
      return server3;
    } else {
      fail(""expected port "" + port + "" to be "" + PORT1 + "", or "" + PORT2 + "", or "" + PORT3);
      return null;
    }
  }",False
"  public static Integer createServerCacheWithLocalRegion() throws Exception
  {
    new HAInterestBaseTest(""temp"").createCache(new Properties());
    AttributesFactory factory = new AttributesFactory();
    factory.setScope(Scope.LOCAL);
    factory.setConcurrencyChecksEnabled(true);
    RegionAttributes attrs = factory.create();
    cache.createRegion(REGION_NAME, attrs);

    BridgeServer server = cache.addBridgeServer();
    int port = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET) ;
    server.setPort(port);
    // ensures updates to be sent instead of invalidations
    server.setNotifyBySubscription(true);
    server.setMaximumTimeBetweenPings(180000);
    server.start();
    return new Integer(server.getPort());

  }",True
"  public static Integer createServerCacheWithLocalRegion() throws Exception {
    new HAInterestBaseTest(""temp"").createCache(new Properties());
    AttributesFactory factory = new AttributesFactory();
    factory.setScope(Scope.LOCAL);
    factory.setConcurrencyChecksEnabled(true);
    RegionAttributes attrs = factory.create();
    cache.createRegion(REGION_NAME, attrs);

    BridgeServer server = cache.addBridgeServer();
    int port = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    server.setPort(port);
    // ensures updates to be sent instead of invalidations
    server.setNotifyBySubscription(true);
    server.setMaximumTimeBetweenPings(180000);
    server.start();
    return new Integer(server.getPort());
  }",False
"  public static void closeCache()
  {
   PoolImpl.AFTER_REGISTER_CALLBACK_FLAG = false ;
   PoolImpl.BEFORE_PRIMARY_IDENTIFICATION_FROM_BACKUP_CALLBACK_FLAG = false ;
   PoolImpl.BEFORE_RECOVER_INTEREST_CALLBACK_FLAG = false ;
   PoolImpl.BEFORE_REGISTER_CALLBACK_FLAG = false ;
   HAInterestBaseTest.isAfterRegistrationCallbackCalled = false ;
   HAInterestBaseTest.isBeforeInterestRecoveryCallbackCalled = false ;
   HAInterestBaseTest.isBeforeRegistrationCallbackCalled = false ;
    if (cache != null && !cache.isClosed()) {
      cache.close();
      cache.getDistributedSystem().disconnect();
    }
  }",True
"  public static void closeCache() {
    PoolImpl.AFTER_REGISTER_CALLBACK_FLAG = false;
    PoolImpl.BEFORE_PRIMARY_IDENTIFICATION_FROM_BACKUP_CALLBACK_FLAG = false;
    PoolImpl.BEFORE_RECOVER_INTEREST_CALLBACK_FLAG = false;
    PoolImpl.BEFORE_REGISTER_CALLBACK_FLAG = false;
    HAInterestBaseTest.isAfterRegistrationCallbackCalled = false;
    HAInterestBaseTest.isBeforeInterestRecoveryCallbackCalled = false;
    HAInterestBaseTest.isBeforeRegistrationCallbackCalled = false;
    if (cache != null && !cache.isClosed()) {
      cache.close();
      cache.getDistributedSystem().disconnect();
    }
    cache = null;
    pool = null;
    conn = null;
  }",False
"    public static void createEntriesK1andK2()
    {
      try {
        Region r1 = cache.getRegion(Region.SEPARATOR+ REGION_NAME);
        assertNotNull(r1);
        if (!r1.containsKey(k1)) {
          r1.create(k1, client_k1);
        }
        if (!r1.containsKey(k2)) {
          r1.create(k2, client_k2);
        }
        assertEquals(r1.getEntry(k1).getValue(), client_k1);
        assertEquals(r1.getEntry(k2).getValue(), client_k2);
      }
      catch (Exception ex) {
        fail(""failed while createEntries()"", ex);
      }
    }",True
"  public static void createEntriesK1andK2() {
    Region r1 = cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r1);
    if (!r1.containsKey(k1)) {
      r1.create(k1, client_k1);
    }
    if (!r1.containsKey(k2)) {
      r1.create(k2, client_k2);
    }
    assertEquals(r1.getEntry(k1).getValue(), client_k1);
    assertEquals(r1.getEntry(k2).getValue(), client_k2);
  }",False
"    public static void stopBothPrimaryAndSecondaryAndRegisterK1AndK2AndVerifyResponse()
    {
      try {
        LocalRegion r = (LocalRegion)cache.getRegion(Region.SEPARATOR+REGION_NAME);
        assertNotNull(r);
        ServerRegionProxy srp = new ServerRegionProxy(r);

        WaitCriterion wc = new WaitCriterion() {
          public boolean done() {
            return pool.getConnectedServerCount() == 3;
          }
          public String description() {
            return ""connected server count never became 3"";
          }
        };
        DistributedTestCase.waitForCriterion(wc, 30 * 1000, 1000, true);

        // close primaryEP
        VM backup = getBackupVM();
        getPrimaryVM().invoke(HAInterestBaseTest.class, ""stopServer"");
        //close secondary
        backup.invoke(HAInterestBaseTest.class, ""stopServer"");
        List list = new ArrayList();
        list.add(k1);
        list.add(k2);
        List serverKeys = srp.registerInterest(list, InterestType.KEY,
          InterestResultPolicy.KEYS, false,
          r.getAttributes().getDataPolicy().ordinal);

        assertNotNull(serverKeys);
        List resultKeys =(List) serverKeys.get(0) ;
        assertEquals(2,resultKeys.size());
        assertTrue(resultKeys.contains(k1));
        assertTrue(resultKeys.contains(k2));
       }
      catch (Exception ex) {
        fail(""failed while region.stopBothPrimaryAndSecondaryAndRegisterK1AndK2AndVerifyResponse()"", ex);
      }
    }",True
"  public static void stopBothPrimaryAndSecondaryAndRegisterK1AndK2AndVerifyResponse() {
    LocalRegion r = (LocalRegion) cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r);
    ServerRegionProxy srp = new ServerRegionProxy(r);

    WaitCriterion wc = new WaitCriterion() {
      @Override
      public boolean done() {
        return pool.getConnectedServerCount() == 3;
      }
      @Override
      public String description() {
        return ""connected server count never became 3"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);

    // close primaryEP
    VM backup = getBackupVM();
    getPrimaryVM().invoke(HAInterestBaseTest.class, ""stopServer"");
    // close secondary
    backup.invoke(HAInterestBaseTest.class, ""stopServer"");
    List list = new ArrayList();
    list.add(k1);
    list.add(k2);
    List serverKeys = srp.registerInterest(list, InterestType.KEY, InterestResultPolicy.KEYS, false, r.getAttributes().getDataPolicy().ordinal);

    assertNotNull(serverKeys);
    List resultKeys = (List) serverKeys.get(0);
    assertEquals(2, resultKeys.size());
    assertTrue(resultKeys.contains(k1));
    assertTrue(resultKeys.contains(k2));
  }",False
" public static void setBridgeObserverForBeforeInterestRecoveryFailure()
 {
   PoolImpl.BEFORE_RECOVER_INTEREST_CALLBACK_FLAG = true;
   BridgeObserverHolder.setInstance(new BridgeObserverAdapter() {
     public void beforeInterestRecovery()
     {
       synchronized (HAInterestBaseTest.class) {
        Thread t = new Thread (){
       public void run(){
         getBackupVM().invoke(HAInterestBaseTest.class, ""startServer"");
         getPrimaryVM().invoke(HAInterestBaseTest.class, ""stopServer"");
     }
     };
     t.start();
     try {
       DistributedTestCase.join(t, 30 * 1000, getLogWriter());
     }catch(Exception ignore) {
       exceptionOccured= true;
     }
         HAInterestBaseTest.isBeforeInterestRecoveryCallbackCalled = true;
         HAInterestBaseTest.class.notify();
         PoolImpl.BEFORE_RECOVER_INTEREST_CALLBACK_FLAG = false;
       }
     }
   });
 }",True
"  public static void setBridgeObserverForBeforeInterestRecoveryFailure() {
    PoolImpl.BEFORE_RECOVER_INTEREST_CALLBACK_FLAG = true;
    BridgeObserverHolder.setInstance(new BridgeObserverAdapter() {
      public void beforeInterestRecovery() {
        synchronized (HAInterestBaseTest.class) {
          Thread t = new Thread() {
            public void run() {
              getBackupVM().invoke(HAInterestBaseTest.class, ""startServer"");
              getPrimaryVM().invoke(HAInterestBaseTest.class, ""stopServer"");
            }
          };
          t.start();
          try {
            DistributedTestCase.join(t, 30 * 1000, getLogWriter());
          } catch (Exception ignore) {
            exceptionOccured = true;
          }
          HAInterestBaseTest.isBeforeInterestRecoveryCallbackCalled = true;
          HAInterestBaseTest.class.notify();
          PoolImpl.BEFORE_RECOVER_INTEREST_CALLBACK_FLAG = false;
        }
      }
    });
  }",False
"    public static void verifyDispatcherIsAlive()
    {
    try {
      assertEquals(""More than one BridgeServer"", 1, cache.getBridgeServers()
          .size());
      WaitCriterion wc = new WaitCriterion() {
        String excuse;
        public boolean done() {
          return cache.getBridgeServers().size() == 1;
        }
        public String description() {
          return excuse;
        }
      };
      DistributedTestCase.waitForCriterion(wc, MAX_WAIT, 1000, true);
      
      BridgeServerImpl bs = (BridgeServerImpl)cache.getBridgeServers()
          .iterator().next();
      assertNotNull(bs);
      assertNotNull(bs.getAcceptor());
      assertNotNull(bs.getAcceptor().getCacheClientNotifier());
      final CacheClientNotifier ccn = bs.getAcceptor().getCacheClientNotifier();

      wc = new WaitCriterion() {
        String excuse;
        public boolean done() {
          return ccn.getClientProxies().size() > 0;
        }
        public String description() {
          return excuse;
        }
      };
      DistributedTestCase.waitForCriterion(wc, MAX_WAIT, 1000, true);

      wc = new WaitCriterion() {
        String excuse;
        Iterator iter_prox;
        CacheClientProxy proxy;
        public boolean done() {
          iter_prox = ccn.getClientProxies().iterator();
          if(iter_prox.hasNext()) {
            proxy = (CacheClientProxy)iter_prox.next();
            return proxy._messageDispatcher.isAlive();
          }
          else {
            return false;
          }         
        }
        public String description() {
          return excuse;
        }
      };
      DistributedTestCase.waitForCriterion(wc, MAX_WAIT, 1000, true);
    }
    catch (Exception ex) {
      fail(""while setting verifyDispatcherIsAlive  "" + ex);
    }
  }",True
"  public static void verifyDispatcherIsAlive() {
    assertEquals(""More than one BridgeServer"", 1, cache.getBridgeServers().size());
    
    WaitCriterion wc = new WaitCriterion() {
      @Override
      public boolean done() {
        return cache.getBridgeServers().size() == 1;
      }
      @Override
      public String description() {
        return ""waiting for cache.getBridgeServers().size() == 1"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);

    BridgeServerImpl bs = (BridgeServerImpl) cache.getBridgeServers().iterator().next();
    assertNotNull(bs);
    assertNotNull(bs.getAcceptor());
    assertNotNull(bs.getAcceptor().getCacheClientNotifier());
    final CacheClientNotifier ccn = bs.getAcceptor().getCacheClientNotifier();

    wc = new WaitCriterion() {
      @Override
      public boolean done() {
        return ccn.getClientProxies().size() > 0;
      }
      @Override
      public String description() {
        return ""waiting for ccn.getClientProxies().size() > 0"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);

    wc = new WaitCriterion() {
      Iterator iter_prox;
      CacheClientProxy proxy;

      @Override
      public boolean done() {
        iter_prox = ccn.getClientProxies().iterator();
        if (iter_prox.hasNext()) {
          proxy = (CacheClientProxy) iter_prox.next();
          return proxy._messageDispatcher.isAlive();
        } else {
          return false;
        }
      }

      @Override
      public String description() {
        return ""waiting for CacheClientProxy _messageDispatcher to be alive"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);
  }",False
"public static void setBridgeObserverForBeforeRegistration(final VM vm)
{
  PoolImpl.BEFORE_REGISTER_CALLBACK_FLAG = true;
  BridgeObserverHolder.setInstance(new BridgeObserverAdapter() {
    public void beforeInterestRegistration()
    {
      synchronized (HAInterestBaseTest.class) {
        vm.invoke(HAInterestBaseTest.class, ""startServer"");
        HAInterestBaseTest.isBeforeRegistrationCallbackCalled = true;
        HAInterestBaseTest.class.notify();
        PoolImpl.BEFORE_REGISTER_CALLBACK_FLAG = false;
      }
    }
  });
}",True
"  public static void setBridgeObserverForBeforeRegistration(final VM vm) {
    PoolImpl.BEFORE_REGISTER_CALLBACK_FLAG = true;
    BridgeObserverHolder.setInstance(new BridgeObserverAdapter() {
      public void beforeInterestRegistration() {
        synchronized (HAInterestBaseTest.class) {
          vm.invoke(HAInterestBaseTest.class, ""startServer"");
          HAInterestBaseTest.isBeforeRegistrationCallbackCalled = true;
          HAInterestBaseTest.class.notify();
          PoolImpl.BEFORE_REGISTER_CALLBACK_FLAG = false;
        }
      }
    });
  }",False
" public static void unSetBridgeObserverForRegistrationCallback()
{
  synchronized (HAInterestBaseTest.class) {
    PoolImpl.BEFORE_REGISTER_CALLBACK_FLAG = false;
    PoolImpl.AFTER_REGISTER_CALLBACK_FLAG = false ;
    HAInterestBaseTest.isBeforeRegistrationCallbackCalled = false;
    HAInterestBaseTest.isAfterRegistrationCallbackCalled = false ;
  }

}",True
"  public static void unSetBridgeObserverForRegistrationCallback() {
    synchronized (HAInterestBaseTest.class) {
      PoolImpl.BEFORE_REGISTER_CALLBACK_FLAG = false;
      PoolImpl.AFTER_REGISTER_CALLBACK_FLAG = false;
      HAInterestBaseTest.isBeforeRegistrationCallbackCalled = false;
      HAInterestBaseTest.isAfterRegistrationCallbackCalled = false;
    }
  }",False
"    public static void startServer()
    {
    try {
      Cache c = CacheFactory.getAnyInstance();
      assertEquals(""More than one BridgeServer"", 1, c.getBridgeServers().size());
      BridgeServerImpl bs = (BridgeServerImpl) c.getBridgeServers().iterator().next();
      assertNotNull(bs);
      bs.start();
    }
      catch (Exception ex) {
        fail(""while startServer()  "" + ex);
      }
    }",True
"  public static void startServer() throws IOException {
    Cache c = CacheFactory.getAnyInstance();
    assertEquals(""More than one BridgeServer"", 1, c.getBridgeServers().size());
    BridgeServerImpl bs = (BridgeServerImpl) c.getBridgeServers().iterator().next();
    assertNotNull(bs);
    bs.start();
  }",False
"  public static void createClientPoolCacheWithSmallRetryInterval(String testName,String host) throws Exception
  {
    Properties props = new Properties();
    props.setProperty(DistributionConfig.MCAST_PORT_NAME, ""0"");
    props.setProperty(DistributionConfig.LOCATORS_NAME, """");
    new HAInterestBaseTest(""temp"").createCache(props);
    CacheServerTestUtil.disableShufflingOfEndpoints();
    PoolImpl p;
    try {
      p = (PoolImpl)PoolManager.createFactory()
        .addServer(host, PORT1)
        .addServer(host, PORT2)
        .setSubscriptionEnabled(true)
        .setSubscriptionRedundancy(-1)
        .setReadTimeout(1000)
        .setSocketBufferSize(32768)
        .setMinConnections(6)
        .setPingInterval(200)
        // .setRetryInterval(200)
        // retryAttempts 3
        .create(""HAInterestBaseTestPool"");
    } finally {
      CacheServerTestUtil.enableShufflingOfEndpoints();
    }
    AttributesFactory factory = new AttributesFactory();
    factory.setScope(Scope.LOCAL);
    factory.setConcurrencyChecksEnabled(true);
    factory.setPoolName(p.getName());

    cache.createRegion(REGION_NAME, factory.create());

    pool = p;
    conn = pool.acquireConnection();
    assertNotNull(conn);
  }",True
"  public static void createClientPoolCacheWithSmallRetryInterval(String testName, String host) throws Exception {
    Properties props = new Properties();
    props.setProperty(DistributionConfig.MCAST_PORT_NAME, ""0"");
    props.setProperty(DistributionConfig.LOCATORS_NAME, """");
    new HAInterestBaseTest(""temp"").createCache(props);
    CacheServerTestUtil.disableShufflingOfEndpoints();
    PoolImpl p;
    try {
      p = (PoolImpl) PoolManager.createFactory()
          .addServer(host, PORT1)
          .addServer(host, PORT2)
          .setSubscriptionEnabled(true)
          .setSubscriptionRedundancy(-1)
          .setReadTimeout(1000)
          .setSocketBufferSize(32768)
          .setMinConnections(6)
          .setPingInterval(200)
          // .setRetryInterval(200)
          // retryAttempts 3
          .create(""HAInterestBaseTestPool"");
    } finally {
      CacheServerTestUtil.enableShufflingOfEndpoints();
    }
    AttributesFactory factory = new AttributesFactory();
    factory.setScope(Scope.LOCAL);
    factory.setConcurrencyChecksEnabled(true);
    factory.setPoolName(p.getName());

    cache.createRegion(REGION_NAME, factory.create());

    pool = p;
    conn = pool.acquireConnection();
    assertNotNull(conn);
  }",False
"    public static void verifyDispatcherIsNotAlive()
    {
    try {
      WaitCriterion wc = new WaitCriterion() {
        String excuse;
        public boolean done() {
          return cache.getBridgeServers().size() == 1;
        }
        public String description() {
          return excuse;
        }
      };
      DistributedTestCase.waitForCriterion(wc, MAX_WAIT, 1000, true);

      BridgeServerImpl bs = (BridgeServerImpl)cache.getBridgeServers()
          .iterator().next();
      assertNotNull(bs);
      assertNotNull(bs.getAcceptor());
      assertNotNull(bs.getAcceptor().getCacheClientNotifier());
      final CacheClientNotifier ccn = bs.getAcceptor().getCacheClientNotifier();
      wc = new WaitCriterion() {
        String excuse;
        public boolean done() {
          return ccn.getClientProxies().size() > 0;
        }
        public String description() {
          return excuse;
        }
      };
      DistributedTestCase.waitForCriterion(wc, MAX_WAIT, 1000, true);

      Iterator iter_prox = ccn.getClientProxies().iterator();
      if (iter_prox.hasNext()) {
        CacheClientProxy proxy = (CacheClientProxy)iter_prox.next();
        assertFalse(""Dispatcher on secondary should not be alive"",
            proxy._messageDispatcher.isAlive());
      }

    }
    catch (Exception ex) {
      fail(""while setting verifyDispatcherIsNotAlive  "" + ex);
    }
  }",True
"  public static void verifyDispatcherIsNotAlive() {
    WaitCriterion wc = new WaitCriterion() {
      @Override
      public boolean done() {
        return cache.getBridgeServers().size() == 1;
      }
      @Override
      public String description() {
        return ""cache.getBridgeServers().size() == 1"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);

    BridgeServerImpl bs = (BridgeServerImpl) cache.getBridgeServers().iterator().next();
    assertNotNull(bs);
    assertNotNull(bs.getAcceptor());
    assertNotNull(bs.getAcceptor().getCacheClientNotifier());
    final CacheClientNotifier ccn = bs.getAcceptor().getCacheClientNotifier();
    
    wc = new WaitCriterion() {
      @Override
      public boolean done() {
        return ccn.getClientProxies().size() > 0;
      }
      @Override
      public String description() {
        return ""waiting for ccn.getClientProxies().size() > 0"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);

    Iterator iter_prox = ccn.getClientProxies().iterator();
    if (iter_prox.hasNext()) {
      CacheClientProxy proxy = (CacheClientProxy) iter_prox.next();
      assertFalse(""Dispatcher on secondary should not be alive"", proxy._messageDispatcher.isAlive());
    }
  }",False
"  public static int getServerPort(VM vm) {
    if (vm == server1) {
      return PORT1;
    } else if (vm == server2) {
      return PORT2;
    } else if (vm == server3) {
      return PORT3;
    } else {
      fail(""expected vm "" + vm + "" to be ""
           + server1
           + "", or ""
           + server2
           + "", or ""
           + server3);
      return -1;
    }
  }",True
"  public static int getServerPort(VM vm) {
    if (vm == server1) {
      return PORT1;
    } else if (vm == server2) {
      return PORT2;
    } else if (vm == server3) {
      return PORT3;
    } else {
      fail(""expected vm "" + vm + "" to be "" + server1 + "", or "" + server2 + "", or "" + server3);
      return -1;
    }
  }",False
"   public void testBothPrimaryAndSecondaryFailureInRegisterInterest() throws Exception{

     createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
     createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    //stop server1 and server2
    VM oldPrimary = getPrimaryVM();
    stopBothPrimaryAndSecondaryAndRegisterK1AndK2AndVerifyResponse();

    verifyDeadAndLiveServers(2,1);
    VM newPrimary = getPrimaryVM(oldPrimary);
    newPrimary.invoke(HAInterestBaseTest.class, ""verifyDispatcherIsAlive"");
    newPrimary.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
  }",True
"  public void testBothPrimaryAndSecondaryFailureInRegisterInterest() throws Exception {
    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    // stop server1 and server2
    VM oldPrimary = getPrimaryVM();
    stopBothPrimaryAndSecondaryAndRegisterK1AndK2AndVerifyResponse();

    verifyDeadAndLiveServers(2, 1);
    VM newPrimary = getPrimaryVM(oldPrimary);
    newPrimary.invoke(HAInterestBaseTest.class, ""verifyDispatcherIsAlive"");
    newPrimary.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
  }",False
"  public void testInterestRegistrationResponseOnBothPrimaryAndSecondary()throws Exception
  {

    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    //register interst and verify response
    registerK1AndK2OnPrimaryAndSecondaryAndVerifyResponse();

  }",True
"  public void testInterestRegistrationResponseOnBothPrimaryAndSecondary() throws Exception {
    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    // register interest and verify response
    registerK1AndK2OnPrimaryAndSecondaryAndVerifyResponse();
  }",False
"  public void testRERegistrationWillNotCreateDuplicateKeysOnServerInterstMaps() throws Exception{

    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    //register multiple times
    reRegisterK1AndK2();

    server1.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
    server2.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
    server3.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
  }",True
"  public void testRERegistrationWillNotCreateDuplicateKeysOnServerInterstMaps() throws Exception {
    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    // register multiple times
    reRegisterK1AndK2();

    server1.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
    server2.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
    server3.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
  }",False
"  public void testPrimaryFailureInRegisterInterest() throws Exception{

    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    //stop primary
    VM oldPrimary = getPrimaryVM();
    stopPrimaryAndRegisterK1AndK2AndVerifyResponse();
    // DSM
    verifyDeadAndLiveServers(1, 2);
    //new primary
    VM newPrimary = getPrimaryVM(oldPrimary);
    newPrimary.invoke(HAInterestBaseTest.class, ""verifyDispatcherIsAlive"");
    newPrimary.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
  }",True
"  public void testPrimaryFailureInRegisterInterest() throws Exception {
    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    // stop primary
    VM oldPrimary = getPrimaryVM();
    stopPrimaryAndRegisterK1AndK2AndVerifyResponse();
    // DSM
    verifyDeadAndLiveServers(1, 2);
    // new primary
    VM newPrimary = getPrimaryVM(oldPrimary);
    newPrimary.invoke(HAInterestBaseTest.class, ""verifyDispatcherIsAlive"");
    newPrimary.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
  }",False
"   public void testInterstRegistrationOnRecoveredEPbyDSM() throws Exception{
     
     addExpectedException(""SocketException"");

     createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
     createEntriesK1andK2();
     registerK1AndK2();
     server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
     server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
     server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"") ;
     
     server1.invoke(HAInterestBaseTest.class, ""stopServer"");
     server2.invoke(HAInterestBaseTest.class, ""stopServer"");
     server3.invoke(HAInterestBaseTest.class, ""stopServer"");
     //All servers are dead at this point , no primary in the system.
     verifyDeadAndLiveServers(3, 0);

     // now start one of the servers
     server2.invoke(HAInterestBaseTest.class, ""startServer"");
     verifyDeadAndLiveServers(2, 1);
     //verify that is it primary , and dispatcher is running
     server2.invoke(HAInterestBaseTest.class, ""verifyDispatcherIsAlive"");
     //verify that interest is registered on this recovered EP
     server2.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");

     // now start one more server ; this should be now secondary
     server1.invoke(HAInterestBaseTest.class, ""startServer"");
     verifyDeadAndLiveServers(1, 2);

     //verify that is it secondary , dispatcher should not be runnig
     server1.invoke(HAInterestBaseTest.class, ""verifyDispatcherIsNotAlive"");
     //verify that interest is registered on this recovered EP as well
     server1.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");

     // now start one more server ; this should be now secondary
     server3.invoke(HAInterestBaseTest.class, ""startServer"");
     verifyDeadAndLiveServers(0, 3);

     //verify that is it secondary , dispatcher should not be runnig
     server3.invoke(HAInterestBaseTest.class, ""verifyDispatcherIsNotAlive"");
     //verify that interest is registered on this recovered EP as well
     server3.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");

   }",True
"  public void testInterstRegistrationOnRecoveredEPbyDSM() throws Exception {
    addExpectedException(""SocketException"");

    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    registerK1AndK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");

    server1.invoke(HAInterestBaseTest.class, ""stopServer"");
    server2.invoke(HAInterestBaseTest.class, ""stopServer"");
    server3.invoke(HAInterestBaseTest.class, ""stopServer"");
    // All servers are dead at this point , no primary in the system.
    verifyDeadAndLiveServers(3, 0);

    // now start one of the servers
    server2.invoke(HAInterestBaseTest.class, ""startServer"");
    verifyDeadAndLiveServers(2, 1);
    // verify that is it primary , and dispatcher is running
    server2.invoke(HAInterestBaseTest.class, ""verifyDispatcherIsAlive"");
    // verify that interest is registered on this recovered EP
    server2.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");

    // now start one more server ; this should be now secondary
    server1.invoke(HAInterestBaseTest.class, ""startServer"");
    verifyDeadAndLiveServers(1, 2);

    // verify that is it secondary , dispatcher should not be runnig
    server1.invoke(HAInterestBaseTest.class, ""verifyDispatcherIsNotAlive"");
    // verify that interest is registered on this recovered EP as well
    server1.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");

    // now start one more server ; this should be now secondary
    server3.invoke(HAInterestBaseTest.class, ""startServer"");
    verifyDeadAndLiveServers(0, 3);

    // verify that is it secondary , dispatcher should not be runnig
    server3.invoke(HAInterestBaseTest.class, ""verifyDispatcherIsNotAlive"");
    // verify that interest is registered on this recovered EP as well
    server3.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
  }",False
"   public void testProbablePrimaryFailureInRegisterInterest()throws Exception{

     createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
     createEntriesK1andK2();
     server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
     server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
     server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"") ;

     VM oldPrimary = getPrimaryVM();
     stopPrimaryAndRegisterK1AndK2AndVerifyResponse();

     verifyDeadAndLiveServers(1,2);
     VM newPrimary = getPrimaryVM(oldPrimary);
     newPrimary.invoke(HAInterestBaseTest.class, ""verifyDispatcherIsAlive"");
     newPrimary.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
   }",True
"  public void testProbablePrimaryFailureInRegisterInterest() throws Exception {
    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");

    VM oldPrimary = getPrimaryVM();
    stopPrimaryAndRegisterK1AndK2AndVerifyResponse();

    verifyDeadAndLiveServers(1, 2);
    VM newPrimary = getPrimaryVM(oldPrimary);
    newPrimary.invoke(HAInterestBaseTest.class, ""verifyDispatcherIsAlive"");
    newPrimary.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
  }",False
"  public void testInterestRegistrationOnBothPrimaryAndSecondary()throws Exception
  {
    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    //register K1 and K2
    registerK1AndK2();
    server1.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
    server2.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
    server3.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
  }",True
"  public void testInterestRegistrationOnBothPrimaryAndSecondary() throws Exception {
    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    // register K1 and K2
    registerK1AndK2();
    server1.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
    server2.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
    server3.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
  }",False
"  public void testSecondaryFailureInRegisterInterest() throws Exception{
    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");

    VM primary = getPrimaryVM();
    stopSecondaryAndRegisterK1AndK2AndVerifyResponse();

    verifyDeadAndLiveServers(1, 2);
    //still primary
    primary.invoke(HAInterestBaseTest.class, ""verifyDispatcherIsAlive"");
    primary.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
  }",True
"  public void testSecondaryFailureInRegisterInterest() throws Exception {
    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");

    VM primary = getPrimaryVM();
    stopSecondaryAndRegisterK1AndK2AndVerifyResponse();

    verifyDeadAndLiveServers(1, 2);
    // still primary
    primary.invoke(HAInterestBaseTest.class, ""verifyDispatcherIsAlive"");
    primary.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
  }",False
"  public void testDSMDetectsServerLiveJustAfterInterestRegistration()throws Exception{

    createClientPoolCache(this.getName(),getServerHostName(server1.getHost()));

    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");

    VM backup = getBackupVM();
    backup.invoke(HAInterestBaseTest.class, ""stopServer"");
    verifyDeadAndLiveServers(1,2);

    setBridgeObserverForAfterRegistration(backup);
    try {
      registerK1AndK2();
      waitForAfterRegistrationCallback();
    } finally {
      unSetBridgeObserverForRegistrationCallback();
    }

    server1.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
    server2.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
    server3.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");

  }",True
"  public void testDSMDetectsServerLiveJustAfterInterestRegistration() throws Exception {
    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));

    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");

    VM backup = getBackupVM();
    backup.invoke(HAInterestBaseTest.class, ""stopServer"");
    verifyDeadAndLiveServers(1, 2);

    setBridgeObserverForAfterRegistration(backup);
    try {
      registerK1AndK2();
      waitForAfterRegistrationCallback();
    } finally {
      unSetBridgeObserverForRegistrationCallback();
    }

    server1.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
    server2.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
    server3.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
  }",False
" public void testBug35945()throws Exception{

   PORT1 =  ((Integer) server1.invoke(HAInterestBaseTest.class, ""createServerCache"")).intValue();
   server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
   createClientPoolCacheConnectionToSingleServer(this.getName(),getServerHostName(server1.getHost()));
   registerK1AndK2();
   verifyRefreshedEntriesFromServer();

   server1.invoke(HAInterestBaseTest.class, ""stopServer"");
   verifyDeadAndLiveServers(1, 0);
   // put on stopped server
   server1.invoke(HAInterestBaseTest.class, ""putK1andK2"");
   // spawn a thread to put on server , which will acquire a lock on entry 
   setBridgeObserverForBeforeInterestRecovery();
   server1.invoke(HAInterestBaseTest.class, ""startServer"");
   verifyDeadAndLiveServers(0, 1);
   waitForBeforeInterestRecoveryCallBack();
   // verify updated value of k1 as a refreshEntriesFromServer
   final Region r1 = cache.getRegion(Region.SEPARATOR+ REGION_NAME);
   assertNotNull(r1);
   
   WaitCriterion wc = new WaitCriterion() {
     String excuse;
     public boolean done() {
       Region.Entry e1 = r1.getEntry(k1);
       Region.Entry e2 = r1.getEntry(k2);
       if (e1 == null || !server_k1_updated.equals(e1.getValue())) {
         excuse=""k1=""+(e1==null?""null"":e1.getValue());
         return false;
       }
       if (e2 == null || !server_k2.equals(e2.getValue())) {
         excuse=""k2=""+(e2==null?""null"":e2.getValue());
         return false;
       }
       return true;
     }
     public String description() {
       return excuse;
     }
   };
   DistributedTestCase.waitForCriterion(wc, 30 * 1000, 1000, true);
  // assertEquals(server_k2, r1.getEntry(k2).getValue());
  // assertEquals(server_k1_updated ,r1.getEntry(k1).getValue());
 }",True
"  public void testBug35945() throws Exception {
    PORT1 = ((Integer) server1.invoke(HAInterestBaseTest.class, ""createServerCache"")).intValue();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    createClientPoolCacheConnectionToSingleServer(this.getName(), getServerHostName(server1.getHost()));
    registerK1AndK2();
    verifyRefreshedEntriesFromServer();

    server1.invoke(HAInterestBaseTest.class, ""stopServer"");
    verifyDeadAndLiveServers(1, 0);
    // put on stopped server
    server1.invoke(HAInterestBaseTest.class, ""putK1andK2"");
    // spawn a thread to put on server , which will acquire a lock on entry
    setBridgeObserverForBeforeInterestRecovery();
    server1.invoke(HAInterestBaseTest.class, ""startServer"");
    verifyDeadAndLiveServers(0, 1);
    waitForBeforeInterestRecoveryCallBack();
    // verify updated value of k1 as a refreshEntriesFromServer
    final Region r1 = cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r1);

    WaitCriterion wc = new WaitCriterion() {
      private String excuse;

      @Override
      public boolean done() {
        Region.Entry e1 = r1.getEntry(k1);
        Region.Entry e2 = r1.getEntry(k2);
        if (e1 == null || !server_k1_updated.equals(e1.getValue())) {
          excuse = ""k1="" + (e1 == null ? ""null"" : e1.getValue());
          return false;
        }
        if (e2 == null || !server_k2.equals(e2.getValue())) {
          excuse = ""k2="" + (e2 == null ? ""null"" : e2.getValue());
          return false;
        }
        return true;
      }

      @Override
      public String description() {
        return excuse;
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);
  }",False
"  public void testPrimaryFailureInUNregisterInterest()throws Exception{
    createClientPoolCache(this.getName(),getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");

    registerK1AndK2();

    VM oldPrimary = getPrimaryVM();
    stopPrimaryAndUnregisterRegisterK1();

    verifyDeadAndLiveServers(1,2);

    VM newPrimary = getPrimaryVM(oldPrimary);
    newPrimary.invoke(HAInterestBaseTest.class, ""verifyDispatcherIsAlive"");
    //primary
    newPrimary.invoke(HAInterestBaseTest.class, ""verifyInterestUNRegistration"");
    //secondary
    getBackupVM().invoke(HAInterestBaseTest.class, ""verifyInterestUNRegistration"");
  }",True
"  public void testPrimaryFailureInUNregisterInterest() throws Exception {
    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");

    registerK1AndK2();

    VM oldPrimary = getPrimaryVM();
    stopPrimaryAndUnregisterRegisterK1();

    verifyDeadAndLiveServers(1, 2);

    VM newPrimary = getPrimaryVM(oldPrimary);
    newPrimary.invoke(HAInterestBaseTest.class, ""verifyDispatcherIsAlive"");
    // primary
    newPrimary.invoke(HAInterestBaseTest.class, ""verifyInterestUNRegistration"");
    // secondary
    getBackupVM().invoke(HAInterestBaseTest.class, ""verifyInterestUNRegistration"");
  }",False
"  public void testSecondaryFailureInUNRegisterInterest()throws Exception{

    createClientPoolCache(this.getName(),getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    registerK1AndK2();
    VM stoppedBackup = stopSecondaryAndUNregisterK1();
    verifyDeadAndLiveServers(1,2);
    //still primary
    getPrimaryVM().invoke(HAInterestBaseTest.class, ""verifyDispatcherIsAlive"");
    //primary
    getPrimaryVM().invoke(HAInterestBaseTest.class, ""verifyInterestUNRegistration"");
    //secondary
    getBackupVM(stoppedBackup).invoke(HAInterestBaseTest.class, ""verifyInterestUNRegistration"");
  }",True
"  public void testSecondaryFailureInUNRegisterInterest() throws Exception {
    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    registerK1AndK2();
    VM stoppedBackup = stopSecondaryAndUNregisterK1();
    verifyDeadAndLiveServers(1, 2);
    // still primary
    getPrimaryVM().invoke(HAInterestBaseTest.class, ""verifyDispatcherIsAlive"");
    // primary
    getPrimaryVM().invoke(HAInterestBaseTest.class, ""verifyInterestUNRegistration"");
    // secondary
    getBackupVM(stoppedBackup).invoke(HAInterestBaseTest.class, ""verifyInterestUNRegistration"");
  }",False
"  public void testInterestRecoveryFailure()throws Exception{

   PORT1 =  ((Integer) server1.invoke(HAInterestBaseTest.class, ""createServerCache"")).intValue();
   server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
   PORT2 =  ((Integer) server2.invoke(HAInterestBaseTest.class, ""createServerCache"")).intValue();
   server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
   createClientPoolCacheWithSmallRetryInterval(this.getName(),getServerHostName(server1.getHost()));
   registerK1AndK2();
   verifyRefreshedEntriesFromServer();
   VM backup = getBackupVM();
   VM primary = getPrimaryVM();
   cache.getLogger().info(""<ExpectedException action=add>"" + ""Server unreachable"" +
       ""</ExpectedException>"");
   try {
     backup.invoke(HAInterestBaseTest.class, ""stopServer"");
     primary.invoke(HAInterestBaseTest.class, ""stopServer"");
     verifyDeadAndLiveServers(2, 0);
   } finally {
     cache.getLogger().info(""<ExpectedException action=remove>"" + ""Server unreachable"" +
         ""</ExpectedException>"");
   }
   primary.invoke(HAInterestBaseTest.class, ""putK1andK2"");
   setBridgeObserverForBeforeInterestRecoveryFailure();
   primary.invoke(HAInterestBaseTest.class, ""startServer"");
   waitForBeforeInterestRecoveryCallBack();
   if(exceptionOccured) {
     fail(""The DSM could not ensure that server 1 is started & serevr 2 is stopped"");
   }
   final Region r1 = cache.getRegion(Region.SEPARATOR+ REGION_NAME);
   assertNotNull(r1);
   //pause(10000);
   WaitCriterion wc = new WaitCriterion() {
     String excuse;
     public boolean done() {
       Region.Entry e1 = r1.getEntry(k1);
       Region.Entry e2 = r1.getEntry(k2);
       if (e1 == null) {
         excuse = ""Entry for k1 still null"";
         return false;
       }
       if (e2 == null) {
         excuse = ""Entry for k2 still null"";
         return false;
       }
       if (!(server_k1.equals(e1.getValue()))) {
         excuse = ""Value for k1 wrong"";
         return false;
       }
       if (!(server_k2.equals(e2.getValue()))) {
         excuse = ""Value for k2 wrong"";
         return false;
       }
       return true;
     }
     public String description() {
       return excuse;
     }
   };
   DistributedTestCase.waitForCriterion(wc, 2 * 60 * 1000, 1000, true);
 }",True
"  public void testInterestRecoveryFailure() throws Exception {
    addExpectedException(""Server unreachable"");
    
    PORT1 = ((Integer) server1.invoke(HAInterestBaseTest.class, ""createServerCache"")).intValue();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    PORT2 = ((Integer) server2.invoke(HAInterestBaseTest.class, ""createServerCache"")).intValue();
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    createClientPoolCacheWithSmallRetryInterval(this.getName(), getServerHostName(server1.getHost()));
    registerK1AndK2();
    verifyRefreshedEntriesFromServer();
    VM backup = getBackupVM();
    VM primary = getPrimaryVM();

    backup.invoke(HAInterestBaseTest.class, ""stopServer"");
    primary.invoke(HAInterestBaseTest.class, ""stopServer"");
    verifyDeadAndLiveServers(2, 0);

    primary.invoke(HAInterestBaseTest.class, ""putK1andK2"");
    setBridgeObserverForBeforeInterestRecoveryFailure();
    primary.invoke(HAInterestBaseTest.class, ""startServer"");
    waitForBeforeInterestRecoveryCallBack();
    if (exceptionOccured) {
      fail(""The DSM could not ensure that server 1 is started & serevr 2 is stopped"");
    }
    final Region r1 = cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r1);
    
    WaitCriterion wc = new WaitCriterion() {
      private String excuse;

      @Override
      public boolean done() {
        Region.Entry e1 = r1.getEntry(k1);
        Region.Entry e2 = r1.getEntry(k2);
        if (e1 == null) {
          excuse = ""Entry for k1 still null"";
          return false;
        }
        if (e2 == null) {
          excuse = ""Entry for k2 still null"";
          return false;
        }
        if (!(server_k1.equals(e1.getValue()))) {
          excuse = ""Value for k1 wrong"";
          return false;
        }
        if (!(server_k2.equals(e2.getValue()))) {
          excuse = ""Value for k2 wrong"";
          return false;
        }
        return true;
      }

      @Override
      public String description() {
        return excuse;
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);
  }",False
" public void testRefreshEntriesFromPrimaryWhenDSMDetectsServerLive()throws Exception{

 PORT1 =  ((Integer) server1.invoke(HAInterestBaseTest.class, ""createServerCache"")).intValue();
 server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
 createClientPoolCacheConnectionToSingleServer(this.getName(),getServerHostName(server1.getHost()));
 registerK1AndK2();
 verifyRefreshedEntriesFromServer();
    // expected ServerConnectivityException
    final ExpectedException expectedEx = addExpectedException(
        ServerConnectivityException.class.getName());
 server1.invoke(HAInterestBaseTest.class, ""stopServer"");
 verifyDeadAndLiveServers(1, 0);
 server1.invoke(HAInterestBaseTest.class, ""putK1andK2"");
 server1.invoke(HAInterestBaseTest.class, ""startServer"");
 verifyDeadAndLiveServers(0, 1);
 final Region r1 = cache.getRegion(Region.SEPARATOR+ REGION_NAME);
 assertNotNull(r1);   
 
 WaitCriterion wc = new WaitCriterion() {
   String excuse;
   public boolean done() {
     Region.Entry e1;
     Region.Entry e2;

     try {
       e1 = r1.getEntry(k1);
       if (e1 == null) {
         excuse = ""Entry for k1 is null"";
         return false;
       }
     }
     catch (EntryDestroyedException e) {
       excuse = ""Entry destroyed"";
       return false;
     }
     if (!server_k1.equals(e1.getValue())) {
       excuse = ""e1 value is not server_k1"";
       return false;
     }
     try {
       e2 = r1.getEntry(k2);
       if (e2 == null) {
         excuse = ""Entry for k2 is null"";
         return false;
       }
     }
     catch (EntryDestroyedException e) {
       excuse = ""Entry destroyed"";
       return false;
     }
     if (!server_k2.equals(e2.getValue())) {
       excuse = ""e2 value is not server_k2"";
       return false;
     }
     return true;
   }
   public String description() {
     return excuse;
   }
 };
 DistributedTestCase.waitForCriterion(wc, 120 * 1000, 1000, true);

 expectedEx.remove();

 //assertEquals(server_k2, r1.getEntry(k2).getValue());
 //assertEquals(server_k1 ,r1.getEntry(k1).getValue());
}",True
"  public void testRefreshEntriesFromPrimaryWhenDSMDetectsServerLive() throws Exception {
    addExpectedException(ServerConnectivityException.class.getName());
    
    PORT1 = ((Integer) server1.invoke(HAInterestBaseTest.class, ""createServerCache"")).intValue();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    createClientPoolCacheConnectionToSingleServer(this.getName(), getServerHostName(server1.getHost()));
    registerK1AndK2();
    verifyRefreshedEntriesFromServer();

    server1.invoke(HAInterestBaseTest.class, ""stopServer"");
    verifyDeadAndLiveServers(1, 0);
    server1.invoke(HAInterestBaseTest.class, ""putK1andK2"");
    server1.invoke(HAInterestBaseTest.class, ""startServer"");
    verifyDeadAndLiveServers(0, 1);
    final Region r1 = cache.getRegion(Region.SEPARATOR + REGION_NAME);
    assertNotNull(r1);

    WaitCriterion wc = new WaitCriterion() {
      private String excuse;

      @Override
      public boolean done() {
        Region.Entry e1;
        Region.Entry e2;

        try {
          e1 = r1.getEntry(k1);
          if (e1 == null) {
            excuse = ""Entry for k1 is null"";
            return false;
          }
        } catch (EntryDestroyedException e) {
          excuse = ""Entry destroyed"";
          return false;
        }
        if (!server_k1.equals(e1.getValue())) {
          excuse = ""e1 value is not server_k1"";
          return false;
        }
        try {
          e2 = r1.getEntry(k2);
          if (e2 == null) {
            excuse = ""Entry for k2 is null"";
            return false;
          }
        } catch (EntryDestroyedException e) {
          excuse = ""Entry destroyed"";
          return false;
        }
        if (!server_k2.equals(e2.getValue())) {
          excuse = ""e2 value is not server_k2"";
          return false;
        }
        return true;
      }

      @Override
      public String description() {
        return excuse;
      }
    };
    DistributedTestCase.waitForCriterion(wc, TIMEOUT_MILLIS, INTERVAL_MILLIS, true);
  }",False
"  public void testDSMDetectsServerLiveJustBeforeInterestRegistration()throws Exception{
    createClientPoolCache(this.getName(),getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    VM backup = getBackupVM();
    backup.invoke(HAInterestBaseTest.class, ""stopServer"");
    verifyDeadAndLiveServers(1, 2);
    setBridgeObserverForBeforeRegistration(backup);
    try {
      registerK1AndK2();
      waitForBeforeRegistrationCallback();
    } finally {
      unSetBridgeObserverForRegistrationCallback();
    }
    server1.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
    server2.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
    server3.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");

  }",True
"  public void testDSMDetectsServerLiveJustBeforeInterestRegistration() throws Exception {
    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));
    createEntriesK1andK2();
    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    VM backup = getBackupVM();
    backup.invoke(HAInterestBaseTest.class, ""stopServer"");
    verifyDeadAndLiveServers(1, 2);
    setBridgeObserverForBeforeRegistration(backup);
    try {
      registerK1AndK2();
      waitForBeforeRegistrationCallback();
    } finally {
      unSetBridgeObserverForRegistrationCallback();
    }
    server1.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
    server2.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
    server3.invoke(HAInterestBaseTest.class, ""verifyInterestRegistration"");
  }",False
" public void testGIIFromSecondaryWhenDSMDetectsServerLive()throws Exception{

   server1.invoke(HAInterestBaseTest.class, ""closeCache"");
   server2.invoke(HAInterestBaseTest.class, ""closeCache"");
   server3.invoke(HAInterestBaseTest.class, ""closeCache"");

   PORT1 =  ((Integer) server1.invoke(HAInterestBaseTest.class, ""createServerCacheWithLocalRegion"")).intValue();
   PORT2 =  ((Integer) server2.invoke(HAInterestBaseTest.class, ""createServerCacheWithLocalRegion"")).intValue();
   PORT3 =  ((Integer) server3.invoke(HAInterestBaseTest.class, ""createServerCacheWithLocalRegion"")).intValue();

   server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
   server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
   server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");

   createClientPoolCache(this.getName(),getServerHostName(server1.getHost()));

   VM backup1 = getBackupVM();
   VM backup2 = getBackupVM(backup1);
   backup1.invoke(HAInterestBaseTest.class, ""stopServer"");
   backup2.invoke(HAInterestBaseTest.class, ""stopServer"");
   verifyDeadAndLiveServers(2, 1);
   registerK1AndK2();
   verifyRefreshedEntriesFromServer();
   backup1.invoke(HAInterestBaseTest.class, ""putK1andK2"");
   backup1.invoke(HAInterestBaseTest.class, ""startServer"");
   verifyDeadAndLiveServers(1, 2);
   verifyRefreshedEntriesFromServer();
 }",True
"  public void testGIIFromSecondaryWhenDSMDetectsServerLive() throws Exception {
    server1.invoke(HAInterestBaseTest.class, ""closeCache"");
    server2.invoke(HAInterestBaseTest.class, ""closeCache"");
    server3.invoke(HAInterestBaseTest.class, ""closeCache"");

    PORT1 = ((Integer) server1.invoke(HAInterestBaseTest.class, ""createServerCacheWithLocalRegion"")).intValue();
    PORT2 = ((Integer) server2.invoke(HAInterestBaseTest.class, ""createServerCacheWithLocalRegion"")).intValue();
    PORT3 = ((Integer) server3.invoke(HAInterestBaseTest.class, ""createServerCacheWithLocalRegion"")).intValue();

    server1.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server2.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");
    server3.invoke(HAInterestBaseTest.class, ""createEntriesK1andK2"");

    createClientPoolCache(this.getName(), getServerHostName(server1.getHost()));

    VM backup1 = getBackupVM();
    VM backup2 = getBackupVM(backup1);
    backup1.invoke(HAInterestBaseTest.class, ""stopServer"");
    backup2.invoke(HAInterestBaseTest.class, ""stopServer"");
    verifyDeadAndLiveServers(2, 1);
    registerK1AndK2();
    verifyRefreshedEntriesFromServer();
    backup1.invoke(HAInterestBaseTest.class, ""putK1andK2"");
    backup1.invoke(HAInterestBaseTest.class, ""startServer"");
    verifyDeadAndLiveServers(1, 2);
    verifyRefreshedEntriesFromServer();
  }",False
"  public void testCustomEntryTtl3()  {
    // Disabled this test for now #50880
  }",True
"  protected void waitForInvalidate(Region.Entry entry, long p_tilt) {
    long tilt = p_tilt;
    // up until the time that the expiry fires, the entry
    // better not be null...
    if (entry == null) {
      // the entire wait routine was called very late, and
      // we have no entry?  That's ok.
      return;
    }
    for (;;) {
      boolean wasInvalidated = fetchEntryValue(entry) == null; // do this 1st
      long now = System.currentTimeMillis(); // do this 2nd
      if (now >= tilt) {
        // once this is true it is ok if it was invalidated
        break;
      }
      if (!wasInvalidated) {
        pause(100);
        continue;
      }
      if (now >= tilt - SLOP) {
        getLogWriter().warning(""Entry invalidated sloppily ""
            + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
        break;
      }
      fail(""Entry invalidated prematurely ""
           + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
    }

    // After the timeout passes, we will tolerate a slight
    // lag before the invalidate becomes visible (due to
    // system loading)
    // Slight lag? WAIT_DEFAULT is 60,000 ms. Many of our tests configure 20ms expiration.
    final int maxWaitTime = Integer.getInteger(WAIT_PROPERTY, WAIT_DEFAULT).intValue();
    tilt += maxWaitTime;
    for (;;) {
      if (fetchEntryValue(entry) == null) break;
      if (System.currentTimeMillis() > tilt) {
        if (fetchEntryValue(entry) == null) break;
        fail(""Entry failed to invalidate"");
      }
      pause(100);
    }
  }",True
"  protected void waitForInvalidate(Region.Entry entry, long p_tilt) {
    waitForInvalidate(entry, p_tilt, 100);
  }",False
"  public void testCustomEntryTtl3() {

    final String name = this.getUniqueName();
    final int timeout1 = 200; // ms
    final int timeout2 = 2000;
    final String key1 = ""KEY1"";
    final String value1 = ""VALUE1"";
    final String value2 = ""VALUE2"";
    
    AttributesFactory factory = new AttributesFactory(getRegionAttributes());
    ExpirationAttributes expire1 =
            new ExpirationAttributes(timeout1, ExpirationAction.INVALIDATE);
//    factory.setEntryIdleTimeout(expire);
    factory.setCustomEntryTimeToLive(new TestExpiry(key1, expire1));
    factory.setStatisticsEnabled(true);
    TestCacheListener list = new TestCacheListener() {
      public void afterCreate2(EntryEvent e) { }
      public void afterUpdate2(EntryEvent e) { }
      public void afterInvalidate2(EntryEvent e) { eventCount ++; }
    };
    eventCount = 0;
    factory.addCacheListener(list);
    RegionAttributes attrs = factory.create();
    
    Region region = null;
    System.setProperty(LocalRegion.EXPIRY_MS_PROPERTY, ""true"");
    try {
      region = createRegion(name, attrs);

      // DebuggerSupport.waitForJavaDebugger(getLogWriter(), ""Set breakpoint in
      // invalidate"");
      ExpiryTask.suspendExpiration();
      Region.Entry entry = null;
      eventCount = 0;
      long tilt;
      try {
        region.create(key1, value1);
        tilt = System.currentTimeMillis() + timeout1;
        entry = region.getEntry(key1);
        assertTrue(list.waitForInvocation(1000));
        Assert.assertTrue(value1.equals(entry.getValue()));
      }
      finally {
        ExpiryTask.permitExpiration();
      }
      waitForInvalidate(entry, tilt);
      if (!getRegionAttributes().getDataPolicy().withPartitioning()) {
        // Disk regions are VERY slow, so we need to wait for the event...
        WaitCriterion wc = new WaitCriterion() {
          public boolean done() {
            return eventCount == 1;
          }
          public String description() {
            return ""eventCount never became 1"";
          }
        };
        DistributedTestCase.waitForCriterion(wc, 10 * 1000, 100, true);
      }
      eventCount = 0;

      // Do it again with a put (I guess)
      ExpiryTask.suspendExpiration();
      try {
        region.put(key1, value1);
        tilt = System.currentTimeMillis() + timeout1;
        entry = region.getEntry(key1);
        Assert.assertTrue(value1.equals(entry.getValue()));
        assertTrue(list.waitForInvocation(10 * 1000));
      }
      finally {
        ExpiryTask.permitExpiration();
      }
      waitForInvalidate(entry, tilt);
      if (!getRegionAttributes().getDataPolicy().withPartitioning()) {
        // Disk regions are VERY slow, so we need to wait for the event...
        WaitCriterion wc = new WaitCriterion() {
          public boolean done() {
            return eventCount == 1;
          }
          public String description() {
            return ""eventCount never became 1"";
          }
        };
        DistributedTestCase.waitForCriterion(wc, 10 * 1000, 100, true);
      }
      eventCount = 0;

      // Change custom expiry for this region now...
      AttributesMutator mutt = region.getAttributesMutator();
      ExpirationAttributes expire2 = new ExpirationAttributes(timeout2,
          ExpirationAction.INVALIDATE);
      mutt.setCustomEntryTimeToLive(new TestExpiry(key1, expire2));
      pause(timeout1 + timeout2); // allow things to clean up

      ExpiryTask.suspendExpiration();
      try {
        region.put(key1, value2);
        tilt = System.currentTimeMillis() + timeout2;
        entry = region.getEntry(key1);
        Assert.assertTrue(value2.equals(entry.getValue()));
        assertTrue(list.waitForInvocation(1000));
      }
      finally {
        ExpiryTask.permitExpiration();
        if (region.getAttributes().getPartitionAttributes() != null)
          System.getProperties().remove(LocalRegion.EXPIRY_MS_PROPERTY);
      }
      waitForInvalidate(entry, tilt);
      if (!getRegionAttributes().getDataPolicy().withPartitioning()) {
        // Disk regions are VERY slow, so we need to wait for the event...
        WaitCriterion wc = new WaitCriterion() {
          public boolean done() {
            return eventCount == 1;
          }
          public String description() {
            return ""eventCount never became 1"";
          }
        };
        DistributedTestCase.waitForCriterion(wc, 10 * 1000, 100, true);
      }
      eventCount = 0;
      
    // Change custom expiry for this region now...
    mutt = region.getAttributesMutator();
    expire2 =
      new ExpirationAttributes(timeout2, ExpirationAction.INVALIDATE);
    mutt.setCustomEntryTimeToLive(new TestExpiry(key1, expire2));
    pause(timeout1 + timeout2); // allow things to clean up
    
    ExpiryTask.suspendExpiration();
    try {
      region.put(key1, value2);
      tilt = System.currentTimeMillis() + timeout2;
      entry = region.getEntry(key1);
      Assert.assertTrue(value2.equals(entry.getValue()));
      assertTrue(list.waitForInvocation(5000));
    } 
    finally {
      ExpiryTask.permitExpiration();
    }
    waitForInvalidate(entry, tilt);
    if (!getRegionAttributes().getDataPolicy().withPartitioning()) {
      // Disk regions are VERY slow, so we need to wait for the event...
      WaitCriterion wc = new WaitCriterion() {
        public boolean done() {
          return eventCount == 1;
        }
        public String description() {
          return ""eventCount never became 1"";
        }
      };
      DistributedTestCase.waitForCriterion(wc, 10 * 1000, 100, true);
    }
    eventCount = 0;
  }
  finally {
    System.getProperties().remove(LocalRegion.EXPIRY_MS_PROPERTY);
  }
  }",True
"  public void testCustomEntryTtl3() {

    final String name = this.getUniqueName();
    final int timeout1 = 20; // ms
    final int timeout2 = 40;
    final String key1 = ""KEY1"";
    final String value1 = ""VALUE1"";
    final String value2 = ""VALUE2"";
    
    AttributesFactory factory = new AttributesFactory(getRegionAttributes());
    ExpirationAttributes expire1 =
            new ExpirationAttributes(timeout1, ExpirationAction.INVALIDATE);
//    factory.setEntryIdleTimeout(expire);
    factory.setCustomEntryTimeToLive(new TestExpiry(key1, expire1));
    factory.setStatisticsEnabled(true);
    TestCacheListener list = new TestCacheListener() {
      public void afterCreate2(EntryEvent e) { }
      public void afterUpdate2(EntryEvent e) { }
      public void afterInvalidate2(EntryEvent e) { eventCount ++; }
    };
    // Disk regions are VERY slow, so we need to wait for the event...
    WaitCriterion waitForEventCountToBeOne = new WaitCriterion() {
      public boolean done() {
        return eventCount == 1;
      }
      public String description() {
        return ""eventCount never became 1"";
      }
    };
    eventCount = 0;
    factory.addCacheListener(list);
    RegionAttributes attrs = factory.create();
    
    Region region = null;
    System.setProperty(LocalRegion.EXPIRY_MS_PROPERTY, ""true"");
    try {
      region = createRegion(name, attrs);

      // DebuggerSupport.waitForJavaDebugger(getLogWriter(), ""Set breakpoint in
      // invalidate"");
      ExpiryTask.suspendExpiration();
      Region.Entry entry = null;
      eventCount = 0;
      long tilt1;
      long tilt2;
      try {
        region.create(key1, value1);
        tilt1 = System.currentTimeMillis() + timeout1;
        entry = region.getEntry(key1);
        assertTrue(list.waitForInvocation(1000));
        Assert.assertTrue(value1.equals(entry.getValue()));
      }
      finally {
        ExpiryTask.permitExpiration();
      }
      waitForInvalidate(entry, tilt1, timeout1/2);
      DistributedTestCase.waitForCriterion(waitForEventCountToBeOne, 10 * 1000, 100, true);
      eventCount = 0;

      // Do it again with a put (I guess)
      ExpiryTask.suspendExpiration();
      try {
        region.put(key1, value1);
        tilt1 = System.currentTimeMillis() + timeout1;
        entry = region.getEntry(key1);
        Assert.assertTrue(value1.equals(entry.getValue()));
        assertTrue(list.waitForInvocation(10 * 1000));
      }
      finally {
        ExpiryTask.permitExpiration();
      }
      waitForInvalidate(entry, tilt1, timeout1/2);
      DistributedTestCase.waitForCriterion(waitForEventCountToBeOne, 10 * 1000, 100, true);
      eventCount = 0;

      // Change custom expiry for this region now...
      final String key2 = ""KEY2"";
      AttributesMutator mutt = region.getAttributesMutator();
      ExpirationAttributes expire2 = new ExpirationAttributes(timeout2,
          ExpirationAction.INVALIDATE);
      mutt.setCustomEntryTimeToLive(new TestExpiry(key2, expire2));

      ExpiryTask.suspendExpiration();
      try {
        region.put(key1, value1);
        region.put(key2, value2);
        tilt1 = System.currentTimeMillis() + timeout1;
        tilt2 = tilt1 + timeout2 - timeout1;
        entry = region.getEntry(key1);
        Assert.assertTrue(value1.equals(entry.getValue()));
        entry = region.getEntry(key2);
        Assert.assertTrue(value2.equals(entry.getValue()));
        assertTrue(list.waitForInvocation(1000));
      }
      finally {
        ExpiryTask.permitExpiration();
      }
      waitForInvalidate(entry, tilt2, timeout2/2);
      DistributedTestCase.waitForCriterion(waitForEventCountToBeOne, 10 * 1000, 100, true);
      eventCount = 0;
      // key1 should not be invalidated since we mutated to custom expiry to only expire key2
      entry = region.getEntry(key1);
      Assert.assertTrue(value1.equals(entry.getValue()));
      // now mutate back to key1 and change the action
      ExpirationAttributes expire3 = new ExpirationAttributes(timeout1, ExpirationAction.DESTROY);
      mutt.setCustomEntryTimeToLive(new TestExpiry(key1, expire3));
      waitForDestroy(entry, tilt1, timeout1/2);
    }
    finally {
      System.getProperties().remove(LocalRegion.EXPIRY_MS_PROPERTY);
    }
  }",False
"  protected void waitForInvalidate(Region.Entry entry, long p_tilt, int pauseMs) {
    long tilt = p_tilt;
    // up until the time that the expiry fires, the entry
    // better not be null...
    if (entry == null) {
      // the entire wait routine was called very late, and
      // we have no entry?  That's ok.
      return;
    }
    for (;;) {
      boolean wasInvalidated = fetchEntryValue(entry) == null; // do this 1st
      long now = System.currentTimeMillis(); // do this 2nd
      if (now >= tilt) {
        // once this is true it is ok if it was invalidated
        break;
      }
      if (!wasInvalidated) {
        pause(pauseMs);
        continue;
      }
      if (now >= tilt - SLOP) {
        getLogWriter().warning(""Entry invalidated sloppily ""
            + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
        break;
      }
      fail(""Entry invalidated prematurely ""
           + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
    }

    // After the timeout passes, we will tolerate a slight
    // lag before the invalidate becomes visible (due to
    // system loading)
    // Slight lag? WAIT_DEFAULT is 60,000 ms. Many of our tests configure 20ms expiration.
    final int maxWaitTime = Integer.getInteger(WAIT_PROPERTY, WAIT_DEFAULT).intValue();
    tilt += maxWaitTime;
    for (;;) {
      if (fetchEntryValue(entry) == null) break;
      if (System.currentTimeMillis() > tilt) {
        if (fetchEntryValue(entry) == null) break;
        fail(""Entry failed to invalidate"");
      }
      pause(pauseMs);
    }
  }",False
"  protected void waitForDestroy(Region.Entry entry, long p_tilt) {
    long tilt = p_tilt;
    // up until the time that the expiry fires, the entry
    // better not be null...
    for (;;) {
      long now = System.currentTimeMillis();
      if (now >= tilt)
        break;
      if (!isEntryDestroyed(entry)) {
        pause(100);
        continue;
      }
      if (now >= tilt - SLOP) {
        getLogWriter().warning(""Entry destroyed sloppily ""
            + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
        break;
      }
      fail(""Entry destroyed prematurely""
          + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
    }

    // After the timeout passes, we will tolerate a slight
    // lag before the destroy becomes visible (due to
    // system loading)
    final int maxWaitTime = Integer.getInteger(WAIT_PROPERTY, WAIT_DEFAULT).intValue();
    tilt += maxWaitTime;
    for (;;) {
      if (isEntryDestroyed(entry))
        break;
      Assert.assertTrue(System.currentTimeMillis() <= tilt,
          ""Entry failed to destroy"");
      pause(100);
    }
  }",True
"  protected void waitForDestroy(Region.Entry entry, long p_tilt, int pauseMs) {
    long tilt = p_tilt;
    // up until the time that the expiry fires, the entry
    // better not be null...
    for (;;) {
      long now = System.currentTimeMillis();
      if (now >= tilt)
        break;
      if (!isEntryDestroyed(entry)) {
        pause(pauseMs);
        continue;
      }
      if (now >= tilt - SLOP) {
        getLogWriter().warning(""Entry destroyed sloppily ""
            + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
        break;
      }
      fail(""Entry destroyed prematurely""
          + ""now="" + now + "" tilt="" + tilt + "" delta = "" + (tilt - now));
    }

    // After the timeout passes, we will tolerate a slight
    // lag before the destroy becomes visible (due to
    // system loading)
    final int maxWaitTime = Integer.getInteger(WAIT_PROPERTY, WAIT_DEFAULT).intValue();
    tilt += maxWaitTime;
    for (;;) {
      if (isEntryDestroyed(entry))
        break;
      Assert.assertTrue(System.currentTimeMillis() <= tilt,
          ""Entry failed to destroy"");
      pause(pauseMs);
    }
  }",False
"  protected void waitForDestroy(Region.Entry entry, long p_tilt) {
      waitForDestroy(entry, p_tilt, 100);
  }",False
"  protected void pause() {
    pause(250);
  }",True
"  public static final void pause(int ms) {
    if (ms > 50) {
      getLogWriter().info(""Pausing for "" + ms + "" ms...""/*, new Exception()*/);
    }
    final long target = System.currentTimeMillis() + ms;
    try {
      for (;;) {
        long msLeft = target - System.currentTimeMillis();
        if (msLeft <= 0) {
          break;
        }
        Thread.sleep(msLeft);
      }
    }
    catch (InterruptedException e) {
      fail(""interrupted"", e);
    }
  }",False
"  public long getBytesInMemory() {
    long result = this.bytesInMemory.get();
    if(result == BUCKET_DESTROYED) {
      return 0;
    }
    
    return result;
  }",False
"    public static void handleFullAsyncQueue(DiskEntry entry, LocalRegion region, VersionTag tag) {
      DiskRegion dr = region.getDiskRegion();
      DiskId did = entry.getDiskId();
      synchronized (entry) {
      dr.acquireReadLock();
      try {
        synchronized (did) {
          if (did.isPendingAsync()) {
            did.setPendingAsync(false);
            final Token entryVal = entry.getValueAsToken();
            final int entryValSize = region.calculateRegionEntryValueSize(entry);
            boolean remove = false;
            try {
              if (Token.isRemovedFromDisk(entryVal)) {
                // onDisk was already deced so just do the valueLength here
                incrementBucketStats(region, 0/*InVM*/, 0/*OnDisk*/,
                                     -did.getValueLength());
                dr.remove(region, entry, true, false);
                if (dr.isBackup()) {
                  did.setKeyId(DiskRegion.INVALID_ID); // fix for bug 41340
                }
                remove = true;
              } else if (Token.isInvalid(entryVal) && !dr.isBackup()) {
                // no need to write invalid to disk if overflow only
              } else if (entryVal != null) {
                writeToDisk(entry, region, true);
              } else {
                //if we have a version tag we need to record the operation
                //to update the RVV
                if(tag != null) {
                  DiskEntry.Helper.doAsyncFlush(tag, region);
                }
                return;
              }
              assert !dr.isSync();
              // Only setValue to null if this was an evict.
              // We could just be a backup that is writing async.
              if (!remove
                  && !Token.isInvalid(entryVal)
                  && entry instanceof LRUEntry
                  && ((LRUEntry)entry).testEvicted()) {
                // Moved this here to fix bug 40116.
                region.updateSizeOnEvict(entry.getKey(), entryValSize);
                // note the old size was already accounted for
                // onDisk was already inced so just do the valueLength here
                incrementBucketStats(region, 0/*InVM*/, 0/*OnDisk*/,
                                     did.getValueLength());
                try {
                  entry.handleValueOverflow(region);
                  entry.setValueWithContext(region,null);
                }finally {
                  entry.afterValueOverflow(region);
                }
              }
              
              //See if we the entry we wrote to disk has the same tag
              //as this entry. If not, write the tag as a conflicting operation.
              //to update the RVV.
              VersionStamp stamp = entry.getVersionStamp();
              if(tag != null && stamp != null 
                  && (stamp.getMemberID() != tag.getMemberID()
                    || stamp.getRegionVersion() != tag.getRegionVersion())) {
                DiskEntry.Helper.doAsyncFlush(tag, region);
              }
            } catch (RegionClearedException ignore) {
              // no need to do the op since it was clobbered by a region clear
            }
          } else {
            //if we have a version tag we need to record the operation
            //to update the RVV, even if we don't write the entry
            if(tag != null) {
              DiskEntry.Helper.doAsyncFlush(tag, region);
            }
          }
        }
      } finally {
        dr.releaseReadLock();
      }
      } // sync entry
    }",True
"    public static void handleFullAsyncQueue(DiskEntry entry, LocalRegion region, VersionTag tag) {
      DiskRegion dr = region.getDiskRegion();
      DiskId did = entry.getDiskId();
      synchronized (entry) {
      dr.acquireReadLock();
      try {
        synchronized (did) {
          if (did.isPendingAsync()) {
            did.setPendingAsync(false);
            final Token entryVal = entry.getValueAsToken();
            final int entryValSize = region.calculateRegionEntryValueSize(entry);
            boolean remove = false;
            try {
              if (Token.isRemovedFromDisk(entryVal)) {
                // onDisk was already deced so just do the valueLength here
                dr.incNumOverflowBytesOnDisk(-did.getValueLength());
                incrementBucketStats(region, 0/*InVM*/, 0/*OnDisk*/,
                                     -did.getValueLength());
                dr.remove(region, entry, true, false);
                if (dr.isBackup()) {
                  did.setKeyId(DiskRegion.INVALID_ID); // fix for bug 41340
                }
                remove = true;
              } else if (Token.isInvalid(entryVal) && !dr.isBackup()) {
                // no need to write invalid to disk if overflow only
              } else if (entryVal != null) {
                writeToDisk(entry, region, true);
              } else {
                //if we have a version tag we need to record the operation
                //to update the RVV
                if(tag != null) {
                  DiskEntry.Helper.doAsyncFlush(tag, region);
                }
                return;
              }
              assert !dr.isSync();
              // Only setValue to null if this was an evict.
              // We could just be a backup that is writing async.
              if (!remove
                  && !Token.isInvalid(entryVal)
                  && entry instanceof LRUEntry
                  && ((LRUEntry)entry).testEvicted()) {
                // Moved this here to fix bug 40116.
                region.updateSizeOnEvict(entry.getKey(), entryValSize);
                // note the old size was already accounted for
                // onDisk was already inced so just do the valueLength here
                dr.incNumOverflowBytesOnDisk(did.getValueLength());
                incrementBucketStats(region, 0/*InVM*/, 0/*OnDisk*/,
                                     did.getValueLength());
                try {
                  entry.handleValueOverflow(region);
                  entry.setValueWithContext(region,null);
                }finally {
                  entry.afterValueOverflow(region);
                }
              }
              
              //See if we the entry we wrote to disk has the same tag
              //as this entry. If not, write the tag as a conflicting operation.
              //to update the RVV.
              VersionStamp stamp = entry.getVersionStamp();
              if(tag != null && stamp != null 
                  && (stamp.getMemberID() != tag.getMemberID()
                    || stamp.getRegionVersion() != tag.getRegionVersion())) {
                DiskEntry.Helper.doAsyncFlush(tag, region);
              }
            } catch (RegionClearedException ignore) {
              // no need to do the op since it was clobbered by a region clear
            }
          } else {
            //if we have a version tag we need to record the operation
            //to update the RVV, even if we don't write the entry
            if(tag != null) {
              DiskEntry.Helper.doAsyncFlush(tag, region);
            }
          }
        }
      } finally {
        dr.releaseReadLock();
      }
      } // sync entry
    }",False
"    public static void update(DiskEntry entry, LocalRegion region, Object newValue) throws RegionClearedException {
      update(entry, region, newValue, null);
    }",True
"    public static void update(DiskEntry entry, LocalRegion region, Object newValue, EntryEventImpl event) throws RegionClearedException {
      DiskRegion dr = region.getDiskRegion();
      if (newValue == null) {
        throw new NullPointerException(LocalizedStrings.DiskEntry_ENTRYS_VALUE_SHOULD_NOT_BE_NULL.toLocalizedString());
      }
      
      //If we have concurrency checks enabled for a persistent region, we need
      //to add an entry to the async queue for every update to maintain the RVV
      boolean maintainRVV = region.concurrencyChecksEnabled && dr.isBackup();
      
      Token oldValue = null;
      int oldValueLength = 0;
      boolean scheduleAsync = false;
      boolean callRemoveFromDisk = false;
      DiskId did = entry.getDiskId();
      VersionTag tag = null;
      Object syncObj = did;
      if (syncObj == null) {
        syncObj = entry;
      }
      if (syncObj == did) {
        dr.acquireReadLock();
      }
      try {
      synchronized (syncObj) {
        oldValue = entry.getValueAsToken();
        if (Token.isRemovedFromDisk(newValue)) {
          if (dr.isBackup()) {
            dr.testIsRecoveredAndClear(did); // fixes bug 41409
          }
          RuntimeException rte = null;
          try {
            if (!Token.isRemovedFromDisk(oldValue)) {
              // removeFromDisk takes care of oldValueLength
              if (dr.isSync()) {
                removeFromDisk(entry, region, false);
              } else {
                callRemoveFromDisk = true; // do it outside the sync
              }
            }
          } catch (RuntimeException e) {
            rte = e;
            throw e;
          }
          finally {
            if (rte != null && (rte instanceof CacheClosedException)) {
             // 47616: not to set the value to be removedFromDisk since it failed to persist
            } else {
              // Asif Ensure that the value is rightly set despite clear so
              // that it can be distributed correctly
              entry.setValueWithContext(region, newValue); // OFFHEAP newValue was already preparedForCache
            }
          }
        }
        else if (newValue instanceof RecoveredEntry) {
          // Now that oplog creates are immediately put in cache
          // a later oplog modify will get us here
          RecoveredEntry re = (RecoveredEntry)newValue;
          long oldKeyId = did.getKeyId();
          long oldOplogId = did.getOplogId();
          long newOplogId = re.getOplogId();
          if (newOplogId != oldOplogId) {
            did.setOplogId(newOplogId);
            re.setOplogId(oldOplogId); // so caller knows oldoplog id
          }
          did.setOffsetInOplog(re.getOffsetInOplog());
          // id already set
          did.setUserBits(re.getUserBits());
          oldValueLength = did.getValueLength();
          did.setValueLength(re.getValueLength());
          // The following undo and then do fixes bug 41849
          // First, undo the stats done for the previous recovered value
          if (oldKeyId < 0) {
            dr.incNumOverflowOnDisk(-1L);
            dr.incNumOverflowBytesOnDisk(-oldValueLength);
            incrementBucketStats(region, 0/*InVM*/, -1/*OnDisk*/, -oldValueLength);
          } else {
            dr.incNumEntriesInVM(-1L);
            incrementBucketStats(region, -1/*InVM*/, 0/*OnDisk*/, 0);
          }
          // Second, do the stats done for the current recovered value
          if (re.getRecoveredKeyId() < 0) {
            if (!entry.isValueNull()) {
              try {
                entry.handleValueOverflow(region);
                entry.setValueWithContext(region, null); // fixes bug 41119
              }finally {
                entry.afterValueOverflow(region);
              }
              
            }
            dr.incNumOverflowOnDisk(1L);
            dr.incNumOverflowBytesOnDisk(did.getValueLength());
            incrementBucketStats(region, 0/*InVM*/, 1/*OnDisk*/,
                                 did.getValueLength());
          } else {
            entry.setValueWithContext(region, entry.prepareValueForCache(region, re.getValue(), false));
            dr.incNumEntriesInVM(1L);
            incrementBucketStats(region, 1/*InVM*/, 0/*OnDisk*/, 0);
          }
        }
        else {
          //The new value in the entry needs to be set after the disk writing 
          // has succeeded. If not , for GemFireXD , it is possible that other thread
          // may pick this transient value from region entry ( which for 
          //offheap will eventually be released ) as index key, 
          //given that this operation is bound to fail in case of
          //disk access exception.
          
          //entry.setValueWithContext(region, newValue); // OFFHEAP newValue already prepared
          
          if(did != null && did.isPendingAsync()) {
            //if the entry was not yet written to disk, we didn't update
            //the bytes on disk.
            oldValueLength = 0;
          } else {
            oldValueLength = getValueLength(did);
          }
          
          if (dr.isBackup()) {
            dr.testIsRecoveredAndClear(did); // fixes bug 41409
            if (dr.isSync()) {
              //In case of compression the value is being set first 
              // because atleast for now , GemFireXD does not support compression
              // if and when it does support, this needs to be taken care of else
              // we risk Bug 48965
              if (AbstractRegionEntry.isCompressible(dr, newValue)) {
                entry.setValueWithContext(region, newValue); // OFFHEAP newValue already prepared
                
                // newValue is prepared and compressed. We can't write compressed values to disk.
                writeToDisk(entry, region, false, event);
              } else {
                writeBytesToDisk(entry, region, false, createValueWrapper(newValue, event));
                entry.setValueWithContext(region, newValue); // OFFHEAP newValue already prepared
              }
              
            } else if (did.isPendingAsync() && !maintainRVV) {
              entry.setValueWithContext(region, newValue); // OFFHEAP newValue already prepared
              
              // nothing needs to be done except
              // fixing up LRU stats
              // @todo fixup LRU stats if needed
              // I'm not sure anything needs to be done here.
              // If we have overflow and it decided to evict this entry
              // how do we handle that case when we are async?
              // Seems like the eviction code needs to leave the value
              // in memory until the pendingAsync is done.
            } else {
              //if the entry is not async, we need to schedule it
              //for regions with concurrency checks enabled, we add an entry
              //to the queue for every entry.
              scheduleAsync = true;
              did.setPendingAsync(true);
              VersionStamp stamp = entry.getVersionStamp();
              if(stamp != null) {
                tag = stamp.asVersionTag();
              }
              entry.setValueWithContext(region, newValue); 
            }
          } else if (did != null) {
            entry.setValueWithContext(region, newValue); // OFFHEAP newValue already prepared
            
            // Mark the id as needing to be written
            // The disk remove that this section used to do caused bug 30961
            // @todo this seems wrong. How does leaving it on disk fix the bug?
            did.markForWriting();
            //did.setValueSerializedSize(0);
          }else {
            entry.setValueWithContext(region, newValue);
          }
          
          if (Token.isRemovedFromDisk(oldValue)) {
            // Note we now initialize entries removed and then set their
            // value once we find no existing entry.
            // So this is the normal path for a brand new entry.
            dr.incNumEntriesInVM(1L);
            incrementBucketStats(region, 1/*InVM*/, 0/*OnDisk*/, 0);
          }
        }
        if (entry instanceof LRUEntry) {
          LRUEntry le = (LRUEntry)entry;
          boolean wasEvicted = le.testEvicted();
          le.unsetEvicted();
          if (!Token.isRemovedFromDisk(newValue)) {
            if (oldValue == null
                // added null check for bug 41759
                || wasEvicted && did != null && did.isPendingAsync()) {
              // Note we do not append this entry because that will be
              // done by lruEntryUpdate
              dr.incNumEntriesInVM(1L);
              dr.incNumOverflowOnDisk(-1L);
              dr.incNumOverflowBytesOnDisk(-oldValueLength);
              incrementBucketStats(region, 1/*InVM*/, -1/*OnDisk*/, -oldValueLength);
            }
          }
        }
      }
      } finally {
        if (syncObj == did) {
          dr.releaseReadLock();
        }
      }
      if (callRemoveFromDisk) {
        removeFromDisk(entry, region, false, oldValue == null, false);
      } else if (scheduleAsync && did.isPendingAsync()) {
        // this needs to be done outside the above sync
        scheduleAsyncWrite(new AsyncDiskEntry(region, entry, tag));
      }
    }",False
"    public static void doAsyncFlush(VersionTag tag, LocalRegion region) {
      if (region.isThisRegionBeingClosedOrDestroyed()) return;
      DiskRegion dr = region.getDiskRegion();
      if (!dr.isBackup()) {
        return;
      }
      assert !dr.isSync();
      dr.acquireReadLock();
      try {
        dr.getDiskStore().putVersionTagOnly(region, tag, true);
      } finally {
        dr.releaseReadLock();
      }
    }",True
"    public static void doAsyncFlush(DiskEntry entry, LocalRegion region, VersionTag tag) {
      if (region.isThisRegionBeingClosedOrDestroyed()) return;
      DiskRegion dr = region.getDiskRegion();
      dr.setClearCountReference();
      synchronized (entry) { // fixes 40116
        // If I don't sync the entry and this method ends up doing an eviction
        // thus setting value to null
        // some other thread is free to fetch the value while the entry is synced
        // and think it has removed it or replaced it. This results in updateSizeOn*
        // being called twice for the same value (once when it is evicted and once
        // when it is removed/updated).
      try {
      dr.acquireReadLock();
      try {
        DiskId did = entry.getDiskId();
        synchronized (did) {
          if (did.isPendingAsync()) {
            did.setPendingAsync(false);
            final Token entryVal = entry.getValueAsToken();
            final int entryValSize = region.calculateRegionEntryValueSize(entry);
            boolean remove = false;
            try {
              if (Token.isRemovedFromDisk(entryVal)) {
                if (region.isThisRegionBeingClosedOrDestroyed()) return;
                // onDisk was already deced so just do the valueLength here
                dr.incNumOverflowBytesOnDisk(-did.getValueLength());
                incrementBucketStats(region, 0/*InVM*/, 0/*OnDisk*/,
                                     -did.getValueLength());
                dr.remove(region, entry, true, false);
                if (dr.isBackup()) {
                  did.setKeyId(DiskRegion.INVALID_ID); // fix for bug 41340
                }
                remove = true;
              } else if ((Token.isInvalid(entryVal) || entryVal == Token.TOMBSTONE) && !dr.isBackup()) {
                // no need to write invalid or tombstones to disk if overflow only
              } else if (entryVal != null) {
                writeToDisk(entry, region, true);
              } else {
                // @todo why would we have a null value here?
                // I'm seeing it show up in tests:
// java.lang.IllegalArgumentException: Must not serialize  null  in this context.
// 	at com.gemstone.gemfire.internal.cache.EntryEventImpl.serialize(EntryEventImpl.java:1024)
// 	at com.gemstone.gemfire.internal.cache.DiskEntry$Helper.writeToDisk(DiskEntry.java:351)
// 	at com.gemstone.gemfire.internal.cache.DiskEntry$Helper.doAsyncFlush(DiskEntry.java:683)
// 	at com.gemstone.gemfire.internal.cache.DiskRegion$FlusherThread.run(DiskRegion.java:1055)
                //if we have a version tag we need to record the operation
                //to update the RVV
                if(tag != null) {
                  DiskEntry.Helper.doAsyncFlush(tag, region);
                }
                return;
              }
              assert !dr.isSync();
              // Only setValue to null if this was an evict.
              // We could just be a backup that is writing async.
              if (!remove
                  && !Token.isInvalid(entryVal)
                  && (entryVal != Token.TOMBSTONE)
                  && entry instanceof LRUEntry
                  && ((LRUEntry)entry).testEvicted()) {
                // Moved this here to fix bug 40116.
                region.updateSizeOnEvict(entry.getKey(), entryValSize);
                // note the old size was already accounted for
                // onDisk was already inced so just do the valueLength here
                dr.incNumOverflowBytesOnDisk(did.getValueLength());
                incrementBucketStats(region, 0/*InVM*/, 0/*OnDisk*/,
                                     did.getValueLength());
                try {
                 entry.handleValueOverflow(region);
                 entry.setValueWithContext(region,null);
                }finally {
                  entry.afterValueOverflow(region);
                }
              }
            } catch (RegionClearedException ignore) {
              // no need to do the op since it was clobbered by a region clear
            }
            
            //See if we the entry we wrote to disk has the same tag
            //as this entry. If not, write the tag as a conflicting operation.
            //to update the RVV.
            VersionStamp stamp = entry.getVersionStamp();
            if(tag != null && stamp != null 
                && (stamp.getMemberID() != tag.getMemberID() 
                || stamp.getRegionVersion() != tag.getRegionVersion())) {
              DiskEntry.Helper.doAsyncFlush(tag, region);
            }
          } else {
            //if we have a version tag we need to record the operation
            //to update the RVV
            if(tag != null) {
              DiskEntry.Helper.doAsyncFlush(tag, region);
            }
          }
        }
      } finally {
        dr.releaseReadLock();
      }
      } finally {
        dr.removeClearCountReference();
      }
      } // sync entry
    }",False
"  private int countEntriesInMem(PartitionedRegion pr) {
    int entriesInMem = 0;
    for(BucketRegion br : pr.getDataStore().getAllLocalBucketRegions()) {
      for(RegionEntry entry : br.entries.regionEntries()) {
        if(entry._getValue() != null && !Token.isRemoved(entry._getValue())) {
          System.out.println(""Still in memory "" + entry.getKey());
          entriesInMem++;
        }
      }
    }
    
    System.out.println(""EntriesInMem = "" + entriesInMem);
    return entriesInMem;
  }",False
"  public void testPersistOverflowStatsAsync() throws Exception
  {
    String regionname = ""testStats"";
    int localMaxMemory = 100;
    PartitionedRegion pr = createPRWithEviction(regionname + 1, localMaxMemory, 0, 1, false, true);
    validateOverflowStats(pr);
  }",False
"  public void testPersistOverflowStats() throws Exception
  {
    String regionname = ""testStats"";
    int localMaxMemory = 100;
    PartitionedRegion pr = createPRWithEviction(regionname + 1, localMaxMemory, 0, 1, true, true);
    validateOverflowStats(pr);
  }",False
"  private PartitionedRegion createPRWithEviction(String name, int lmax, int redundancy, int evictionCount, boolean diskSync, boolean persistent) {
    PartitionAttributesFactory paf = new PartitionAttributesFactory();
    paf
      .setLocalMaxMemory(lmax)
      .setRedundantCopies(redundancy)
      .setTotalNumBuckets(13); // set low to reduce logging
    AttributesFactory af = new AttributesFactory();
    af.setPartitionAttributes(paf.create());
    if(persistent) {
      af.setDataPolicy(DataPolicy.PERSISTENT_PARTITION);
    }
    af.setEvictionAttributes(EvictionAttributes.createLRUEntryAttributes(1, EvictionAction.OVERFLOW_TO_DISK));
    af.setDiskStoreName(""diskstore"");
    af.setDiskSynchronous(diskSync);
    Cache cache = PartitionedRegionTestHelper.createCache();
    DISK_DIR.mkdir();
    cache.createDiskStoreFactory().setDiskDirs(new File[] {DISK_DIR}).create(""diskstore"");
    PartitionedRegion pr = null;
    try {
      pr = (PartitionedRegion)cache.createRegion(name, af.create());
    }
    catch (RegionExistsException rex) {
      pr = (PartitionedRegion)cache.getRegion(name);
    }    
    return pr;
  }",False
"  private void validateOverflowStats(PartitionedRegion pr) throws Exception  {
    Statistics stats = pr.getPrStats().getStats();
    DiskRegionStats diskStats = pr.getDiskRegionStats();
    
    assertEquals(0 , stats.getLong(""dataStoreBytesInUse""));
    assertEquals(0 , stats.getInt(""dataStoreEntryCount""));
    assertEquals(0 , diskStats.getNumOverflowBytesOnDisk());
    assertEquals(0 , diskStats.getNumEntriesInVM());
    assertEquals(0 , diskStats.getNumOverflowOnDisk());
    assertEquals(stats.getLong(""dataStoreBytesInUse""), getMemBytes(pr));
    assertEquals(diskStats.getNumOverflowBytesOnDisk(), getDiskBytes(pr));

    
    int numEntries = 0;
    
    pr.put(0, 0);
    numEntries++;
    pr.getDiskStore().flush();
    
    long singleEntryMemSize = stats.getLong(""dataStoreBytesInUse"");
    assertEquals(1 , stats.getInt(""dataStoreEntryCount""));
    assertEquals(0 , diskStats.getNumOverflowBytesOnDisk());
    assertEquals(1 , diskStats.getNumEntriesInVM());
    assertEquals(0 , diskStats.getNumOverflowOnDisk());
    assertEquals(stats.getLong(""dataStoreBytesInUse""), getMemBytes(pr));
    assertEquals(diskStats.getNumOverflowBytesOnDisk(), getDiskBytes(pr));
    
    pr.put(1, 1);
    numEntries++;
    pr.getDiskStore().flush();
    
    assertEquals(singleEntryMemSize, stats.getLong(""dataStoreBytesInUse""));
    assertEquals(2 , stats.getInt(""dataStoreEntryCount""));
    long entryOverflowSize = diskStats.getNumOverflowBytesOnDisk();
    assertEquals(1 , diskStats.getNumEntriesInVM());
    assertEquals(1 , diskStats.getNumOverflowOnDisk());
    assertEquals(stats.getLong(""dataStoreBytesInUse""), getMemBytes(pr));
    assertEquals(diskStats.getNumOverflowBytesOnDisk(), getDiskBytes(pr));
    
    assertTrue(entryOverflowSize > 0);
    
    for(; numEntries < pr.getTotalNumberOfBuckets() * 5; numEntries++) {
      pr.put(numEntries, numEntries);
    }
    pr.getDiskStore().flush();
    
    assertEquals(singleEntryMemSize, stats.getLong(""dataStoreBytesInUse""));
    assertEquals(numEntries , stats.getInt(""dataStoreEntryCount""));
    assertEquals((numEntries -1) * entryOverflowSize, diskStats.getNumOverflowBytesOnDisk());
    assertEquals(1 , diskStats.getNumEntriesInVM());
    assertEquals((numEntries -1) , diskStats.getNumOverflowOnDisk());
    assertEquals(stats.getLong(""dataStoreBytesInUse""), getMemBytes(pr));
    assertEquals(diskStats.getNumOverflowBytesOnDisk(), getDiskBytes(pr));
    
    
    //Update some entries 
    for(int i = 0; i < numEntries / 2; i++) {
      pr.put(i, i*2);
    }
    pr.getDiskStore().flush();
    
    assertEquals(singleEntryMemSize, stats.getLong(""dataStoreBytesInUse""));
    assertEquals(numEntries , stats.getInt(""dataStoreEntryCount""));
    assertEquals((numEntries -1) * entryOverflowSize, diskStats.getNumOverflowBytesOnDisk());
    assertEquals(1 , diskStats.getNumEntriesInVM());
    assertEquals((numEntries -1) , diskStats.getNumOverflowOnDisk());
    assertEquals(stats.getLong(""dataStoreBytesInUse""), getMemBytes(pr));
    assertEquals(diskStats.getNumOverflowBytesOnDisk(), getDiskBytes(pr));
    
    //Get some entries to trigger evictions
    for(int i = 0; i < numEntries / 2; i++) {
      pr.get(i);
    }
    pr.getDiskStore().flush();
    
    assertEquals(singleEntryMemSize, stats.getLong(""dataStoreBytesInUse""));
    assertEquals(numEntries , stats.getInt(""dataStoreEntryCount""));
    assertEquals((numEntries -1) * entryOverflowSize, diskStats.getNumOverflowBytesOnDisk());
    assertEquals(1 , diskStats.getNumEntriesInVM());
    assertEquals((numEntries -1) , diskStats.getNumOverflowOnDisk());
    assertEquals(stats.getLong(""dataStoreBytesInUse""), getMemBytes(pr));
    assertEquals(diskStats.getNumOverflowBytesOnDisk(), getDiskBytes(pr));
    
    
    //Remove some entries
    for(; numEntries > 100; numEntries--) {
      pr.remove(numEntries);
    }
    pr.getDiskStore().flush();
    
    assertEquals(singleEntryMemSize, stats.getLong(""dataStoreBytesInUse""));
    assertEquals(numEntries , stats.getInt(""dataStoreEntryCount""));
    assertEquals((numEntries -1) * entryOverflowSize, diskStats.getNumOverflowBytesOnDisk());
    assertEquals(1 , diskStats.getNumEntriesInVM());
    assertEquals((numEntries -1) , diskStats.getNumOverflowOnDisk());
    assertEquals(stats.getLong(""dataStoreBytesInUse""), getMemBytes(pr));
    assertEquals(diskStats.getNumOverflowBytesOnDisk(), getDiskBytes(pr));

    //Update the same entry twice
    pr.put(5, 5);
    pr.put(5, 6);
    pr.getDiskStore().flush();
    
    assertEquals(singleEntryMemSize, stats.getLong(""dataStoreBytesInUse""));
    assertEquals(numEntries , stats.getInt(""dataStoreEntryCount""));
    assertEquals((numEntries -1) * entryOverflowSize, diskStats.getNumOverflowBytesOnDisk());
    assertEquals(1 , diskStats.getNumEntriesInVM());
    assertEquals((numEntries -1) , diskStats.getNumOverflowOnDisk());
    assertEquals(stats.getLong(""dataStoreBytesInUse""), getMemBytes(pr));
    assertEquals(diskStats.getNumOverflowBytesOnDisk(), getDiskBytes(pr));
    
   //Put get put - seems to leave entry in memory?
    pr.put(10, 11);
    pr.get(10);
    pr.put(10, 12);
    
    pr.getDiskStore().flush();
    
    //Workaround for GEODE-92. We are leaving more than 1 entry in memory. To
    //validate that stats, let's confirm the stats match what is actually in
    //memory
    //int entriesInMem = 1;
    int entriesInMem = countEntriesInMem(pr);
    
    assertEquals(singleEntryMemSize * entriesInMem, stats.getLong(""dataStoreBytesInUse""));
    assertEquals(numEntries , stats.getInt(""dataStoreEntryCount""));
    assertEquals((numEntries - entriesInMem) * entryOverflowSize, diskStats.getNumOverflowBytesOnDisk());
    assertEquals(entriesInMem , diskStats.getNumEntriesInVM());
    assertEquals((numEntries - entriesInMem) , diskStats.getNumOverflowOnDisk());
    assertEquals(stats.getLong(""dataStoreBytesInUse""), getMemBytes(pr));
    assertEquals(diskStats.getNumOverflowBytesOnDisk(), getDiskBytes(pr));
    
    //Do some random operations

    System.out.println(""----Doing random operations"");
    Random rand = new Random(12345L);
    for(int i =0; i < 1000; i++) {
      int key = rand.nextInt(numEntries);
      int op = rand.nextInt(3);
      switch(op) {
        case 0:
          pr.put(key, rand.nextInt());
          break;
        case 1:
          pr.get(key);
          break;
        case 2:
          pr.remove(key);
          break;
      }
    }
    
    pr.getDiskStore().flush();
    
    System.out.println(""----Done with random operations"");

    numEntries = pr.entryCount();
    
    //Workaround for GEODE-92. We are leaving more than 1 entry in memory. To
    //validate that stats, let's confirm the stats match what is actually in
    //memory
    //entriesInMem = 1;
    entriesInMem = countEntriesInMem(pr);
    
    assertEquals(singleEntryMemSize * entriesInMem, stats.getLong(""dataStoreBytesInUse""));
    assertEquals(numEntries , stats.getInt(""dataStoreEntryCount""));
    assertEquals((numEntries - entriesInMem) * entryOverflowSize, diskStats.getNumOverflowBytesOnDisk());
    //Disabled for GEODE-93. numEntriesInVM and numOVerflowOnDisk are incorrect
//    assertEquals(entriesInMem , diskStats.getNumEntriesInVM());
//    assertEquals((numEntries - entriesInMem) , diskStats.getNumOverflowOnDisk());
      assertEquals(stats.getLong(""dataStoreBytesInUse""), getMemBytes(pr));
      assertEquals(diskStats.getNumOverflowBytesOnDisk(), getDiskBytes(pr));
    }",False
"  private long getMemBytes(PartitionedRegion pr) {
    Set<BucketRegion> brs = pr.getDataStore().getAllLocalBucketRegions();
    
    long bytes = 0;
    for(Iterator<BucketRegion> itr = brs.iterator(); itr.hasNext(); ) {
      BucketRegion br = itr.next();
      bytes += br.getBytesInMemory();
    }
    
    return bytes;
  }",False
"  public void testOverflowStatsAsync() throws Exception
  {
    String regionname = ""testStats"";
    int localMaxMemory = 100;
    PartitionedRegion pr = createPRWithEviction(regionname + 1, localMaxMemory, 0, 1, false, false);
    validateOverflowStats(pr);
  }",False
"  public void tearDown() throws IOException {
    PartitionedRegionTestHelper.closeCache();
    FileUtil.delete(DISK_DIR);
  }",False
"  public void testOverflowStats() throws Exception
  {
    String regionname = ""testStats"";
    int localMaxMemory = 100;
    PartitionedRegion pr = createPRWithEviction(regionname + 1, localMaxMemory, 0, 1, true, false);
    validateOverflowStats(pr);
  }",False
"  private Object getDiskBytes(PartitionedRegion pr) {
Set<BucketRegion> brs = pr.getDataStore().getAllLocalBucketRegions();
    
    long bytes = 0;
    for(Iterator<BucketRegion> itr = brs.iterator(); itr.hasNext(); ) {
      BucketRegion br = itr.next();
      bytes += br.getNumOverflowBytesOnDisk();
    }
    
    return bytes;
  }",False
"public static synchronized void closeCache()
 {
  if(cache != null){
  cache.close();
  }
   
 }",True
"public static synchronized void closeCache()
 {
  if(cache != null){
    cache.close();
    cache = null;
  }
   
 }",False
"  public void testMoveBucketsOverflowToDisk() throws Throwable {
    
    System.setProperty(""gemfire.LOG_REBALANCE"", ""true"");
    invokeInEveryVM(new SerializableCallable() {
      
      @Override
      public Object call() throws Exception {
        System.setProperty(""gemfire.LOG_REBALANCE"", ""true"");
        return null;
      }
    });

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    VM vm2 = host.getVM(2);
    VM vm3 = host.getVM(3);

    SerializableRunnable createPrRegion = new SerializableRunnable(""createRegion"") {
      public void run()
      {
        Cache cache = getCache();
        AttributesFactory attr = new AttributesFactory();
        PartitionAttributesFactory paf = new PartitionAttributesFactory();
        paf.setRedundantCopies(1);
        paf.setRecoveryDelay(-1);
        paf.setStartupRecoveryDelay(-1);
        PartitionAttributes prAttr = paf.create();
        attr.setPartitionAttributes(prAttr);
        attr.setEvictionAttributes(EvictionAttributes.createLRUEntryAttributes(1, EvictionAction.OVERFLOW_TO_DISK));
        cache.createRegion(""region1"", attr.create());
      }
    };
    
    //Create the region in two VMs
    vm0.invoke(createPrRegion);
    vm1.invoke(createPrRegion);
    
    //Create some buckets
    vm0.invoke(new SerializableRunnable(""createSomeBuckets"") {
      
      public void run() {
        Cache cache = getCache();
        Region region = cache.getRegion(""region1"");
        for(int i =0; i < 12; i++) {
          Map m = new HashMap();
          for (int j = 0; j < 200; j++) {
            m.put(Integer.valueOf(i + 113*j), ""A"");
          }
          region.putAll(m);
        }
      }
    });

    //Do some puts and gets, to trigger eviction
    SerializableRunnable doOps = new SerializableRunnable(""doOps"") {
      
      public void run() {
        Cache cache = getCache();
        Region region = cache.getRegion(""region1"");
        
        Random rand = new Random();
        
        for(int count = 0; count < 5000; count++) {
          int bucket = (int) (count % 12);
          int key = rand.nextInt(20);
          region.put(Integer.valueOf(bucket + 113*key), ""B"");
        }
        
        for(int count = 0; count < 500; count++) {
          int bucket = (int) (count % 12);
          int key = rand.nextInt(20);
          region.get(Integer.valueOf(bucket + 113*key));
        }
      }
    };
    
    //Do some operations
    vm0.invoke(doOps);
    
    //Create the region in one more VM.
    vm2.invoke(createPrRegion);
    
    //Now do a rebalance
    final Long totalSize = (Long) vm0.invoke(new SerializableCallable(""simulateRebalance"") {
      
      public Object call() {
        Cache cache = getCache();
        ResourceManager manager = cache.getResourceManager();
        RebalanceResults results = doRebalance(false, manager);
        assertEquals(0, results.getTotalBucketCreatesCompleted());
        //We don't know how many primaries will move, it depends on
        //if the move bucket code moves the primary or a redundant bucket
        //assertEquals(0, results.getTotalPrimaryTransfersCompleted());
        assertEquals(8, results.getTotalBucketTransfersCompleted());
        assertTrue(0 < results.getTotalBucketTransferBytes());
        Set<PartitionRebalanceInfo> detailSet = results.getPartitionRebalanceDetails();
        assertEquals(1, detailSet.size());
        PartitionRebalanceInfo details = detailSet.iterator().next();
        assertEquals(0, details.getBucketCreatesCompleted());
        assertTrue(0 < details.getBucketTransferBytes());
        assertEquals(8, details.getBucketTransfersCompleted());
        
        long totalSize = 0;
        Set<PartitionMemberInfo> beforeDetails = details.getPartitionMemberDetailsAfter();
        for(PartitionMemberInfo memberDetails: beforeDetails) {
          totalSize += memberDetails.getSize();
        }
        
        long afterSize = 0;
        Set<PartitionMemberInfo> afterDetails = details.getPartitionMemberDetailsAfter();
        assertEquals(3, afterDetails.size());
        for(PartitionMemberInfo memberDetails: afterDetails) {
          assertEquals(8, memberDetails.getBucketCount());
          assertEquals(4, memberDetails.getPrimaryCount());
          afterSize += memberDetails.getSize();
        }
        assertEquals(totalSize, afterSize);
        verifyStats(manager, results);
        
        return Long.valueOf(totalSize);
      }
    });

    SerializableRunnable checkBalance = new SerializableRunnable(""checkBalance"") {

      public void run() {
        Cache cache = getCache();
        Region region = cache.getRegion(""region1"");
        PartitionRegionInfo details = PartitionRegionHelper.getPartitionRegionInfo(region);
        assertEquals(12, details.getCreatedBucketCount());
        assertEquals(1,details.getActualRedundantCopies());
        assertEquals(0,details.getLowRedundancyBucketCount());
        getLogWriter().info(""details="" + details.getPartitionMemberInfo());
        long afterSize = 0;
        for(PartitionMemberInfo memberDetails: details.getPartitionMemberInfo()) {
          assertEquals(8, memberDetails.getBucketCount());
          assertEquals(4, memberDetails.getPrimaryCount());
          afterSize += memberDetails.getSize();
        }
        //assertEquals(totalSize.longValue(), afterSize);
      }
    };

    vm0.invoke(checkBalance);
    vm1.invoke(checkBalance);
    vm2.invoke(checkBalance);
    
    //Create the region in one more VM.
    vm3.invoke(createPrRegion);
    
    //Do another rebalance
    vm0.invoke(new SerializableCallable(""simulateRebalance"") {
      
      public Object call() {
        Cache cache = getCache();
        ResourceManager manager = cache.getResourceManager();
        RebalanceResults results = doRebalance(false, manager);
        assertEquals(0, results.getTotalBucketCreatesCompleted());
        //We don't know how many primaries will move, it depends on
        //if the move bucket code moves the primary or a redundant bucket
        //assertEquals(0, results.getTotalPrimaryTransfersCompleted());
        assertEquals(6, results.getTotalBucketTransfersCompleted());
        assertTrue(0 < results.getTotalBucketTransferBytes());
        Set<PartitionRebalanceInfo> detailSet = results.getPartitionRebalanceDetails();
        assertEquals(1, detailSet.size());
        PartitionRebalanceInfo details = detailSet.iterator().next();
        assertEquals(0, details.getBucketCreatesCompleted());
        assertTrue(0 < details.getBucketTransferBytes());
        assertEquals(6, details.getBucketTransfersCompleted());
        
        long totalSize = 0;
        Set<PartitionMemberInfo> beforeDetails = details.getPartitionMemberDetailsAfter();
        for(PartitionMemberInfo memberDetails: beforeDetails) {
          totalSize += memberDetails.getSize();
        }
        
        long afterSize = 0;
        Set<PartitionMemberInfo> afterDetails = details.getPartitionMemberDetailsAfter();
        assertEquals(4, afterDetails.size());
        for(PartitionMemberInfo memberDetails: afterDetails) {
          assertEquals(6, memberDetails.getBucketCount());
//          assertEquals(3, memberDetails.getPrimaryCount());
          afterSize += memberDetails.getSize();
        }
        assertEquals(totalSize, afterSize);
        //TODO - need to fix verifyStats to handle a second rebalance
//        verifyStats(manager, results);
        
        return Long.valueOf(totalSize);
      }
    });

      checkBalance = new SerializableRunnable(""checkBalance"") {

        public void run() {
          Cache cache = getCache();
          Region region = cache.getRegion(""region1"");
          PartitionRegionInfo details = PartitionRegionHelper.getPartitionRegionInfo(region);
          assertEquals(12, details.getCreatedBucketCount());
          assertEquals(1,details.getActualRedundantCopies());
          assertEquals(0,details.getLowRedundancyBucketCount());
          getLogWriter().info(""details="" + details.getPartitionMemberInfo());
          long afterSize = 0;
          for(PartitionMemberInfo memberDetails: details.getPartitionMemberInfo()) {
            assertEquals(6, memberDetails.getBucketCount());
            //            assertEquals(3, memberDetails.getPrimaryCount());
            afterSize += memberDetails.getSize();
          }
          //assertEquals(totalSize.longValue(), afterSize);
        }
      };

      vm0.invoke(checkBalance);
      vm1.invoke(checkBalance);
      vm2.invoke(checkBalance);
  }",False
"  public String[] fetchJvmThreads() {
    long threadIds[] = threadMXBean.getAllThreadIds();
    ThreadInfo[] threadInfos = threadMXBean.getThreadInfo(threadIds, 0);
    if (threadInfos == null || threadInfos.length < 1) {
      return ManagementConstants.NO_DATA_STRING;
    }
    String[] thrdStr = new String[threadInfos.length];
    int j = 0;
    for (ThreadInfo thInfo : threadInfos) {
      thrdStr[j] = thInfo.getThreadName();
      j++;
    }
    return thrdStr;
  }",True
"  public String[] fetchJvmThreads() {
    long threadIds[] = threadMXBean.getAllThreadIds();
    ThreadInfo[] threadInfos = threadMXBean.getThreadInfo(threadIds, 0);
    if (threadInfos == null || threadInfos.length < 1) {
      return ManagementConstants.NO_DATA_STRING;
    }
    ArrayList<String> thrdStr = new ArrayList<String>(threadInfos.length);
    for (ThreadInfo thInfo : threadInfos) {
      if (thInfo != null) {
        thrdStr.add(thInfo.getThreadName());
      }
    }
    String[] result = new String[thrdStr.size()];
    return thrdStr.toArray(result);
  }",False
"  public void testRemoteCacheListener() throws InterruptedException {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
    final Object oldValue = ""OLD_VALUE"";
    final Object newValue = ""NEW_VALUE"";
//    final Object key2 = ""KEY2"";
//    final Object value2 = ""VALUE2"";

    SerializableRunnable populate =
      new CacheSerializableRunnable(""Create Region and Put"") {
          public void run2() throws CacheException {
            Region region = createRegion(name);
            region.put(key, oldValue);
          }
        };

    Host host = Host.getHost(0);
    final VM vm0 = host.getVM(0);
    final VM vm1 = host.getVM(1);

    vm0.invoke(populate);
    vm1.invoke(populate);

    vm1.invoke(new CacheSerializableRunnable(""Set listener"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterUpdate2(EntryEvent event) {
                assertEquals(Operation.UPDATE, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
                assertEquals(key, event.getKey());
                assertEquals(oldValue, event.getOldValue());
                assertEquals(newValue, event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());
                if (event.getRegion().getAttributes().getOffHeap()) {
                  // since off heap always serializes the old value is serialized and available
                  assertEquals(oldValue, event.getSerializedOldValue().getDeserializedValue());
                } else {
                  assertEquals(null, event.getSerializedOldValue()); // since it was put originally in this VM
                }
                DataInputStream dis = new DataInputStream(new ByteArrayInputStream(event.getSerializedNewValue().getSerializedValue()));
                try {
                  assertEquals(newValue, DataSerializer.readObject(dis));
                } catch (Exception e) {
                  fail(""Unexpected Exception"", e);
                }
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    pauseIfNecessary();

    vm0.invoke(new CacheSerializableRunnable(""Update"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.put(key, newValue, getSystem().getDistributedMember());
        }
      });

    pauseIfNecessary();

    vm1.invoke(new CacheSerializableRunnable(""Verify Update"") {
        public void run2() throws CacheException {
          assertTrue(listener.wasInvoked());

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterInvalidate2(EntryEvent event) {
                assertEquals(Operation.INVALIDATE, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
                assertEquals(key, event.getKey());
                assertEquals(newValue, event.getOldValue());
                assertNull(event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());
                assertNull(event.getSerializedNewValue());
                DataInputStream dis = new DataInputStream(new ByteArrayInputStream(event.getSerializedOldValue().getSerializedValue()));
                try {
                  assertEquals(newValue, DataSerializer.readObject(dis));
                } catch (Exception e) {
                  fail(""Unexpected Exception"", e);
                }
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Invalidate"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.invalidate(key, getSystem().getDistributedMember());
        }
      });

    pause();

    vm1.invoke(new CacheSerializableRunnable(""Verify Invalidate"") {
        public void run2() throws CacheException {
          assertTrue(listener.wasInvoked());

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterDestroy2(EntryEvent event) {
                assertTrue(event.getOperation().isDestroy());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
                assertEquals(key, event.getKey());
                assertNull(event.getOldValue());
                assertNull(event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());
                assertNull(event.getSerializedOldValue());
                assertNull(event.getSerializedNewValue());
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Destroy"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.destroy(key, getSystem().getDistributedMember());
        }
      });

    pause();

    vm1.invoke(new CacheSerializableRunnable(""Verify Destroy"") {
        public void run2() throws CacheException {
          assertTrue(listener.wasInvoked());

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterRegionInvalidate2(RegionEvent event) {
                assertEquals(Operation.REGION_INVALIDATE, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Invalidate Region"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.invalidateRegion(getSystem().getDistributedMember());
        }
      });

    pause();

    vm1.invoke(new CacheSerializableRunnable(""Verify Invalidate Region"") {
        public void run2() throws CacheException {
          assertTrue(listener.wasInvoked());

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterRegionDestroy2(RegionEvent event) {
                assertEquals(Operation.REGION_DESTROY, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Destroy Region"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.destroyRegion(getSystem().getDistributedMember());
        }
      });

    pause();

    vm1.invoke(new CacheSerializableRunnable(""Verify Destroy Region"") {
        public void run2() throws CacheException {
          assertTrue(listener.wasInvoked());
        }
      });
  }",True
"  public void testRemoteCacheListener() throws InterruptedException {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
    final Object oldValue = ""OLD_VALUE"";
    final Object newValue = ""NEW_VALUE"";
//    final Object key2 = ""KEY2"";
//    final Object value2 = ""VALUE2"";

    SerializableRunnable populate =
      new CacheSerializableRunnable(""Create Region and Put"") {
          public void run2() throws CacheException {
            Region region = createRegion(name);
            region.put(key, oldValue);
          }
        };

    Host host = Host.getHost(0);
    final VM vm0 = host.getVM(0);
    final VM vm1 = host.getVM(1);

    vm0.invoke(populate);
    vm1.invoke(populate);

    vm1.invoke(new CacheSerializableRunnable(""Set listener"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterUpdate2(EntryEvent event) {
                assertEquals(Operation.UPDATE, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
                assertEquals(key, event.getKey());
                assertEquals(oldValue, event.getOldValue());
                assertEquals(newValue, event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());
                if (event.getRegion().getAttributes().getOffHeap()) {
                  // since off heap always serializes the old value is serialized and available
                  assertEquals(oldValue, event.getSerializedOldValue().getDeserializedValue());
                } else {
                  assertEquals(null, event.getSerializedOldValue()); // since it was put originally in this VM
                }
                DataInputStream dis = new DataInputStream(new ByteArrayInputStream(event.getSerializedNewValue().getSerializedValue()));
                try {
                  assertEquals(newValue, DataSerializer.readObject(dis));
                } catch (Exception e) {
                  fail(""Unexpected Exception"", e);
                }
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    // I see no reason to pause here.
    // The test used to pause here but only if no-ack.
    // But we have no operations to wait for.
    // The last thing we did was install a listener in vm1
    // and it is possible that vm0 does not yet know we have
    // a listener but for this test it does not matter.
    // So I'm commenting out the following pause:
    //pauseIfNecessary();

    vm0.invoke(new CacheSerializableRunnable(""Update"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.put(key, newValue, getSystem().getDistributedMember());
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Verify Update"") {
        public void run2() throws CacheException {
          listener.waitForInvocation(3000, 10);

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterInvalidate2(EntryEvent event) {
                assertEquals(Operation.INVALIDATE, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
                assertEquals(key, event.getKey());
                assertEquals(newValue, event.getOldValue());
                assertNull(event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());
                assertNull(event.getSerializedNewValue());
                DataInputStream dis = new DataInputStream(new ByteArrayInputStream(event.getSerializedOldValue().getSerializedValue()));
                try {
                  assertEquals(newValue, DataSerializer.readObject(dis));
                } catch (Exception e) {
                  fail(""Unexpected Exception"", e);
                }
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Invalidate"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.invalidate(key, getSystem().getDistributedMember());
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Verify Invalidate"") {
        public void run2() throws CacheException {
          listener.waitForInvocation(3000, 10);

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterDestroy2(EntryEvent event) {
                assertTrue(event.getOperation().isDestroy());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
                assertEquals(key, event.getKey());
                assertNull(event.getOldValue());
                assertNull(event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());
                assertNull(event.getSerializedOldValue());
                assertNull(event.getSerializedNewValue());
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Destroy"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.destroy(key, getSystem().getDistributedMember());
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Verify Destroy"") {
        public void run2() throws CacheException {
          listener.waitForInvocation(3000, 10);

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterRegionInvalidate2(RegionEvent event) {
                assertEquals(Operation.REGION_INVALIDATE, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Invalidate Region"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.invalidateRegion(getSystem().getDistributedMember());
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Verify Invalidate Region"") {
        public void run2() throws CacheException {
          listener.waitForInvocation(3000, 10);

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterRegionDestroy2(RegionEvent event) {
                assertEquals(Operation.REGION_DESTROY, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Destroy Region"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.destroyRegion(getSystem().getDistributedMember());
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Verify Destroy Region"") {
        public void run2() throws CacheException {
          listener.waitForInvocation(3000, 10);
        }
      });
  }",False
"  public void testRemoteCacheListenerInSubregion() throws InterruptedException {
    if (!supportsSubregions()) {
      return;
    }
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
          }
        };

    Host host = Host.getHost(0);
    final VM vm0 = host.getVM(0);
    final VM vm1 = host.getVM(1);

    vm0.invoke(new CacheSerializableRunnable(""Create Root"") {
      public void run2() throws CacheException {
        createRootRegion();
      }
    });

    vm1.invoke(create);

    vm1.invoke(new CacheSerializableRunnable(""Set listener"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterRegionInvalidate2(RegionEvent event) {
                assertEquals(Operation.REGION_INVALIDATE, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    pauseIfNecessary();


    vm0.invoke(new CacheSerializableRunnable(""Invalidate Root Region"") {
        public void run2() throws CacheException {
          getRootRegion().invalidateRegion(getSystem().getDistributedMember());
        }
      });

    pauseIfNecessary();

    vm1.invoke(new CacheSerializableRunnable(""Verify Invalidate Region"") {
        public void run2() throws CacheException {
          assertTrue(listener.wasInvoked());

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterRegionDestroy2(RegionEvent event) {
                assertEquals(Operation.REGION_DESTROY, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    pauseIfNecessary();

    vm0.invoke(new CacheSerializableRunnable(""Destroy Root Region"") {
        public void run2() throws CacheException {
          getRootRegion().destroyRegion(getSystem().getDistributedMember());
        }
      });

    pauseIfNecessary();

    vm1.invoke(new CacheSerializableRunnable(""Verify Destroy Region"") {
        public void run2() throws CacheException {
          assertTrue(listener.wasInvoked());
        }
      });
  }",True
"  public void testRemoteCacheListenerInSubregion() throws InterruptedException {
    if (!supportsSubregions()) {
      return;
    }
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
          }
        };

    Host host = Host.getHost(0);
    final VM vm0 = host.getVM(0);
    final VM vm1 = host.getVM(1);

    vm0.invoke(new CacheSerializableRunnable(""Create Root"") {
      public void run2() throws CacheException {
        createRootRegion();
      }
    });

    vm1.invoke(create);

    vm1.invoke(new CacheSerializableRunnable(""Set listener"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterRegionInvalidate2(RegionEvent event) {
                assertEquals(Operation.REGION_INVALIDATE, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Invalidate Root Region"") {
        public void run2() throws CacheException {
          getRootRegion().invalidateRegion(getSystem().getDistributedMember());
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Verify Invalidate Region"") {
        public void run2() throws CacheException {
          listener.waitForInvocation(3000, 10);

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterRegionDestroy2(RegionEvent event) {
                assertEquals(Operation.REGION_DESTROY, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Destroy Root Region"") {
        public void run2() throws CacheException {
          getRootRegion().destroyRegion(getSystem().getDistributedMember());
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Verify Destroy Region"") {
        public void run2() throws CacheException {
          listener.waitForInvocation(3000, 10);
        }
      });
  }",False
"  public void testDistributedInvalidate4() throws InterruptedException {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
    final Object value = ""VALUE"";

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            Region region = createRegion(name);
            region.put(key, value);
          }
        };

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);

    vm0.invoke(create);

    int vmCount = host.getVMCount();
    for (int i = 1; i < vmCount; i++) {
      VM vm = host.getVM(i);
      vm.invoke(create);
    }

    Thread.sleep(250);


    SerializableRunnable invalidate =
      new CacheSerializableRunnable(""Invalidate Entry"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.invalidate(key);
        }
      };

    for (int i = 0; i < vmCount; i++) {
      VM vm = host.getVM(i);
      vm.invoke(invalidate);
    }

    SerializableRunnable verify =
      new CacheSerializableRunnable(""Verify entry invalidation"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            Region.Entry entry = region.getEntry(key);
            assertNotNull(entry);
            assertNull(entry.getValue());
          }
        };

    for (int i = 0; i < vmCount; i++) {
      VM vm = host.getVM(i);
      vm.invoke(verify);
    }

    pauseIfNecessary(2500);  // wait for messages to acquiesce before tearing down
    getLogWriter().info(""Tearing down..."");
  }",True
"  public void testDistributedInvalidate4() throws InterruptedException {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
    final Object value = ""VALUE"";

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            Region region = createRegion(name);
            region.put(key, value);
          }
        };

    Host host = Host.getHost(0);
    int vmCount = host.getVMCount();
    for (int i = 0; i < vmCount; i++) {
      VM vm = host.getVM(i);
      vm.invoke(create);
    }

    pause();

    SerializableRunnable invalidate =
      new CacheSerializableRunnable(""Invalidate Entry"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.invalidate(key);
        }
      };

    for (int i = 0; i < vmCount; i++) {
      VM vm = host.getVM(i);
      vm.invoke(invalidate);
    }

    SerializableRunnable verify =
      new CacheSerializableRunnable(""Verify entry invalidation"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            Region.Entry entry = region.getEntry(key);
            assertNotNull(entry);
            assertNull(entry.getValue());
          }
        };

    for (int i = 0; i < vmCount; i++) {
      VM vm = host.getVM(i);
      vm.invoke(verify);
    }

    // Why is this long 2.5 second pause needed on no-ack?
    pauseIfNecessary(2500);  // wait for messages to acquiesce before tearing down
    getLogWriter().info(""Tearing down..."");
  }",False
"  public boolean waitForInvocation(int timeoutMs) {
    if (!this.invoked) {
      WaitCriterion ev = new WaitCriterion() {
        public boolean done() {
          return invoked;
        }
        public String description() {
          return null;
        }
      };
      DistributedTestCase.waitForCriterion(ev, timeoutMs, 200, true);
    }
    return wasInvoked();
  }",True
"  public boolean waitForInvocation(int timeoutMs, long interval) {
    if (!this.invoked) {
      WaitCriterion ev = new WaitCriterion() {
        public boolean done() {
          return invoked;
        }
        public String description() {
          return ""listener was never invoked"";
        }
      };
      DistributedTestCase.waitForCriterion(ev, timeoutMs, interval, true);
    }
    return wasInvoked();
  }",False
"  public boolean wasInvoked() {
    checkForError();
    boolean value = this.invoked;
    this.invoked = false;
    return value;
  }",True
"  public boolean wasInvoked() {
    checkForError();
    boolean value = this.invoked;
    if (value) {
      this.invoked = false;
    }
    return value;
  }",False
"  public boolean waitForInvocation(int timeoutMs) {
    return waitForInvocation(timeoutMs, 200);
  }",False
"  public EntryExpiryTask getEntryExpiryTask(Object key) {
    BucketRegion br = this.getDataStore().getLocalBucketByKey(key);
    if (br == null) {
      throw new EntryNotFoundException(""Bucket for key "" + key + "" does not exist."");
    }
    return br.getEntryExpiryTask(key);
  }",False
"    public void testUpdateResetsIdleTime() throws InterruptedException {

      final String name = this.getUniqueName();
      // test no longer waits for this timeout to expire
      final int timeout = 90; // seconds
      final Object key = ""KEY"";
      final Object value = ""VALUE"";

      Host host = Host.getHost(0);
      VM vm0 = host.getVM(0);
      VM vm1 = host.getVM(1);


      vm1.invoke(new CacheSerializableRunnable(""Create Region "" + name) {
        public void run2() throws CacheException {
          AttributesFactory factory = new AttributesFactory(getRegionAttributes());
          factory.setStatisticsEnabled(true);
          ExpirationAttributes expire =
              new ExpirationAttributes(timeout,
                  ExpirationAction.DESTROY);
          factory.setEntryIdleTimeout(expire);
          if(getRegionAttributes().getPartitionAttributes() != null){
            createRegion(name, factory.create());  
          } else {
            createRegion(name);
          }          
        }
      });

      vm0.invoke(new CacheSerializableRunnable(""Create with Idle"") {
        public void run2() throws CacheException {
          AttributesFactory factory = new AttributesFactory(getRegionAttributes());
          factory.setStatisticsEnabled(true);
          ExpirationAttributes expire =
              new ExpirationAttributes(timeout,
                  ExpirationAction.DESTROY);
          factory.setEntryIdleTimeout(expire);
          LocalRegion region =
              (LocalRegion) createRegion(name, factory.create());
          region.create(key, null);
          EntryExpiryTask eet = region.getEntryExpiryTask(key);
          region.create(""createExpiryTime"", eet.getExpirationTime());
          waitForExpiryClockToChange(region);
        }
      });

      vm1.invoke(new CacheSerializableRunnable(""Update entry"") {
        public void run2() throws CacheException {
          final Region r = getRootRegion().getSubregion(name);
          assertNotNull(r);
          r.put(key, value);
        }
      });

      vm0.invoke(new CacheSerializableRunnable(""Verify reset"") {
        public void run2() throws CacheException {
          final LocalRegion region =
              (LocalRegion) getRootRegion().getSubregion(name);

          // wait for update to reach us from vm1 (needed if no-ack)
          WaitCriterion waitForUpdate = new WaitCriterion() {
            public boolean done() {
              return value.equals(region.get(key));
            }
            public String description() {
              return ""never saw update of "" + key;
            }
          };
          DistributedTestCase.waitForCriterion(waitForUpdate, 3000, 10, true);

          EntryExpiryTask eet = region.getEntryExpiryTask(key);
          long createExpiryTime = (Long) region.get(""createExpiryTime"");
          long updateExpiryTime = eet.getExpirationTime();
          if (updateExpiryTime - createExpiryTime <= 0L) {
            fail(""update did not reset the expiration time. createExpiryTime="" + createExpiryTime + "" updateExpiryTime="" + updateExpiryTime);
          }
        }
      });
    }",True
"    public void testUpdateResetsIdleTime() throws InterruptedException {

      final String name = this.getUniqueName();
      // test no longer waits for this timeout to expire
      final int timeout = 90; // seconds
      final Object key = ""KEY"";
      final Object value = ""VALUE"";

      Host host = Host.getHost(0);
      VM vm0 = host.getVM(0);
      VM vm1 = host.getVM(1);


      vm0.invoke(new CacheSerializableRunnable(""Create with Idle"") {
        public void run2() throws CacheException {
          AttributesFactory factory = new AttributesFactory(getRegionAttributes());
          factory.setStatisticsEnabled(true);
          ExpirationAttributes expire =
              new ExpirationAttributes(timeout,
                  ExpirationAction.DESTROY);
          factory.setEntryIdleTimeout(expire);
          LocalRegion region =
              (LocalRegion) createRegion(name, factory.create());
          if (region.getDataPolicy().withPartitioning()) {
            // Force all buckets to be created locally so the
            // test will know that the create happens in this vm
            // and the update (in vm1) is remote.
            PartitionRegionHelper.assignBucketsToPartitions(region);
          }
          region.create(key, null);
          EntryExpiryTask eet = region.getEntryExpiryTask(key);
          region.create(""createExpiryTime"", eet.getExpirationTime());
          waitForExpiryClockToChange(region);
        }
      });

      vm1.invoke(new CacheSerializableRunnable(""Create Region "" + name) {
        public void run2() throws CacheException {
          AttributesFactory factory = new AttributesFactory(getRegionAttributes());
          factory.setStatisticsEnabled(true);
          ExpirationAttributes expire =
              new ExpirationAttributes(timeout,
                  ExpirationAction.DESTROY);
          factory.setEntryIdleTimeout(expire);
          if(getRegionAttributes().getPartitionAttributes() != null){
            createRegion(name, factory.create());  
          } else {
            createRegion(name);
          }          
        }
      });

      vm1.invoke(new CacheSerializableRunnable(""Update entry"") {
        public void run2() throws CacheException {
          final Region r = getRootRegion().getSubregion(name);
          assertNotNull(r);
          r.put(key, value);
        }
      });

      vm0.invoke(new CacheSerializableRunnable(""Verify reset"") {
        public void run2() throws CacheException {
          final LocalRegion region =
              (LocalRegion) getRootRegion().getSubregion(name);

          // wait for update to reach us from vm1 (needed if no-ack)
          WaitCriterion waitForUpdate = new WaitCriterion() {
            public boolean done() {
              return value.equals(region.get(key));
            }
            public String description() {
              return ""never saw update of "" + key;
            }
          };
          DistributedTestCase.waitForCriterion(waitForUpdate, 3000, 10, true);

          EntryExpiryTask eet = region.getEntryExpiryTask(key);
          long createExpiryTime = (Long) region.get(""createExpiryTime"");
          long updateExpiryTime = eet.getExpirationTime();
          if (updateExpiryTime - createExpiryTime <= 0L) {
            fail(""update did not reset the expiration time. createExpiryTime="" + createExpiryTime + "" updateExpiryTime="" + updateExpiryTime);
          }
        }
      });
    }",False
"  public void testEntryIdleReset() throws Exception {

    final String name = this.getUniqueName();
    // Test no longer waits for this timeout to expire
    final int timeout = 90; // seconds
    final String key = ""KEY"";
    final String value = ""VALUE"";
    
    AttributesFactory factory = new AttributesFactory(getRegionAttributes());
    ExpirationAttributes expire =
            new ExpirationAttributes(timeout, ExpirationAction.DESTROY);
    factory.setEntryIdleTimeout(expire);
    factory.setStatisticsEnabled(true);
    RegionAttributes attrs = factory.create();
    
    LocalRegion region = (LocalRegion) createRegion(name, attrs);
    region.create(key, null);
    EntryExpiryTask eet = region.getEntryExpiryTask(key);
    long createExpiryTime = eet.getExpirationTime();

    waitForExpiryClockToChange(region);
    region.get(key); // touch
    assertSame(eet, region.getEntryExpiryTask(key));
    long getExpiryTime = eet.getExpirationTime();
    if (getExpiryTime - createExpiryTime <= 0L) {
      fail(""get did not reset the expiration time. createExpiryTime="" + createExpiryTime + "" getExpiryTime="" + getExpiryTime);
    }
    
    waitForExpiryClockToChange(region);
    region.put(key, value); // touch
    assertSame(eet, region.getEntryExpiryTask(key));
    long putExpiryTime = eet.getExpirationTime();
    if (putExpiryTime - getExpiryTime <= 0L) {
      fail(""put did not reset the expiration time. getExpiryTime="" + getExpiryTime + "" putExpiryTime="" + putExpiryTime);
    }

    // TODO other ops that should be validated?

    // Now verify operations that do not modify the expiry time
    
    waitForExpiryClockToChange(region);
    region.invalidate(key); // touch
    assertSame(eet, region.getEntryExpiryTask(key));
    long invalidateExpiryTime = eet.getExpirationTime();
    if (invalidateExpiryTime != putExpiryTime) {
      fail(""invalidate did reset the expiration time. putExpiryTime="" + putExpiryTime + "" invalidateExpiryTime="" + invalidateExpiryTime);
    }
  }",True
"  public void testEntryIdleReset() throws Exception {

    final String name = this.getUniqueName();
    // Test no longer waits for this timeout to expire
    final int timeout = 90; // seconds
    final String key = ""KEY"";
    final String value = ""VALUE"";
    
    AttributesFactory factory = new AttributesFactory(getRegionAttributes());
    ExpirationAttributes expire =
            new ExpirationAttributes(timeout, ExpirationAction.DESTROY);
    factory.setEntryIdleTimeout(expire);
    factory.setStatisticsEnabled(true);
    RegionAttributes attrs = factory.create();
    
    LocalRegion region = (LocalRegion) createRegion(name, attrs);
    region.create(key, null);
    EntryExpiryTask eet = region.getEntryExpiryTask(key);
    long createExpiryTime = eet.getExpirationTime();

    waitForExpiryClockToChange(region);
    region.get(key); // touch
    assertSame(eet, region.getEntryExpiryTask(key));
    long getExpiryTime = eet.getExpirationTime();
    if (getExpiryTime - createExpiryTime <= 0L) {
      fail(""get did not reset the expiration time. createExpiryTime="" + createExpiryTime + "" getExpiryTime="" + getExpiryTime);
    }
    
    waitForExpiryClockToChange(region);
    region.put(key, value); // touch
    assertSame(eet, region.getEntryExpiryTask(key));
    long putExpiryTime = eet.getExpirationTime();
    if (putExpiryTime - getExpiryTime <= 0L) {
      fail(""put did not reset the expiration time. getExpiryTime="" + getExpiryTime + "" putExpiryTime="" + putExpiryTime);
    }

    // TODO other ops that should be validated?

    // Now verify operations that do not modify the expiry time
    
    waitForExpiryClockToChange(region);
    region.invalidate(key); // touch
    assertSame(eet, region.getEntryExpiryTask(key));
    long invalidateExpiryTime = eet.getExpirationTime();
    if (region.getConcurrencyChecksEnabled()) {
      if (putExpiryTime - getExpiryTime <= 0L) {
        fail(""invalidate did not reset the expiration time. putExpiryTime="" + putExpiryTime + "" invalidateExpiryTime="" + invalidateExpiryTime);
      }
    } else {
      if (invalidateExpiryTime != putExpiryTime) {
        fail(""invalidate did reset the expiration time. putExpiryTime="" + putExpiryTime + "" invalidateExpiryTime="" + invalidateExpiryTime);
      }
    }
  }",False
"  public void testEntryIdleTimeout3() {

    final String name = this.getUniqueName();
    final int timeout1 = 200; // ms
    final int timeout2 = 2000;
    final String key1 = ""KEY1"";
    final String value1 = ""VALUE1"";
    final String value2 = ""VALUE2"";
    
    AttributesFactory factory = new AttributesFactory(getRegionAttributes());
    ExpirationAttributes expire1 =
            new ExpirationAttributes(timeout1, ExpirationAction.INVALIDATE);
    factory.setEntryIdleTimeout(expire1);
    factory.setStatisticsEnabled(true);
    TestCacheListener list = new TestCacheListener() {
      public void afterCreate2(EntryEvent e) { }
      public void afterUpdate2(EntryEvent e) { }
      public void afterInvalidate2(EntryEvent e) { eventCount ++; }
    };
    eventCount = 0;
    factory.addCacheListener(list);
    RegionAttributes attrs = factory.create();
    
    Region region = null;
    System.setProperty(LocalRegion.EXPIRY_MS_PROPERTY, ""true"");
    try {
      region = createRegion(name, attrs);
    } 
    finally {
      if(region.getAttributes().getPartitionAttributes() == null)
        System.getProperties().remove(LocalRegion.EXPIRY_MS_PROPERTY);
    }

    // DebuggerSupport.waitForJavaDebugger(getLogWriter(), ""Set breakpoint in invalidate"");
    ExpiryTask.suspendExpiration();
    Region.Entry entry = null;
    long tilt;
    try {
      region.create(key1, value1);
      tilt = System.currentTimeMillis() + timeout1;
      assertTrue(list.waitForInvocation(5000));
      entry = region.getEntry(key1);
      Assert.assertTrue(value1.equals(entry.getValue()));
    } 
    finally {
      ExpiryTask.permitExpiration();
    }
    waitForInvalidate(entry, tilt);
    if (!getRegionAttributes().getDataPolicy().withPartitioning()) {
      // Disk regions are VERY slow, so we need to wait for the event...
      WaitCriterion wc = new WaitCriterion() {
        public boolean done() {
          return eventCount == 1;
        }
        public String description() {
          return ""eventCount never became 1"";
        }
      };
      DistributedTestCase.waitForCriterion(wc, 10 * 1000, 100, true);
    }
    eventCount = 0;

    // Do it again with a put (I guess)
    ExpiryTask.suspendExpiration();
    try {
      region.put(key1, value1);
      tilt = System.currentTimeMillis() + timeout1;
      entry = region.getEntry(key1);
      Assert.assertTrue(value1.equals(entry.getValue()));
      assertTrue(list.waitForInvocation(5000));
    } 
    finally {
      ExpiryTask.permitExpiration();
    }
    waitForInvalidate(entry, tilt);
    if (!getRegionAttributes().getDataPolicy().withPartitioning()) {
      // Disk regions are VERY slow, so we need to wait for the event...
      WaitCriterion wc = new WaitCriterion() {
        public boolean done() {
          return eventCount == 1;
        }
        public String description() {
          return ""eventCount never became 1"";
        }
      };
      DistributedTestCase.waitForCriterion(wc, 10 * 1000, 100, true);
    }
    eventCount = 0;
    
    // Change expiry for this region now...
    AttributesMutator mutt = region.getAttributesMutator();
    ExpirationAttributes expire2 =
      new ExpirationAttributes(timeout2, ExpirationAction.INVALIDATE);
    mutt.setEntryIdleTimeout(expire2);
    
    ExpiryTask.suspendExpiration();
    try {
      region.put(key1, value2);
      tilt = System.currentTimeMillis() + timeout2;
      entry = region.getEntry(key1);
      Assert.assertTrue(value2.equals(entry.getValue()));
      assertTrue(list.waitForInvocation(5000));
    } 
    finally {
      ExpiryTask.permitExpiration();
      if(region.getAttributes().getPartitionAttributes() != null)
        System.getProperties().remove(LocalRegion.EXPIRY_MS_PROPERTY);
    }
    waitForInvalidate(entry, tilt);
    if (!region.getAttributes().getDataPolicy().withPartitioning()) {
      // Disk regions are VERY slow, so we need to wait for the event...
      WaitCriterion wc = new WaitCriterion() {
        public boolean done() {
          return eventCount == 1;
        }
        public String description() {
          return ""eventCount never became 1"";
        }
      };
      DistributedTestCase.waitForCriterion(wc, 10 * 1000, 100, true);
    }
    eventCount = 0;
  }",True
"  public void testEntryIdleTimeout3() {
    final String name = this.getUniqueName();
    // test no longer waits for this expiration to happen
    final int timeout1 = 500 * 1000; // ms
    final int timeout2 = 2000 * 1000; // ms
    final String key1 = ""KEY1"";
    final String value1 = ""VALUE1"";
    
    AttributesFactory factory = new AttributesFactory(getRegionAttributes());
    ExpirationAttributes expire1 =
            new ExpirationAttributes(timeout1, ExpirationAction.INVALIDATE);
    factory.setEntryIdleTimeout(expire1);
    factory.setStatisticsEnabled(true);
    TestCacheListener list = new TestCacheListener() {
      public void afterCreate2(EntryEvent e) { }
      public void afterUpdate2(EntryEvent e) { }
      public void afterInvalidate2(EntryEvent e) { eventCount ++; }
    };
    eventCount = 0;
    factory.addCacheListener(list);
    RegionAttributes attrs = factory.create();
    
    LocalRegion region;
    System.setProperty(LocalRegion.EXPIRY_MS_PROPERTY, ""true"");
    try {
      region = (LocalRegion) createRegion(name, attrs);
    } finally {
      System.getProperties().remove(LocalRegion.EXPIRY_MS_PROPERTY);
    }

    region.create(key1, value1);
    EntryExpiryTask eet = region.getEntryExpiryTask(key1);
    final long firstExpiryTime = eet.getExpirationTime();

    AttributesMutator mutt = region.getAttributesMutator();
    ExpirationAttributes expire2 = new ExpirationAttributes(timeout2, ExpirationAction.INVALIDATE);
    mutt.setEntryIdleTimeout(expire2);
    eet = region.getEntryExpiryTask(key1);
    final long secondExpiryTime = eet.getExpirationTime();
    if ((secondExpiryTime - firstExpiryTime) <= 0) {
      fail(""expiration time should have been greater after changing region config from 500 to 2000. firstExpiryTime="" + firstExpiryTime + "" secondExpiryTime="" + secondExpiryTime);
    }
    
    // now set back to be more recent
    mutt = region.getAttributesMutator();
    ExpirationAttributes expire3 = new ExpirationAttributes(timeout1, ExpirationAction.INVALIDATE);
    mutt.setEntryIdleTimeout(expire3);
    eet = region.getEntryExpiryTask(key1);
    final long thirdExpiryTime = eet.getExpirationTime();
    assertEquals(firstExpiryTime, thirdExpiryTime);
    // confirm that it still has not expired
    assertEquals(0, eventCount);
    
    // now set it to a really short time and make sure it expires immediately
    waitForExpiryClockToChange(region);
    final Region.Entry entry = region.getEntry(key1);
    mutt = region.getAttributesMutator();
    ExpirationAttributes expire4 = new ExpirationAttributes(1, ExpirationAction.INVALIDATE);
    mutt.setEntryIdleTimeout(expire4);
    WaitCriterion wc = new WaitCriterion() {
      public boolean done() {
        return fetchEntryValue(entry) == null;
      }
      public String description() {
        return ""entry never became invalid"";
      }
    };
    DistributedTestCase.waitForCriterion(wc, 10 * 1000, 10, true);

    WaitCriterion waitForEventCountToBeOne = new WaitCriterion() {
      public boolean done() {
        return eventCount == 1;
      }
      public String description() {
        return ""eventCount never became 1"";
      }
    };
    DistributedTestCase.waitForCriterion(waitForEventCountToBeOne, 10 * 1000, 10, true);
    eventCount = 0;
  }",False
"    public void rebalance() {
      try {
        RebalanceOperation operation = getCache().getResourceManager().createRebalanceFactory().start();
        RebalanceResults result = operation.getResults();
        logger.info(""Rebalance result: RebalanceResultsImpl [TotalBucketCreateBytes=""
            + result.getTotalBucketCreateBytes() + "", TotalBucketCreatesCompleted=""
            + result.getTotalBucketCreatesCompleted() + "", TotalBucketTransferBytes=""
            + result.getTotalBucketTransferBytes() + "", TotalBucketTransfersCompleted=""
            + result.getTotalBucketTransfersCompleted() + "", TotalPrimaryTransfersCompleted=""
            + result.getTotalPrimaryTransfersCompleted() + ""]"");
      } catch (CancellationException e) {
        logger.info(""Error rebalancing the cluster"", e);
      } catch (InterruptedException e) {
        logger.info(""Error rebalancing the cluster"", e);
      }
    }",True
"    public void rebalance() {
      try {
        RebalanceOperation operation = getCache().getResourceManager().createRebalanceFactory().start();
        RebalanceResults result = operation.getResults();
        logger.info(""Rebalance result: [TotalBucketCreateBytes="" + result.getTotalBucketCreateBytes()
            + "", TotalBucketCreateTime="" + result.getTotalBucketCreateTime() + "", TotalBucketCreatesCompleted=""
            + result.getTotalBucketCreatesCompleted() + "", TotalBucketTransferBytes=""
            + result.getTotalBucketTransferBytes() + "", TotalBucketTransferTime="" + result.getTotalBucketTransferTime()
            + "", TotalBucketTransfersCompleted="" + +result.getTotalBucketTransfersCompleted()
            + "", TotalPrimaryTransferTime="" + result.getTotalPrimaryTransferTime()
            + "", TotalPrimaryTransfersCompleted="" + result.getTotalPrimaryTransfersCompleted() + "", TotalTime=""
            + result.getTotalTime() + ""]"");
      } catch (CancellationException e) {
        logger.info(""Error rebalancing the cluster"", e);
      } catch (InterruptedException e) {
        logger.info(""Error rebalancing the cluster"", e);
      }
    }",False
"  public void init(Properties props) {
    if (logger.isDebugEnabled()) {
      logger.debug(""Initiazing "" + this.getClass().getSimpleName() + "" with "" + props);
    }

    auditor.init(props);

    String schedule = null;
    if (props != null) {
      schedule = props.getProperty(SCHEDULE);
    }
    scheduler.init(schedule);
  }",True
"  public void init(Properties props) {
    if (logger.isDebugEnabled()) {
      logger.debug(""Initializing "" + this.getClass().getSimpleName() + "" with "" + props);
    }

    auditor.init(props);

    String schedule = null;
    if (props != null) {
      schedule = props.getProperty(SCHEDULE);
    }
    scheduler.init(schedule);
  }",False
"    public void init(Properties props) {
      if (logger.isDebugEnabled()) {
        logger.debug(""Initiazing "" + this.getClass().getSimpleName());
      }

      if (props != null) {
        if (props.getProperty(SIZE_THRESHOLD_PERCENT) != null) {
          sizeThreshold = Integer.valueOf(props.getProperty(SIZE_THRESHOLD_PERCENT));
          if (sizeThreshold <= 0 || sizeThreshold >= 100) {
            throw new GemFireConfigException(SIZE_THRESHOLD_PERCENT + "" should be integer, 1 to 99"");
          }
        }
      }
    }",True
"    public void init(Properties props) {
      if (logger.isDebugEnabled()) {
        logger.debug(""Initializing "" + this.getClass().getSimpleName());
      }

      if (props != null) {
        if (props.getProperty(SIZE_THRESHOLD_PERCENT) != null) {
          sizeThreshold = Integer.valueOf(props.getProperty(SIZE_THRESHOLD_PERCENT));
          if (sizeThreshold <= 0 || sizeThreshold >= 100) {
            throw new GemFireConfigException(SIZE_THRESHOLD_PERCENT + "" should be integer, 1 to 99"");
          }
        }
      }
    }",False
"    public void releaseAutoBalanceLock() {
      DistributedLockService dls = getDLS();
      dls.unlock(AUTO_BALANCER_LOCK);
      if (logger.isDebugEnabled()) {
        logger.debug(""Successfully release auto-balance ownership"");
      }
    }",True
"    public void releaseAutoBalanceLock() {
      DistributedLockService dls = getDLS();
      dls.unlock(AUTO_BALANCER_LOCK);
      if (logger.isDebugEnabled()) {
        logger.debug(""Successfully released auto-balance ownership"");
      }
    }",False
"    public boolean acquireAutoBalanceLock() {
      DistributedLockService dls = getDLS();

      boolean result = dls.lock(AUTO_BALANCER_LOCK, 0, -1);
      if (logger.isDebugEnabled()) {
        logger.debug(""Grabed AutoBalancer lock? "" + result);
      }
      return result;
    }",True
"    public boolean acquireAutoBalanceLock() {
      DistributedLockService dls = getDLS();

      boolean result = dls.lock(AUTO_BALANCER_LOCK, 0, -1);
      if (logger.isDebugEnabled()) {
        logger.debug(""Grabbed AutoBalancer lock? "" + result);
      }
      return result;
    }",False
"    public void init(String schedule) {
      if (logger.isDebugEnabled()) {
        logger.debug(""Initiazing "" + this.getClass().getSimpleName() + "" with "" + schedule);
      }

      if (schedule == null || schedule.isEmpty()) {
        throw new GemFireConfigException(""Missing configuration: "" + SCHEDULE);
      }
      if (!CronExpression.isValidExpression(schedule)) {
        throw new GemFireConfigException(""Invalid schedule: "" + schedule);
      }
      generator = new CronSequenceGenerator(schedule);

      submitNext();
    }",True
"    public void init(String schedule) {
      if (logger.isDebugEnabled()) {
        logger.debug(""Initializing "" + this.getClass().getSimpleName() + "" with "" + schedule);
      }

      if (schedule == null || schedule.isEmpty()) {
        throw new GemFireConfigException(""Missing configuration: "" + SCHEDULE);
      }
      if (!CronExpression.isValidExpression(schedule)) {
        throw new GemFireConfigException(""Invalid schedule: "" + schedule);
      }
      generator = new CronSequenceGenerator(schedule);

      submitNext();
    }",False
"    public void incrementAttemptCounter() {
      GemFireCacheImpl cache = getCache();
      try {
        cache.getResourceManager().getStats().incAutoRebalanceAttempts();
      } catch (Exception e) {
        logger.warn(""Failed ot increment AutoBalanceAttempts counter"");
      }
    }",True
"    public void incrementAttemptCounter() {
      GemFireCacheImpl cache = getCache();
      try {
        cache.getResourceManager().getStats().incAutoRebalanceAttempts();
      } catch (Exception e) {
        logger.warn(""Failed to increment AutoBalanceAttempts counter"");
      }
    }",False
"  protected void flushIfNecessary(Region r) {
    DistributedRegion dr = (DistributedRegion)r;
    Set<InternalDistributedMember> targets = dr.getDistributionAdvisor().adviseCacheOp();
    StateFlushOperation.flushTo(targets, dr);
  }",False
"  public void testReplicate() throws InterruptedException {
    if (!supportsReplication()) {
      return;
    }
    pauseIfNecessary(100); // wait for previous tearDown to complete

    final String name = this.getUniqueName();
    final Object key1 = ""KEY1"";
    final Object value1 = ""VALUE1"";
    final Object key2 = ""KEY2"";

    Object[] v = new Object[3000];
    Arrays.fill(v, new Integer(0xCAFE));

    final Object value2 = Arrays.asList(v);
    final Object key3 = ""KEY3"";
    final Object value3 = ""VALUE3"";

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm2 = host.getVM(2); // use VM on separate shared memory in case shared regions

    SerializableRunnable create = new
      CacheSerializableRunnable(""Create Mirrored Region"") {
        public void run2() throws CacheException {
          RegionAttributes ra = getRegionAttributes();
          AttributesFactory factory =
            new AttributesFactory(ra);
          if (ra.getEvictionAttributes() == null
              || !ra.getEvictionAttributes().getAction().isOverflowToDisk()) {
            factory.setDiskStoreName(null);
          }
          factory.setDataPolicy(DataPolicy.REPLICATE);
          createRegion(name, factory.create());
        }
      };

    vm0.invoke(create);
    Thread.sleep(250);
    vm2.invoke(create);
    Thread.sleep(250);

    vm0.invoke(new CacheSerializableRunnable(""Put data"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.put(key1, value1);
          region.put(key2, value2);
          region.put(key3, value3);
        }
      });

    invokeRepeatingIfNecessary(vm2, new CacheSerializableRunnable(""Wait for update"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        assertNotNull(region.getEntry(key1));
        assertNotNull(region.getEntry(key2));
        assertNotNull(region.getEntry(key3));
      }
    });

    // Destroy the local entries so we know that they are not found by
    // a netSearch
    vm0.invoke(new CacheSerializableRunnable(""Remove local entries"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.localDestroyRegion();
        }
      });

    invokeRepeatingIfNecessary(vm2, new CacheSerializableRunnable(""Verify keys"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);

          // small
          Region.Entry entry1 = region.getEntry(key1);
          assertNotNull(entry1);
          assertEquals(value1, entry1.getValue());

          // large
          Region.Entry entry2 = region.getEntry(key2);
          assertNotNull(entry2);
          assertEquals(value2, entry2.getValue());

          // small
          Region.Entry entry3 = region.getEntry(key3);
          assertNotNull(entry3);
          assertEquals(value3, entry3.getValue());
        }
      });
  }",True
"  public void testReplicate() throws InterruptedException {
    if (!supportsReplication()) {
      return;
    }
    //pauseIfNecessary(100); // wait for previous tearDown to complete

    final String name = this.getUniqueName();
    final Object key1 = ""KEY1"";
    final Object value1 = ""VALUE1"";
    final Object key2 = ""KEY2"";

    Object[] v = new Object[3000];
    Arrays.fill(v, new Integer(0xCAFE));

    final Object value2 = Arrays.asList(v);
    final Object key3 = ""KEY3"";
    final Object value3 = ""VALUE3"";

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm2 = host.getVM(2); // use VM on separate shared memory in case shared regions

    SerializableRunnable create = new
      CacheSerializableRunnable(""Create Mirrored Region"") {
        public void run2() throws CacheException {
          RegionAttributes ra = getRegionAttributes();
          AttributesFactory factory =
            new AttributesFactory(ra);
          if (ra.getEvictionAttributes() == null
              || !ra.getEvictionAttributes().getAction().isOverflowToDisk()) {
            factory.setDiskStoreName(null);
          }
          factory.setDataPolicy(DataPolicy.REPLICATE);
          createRegion(name, factory.create());
        }
      };

    vm0.invoke(create);
    vm2.invoke(create);

    vm0.invoke(new CacheSerializableRunnable(""Put data"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.put(key1, value1);
          region.put(key2, value2);
          region.put(key3, value3);
          flushIfNecessary(region);
          }
      });

    invokeRepeatingIfNecessary(vm2, new CacheSerializableRunnable(""Wait for update"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        assertNotNull(region.getEntry(key1));
        assertNotNull(region.getEntry(key2));
        assertNotNull(region.getEntry(key3));
      }
    });

    // Destroy the local entries so we know that they are not found by
    // a netSearch
    vm0.invoke(new CacheSerializableRunnable(""Remove local entries"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.localDestroyRegion();
          flushIfNecessary(region);
        }
      });

    invokeRepeatingIfNecessary(vm2, new CacheSerializableRunnable(""Verify keys"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);

          // small
          Region.Entry entry1 = region.getEntry(key1);
          assertNotNull(entry1);
          assertEquals(value1, entry1.getValue());

          // large
          Region.Entry entry2 = region.getEntry(key2);
          assertNotNull(entry2);
          assertEquals(value2, entry2.getValue());

          // small
          Region.Entry entry3 = region.getEntry(key3);
          assertNotNull(entry3);
          assertEquals(value3, entry3.getValue());
        }
      });
  }",False
"  public void testMirroredDataFromNonMirrored()
    throws InterruptedException {
    if (!supportsReplication()) {
      return;
    }

    final String name = this.getUniqueName();
    final Object key1 = ""KEY1"";
    final Object value1 = ""VALUE1"";
    final Object key2 = ""KEY2"";
    final Object value2 = ""VALUE2"";
    final Object key3 = ""KEY3"";
    final Object value3 = ""VALUE3"";

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm2 = host.getVM(2); // use a VM on a different gemfire system

    SerializableRunnable create = new CacheSerializableRunnable(""Populate non-mirrored region"") {
      public void run2() throws CacheException {
        RegionAttributes ra = getRegionAttributes();
        AttributesFactory fac =
          new AttributesFactory(ra);
        if (ra.getEvictionAttributes() == null
            || !ra.getEvictionAttributes().getAction().isOverflowToDisk()) {
          fac.setDiskStoreName(null);
        }
        fac.setDataPolicy(DataPolicy.NORMAL);
        //fac.setPersistBackup(false);
        Region region = createRegion(name, fac.create());
        region.put(key1, value1);
        region.put(key2, value2);
        region.put(key3, value3);
      }
    };

    class MirroredDataFromNonMirroredListener extends TestCacheListener {
      // use modifiable ArrayLists
      List expectedKeys = new ArrayList(Arrays.asList(new Object[] {
        key1, key2, key3}));
      List expectedValues = new ArrayList(Arrays.asList(new Object[] {
        value1, value2, value3}));

      public synchronized void afterCreate2(EntryEvent event) {
        //getLogWriter().info(""Invoking afterCreate2 with key="" + event.getKey());
        int index = expectedKeys.indexOf(event.getKey());
        assertTrue(index >= 0);
        assertEquals(expectedValues.remove(index), event.getNewValue());
        expectedKeys.remove(index);
        getLogWriter().info(""afterCreate called in "" +
         ""MirroredDataFromNonMirroredListener for key:"" + event.getKey());
      }
    }

    vm0.invoke(new CacheSerializableRunnable(""Create Mirrored Region"") {
        public void run2() throws CacheException {
          RegionAttributes ra = getRegionAttributes();
          AttributesFactory factory =
            new AttributesFactory(ra);
          if (ra.getEvictionAttributes() == null
              || !ra.getEvictionAttributes().getAction().isOverflowToDisk()) {
            factory.setDiskStoreName(null);
          }
          factory.setDataPolicy(DataPolicy.REPLICATE);
          factory.addCacheListener(new MirroredDataFromNonMirroredListener());
          createRegion(name, factory.create());
        }
      });

    vm2.invoke(create);

    // Destroy the local entries so we know that they are not found by
    // a netSearch
    vm2.invoke(new CacheSerializableRunnable(""Remove local entries"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.localDestroy(key1);
          region.localDestroy(key2);
          region.localDestroy(key3);
        }
      });

    pauseIfNecessary(500);

    vm0.invoke(new CacheSerializableRunnable(""Verify keys/values and listener"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);

          Region.Entry entry1 = region.getEntry(key1);
          assertNotNull(entry1);
          assertEquals(value1, entry1.getValue());

          Region.Entry entry2 = region.getEntry(key2);
          assertNotNull(entry2);
          assertEquals(value2, entry2.getValue());

          Region.Entry entry3 = region.getEntry(key3);
          assertNotNull(entry3);
          assertEquals(value3, entry3.getValue());

          MirroredDataFromNonMirroredListener lsnr =
            (MirroredDataFromNonMirroredListener)region.
            getAttributes().getCacheListeners()[0];

          assertTrue(lsnr.wasInvoked());
          assertTrue(""expectedKeys should be empty, but was: "" + lsnr.expectedKeys,
                     lsnr.expectedKeys.isEmpty());
        }
      });
  }",True
"  public void testMirroredDataFromNonMirrored()
    throws InterruptedException {
    if (!supportsReplication()) {
      return;
    }

    final String name = this.getUniqueName();
    final Object key1 = ""KEY1"";
    final Object value1 = ""VALUE1"";
    final Object key2 = ""KEY2"";
    final Object value2 = ""VALUE2"";
    final Object key3 = ""KEY3"";
    final Object value3 = ""VALUE3"";

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm2 = host.getVM(2); // use a VM on a different gemfire system

    SerializableRunnable create = new CacheSerializableRunnable(""Populate non-mirrored region"") {
      public void run2() throws CacheException {
        RegionAttributes ra = getRegionAttributes();
        AttributesFactory fac =
          new AttributesFactory(ra);
        if (ra.getEvictionAttributes() == null
            || !ra.getEvictionAttributes().getAction().isOverflowToDisk()) {
          fac.setDiskStoreName(null);
        }
        fac.setDataPolicy(DataPolicy.NORMAL);
        //fac.setPersistBackup(false);
        Region region = createRegion(name, fac.create());
        region.put(key1, value1);
        region.put(key2, value2);
        region.put(key3, value3);
        flushIfNecessary(region);
      }
    };

    class MirroredDataFromNonMirroredListener extends TestCacheListener {
      // use modifiable ArrayLists
      List expectedKeys = new ArrayList(Arrays.asList(new Object[] {
        key1, key2, key3}));
      List expectedValues = new ArrayList(Arrays.asList(new Object[] {
        value1, value2, value3}));

      public synchronized void afterCreate2(EntryEvent event) {
        //getLogWriter().info(""Invoking afterCreate2 with key="" + event.getKey());
        int index = expectedKeys.indexOf(event.getKey());
        assertTrue(index >= 0);
        assertEquals(expectedValues.remove(index), event.getNewValue());
        expectedKeys.remove(index);
        getLogWriter().info(""afterCreate called in "" +
         ""MirroredDataFromNonMirroredListener for key:"" + event.getKey());
      }
    }

    vm0.invoke(new CacheSerializableRunnable(""Create Mirrored Region"") {
        public void run2() throws CacheException {
          RegionAttributes ra = getRegionAttributes();
          AttributesFactory factory =
            new AttributesFactory(ra);
          if (ra.getEvictionAttributes() == null
              || !ra.getEvictionAttributes().getAction().isOverflowToDisk()) {
            factory.setDiskStoreName(null);
          }
          factory.setDataPolicy(DataPolicy.REPLICATE);
          factory.addCacheListener(new MirroredDataFromNonMirroredListener());
          createRegion(name, factory.create());
        }
      });

    vm2.invoke(create);

    // Destroy the local entries so we know that they are not found by
    // a netSearch
    vm2.invoke(new CacheSerializableRunnable(""Remove local entries"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.localDestroy(key1);
          region.localDestroy(key2);
          region.localDestroy(key3);
          flushIfNecessary(region);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Verify keys/values and listener"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);

          Region.Entry entry1 = region.getEntry(key1);
          assertNotNull(entry1);
          assertEquals(value1, entry1.getValue());

          Region.Entry entry2 = region.getEntry(key2);
          assertNotNull(entry2);
          assertEquals(value2, entry2.getValue());

          Region.Entry entry3 = region.getEntry(key3);
          assertNotNull(entry3);
          assertEquals(value3, entry3.getValue());

          MirroredDataFromNonMirroredListener lsnr =
            (MirroredDataFromNonMirroredListener)region.
            getAttributes().getCacheListeners()[0];

          assertTrue(lsnr.wasInvoked());
          assertTrue(""expectedKeys should be empty, but was: "" + lsnr.expectedKeys,
                     lsnr.expectedKeys.isEmpty());
        }
      });
  }",False
"  public void testDistributedInvalidate4() throws InterruptedException {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
    final Object value = ""VALUE"";

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            Region region = createRegion(name);
            region.put(key, value);
          }
        };

    Host host = Host.getHost(0);
    int vmCount = host.getVMCount();
    for (int i = 0; i < vmCount; i++) {
      VM vm = host.getVM(i);
      vm.invoke(create);
    }

    pause();

    SerializableRunnable invalidate =
      new CacheSerializableRunnable(""Invalidate Entry"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.invalidate(key);
        }
      };

    for (int i = 0; i < vmCount; i++) {
      VM vm = host.getVM(i);
      vm.invoke(invalidate);
    }

    SerializableRunnable verify =
      new CacheSerializableRunnable(""Verify entry invalidation"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            Region.Entry entry = region.getEntry(key);
            assertNotNull(entry);
            assertNull(entry.getValue());
          }
        };

    for (int i = 0; i < vmCount; i++) {
      VM vm = host.getVM(i);
      vm.invoke(verify);
    }

    // Why is this long 2.5 second pause needed on no-ack?
    pauseIfNecessary(2500);  // wait for messages to acquiesce before tearing down
    getLogWriter().info(""Tearing down..."");
  }",True
"  public void testDistributedInvalidate4() throws InterruptedException {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
    final Object value = ""VALUE"";

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
          }
        };

    Host host = Host.getHost(0);
    int vmCount = host.getVMCount();
    for (int i = 0; i < vmCount; i++) {
      VM vm = host.getVM(i);
      vm.invoke(create);
    }

    SerializableRunnable put =
        new CacheSerializableRunnable(""put entry"") {
            public void run2() throws CacheException {
              Region region =
                  getRootRegion().getSubregion(name);
              region.put(key, value);
              flushIfNecessary(region);
            }
          };

      for (int i = 0; i < vmCount; i++) {
        VM vm = host.getVM(i);
        vm.invoke(put);
      }

      SerializableRunnable invalidate =
      new CacheSerializableRunnable(""Invalidate Entry"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.invalidate(key);
          flushIfNecessary(region);
        }
      };

    for (int i = 0; i < vmCount; i++) {
      VM vm = host.getVM(i);
      vm.invoke(invalidate);
    }

    SerializableRunnable verify =
      new CacheSerializableRunnable(""Verify entry invalidation"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            Region.Entry entry = region.getEntry(key);
            assertNotNull(entry);
            assertNull(entry.getValue());
          }
        };

    for (int i = 0; i < vmCount; i++) {
      VM vm = host.getVM(i);
      vm.invoke(verify);
    }
  }",False
"  public void testCacheLoaderModifyingArgument()
    throws InterruptedException {

    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
    final Object value = ""VALUE"";
    final Object one = ""ONE"";
    final Object two = ""TWO"";

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
          }
        };


    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    vm0.invoke(create);
    vm1.invoke(create);

    CacheSerializableRunnable setLoader = new CacheSerializableRunnable(""Set CacheLoader"") {
      public void run2() throws CacheException {
        final Region region =
          getRootRegion().getSubregion(name);
        loader = new TestCacheLoader() {
            public Object load2(LoaderHelper helper)
              throws CacheLoaderException {

              Object[] array = (Object[]) helper.getArgument();
              assertEquals(one, array[0]);
              array[0] = two;
              return value;
            }
          };
        region.getAttributesMutator().setCacheLoader(loader);
      }
    };

    vm0.invoke(setLoader);

    // if  this is a partitioned region, we need the loader in both vms
    vm1.invoke(new CacheSerializableRunnable(""Conditionally create second loader"") {
      public void run2() throws CacheException {
        final Region region = getRootRegion().getSubregion(name);
        if (region.getAttributes().getPartitionAttributes() != null) {
          loader = new TestCacheLoader() {
            public Object load2(LoaderHelper helper)
              throws CacheLoaderException {

              Object[] array = (Object[]) helper.getArgument();
              assertEquals(one, array[0]);
              array[0] = two;
              return value;
            }
          };
          region.getAttributesMutator().setCacheLoader(loader);
        }
      }
    });

    vm1.invoke(new CacheSerializableRunnable(""Set CacheWriter"") {
        public void run2() throws CacheException {
          final Region region = getRootRegion().getSubregion(name);
          writer = new TestCacheWriter() {
              public void beforeCreate2(EntryEvent event)
                throws CacheWriterException {

                Object[] array = (Object[]) event.getCallbackArgument();
                assertEquals(two, array[0]);
              }
            };
          region.getAttributesMutator().setCacheWriter(writer);
        }
      });

    pauseIfNecessary();

    vm0.invoke(new CacheSerializableRunnable(""Create entry"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          Object[] array = { one };
          Object result = region.get(key, array);
          assertTrue(loader.wasInvoked());
          assertEquals(value, result);
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Validate callback"") {
        public void run2() throws CacheException {
//          if (getRootRegion().getSubregion(name).getAttributes()
//              .getPartitionAttributes() == null) { // bug 36500 - remove check when fixed
            assertTrue(writer.wasInvoked());
//          }
        }
      });
  }",True
"  public void testCacheLoaderModifyingArgument()
    throws InterruptedException {

    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
    final Object value = ""VALUE"";
    final Object one = ""ONE"";
    final Object two = ""TWO"";

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
          }
        };


    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    vm0.invoke(create);
    vm1.invoke(create);

    CacheSerializableRunnable setLoader = new CacheSerializableRunnable(""Set CacheLoader"") {
      public void run2() throws CacheException {
        final Region region =
          getRootRegion().getSubregion(name);
        loader = new TestCacheLoader() {
            public Object load2(LoaderHelper helper)
              throws CacheLoaderException {

              Object[] array = (Object[]) helper.getArgument();
              assertEquals(one, array[0]);
              array[0] = two;
              return value;
            }
          };
        region.getAttributesMutator().setCacheLoader(loader);
        flushIfNecessary(region);
      }
    };

    vm0.invoke(setLoader);

    // if  this is a partitioned region, we need the loader in both vms
    vm1.invoke(new CacheSerializableRunnable(""Conditionally create second loader"") {
      public void run2() throws CacheException {
        final Region region = getRootRegion().getSubregion(name);
        if (region.getAttributes().getPartitionAttributes() != null) {
          loader = new TestCacheLoader() {
            public Object load2(LoaderHelper helper)
              throws CacheLoaderException {

              Object[] array = (Object[]) helper.getArgument();
              assertEquals(one, array[0]);
              array[0] = two;
              return value;
            }
          };
          region.getAttributesMutator().setCacheLoader(loader);
        }
      }
    });

    vm1.invoke(new CacheSerializableRunnable(""Set CacheWriter"") {
        public void run2() throws CacheException {
          final Region region = getRootRegion().getSubregion(name);
          writer = new TestCacheWriter() {
              public void beforeCreate2(EntryEvent event)
                throws CacheWriterException {

                Object[] array = (Object[]) event.getCallbackArgument();
                assertEquals(two, array[0]);
              }
            };
          region.getAttributesMutator().setCacheWriter(writer);
          flushIfNecessary(region);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Create entry"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          Object[] array = { one };
          Object result = region.get(key, array);
          assertTrue(loader.wasInvoked());
          assertEquals(value, result);
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Validate callback"") {
        public void run2() throws CacheException {
//          if (getRootRegion().getSubregion(name).getAttributes()
//              .getPartitionAttributes() == null) { // bug 36500 - remove check when fixed
            assertTrue(writer.wasInvoked());
//          }
        }
      });
  }",False
"  public void testDeltaWithReplicate() throws InterruptedException {
    if (!supportsReplication()) {
      return;
    }
    pauseIfNecessary(100); // wait for previous tearDown to complete
    
    final String name = this.getUniqueName();
    final Object key1 = ""KEY1"";
    final Object value1 = ""VALUE1"";
    final Object key2 = ""KEY2"";
    final Object value2 = new Integer (0xCAFE);
    final Object key3 = ""KEY3"";
    final Object value3 = ""VALUE3"";
    
    final Delta delta = new AddTen();

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm2 = host.getVM(2); // use VM on separate shared memory in case shared regions
    
    SerializableRunnable create = new
    CacheSerializableRunnable(""Create Replicate Region"") {
      public void run2() throws CacheException {
        RegionAttributes ra = getRegionAttributes();
        AttributesFactory factory =
          new AttributesFactory(ra);
        if (ra.getEvictionAttributes() == null
            || !ra.getEvictionAttributes().getAction().isOverflowToDisk()) {
          factory.setDiskStoreName(null);
        }
        factory.setDataPolicy(DataPolicy.REPLICATE);
        createRegion(name, factory.create());
      }
    };
    
    vm0.invoke(create);
    Thread.sleep(250);
    vm2.invoke(create);
    Thread.sleep(250);
    
    vm0.invoke(new CacheSerializableRunnable(""Put data"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        region.put(key1, value1);
        region.put(key2, value2);
        region.put(key3, value3);
      }
    });
    
    invokeRepeatingIfNecessary(vm2, new CacheSerializableRunnable(""Wait for update"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        assertNotNull(region.getEntry(key1));
        assertNotNull(region.getEntry(key2));
        assertNotNull(region.getEntry(key3));
      }
    });
    
    // apply delta
    vm0.invoke(new CacheSerializableRunnable(""Apply delta"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        region.put(key1, delta);
        region.put(key2, delta);
        region.put(key3, delta);
      }
    });
    
    CacheSerializableRunnable verify = 
      new CacheSerializableRunnable(""Verify values"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          
          Region.Entry entry1 = region.getEntry(key1);
          assertNotNull(entry1);
          assertEquals(""VALUE1 10"", entry1.getValue());
          
          Region.Entry entry2 = region.getEntry(key2);
          assertNotNull(entry2);
          assertEquals(new Integer(0xCAFE + 10), entry2.getValue());
          
          Region.Entry entry3 = region.getEntry(key3);
          assertNotNull(entry3);
          assertEquals(""VALUE3 10"", entry3.getValue());
        }
      };
    
    invokeRepeatingIfNecessary(vm0, verify);
    
    
    // Destroy the local entries so we know that they are not found by
    // a netSearch
    vm0.invoke(new CacheSerializableRunnable(""Remove local entries"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        region.localDestroyRegion();
      }
    });
    
    invokeRepeatingIfNecessary(vm2, verify);
    
  }",True
"  public void testDeltaWithReplicate() throws InterruptedException {
    if (!supportsReplication()) {
      return;
    }
    //pauseIfNecessary(100); // wait for previous tearDown to complete
    
    final String name = this.getUniqueName();
    final Object key1 = ""KEY1"";
    final Object value1 = ""VALUE1"";
    final Object key2 = ""KEY2"";
    final Object value2 = new Integer (0xCAFE);
    final Object key3 = ""KEY3"";
    final Object value3 = ""VALUE3"";
    
    final Delta delta = new AddTen();

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm2 = host.getVM(2); // use VM on separate shared memory in case shared regions
    
    SerializableRunnable create = new
    CacheSerializableRunnable(""Create Replicate Region"") {
      public void run2() throws CacheException {
        RegionAttributes ra = getRegionAttributes();
        AttributesFactory factory =
          new AttributesFactory(ra);
        if (ra.getEvictionAttributes() == null
            || !ra.getEvictionAttributes().getAction().isOverflowToDisk()) {
          factory.setDiskStoreName(null);
        }
        factory.setDataPolicy(DataPolicy.REPLICATE);
        createRegion(name, factory.create());
      }
    };
    
    vm0.invoke(create);
    Thread.sleep(250);
    vm2.invoke(create);
    Thread.sleep(250);
    
    vm0.invoke(new CacheSerializableRunnable(""Put data"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        region.put(key1, value1);
        region.put(key2, value2);
        region.put(key3, value3);
      }
    });
    
    invokeRepeatingIfNecessary(vm2, new CacheSerializableRunnable(""Wait for update"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        assertNotNull(region.getEntry(key1));
        assertNotNull(region.getEntry(key2));
        assertNotNull(region.getEntry(key3));
      }
    });
    
    // apply delta
    vm0.invoke(new CacheSerializableRunnable(""Apply delta"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        region.put(key1, delta);
        region.put(key2, delta);
        region.put(key3, delta);
      }
    });
    
    CacheSerializableRunnable verify = 
      new CacheSerializableRunnable(""Verify values"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          
          Region.Entry entry1 = region.getEntry(key1);
          assertNotNull(entry1);
          assertEquals(""VALUE1 10"", entry1.getValue());
          
          Region.Entry entry2 = region.getEntry(key2);
          assertNotNull(entry2);
          assertEquals(new Integer(0xCAFE + 10), entry2.getValue());
          
          Region.Entry entry3 = region.getEntry(key3);
          assertNotNull(entry3);
          assertEquals(""VALUE3 10"", entry3.getValue());
        }
      };
    
    invokeRepeatingIfNecessary(vm0, verify);
    
    
    // Destroy the local entries so we know that they are not found by
    // a netSearch
    vm0.invoke(new CacheSerializableRunnable(""Remove local entries"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        region.localDestroyRegion();
      }
    });
    
    invokeRepeatingIfNecessary(vm2, verify);
    
  }",False
"  public void testDistributedInvalidate() {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
          }
        };

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    VM vm2 = host.getVM(2);

    vm0.invoke(create);
    vm1.invoke(create);

    // vm2 is on a different gemfire system
    vm2.invoke(create);

    final Object key = ""KEY"";
    final Object value = ""VALUE"";

    SerializableRunnable put =
      new CacheSerializableRunnable(""Put key/value"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            region.put(key, value);
          }
        };

    vm0.invoke(put);
    vm1.invoke(put);
    vm2.invoke(put);

    pauseIfNecessary(500);

    vm0.invoke(new CacheSerializableRunnable(""Invalidate Entry"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.invalidate(key);
        }
      });

    CacheSerializableRunnable verify =
      new CacheSerializableRunnable(""Verify entry invalidation"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            Region.Entry entry = region.getEntry(key);
            assertNotNull(entry);
            if (entry.getValue() != null) {
              // changed from severe to fine because it is possible
              // for this to return non-null on d-no-ack
              // that is was invokeRepeatingIfNecessary is called
              getLogWriter().fine(""invalidated entry has value of "" + entry.getValue());
            }
            assertNull(entry.getValue());
          }
        };


    invokeRepeatingIfNecessary(vm1, verify);
    invokeRepeatingIfNecessary(vm2, verify);
  }",True
"  public void testDistributedInvalidate() {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
          }
        };

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    VM vm2 = host.getVM(2);

    vm0.invoke(create);
    vm1.invoke(create);

    // vm2 is on a different gemfire system
    vm2.invoke(create);

    final Object key = ""KEY"";
    final Object value = ""VALUE"";

    SerializableRunnable put =
      new CacheSerializableRunnable(""Put key/value"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            region.put(key, value);
            flushIfNecessary(region);
          }
        };

    vm0.invoke(put);
    vm1.invoke(put);
    vm2.invoke(put);

    vm0.invoke(new CacheSerializableRunnable(""Invalidate Entry"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.invalidate(key);
          flushIfNecessary(region);
        }
      });

    CacheSerializableRunnable verify =
      new CacheSerializableRunnable(""Verify entry invalidation"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            Region.Entry entry = region.getEntry(key);
            assertNotNull(entry);
            if (entry.getValue() != null) {
              // changed from severe to fine because it is possible
              // for this to return non-null on d-no-ack
              // that is was invokeRepeatingIfNecessary is called
              getLogWriter().fine(""invalidated entry has value of "" + entry.getValue());
            }
            assertNull(entry.getValue());
          }
        };


    vm1.invoke(verify);
    vm2.invoke(verify);
  }",False
"  public void DISABLED_testNBRegionInvalidationDuringGetInitialImage() throws Throwable {
    DistributedTestCase.disconnectAllFromDS();
    if (!supportsReplication()) {
      return;
    }
    // don't run this for noAck, too many race conditions
    if (getRegionAttributes().getScope().isDistributedNoAck()) return;

    final String name = this.getUniqueName();
    final byte[][] values = new byte[NB1_NUM_ENTRIES][];

    for (int i = 0; i < NB1_NUM_ENTRIES; i++) {
      values[i] = new byte[NB1_VALUE_SIZE];
      Arrays.fill(values[i], (byte)0x42);
    }

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm2 = host.getVM(2);

    SerializableRunnable create = new
      CacheSerializableRunnable(""Create Mirrored Region"") {
        public void run2() throws CacheException {
          beginCacheXml();
          { // root region must be DACK because its used to sync up async subregions
            AttributesFactory factory = new AttributesFactory();
            factory.setScope(Scope.DISTRIBUTED_ACK);
            factory.setDataPolicy(DataPolicy.NORMAL);
            factory.setSubscriptionAttributes(new SubscriptionAttributes(InterestPolicy.ALL));
            createRootRegion(factory.create());
          }
          {
            AttributesFactory factory =
              new AttributesFactory(getRegionAttributes());
            factory.setDataPolicy(DataPolicy.REPLICATE);
            createRegion(name, factory.create());
          }
          finishCacheXml(name);
          // reset slow
          com.gemstone.gemfire.internal.cache.InitialImageOperation.slowImageProcessing = 0;
        }
      };


    vm0.invoke(new
      CacheSerializableRunnable(""Create Nonmirrored Region"") {
        public void run2() throws CacheException {
          { // root region must be DACK because its used to sync up async subregions
            AttributesFactory factory = new AttributesFactory();
            factory.setScope(Scope.DISTRIBUTED_ACK);
            factory.setDataPolicy(DataPolicy.EMPTY);
            createRootRegion(factory.create());
          }
          {
            AttributesFactory factory =
              new AttributesFactory(getRegionAttributes());
            factory.setDataPolicy(DataPolicy.REPLICATE);
            createRegion(name, factory.create());
          }
          // reset slow
          com.gemstone.gemfire.internal.cache.InitialImageOperation.slowImageProcessing = 0;
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Put initial data"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          for (int i = 0; i < NB1_NUM_ENTRIES; i++) {
            region.put(new Integer(i), values[i]);
          }
          assertEquals(NB1_NUM_ENTRIES, region.keySet().size());
        }
      });


//    attachDebugger(vm0, ""vm0"");
//    attachDebugger(vm2, ""vm2"");

    // start asynchronous process that does updates to the data
    AsyncInvocation async = vm0.invokeAsync(new CacheSerializableRunnable(""Do Nonblocking Operations"") {
      public void run2() throws CacheException {
        Region region =
          getRootRegion().getSubregion(name);

        // wait for profile of getInitialImage cache to show up
        final com.gemstone.gemfire.internal.cache.CacheDistributionAdvisor adv =
          ((com.gemstone.gemfire.internal.cache.DistributedRegion)region).getCacheDistributionAdvisor();
        final int expectedProfiles = 1;
        WaitCriterion ev = new WaitCriterion() {
          public boolean done() {
            return adv.adviseReplicates().size() >= expectedProfiles;
          }
          public String description() {
            return ""profile count never reached "" + expectedProfiles;
          }
        };
        DistributedTestCase.waitForCriterion(ev, 30 * 1000, 200, true);

        // operate on every odd entry with different value, alternating between
        // updates, invalidates, and destroys. These operations are likely
        // to be nonblocking if a sufficient number of updates get through
        // before the get initial image is complete.
        for (int i = 1; i < NB1_NUM_ENTRIES; i += 2) {

          // at magical number 301, do a region invalidation, then continue
          // as before
          if (i == 301) {
//            DebuggerSupport.waitForJavaDebugger(getLogWriter(), ""About to invalidate region"");
            pauseIfNecessary(300); // wait for previous updates to be processed
            region.invalidateRegion();
            pauseIfNecessary(500);
          }

          Object key = new Integer(i);
          switch (i % 6) {
            case 1: // UPDATE
              // use the current timestamp so we know when it happened
              // we could have used last modification timestamps, but
              // this works without enabling statistics
              Object value = new Long(System.currentTimeMillis());
              region.put(key, value);
              // no longer safe since get is not allowed to member doing GII
//               if (getRegionAttributes().getScope().isDistributedAck()) {
//                 // do a nonblocking netSearch
//                 region.localInvalidate(key);
//                 assertEquals(value, region.get(key));
//               }
              break;
            case 3: // INVALIDATE
              region.invalidate(key);
              if (getRegionAttributes().getScope().isDistributedAck()) {
                // do a nonblocking netSearch
                value = region.get(key);
                assertNull(""Expected null value for key: "" + i + "" but got "" + value,
                          value);
              }
              break;
            case 5: // DESTROY
              region.destroy(key);
              if (getRegionAttributes().getScope().isDistributedAck()) {
                // do a nonblocking netSearch
                assertNull(region.get(key));
              }
              break;
            default: fail(""unexpected modulus result: "" + i);
              break;
          }
        }
        // now do a put and our DACK root region which will not complete
        // until processed on otherside which means everything done before this
        // point has been processed
        getRootRegion().put(""DONE"", ""FLUSH_OPS"");
      }
    });

    // in the meantime, do the get initial image in vm2
    // slow down image processing to make it more likely to get async updates
    if (!getRegionAttributes().getScope().isGlobal()) {
      vm2.invoke(new SerializableRunnable(""Set slow image processing"") {
          public void run() {
            // make sure the cache is set up before turning on slow
            // image processing
            getRootRegion();
            // if this is a no_ack test, then we need to slow down more because of the
            // pauses in the nonblocking operations
            int pause = /*getRegionAttributes().getScope().isAck() ? */100/* : 300*/;
            com.gemstone.gemfire.internal.cache.InitialImageOperation.slowImageProcessing = pause;
          }
        });
    }

    AsyncInvocation asyncGII = vm2.invokeAsync(create);


    if (!getRegionAttributes().getScope().isGlobal()) {
      // wait for nonblocking operations to complete
      try {
        DistributedTestCase.join(async, 30 * 1000, getLogWriter());
      } finally {
        vm2.invoke(new SerializableRunnable(""Set fast image processing"") {
          public void run() {
            com.gemstone.gemfire.internal.cache.InitialImageOperation.slowImageProcessing = 0;
          }
        });
      }
      getLogWriter().info(""after async nonblocking ops complete"");
    }

    // wait for GII to complete
    DistributedTestCase.join(asyncGII, 30 * 1000, getLogWriter());
    final long iiComplete = System.currentTimeMillis();
    getLogWriter().info(""Complete GetInitialImage at: "" + System.currentTimeMillis());
    if (getRegionAttributes().getScope().isGlobal()) {
      // wait for nonblocking operations to complete
      DistributedTestCase.join(async, 30 * 1000, getLogWriter());
    }
    if (asyncGII.exceptionOccurred()) {
      throw new Error(""asyncGII failed"", asyncGII.getException());
    }
    if (async.exceptionOccurred()) {
      throw new Error(""async failed"", async.getException());
    }

    // Locally destroy the region in vm0 so we know that they are not found by
    // a netSearch
    vm0.invoke(new CacheSerializableRunnable(""Locally destroy region"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.localDestroyRegion();
        }
      });


      // invoke repeating so noack regions wait for all updates to get processed
    vm2.invokeRepeatingIfNecessary(new CacheSerializableRunnable(""Verify entryCount"") {
        private boolean entriesDumped = false;

        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          // expected entry count (subtract entries destroyed)
          int entryCount = NB1_NUM_ENTRIES - NB1_NUM_ENTRIES / 6;
          int actualCount = region.entrySet(false).size();
          if (actualCount == NB1_NUM_ENTRIES) {
            // entries not destroyed, dump entries that were supposed to have been destroyed
            dumpDestroyedEntries(region);
          }
          assertEquals(entryCount, actualCount);
        }

        private void dumpDestroyedEntries(Region region) throws EntryNotFoundException {
          if (entriesDumped) return;
          entriesDumped = true;

          LogWriter logger = getLogWriter();
          logger.info(""DUMPING Entries with values in VM that should have been destroyed:"");
          for (int i = 5; i < NB1_NUM_ENTRIES; i += 6) {
            logger.info(i + ""-->"" +
              ((com.gemstone.gemfire.internal.cache.LocalRegion)region).getValueInVM(new Integer(i)));
          }
        }
    }, 3000);

    vm2.invoke(new CacheSerializableRunnable(""Verify keys/values & Nonblocking"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          // expected entry count (subtract entries destroyed)
          int entryCount = NB1_NUM_ENTRIES - NB1_NUM_ENTRIES / 6;
          assertEquals(entryCount, region.entrySet(false).size());
          // determine how many entries were updated before getInitialImage
          // was complete
          int numConcurrent = 0;

          for (int i = 0; i < NB1_NUM_ENTRIES; i++) {
            Region.Entry entry = region.getEntry(new Integer(i));
            if (i < 301) {
              if (i % 6 == 5) {
                assertNull(""Expected entry for "" + i + "" to be destroyed but it is "" + entry,
                            entry); // destroyed
              }
              else {
                assertNotNull(entry);
                Object v = entry.getValue();
                assertNull(""Expected value for "" + i + "" to be null, but was "" + v,
                            v);
              }
            }
            else {
              Object v = entry == null ? null : entry.getValue();
              switch (i % 6) {
                // even keys are originals
                case 0: case 2: case 4:
                  assertNotNull(entry);
                  assertNull(""Expected value for "" + i + "" to be null, but was "" + v,
                              v);
                  break;
                case 1: // updated
                  assertNotNull(""Expected to find an entry for #""+i, entry);
                  assertNotNull(""Expected to find a value for #""+i, v);
                  assertTrue(""Value for key "" + i + "" is not a Long, is a "" +
                             v.getClass().getName(), v instanceof Long);
                  Long timestamp = (Long)entry.getValue();
                  if (timestamp.longValue() < iiComplete) {
                    numConcurrent++;
                  }
                  break;
                case 3: // invalidated
                  assertNotNull(""Expected to find an entry for #""+i, entry);
                  assertNull(""Expected value for "" + i + "" to be null, but was "" + v, v);
                  break;
                case 5: // destroyed
                  assertNull(""Expected to not find an entry for #""+i, entry);
                  break;
                default:
                  fail(""unexpected modulus result: "" + (i % 6));
                  break;
              }
            }
          }
          getLogWriter().info(name + "": "" + numConcurrent + "" entries out of "" + entryCount +
                              "" were updated concurrently with getInitialImage"");

          // [sumedh] Occasionally fails. Do these assertions really make sense?
          // Looks like some random expectations that will always be a hit/miss.

          // make sure at least some of them were concurrent
          if (getRegionAttributes().getScope().isGlobal()) {
            assertTrue(""Too many concurrent updates when expected to block: "" + numConcurrent,
                        numConcurrent < 300);
          }
          else {
            assertTrue(""Not enough updates concurrent with getInitialImage occurred to my liking. ""
                        + numConcurrent + "" entries out of "" + entryCount +
                        "" were updated concurrently with getInitialImage, and I'd expect at least 50 or so"",
                        numConcurrent >= 30);
          }
        }
      });
  }",True
"  public void DISABLED_testNBRegionInvalidationDuringGetInitialImage() throws Throwable {
    DistributedTestCase.disconnectAllFromDS();
    if (!supportsReplication()) {
      return;
    }
    // don't run this for noAck, too many race conditions
    if (getRegionAttributes().getScope().isDistributedNoAck()) return;

    final String name = this.getUniqueName();
    final byte[][] values = new byte[NB1_NUM_ENTRIES][];

    for (int i = 0; i < NB1_NUM_ENTRIES; i++) {
      values[i] = new byte[NB1_VALUE_SIZE];
      Arrays.fill(values[i], (byte)0x42);
    }

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm2 = host.getVM(2);

    SerializableRunnable create = new
      CacheSerializableRunnable(""Create Mirrored Region"") {
        public void run2() throws CacheException {
          beginCacheXml();
          { // root region must be DACK because its used to sync up async subregions
            AttributesFactory factory = new AttributesFactory();
            factory.setScope(Scope.DISTRIBUTED_ACK);
            factory.setDataPolicy(DataPolicy.NORMAL);
            factory.setSubscriptionAttributes(new SubscriptionAttributes(InterestPolicy.ALL));
            createRootRegion(factory.create());
          }
          {
            AttributesFactory factory =
              new AttributesFactory(getRegionAttributes());
            factory.setDataPolicy(DataPolicy.REPLICATE);
            createRegion(name, factory.create());
          }
          finishCacheXml(name);
          // reset slow
          com.gemstone.gemfire.internal.cache.InitialImageOperation.slowImageProcessing = 0;
        }
      };


    vm0.invoke(new
      CacheSerializableRunnable(""Create Nonmirrored Region"") {
        public void run2() throws CacheException {
          { // root region must be DACK because its used to sync up async subregions
            AttributesFactory factory = new AttributesFactory();
            factory.setScope(Scope.DISTRIBUTED_ACK);
            factory.setDataPolicy(DataPolicy.EMPTY);
            createRootRegion(factory.create());
          }
          {
            AttributesFactory factory =
              new AttributesFactory(getRegionAttributes());
            factory.setDataPolicy(DataPolicy.REPLICATE);
            createRegion(name, factory.create());
          }
          // reset slow
          com.gemstone.gemfire.internal.cache.InitialImageOperation.slowImageProcessing = 0;
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Put initial data"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          for (int i = 0; i < NB1_NUM_ENTRIES; i++) {
            region.put(new Integer(i), values[i]);
          }
          assertEquals(NB1_NUM_ENTRIES, region.keySet().size());
        }
      });


//    attachDebugger(vm0, ""vm0"");
//    attachDebugger(vm2, ""vm2"");

    // start asynchronous process that does updates to the data
    AsyncInvocation async = vm0.invokeAsync(new CacheSerializableRunnable(""Do Nonblocking Operations"") {
      public void run2() throws CacheException {
        Region region =
          getRootRegion().getSubregion(name);

        // wait for profile of getInitialImage cache to show up
        final com.gemstone.gemfire.internal.cache.CacheDistributionAdvisor adv =
          ((com.gemstone.gemfire.internal.cache.DistributedRegion)region).getCacheDistributionAdvisor();
        final int expectedProfiles = 1;
        WaitCriterion ev = new WaitCriterion() {
          public boolean done() {
            return adv.adviseReplicates().size() >= expectedProfiles;
          }
          public String description() {
            return ""profile count never reached "" + expectedProfiles;
          }
        };
        DistributedTestCase.waitForCriterion(ev, 30 * 1000, 200, true);

        // operate on every odd entry with different value, alternating between
        // updates, invalidates, and destroys. These operations are likely
        // to be nonblocking if a sufficient number of updates get through
        // before the get initial image is complete.
        for (int i = 1; i < NB1_NUM_ENTRIES; i += 2) {

          // at magical number 301, do a region invalidation, then continue
          // as before
          if (i == 301) {
//            DebuggerSupport.waitForJavaDebugger(getLogWriter(), ""About to invalidate region"");
            // wait for previous updates to be processed
            flushIfNecessary(region);
            region.invalidateRegion();
            flushIfNecessary(region);
          }

          Object key = new Integer(i);
          switch (i % 6) {
            case 1: // UPDATE
              // use the current timestamp so we know when it happened
              // we could have used last modification timestamps, but
              // this works without enabling statistics
              Object value = new Long(System.currentTimeMillis());
              region.put(key, value);
              // no longer safe since get is not allowed to member doing GII
//               if (getRegionAttributes().getScope().isDistributedAck()) {
//                 // do a nonblocking netSearch
//                 region.localInvalidate(key);
//                 assertEquals(value, region.get(key));
//               }
              break;
            case 3: // INVALIDATE
              region.invalidate(key);
              if (getRegionAttributes().getScope().isDistributedAck()) {
                // do a nonblocking netSearch
                value = region.get(key);
                assertNull(""Expected null value for key: "" + i + "" but got "" + value,
                          value);
              }
              break;
            case 5: // DESTROY
              region.destroy(key);
              if (getRegionAttributes().getScope().isDistributedAck()) {
                // do a nonblocking netSearch
                assertNull(region.get(key));
              }
              break;
            default: fail(""unexpected modulus result: "" + i);
              break;
          }
        }
        // now do a put and our DACK root region which will not complete
        // until processed on otherside which means everything done before this
        // point has been processed
        getRootRegion().put(""DONE"", ""FLUSH_OPS"");
      }
    });

    // in the meantime, do the get initial image in vm2
    // slow down image processing to make it more likely to get async updates
    if (!getRegionAttributes().getScope().isGlobal()) {
      vm2.invoke(new SerializableRunnable(""Set slow image processing"") {
          public void run() {
            // make sure the cache is set up before turning on slow
            // image processing
            getRootRegion();
            // if this is a no_ack test, then we need to slow down more because of the
            // pauses in the nonblocking operations
            int pause = /*getRegionAttributes().getScope().isAck() ? */100/* : 300*/;
            com.gemstone.gemfire.internal.cache.InitialImageOperation.slowImageProcessing = pause;
          }
        });
    }

    AsyncInvocation asyncGII = vm2.invokeAsync(create);


    if (!getRegionAttributes().getScope().isGlobal()) {
      // wait for nonblocking operations to complete
      try {
        DistributedTestCase.join(async, 30 * 1000, getLogWriter());
      } finally {
        vm2.invoke(new SerializableRunnable(""Set fast image processing"") {
          public void run() {
            com.gemstone.gemfire.internal.cache.InitialImageOperation.slowImageProcessing = 0;
          }
        });
      }
      getLogWriter().info(""after async nonblocking ops complete"");
    }

    // wait for GII to complete
    DistributedTestCase.join(asyncGII, 30 * 1000, getLogWriter());
    final long iiComplete = System.currentTimeMillis();
    getLogWriter().info(""Complete GetInitialImage at: "" + System.currentTimeMillis());
    if (getRegionAttributes().getScope().isGlobal()) {
      // wait for nonblocking operations to complete
      DistributedTestCase.join(async, 30 * 1000, getLogWriter());
    }
    if (asyncGII.exceptionOccurred()) {
      throw new Error(""asyncGII failed"", asyncGII.getException());
    }
    if (async.exceptionOccurred()) {
      throw new Error(""async failed"", async.getException());
    }

    // Locally destroy the region in vm0 so we know that they are not found by
    // a netSearch
    vm0.invoke(new CacheSerializableRunnable(""Locally destroy region"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.localDestroyRegion();
        }
      });


      // invoke repeating so noack regions wait for all updates to get processed
    vm2.invokeRepeatingIfNecessary(new CacheSerializableRunnable(""Verify entryCount"") {
        private boolean entriesDumped = false;

        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          // expected entry count (subtract entries destroyed)
          int entryCount = NB1_NUM_ENTRIES - NB1_NUM_ENTRIES / 6;
          int actualCount = region.entrySet(false).size();
          if (actualCount == NB1_NUM_ENTRIES) {
            // entries not destroyed, dump entries that were supposed to have been destroyed
            dumpDestroyedEntries(region);
          }
          assertEquals(entryCount, actualCount);
        }

        private void dumpDestroyedEntries(Region region) throws EntryNotFoundException {
          if (entriesDumped) return;
          entriesDumped = true;

          LogWriter logger = getLogWriter();
          logger.info(""DUMPING Entries with values in VM that should have been destroyed:"");
          for (int i = 5; i < NB1_NUM_ENTRIES; i += 6) {
            logger.info(i + ""-->"" +
              ((com.gemstone.gemfire.internal.cache.LocalRegion)region).getValueInVM(new Integer(i)));
          }
        }
    }, 3000);

    vm2.invoke(new CacheSerializableRunnable(""Verify keys/values & Nonblocking"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          // expected entry count (subtract entries destroyed)
          int entryCount = NB1_NUM_ENTRIES - NB1_NUM_ENTRIES / 6;
          assertEquals(entryCount, region.entrySet(false).size());
          // determine how many entries were updated before getInitialImage
          // was complete
          int numConcurrent = 0;

          for (int i = 0; i < NB1_NUM_ENTRIES; i++) {
            Region.Entry entry = region.getEntry(new Integer(i));
            if (i < 301) {
              if (i % 6 == 5) {
                assertNull(""Expected entry for "" + i + "" to be destroyed but it is "" + entry,
                            entry); // destroyed
              }
              else {
                assertNotNull(entry);
                Object v = entry.getValue();
                assertNull(""Expected value for "" + i + "" to be null, but was "" + v,
                            v);
              }
            }
            else {
              Object v = entry == null ? null : entry.getValue();
              switch (i % 6) {
                // even keys are originals
                case 0: case 2: case 4:
                  assertNotNull(entry);
                  assertNull(""Expected value for "" + i + "" to be null, but was "" + v,
                              v);
                  break;
                case 1: // updated
                  assertNotNull(""Expected to find an entry for #""+i, entry);
                  assertNotNull(""Expected to find a value for #""+i, v);
                  assertTrue(""Value for key "" + i + "" is not a Long, is a "" +
                             v.getClass().getName(), v instanceof Long);
                  Long timestamp = (Long)entry.getValue();
                  if (timestamp.longValue() < iiComplete) {
                    numConcurrent++;
                  }
                  break;
                case 3: // invalidated
                  assertNotNull(""Expected to find an entry for #""+i, entry);
                  assertNull(""Expected value for "" + i + "" to be null, but was "" + v, v);
                  break;
                case 5: // destroyed
                  assertNull(""Expected to not find an entry for #""+i, entry);
                  break;
                default:
                  fail(""unexpected modulus result: "" + (i % 6));
                  break;
              }
            }
          }
          getLogWriter().info(name + "": "" + numConcurrent + "" entries out of "" + entryCount +
                              "" were updated concurrently with getInitialImage"");

          // [sumedh] Occasionally fails. Do these assertions really make sense?
          // Looks like some random expectations that will always be a hit/miss.

          // make sure at least some of them were concurrent
          if (getRegionAttributes().getScope().isGlobal()) {
            assertTrue(""Too many concurrent updates when expected to block: "" + numConcurrent,
                        numConcurrent < 300);
          }
          else {
            assertTrue(""Not enough updates concurrent with getInitialImage occurred to my liking. ""
                        + numConcurrent + "" entries out of "" + entryCount +
                        "" were updated concurrently with getInitialImage, and I'd expect at least 50 or so"",
                        numConcurrent >= 30);
          }
        }
      });
  }",False
"  public void testDistributedRegionDestroy()
    throws InterruptedException {

    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
          }
        };

    invokeInEveryVM(create);

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);

    vm0.invoke(new CacheSerializableRunnable(""Destroy Region"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.destroyRegion();
        }
      });

    pauseIfNecessary(400);

    invokeInEveryVM(new CacheSerializableRunnable(""Verify region destruction"") {
      public void run2() throws CacheException {
        WaitCriterion ev = new WaitCriterion() {
          public boolean done() {
            return getRootRegion().getSubregion(name) == null;
          }
          public String description() {
            return ""Waiting for region "" + name + "" to be destroyed"";
          }
        };
        DistributedTestCase.waitForCriterion(ev, 60 * 1000, 200, true);
        Region region = getRootRegion().getSubregion(name);
        assertNull(region);
      }
    });
  }",True
"  public void testDistributedRegionDestroy()
    throws InterruptedException {

    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
          }
        };

    invokeInEveryVM(create);

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);

    vm0.invoke(new CacheSerializableRunnable(""Destroy Region"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.destroyRegion();
          flushIfNecessary(region);
        }
      });

    invokeInEveryVM(new CacheSerializableRunnable(""Verify region destruction"") {
      public void run2() throws CacheException {
        WaitCriterion ev = new WaitCriterion() {
          public boolean done() {
            return getRootRegion().getSubregion(name) == null;
          }
          public String description() {
            return ""Waiting for region "" + name + "" to be destroyed"";
          }
        };
        DistributedTestCase.waitForCriterion(ev, 60 * 1000, 10, true);
        Region region = getRootRegion().getSubregion(name);
        assertNull(region);
      }
    });
  }",False
"  public void testTXUpdateLoadNoConflict() throws Exception {
    /*
     * this no longer holds true - we have load conflicts now
     * 
     */
    if(true) {
      return;
    }
    
    if (!supportsTransactions()) {
      return;
    }
    assertTrue(getRegionAttributes().getScope().isDistributed());
    CacheTransactionManager txMgr = this.getCache().getCacheTransactionManager();

    if (getRegionAttributes().getScope().isGlobal()
        || getRegionAttributes().getDataPolicy().withPersistence()) {
      return;
    }
    final String rgnName = getUniqueName();

    SerializableRunnable create = new SerializableRunnable(""testTXUpdateLoadNoConflict: Create Region & Load value"") {
      public void run() {
        CacheTransactionManager txMgr2 = getCache().getCacheTransactionManager();
        MyTransactionListener tl = new MyTransactionListener();
        txMgr2.addListener(tl);
        try {
          Region rgn = createRegion(rgnName);
          AttributesMutator mutator = rgn.getAttributesMutator();
          mutator.setCacheLoader(new CacheLoader() {
              int count = 0;
              public Object load(LoaderHelper helper)
                throws CacheLoaderException
              {
                count++;
                return ""LV "" + count;

              }
              public void close() {}
            });
          Object value = rgn.get(""key"");
          assertEquals(""LV 1"", value);
          getSystem().getLogWriter().info(""testTXUpdateLoadNoConflict: loaded Key"");
        }
        catch (CacheException e) {
          fail(""While creating region"", e);
        }
      }
    };

    VM vm0 = Host.getHost(0).getVM(0);
    // GemFireVersion.waitForJavaDebugger(getLogWriter(), ""CTRLR WAITING AFTER CREATE"");

    try {
      MyTransactionListener tl = new MyTransactionListener();
      txMgr.addListener(tl);
      AttributesFactory rgnAtts = new AttributesFactory(getRegionAttributes());
      rgnAtts.setDataPolicy(DataPolicy.REPLICATE);
      Region rgn = createRegion(rgnName, rgnAtts.create());

      txMgr.begin();
      TransactionId myTXId = txMgr.getTransactionId();

      rgn.create(""key"", ""txValue"");

      vm0.invoke(create);

      pauseIfNecessary(); // give us a chance to get the update
      {
        TXStateProxy tx = ((TXManagerImpl)txMgr).internalSuspend();
        assertTrue(rgn.containsKey(""key""));
        assertEquals(""LV 1"", rgn.getEntry(""key"").getValue());
        ((TXManagerImpl)txMgr).resume(tx);
      }
      // make sure transactional view is still correct
      assertEquals(""txValue"", rgn.getEntry(""key"").getValue());

      txMgr.commit();
      getSystem().getLogWriter().info(""testTXUpdateLoadNoConflict: did commit"");
      assertEquals(""txValue"", rgn.getEntry(""key"").getValue());
      {
        Collection events = tl.lastEvent.getCreateEvents();
        assertEquals(1, events.size());
        EntryEvent ev = (EntryEvent)events.iterator().next();
        assertEquals(myTXId, ev.getTransactionId());
        assertTrue(ev.getRegion() == rgn);
        assertEquals(""key"", ev.getKey());
        assertEquals(""txValue"", ev.getNewValue());
        assertEquals(null, ev.getOldValue());
        assertTrue(!ev.getOperation().isLocalLoad());
        assertTrue(!ev.getOperation().isNetLoad());
        assertTrue(!ev.getOperation().isLoad());
        assertTrue(!ev.getOperation().isNetSearch());
        assertTrue(!ev.getOperation().isExpiration());
        assertEquals(null, ev.getCallbackArgument());
        assertEquals(true, ev.isCallbackArgumentAvailable());
        assertTrue(!ev.isOriginRemote());
        assertTrue(ev.getOperation().isDistributed());
      }

      // Now setup recreate the region in the controller with NONE
      // so test can do local destroys.
      rgn.localDestroyRegion();
      rgnAtts.setDataPolicy(DataPolicy.NORMAL);
      rgn = createRegion(rgnName, rgnAtts.create());

      // now see if net loader is working
      Object v2 = rgn.get(""key2"");
      assertEquals(""LV 2"", v2);

      // now confirm that netload does not cause a conflict
      txMgr.begin();
      myTXId = txMgr.getTransactionId();

      rgn.create(""key3"", ""txValue3"");

      {
        TXStateProxy tx = ((TXManagerImpl)txMgr).internalSuspend();
        // do a get outside of the transaction to force a net load
        Object v3 = rgn.get(""key3"");
        assertEquals(""LV 3"", v3);
        ((TXManagerImpl)txMgr).resume(tx);
      }
      // make sure transactional view is still correct
      assertEquals(""txValue3"", rgn.getEntry(""key3"").getValue());

      txMgr.commit();
      getSystem().getLogWriter().info(""testTXUpdateLoadNoConflict: did commit"");
      assertEquals(""txValue3"", rgn.getEntry(""key3"").getValue());
      {
        Collection events = tl.lastEvent.getCreateEvents();
        assertEquals(1, events.size());
        EntryEvent ev = (EntryEvent)events.iterator().next();
        assertEquals(myTXId, ev.getTransactionId());
        assertTrue(ev.getRegion() == rgn);
        assertEquals(""key3"", ev.getKey());
        assertEquals(""txValue3"", ev.getNewValue());
        assertEquals(null, ev.getOldValue());
        assertTrue(!ev.getOperation().isLocalLoad());
        assertTrue(!ev.getOperation().isNetLoad());
        assertTrue(!ev.getOperation().isLoad());
        assertTrue(!ev.getOperation().isNetSearch());
        assertTrue(!ev.getOperation().isExpiration());
        assertEquals(null, ev.getCallbackArgument());
        assertEquals(true, ev.isCallbackArgumentAvailable());
        assertTrue(!ev.isOriginRemote());
        assertTrue(ev.getOperation().isDistributed());
      }

      // now see if tx net loader is working

      // now confirm that netload does not cause a conflict
      txMgr.begin();
      myTXId = txMgr.getTransactionId();
      Object v4 = rgn.get(""key4"");
      assertEquals(""LV 4"", v4);
      assertEquals(""LV 4"", rgn.get(""key4""));
      assertEquals(""LV 4"", rgn.getEntry(""key4"").getValue());
      txMgr.rollback();
      // confirm that netLoad is transactional
      assertEquals(""LV 5"", rgn.get(""key4""));
      assertEquals(""LV 5"", rgn.getEntry(""key4"").getValue());

      // make sure non-tx netsearch works
      assertEquals(""txValue"", rgn.get(""key""));
      assertEquals(""txValue"", rgn.getEntry(""key"").getValue());

      // make sure net-search result does not conflict with commit
      rgn.localInvalidate(""key"");
      txMgr.begin();
      myTXId = txMgr.getTransactionId();

      rgn.put(""key"", ""new txValue"");

      {
        TXStateProxy tx = ((TXManagerImpl)txMgr).internalSuspend();
        // do a get outside of the transaction to force a netsearch
        assertEquals(""txValue"", rgn.get(""key"")); // does a netsearch
        assertEquals(""txValue"", rgn.getEntry(""key"").getValue());
        ((TXManagerImpl)txMgr).resume(tx);
      }
      // make sure transactional view is still correct
      assertEquals(""new txValue"", rgn.getEntry(""key"").getValue());

      txMgr.commit();
      pauseIfNecessary(); // give other side change to process commit
      getSystem().getLogWriter().info(""testTXUpdateLoadNoConflict: did commit"");
      assertEquals(""new txValue"", rgn.getEntry(""key"").getValue());
      {
        Collection events = tl.lastEvent.getPutEvents();
        assertEquals(1, events.size());
        EntryEvent ev = (EntryEvent)events.iterator().next();
        assertEquals(myTXId, ev.getTransactionId());
        assertTrue(ev.getRegion() == rgn);
        assertEquals(""key"", ev.getKey());
        assertEquals(""new txValue"", ev.getNewValue());
        assertEquals(null, ev.getOldValue());
        assertTrue(!ev.getOperation().isLocalLoad());
        assertTrue(!ev.getOperation().isNetLoad());
        assertTrue(!ev.getOperation().isLoad());
        assertTrue(!ev.getOperation().isNetSearch());
        assertTrue(!ev.getOperation().isExpiration());
        assertEquals(null, ev.getCallbackArgument());
        assertEquals(true, ev.isCallbackArgumentAvailable());
        assertTrue(!ev.isOriginRemote());
        assertTrue(ev.getOperation().isDistributed());
      }


      // make sure tx local invalidate allows netsearch
      Object localCmtValue = rgn.getEntry(""key"").getValue();
      txMgr.begin();
      assertSame(localCmtValue, rgn.getEntry(""key"").getValue());
      rgn.localInvalidate(""key"");
      assertNull(rgn.getEntry(""key"").getValue());
      // now make sure a get will do a netsearch and find the value
      // in the other vm instead of the one in local cmt state
      Object txValue = rgn.get(""key"");
      assertNotSame(localCmtValue, txValue);
      assertSame(txValue, rgn.get(""key""));
      assertNotSame(localCmtValue, rgn.getEntry(""key"").getValue());
      // make sure we did a search and not a load
      assertEquals(localCmtValue, rgn.getEntry(""key"").getValue());
      // now make sure that if we do a tx distributed invalidate
      // that we will do a load and not a search
      rgn.invalidate(""key"");
      assertNull(rgn.getEntry(""key"").getValue());
      txValue = rgn.get(""key"");
      assertEquals(""LV 6"", txValue);
      assertSame(txValue, rgn.get(""key""));
      assertEquals(""LV 6"", rgn.getEntry(""key"").getValue());
      // now make sure after rollback that local cmt state has not changed
      txMgr.rollback();
      assertSame(localCmtValue, rgn.getEntry(""key"").getValue());
    }
    catch(Exception e) {
      CacheFactory.getInstance(getSystem()).close();
      getSystem().getLogWriter().fine(""testTXUpdateLoadNoConflict: Caused exception in createRegion"");
      throw e;
    }

  }",True
"  public void testTXUpdateLoadNoConflict() throws Exception {
    /*
     * this no longer holds true - we have load conflicts now
     * 
     */
    if(true) {
      return;
    }
    
    if (!supportsTransactions()) {
      return;
    }
    assertTrue(getRegionAttributes().getScope().isDistributed());
    CacheTransactionManager txMgr = this.getCache().getCacheTransactionManager();

    if (getRegionAttributes().getScope().isGlobal()
        || getRegionAttributes().getDataPolicy().withPersistence()) {
      return;
    }
    final String rgnName = getUniqueName();

    SerializableRunnable create = new SerializableRunnable(""testTXUpdateLoadNoConflict: Create Region & Load value"") {
      public void run() {
        CacheTransactionManager txMgr2 = getCache().getCacheTransactionManager();
        MyTransactionListener tl = new MyTransactionListener();
        txMgr2.addListener(tl);
        try {
          Region rgn = createRegion(rgnName);
          AttributesMutator mutator = rgn.getAttributesMutator();
          mutator.setCacheLoader(new CacheLoader() {
              int count = 0;
              public Object load(LoaderHelper helper)
                throws CacheLoaderException
              {
                count++;
                return ""LV "" + count;

              }
              public void close() {}
            });
          Object value = rgn.get(""key"");
          assertEquals(""LV 1"", value);
          getSystem().getLogWriter().info(""testTXUpdateLoadNoConflict: loaded Key"");
          flushIfNecessary(rgn);
        }
        catch (CacheException e) {
          fail(""While creating region"", e);
        }
      }
    };

    VM vm0 = Host.getHost(0).getVM(0);
    // GemFireVersion.waitForJavaDebugger(getLogWriter(), ""CTRLR WAITING AFTER CREATE"");

    try {
      MyTransactionListener tl = new MyTransactionListener();
      txMgr.addListener(tl);
      AttributesFactory rgnAtts = new AttributesFactory(getRegionAttributes());
      rgnAtts.setDataPolicy(DataPolicy.REPLICATE);
      Region rgn = createRegion(rgnName, rgnAtts.create());

      txMgr.begin();
      TransactionId myTXId = txMgr.getTransactionId();

      rgn.create(""key"", ""txValue"");

      vm0.invoke(create);

      {
        TXStateProxy tx = ((TXManagerImpl)txMgr).internalSuspend();
        assertTrue(rgn.containsKey(""key""));
        assertEquals(""LV 1"", rgn.getEntry(""key"").getValue());
        ((TXManagerImpl)txMgr).resume(tx);
      }
      // make sure transactional view is still correct
      assertEquals(""txValue"", rgn.getEntry(""key"").getValue());

      txMgr.commit();
      getSystem().getLogWriter().info(""testTXUpdateLoadNoConflict: did commit"");
      assertEquals(""txValue"", rgn.getEntry(""key"").getValue());
      {
        Collection events = tl.lastEvent.getCreateEvents();
        assertEquals(1, events.size());
        EntryEvent ev = (EntryEvent)events.iterator().next();
        assertEquals(myTXId, ev.getTransactionId());
        assertTrue(ev.getRegion() == rgn);
        assertEquals(""key"", ev.getKey());
        assertEquals(""txValue"", ev.getNewValue());
        assertEquals(null, ev.getOldValue());
        assertTrue(!ev.getOperation().isLocalLoad());
        assertTrue(!ev.getOperation().isNetLoad());
        assertTrue(!ev.getOperation().isLoad());
        assertTrue(!ev.getOperation().isNetSearch());
        assertTrue(!ev.getOperation().isExpiration());
        assertEquals(null, ev.getCallbackArgument());
        assertEquals(true, ev.isCallbackArgumentAvailable());
        assertTrue(!ev.isOriginRemote());
        assertTrue(ev.getOperation().isDistributed());
      }

      // Now setup recreate the region in the controller with NONE
      // so test can do local destroys.
      rgn.localDestroyRegion();
      rgnAtts.setDataPolicy(DataPolicy.NORMAL);
      rgn = createRegion(rgnName, rgnAtts.create());

      // now see if net loader is working
      Object v2 = rgn.get(""key2"");
      assertEquals(""LV 2"", v2);

      // now confirm that netload does not cause a conflict
      txMgr.begin();
      myTXId = txMgr.getTransactionId();

      rgn.create(""key3"", ""txValue3"");

      {
        TXStateProxy tx = ((TXManagerImpl)txMgr).internalSuspend();
        // do a get outside of the transaction to force a net load
        Object v3 = rgn.get(""key3"");
        assertEquals(""LV 3"", v3);
        ((TXManagerImpl)txMgr).resume(tx);
      }
      // make sure transactional view is still correct
      assertEquals(""txValue3"", rgn.getEntry(""key3"").getValue());

      txMgr.commit();
      getSystem().getLogWriter().info(""testTXUpdateLoadNoConflict: did commit"");
      assertEquals(""txValue3"", rgn.getEntry(""key3"").getValue());
      {
        Collection events = tl.lastEvent.getCreateEvents();
        assertEquals(1, events.size());
        EntryEvent ev = (EntryEvent)events.iterator().next();
        assertEquals(myTXId, ev.getTransactionId());
        assertTrue(ev.getRegion() == rgn);
        assertEquals(""key3"", ev.getKey());
        assertEquals(""txValue3"", ev.getNewValue());
        assertEquals(null, ev.getOldValue());
        assertTrue(!ev.getOperation().isLocalLoad());
        assertTrue(!ev.getOperation().isNetLoad());
        assertTrue(!ev.getOperation().isLoad());
        assertTrue(!ev.getOperation().isNetSearch());
        assertTrue(!ev.getOperation().isExpiration());
        assertEquals(null, ev.getCallbackArgument());
        assertEquals(true, ev.isCallbackArgumentAvailable());
        assertTrue(!ev.isOriginRemote());
        assertTrue(ev.getOperation().isDistributed());
      }

      // now see if tx net loader is working

      // now confirm that netload does not cause a conflict
      txMgr.begin();
      myTXId = txMgr.getTransactionId();
      Object v4 = rgn.get(""key4"");
      assertEquals(""LV 4"", v4);
      assertEquals(""LV 4"", rgn.get(""key4""));
      assertEquals(""LV 4"", rgn.getEntry(""key4"").getValue());
      txMgr.rollback();
      // confirm that netLoad is transactional
      assertEquals(""LV 5"", rgn.get(""key4""));
      assertEquals(""LV 5"", rgn.getEntry(""key4"").getValue());

      // make sure non-tx netsearch works
      assertEquals(""txValue"", rgn.get(""key""));
      assertEquals(""txValue"", rgn.getEntry(""key"").getValue());

      // make sure net-search result does not conflict with commit
      rgn.localInvalidate(""key"");
      txMgr.begin();
      myTXId = txMgr.getTransactionId();

      rgn.put(""key"", ""new txValue"");

      {
        TXStateProxy tx = ((TXManagerImpl)txMgr).internalSuspend();
        // do a get outside of the transaction to force a netsearch
        assertEquals(""txValue"", rgn.get(""key"")); // does a netsearch
        assertEquals(""txValue"", rgn.getEntry(""key"").getValue());
        ((TXManagerImpl)txMgr).resume(tx);
      }
      // make sure transactional view is still correct
      assertEquals(""new txValue"", rgn.getEntry(""key"").getValue());

      txMgr.commit();
      flushIfNecessary(rgn); // give other side change to process commit
      getSystem().getLogWriter().info(""testTXUpdateLoadNoConflict: did commit"");
      assertEquals(""new txValue"", rgn.getEntry(""key"").getValue());
      {
        Collection events = tl.lastEvent.getPutEvents();
        assertEquals(1, events.size());
        EntryEvent ev = (EntryEvent)events.iterator().next();
        assertEquals(myTXId, ev.getTransactionId());
        assertTrue(ev.getRegion() == rgn);
        assertEquals(""key"", ev.getKey());
        assertEquals(""new txValue"", ev.getNewValue());
        assertEquals(null, ev.getOldValue());
        assertTrue(!ev.getOperation().isLocalLoad());
        assertTrue(!ev.getOperation().isNetLoad());
        assertTrue(!ev.getOperation().isLoad());
        assertTrue(!ev.getOperation().isNetSearch());
        assertTrue(!ev.getOperation().isExpiration());
        assertEquals(null, ev.getCallbackArgument());
        assertEquals(true, ev.isCallbackArgumentAvailable());
        assertTrue(!ev.isOriginRemote());
        assertTrue(ev.getOperation().isDistributed());
      }


      // make sure tx local invalidate allows netsearch
      Object localCmtValue = rgn.getEntry(""key"").getValue();
      txMgr.begin();
      assertSame(localCmtValue, rgn.getEntry(""key"").getValue());
      rgn.localInvalidate(""key"");
      assertNull(rgn.getEntry(""key"").getValue());
      // now make sure a get will do a netsearch and find the value
      // in the other vm instead of the one in local cmt state
      Object txValue = rgn.get(""key"");
      assertNotSame(localCmtValue, txValue);
      assertSame(txValue, rgn.get(""key""));
      assertNotSame(localCmtValue, rgn.getEntry(""key"").getValue());
      // make sure we did a search and not a load
      assertEquals(localCmtValue, rgn.getEntry(""key"").getValue());
      // now make sure that if we do a tx distributed invalidate
      // that we will do a load and not a search
      rgn.invalidate(""key"");
      assertNull(rgn.getEntry(""key"").getValue());
      txValue = rgn.get(""key"");
      assertEquals(""LV 6"", txValue);
      assertSame(txValue, rgn.get(""key""));
      assertEquals(""LV 6"", rgn.getEntry(""key"").getValue());
      // now make sure after rollback that local cmt state has not changed
      txMgr.rollback();
      assertSame(localCmtValue, rgn.getEntry(""key"").getValue());
    }
    catch(Exception e) {
      CacheFactory.getInstance(getSystem()).close();
      getSystem().getLogWriter().fine(""testTXUpdateLoadNoConflict: Caused exception in createRegion"");
      throw e;
    }

  }",False
"  public void testDistributedRegionInvalidate()
    throws InterruptedException {
    if (!supportsSubregions()) {
      return;
    }
    final String name = this.getUniqueName();
    final String subname = ""sub"";
    final boolean useSubs = getRegionAttributes().getPartitionAttributes() == null;

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            Region region;
            region = createRegion(name);
            if (useSubs) {
              region.createSubregion(subname, region.getAttributes());
            }
          }
        };

    invokeInEveryVM(create);

    final Object key = ""KEY"";
    final Object value = ""VALUE"";
    final Object key2 = ""KEY2"";
    final Object value2 = ""VALUE2"";

    SerializableRunnable put =
      new CacheSerializableRunnable(""Put key/value"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            region.put(key, value);
            region.put(key2, value2);

            if (useSubs) {
              Region subregion = region.getSubregion(subname);
              subregion.put(key, value);
              subregion.put(key2, value2);
            }
          }
        };

    invokeInEveryVM(put);

    // wait for update messages to all be propagated
    pauseIfNecessary(1000);

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);

    vm0.invoke(new CacheSerializableRunnable(""Invalidate Region"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.invalidateRegion();
        }
      });

    CacheSerializableRunnable verify =
      new CacheSerializableRunnable(""Verify region invalidation"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            {
              Region.Entry entry = region.getEntry(key);
              assertNotNull(entry);
              Object v = entry.getValue();
              assertNull(""Expected null but was "" + v, v);

              entry = region.getEntry(key2);
              assertNotNull(entry);
              assertNull(entry.getValue());
            }

            if (useSubs) {
              Region subregion = region.getSubregion(subname);
              Region.Entry entry = subregion.getEntry(key);
              assertNotNull(entry);
              assertNull(entry.getValue());

              entry = subregion.getEntry(key2);
              assertNotNull(entry);
              assertNull(entry.getValue());
            }
          }
        };

    invokeInEveryVMRepeatingIfNecessary(verify);
  }",True
"  public void testDistributedRegionInvalidate()
    throws InterruptedException {
    if (!supportsSubregions()) {
      return;
    }
    final String name = this.getUniqueName();
    final String subname = ""sub"";
    final boolean useSubs = getRegionAttributes().getPartitionAttributes() == null;

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            Region region;
            region = createRegion(name);
            if (useSubs) {
              region.createSubregion(subname, region.getAttributes());
            }
          }
        };

    invokeInEveryVM(create);

    final Object key = ""KEY"";
    final Object value = ""VALUE"";
    final Object key2 = ""KEY2"";
    final Object value2 = ""VALUE2"";

    SerializableRunnable put =
      new CacheSerializableRunnable(""Put key/value"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            region.put(key, value);
            region.put(key2, value2);
            flushIfNecessary(region);

            if (useSubs) {
              Region subregion = region.getSubregion(subname);
              subregion.put(key, value);
              subregion.put(key2, value2);
              flushIfNecessary(subregion);
            }
          }
        };

    invokeInEveryVM(put);

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);

    vm0.invoke(new CacheSerializableRunnable(""Invalidate Region"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.invalidateRegion();
        }
      });

    CacheSerializableRunnable verify =
      new CacheSerializableRunnable(""Verify region invalidation"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            {
              Region.Entry entry = region.getEntry(key);
              assertNotNull(entry);
              Object v = entry.getValue();
              assertNull(""Expected null but was "" + v, v);

              entry = region.getEntry(key2);
              assertNotNull(entry);
              assertNull(entry.getValue());
            }

            if (useSubs) {
              Region subregion = region.getSubregion(subname);
              Region.Entry entry = subregion.getEntry(key);
              assertNotNull(entry);
              assertNull(entry.getValue());

              entry = subregion.getEntry(key2);
              assertNotNull(entry);
              assertNull(entry.getValue());
            }
          }
        };

    invokeInEveryVMRepeatingIfNecessary(verify);
  }",False
"  public void testRemoteCacheLoaderArg() throws InterruptedException {
    if (!supportsNetLoad()) {
      return;
    }
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
    final Object value = ""VALUE"";
    final String arg = ""ARG"";

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
            // Can't test non-Serializable callback argument here
            // because netLoad will not occur because there are no
            // other members with the region defined when it is
            // created.  Hooray for intelligent messaging.
          }
        };


    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    vm0.invoke(create);
    vm1.invoke(create);

    vm1.invoke(new CacheSerializableRunnable(""Set CacheLoader"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          loader = new TestCacheLoader() {
              public Object load2(LoaderHelper helper)
                throws CacheLoaderException {
                assertEquals(region, helper.getRegion());
                assertEquals(key, helper.getKey());
                assertEquals(arg, helper.getArgument());

                return value;
              }
            };
          region.getAttributesMutator().setCacheLoader(loader);
        }
      });

   pauseIfNecessary();

   pauseIfNecessary();

    vm0.invoke(new CacheSerializableRunnable(""Remote load"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);

          try {
            // Use a non-serializable arg object
            region.get(key, new Object() { });
            fail(""Should have thrown an IllegalArgumentException"");

          } catch (IllegalArgumentException ex) {
            // pass...
          }
          assertNull(region.getEntry(key));
          try {
           assertEquals(value, region.get(key, arg));
          }
          catch(IllegalArgumentException e) {}
       }
      });

    vm1.invoke(new SerializableRunnable(""Verify loader"") {
        public void run() {
          assertTrue(loader.wasInvoked());
        }
      });
  }",True
"  public void testRemoteCacheLoaderArg() throws InterruptedException {
    if (!supportsNetLoad()) {
      return;
    }
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
    final Object value = ""VALUE"";
    final String arg = ""ARG"";

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
            // Can't test non-Serializable callback argument here
            // because netLoad will not occur because there are no
            // other members with the region defined when it is
            // created.  Hooray for intelligent messaging.
          }
        };


    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    vm0.invoke(create);
    vm1.invoke(create);

    vm1.invoke(new CacheSerializableRunnable(""Set CacheLoader"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          loader = new TestCacheLoader() {
              public Object load2(LoaderHelper helper)
                throws CacheLoaderException {
                assertEquals(region, helper.getRegion());
                assertEquals(key, helper.getKey());
                assertEquals(arg, helper.getArgument());

                return value;
              }
            };
          region.getAttributesMutator().setCacheLoader(loader);
          flushIfNecessary(region);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Remote load"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);

          try {
            // Use a non-serializable arg object
            region.get(key, new Object() { });
            fail(""Should have thrown an IllegalArgumentException"");

          } catch (IllegalArgumentException ex) {
            // pass...
          }
          assertNull(region.getEntry(key));
          try {
           assertEquals(value, region.get(key, arg));
          }
          catch(IllegalArgumentException e) {}
       }
      });

    vm1.invoke(new SerializableRunnable(""Verify loader"") {
        public void run() {
          assertTrue(loader.wasInvoked());
        }
      });
  }",False
"  public void testRemoteCacheLoaderException() throws InterruptedException {
    if (!supportsNetLoad()) {
      return;
    }
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
//    final Object value = ""VALUE"";

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
          }
        };


    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    vm0.invoke(create);
    vm1.invoke(create);

    vm1.invoke(new CacheSerializableRunnable(""Set CacheLoader"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          loader = new TestCacheLoader() {
              public Object load2(LoaderHelper helper)
                throws CacheLoaderException {
                assertEquals(region, helper.getRegion());
                assertEquals(key, helper.getKey());
                assertNull(helper.getArgument());

                String s = ""Test Exception"";
                throw new CacheLoaderException(s);
              }
            };
          region.getAttributesMutator().setCacheLoader(loader);
        }
      });

    pauseIfNecessary();

    vm0.invoke(new CacheSerializableRunnable(""Remote load"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          try {
            region.get(key);
            fail(""Should have thrown a CacheLoaderException"");

          } catch (CacheLoaderException ex) {
            // pass...
          }
        }
      });

    vm1.invoke(new SerializableRunnable(""Verify loader"") {
        public void run() {
          assertTrue(loader.wasInvoked());
        }
      });
  }",True
"  public void testRemoteCacheLoaderException() throws InterruptedException {
    if (!supportsNetLoad()) {
      return;
    }
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
//    final Object value = ""VALUE"";

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
          }
        };


    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    vm0.invoke(create);
    vm1.invoke(create);

    vm1.invoke(new CacheSerializableRunnable(""Set CacheLoader"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          loader = new TestCacheLoader() {
              public Object load2(LoaderHelper helper)
                throws CacheLoaderException {
                assertEquals(region, helper.getRegion());
                assertEquals(key, helper.getKey());
                assertNull(helper.getArgument());

                String s = ""Test Exception"";
                throw new CacheLoaderException(s);
              }
            };
          region.getAttributesMutator().setCacheLoader(loader);
          flushIfNecessary(region);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Remote load"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          try {
            region.get(key);
            fail(""Should have thrown a CacheLoaderException"");

          } catch (CacheLoaderException ex) {
            // pass...
          }
        }
      });

    vm1.invoke(new SerializableRunnable(""Verify loader"") {
        public void run() {
          assertTrue(loader.wasInvoked());
        }
      });
  }",False
"  public void testNoMirroredDataToNonMirrored()
    throws InterruptedException {
    if (!supportsReplication()) {
      return;
    }

    final String name = this.getUniqueName();
    final Object key1 = ""KEY1"";
    final Object value1 = ""VALUE1"";
    final Object key2 = ""KEY2"";
    final Object value2 = ""VALUE2"";
    final Object key3 = ""KEY3"";
    final Object value3 = ""VALUE3"";

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm2 = host.getVM(2); // use VM on different gemfire system

    vm0.invoke(new CacheSerializableRunnable(""Create Non-mirrored Region"") {
        public void run2() throws CacheException {
          createRegion(name, getRegionAttributes());
        }
      });

    SerializableRunnable create = new CacheSerializableRunnable(""Populate mirrored region"") {
      public void run2() throws CacheException {
        RegionAttributes ra = getRegionAttributes();
        AttributesFactory factory =
          new AttributesFactory(ra);
        if (ra.getEvictionAttributes() == null
            || !ra.getEvictionAttributes().getAction().isOverflowToDisk()) {
          factory.setDiskStoreName(null);
        }
        factory.setDataPolicy(DataPolicy.REPLICATE);
        Region region =
          createRegion(name, factory.create());
        region.put(key1, value1);
        region.put(key2, value2);
        region.put(key3, value3);
      }
    };

    pauseIfNecessary();

    vm2.invoke(create);

    pauseIfNecessary();

    // Make sure that data wasn't pushed
    vm0.invoke(new CacheSerializableRunnable(""Verify keys/values"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          Region.Entry entry1 = region.getEntry(key1);
          if (!getRegionAttributes().getDataPolicy().withReplication()) {
            if (entry1 != null) {
              getLogWriter().info(""found entry "" + entry1);
            }
            assertNull(entry1);
          }
          else {
            assertNotNull(entry1);
          }

          Region.Entry entry2 = region.getEntry(key2);
          if (!getRegionAttributes().getDataPolicy().withReplication()) {
            assertNull(entry2);
          }
          else {
            assertNotNull(entry2);
          }

          Region.Entry entry3 = region.getEntry(key3);
          if (!getRegionAttributes().getDataPolicy().withReplication()) {
            assertNull(entry3);
          }
          else {
            assertNotNull(entry3);
          }
        }
    });
  }",True
"  public void testNoMirroredDataToNonMirrored()
    throws InterruptedException {
    if (!supportsReplication()) {
      return;
    }

    final String name = this.getUniqueName();
    final Object key1 = ""KEY1"";
    final Object value1 = ""VALUE1"";
    final Object key2 = ""KEY2"";
    final Object value2 = ""VALUE2"";
    final Object key3 = ""KEY3"";
    final Object value3 = ""VALUE3"";

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm2 = host.getVM(2); // use VM on different gemfire system

    vm0.invoke(new CacheSerializableRunnable(""Create Non-mirrored Region"") {
        public void run2() throws CacheException {
          createRegion(name, getRegionAttributes());
        }
      });

    SerializableRunnable create = new CacheSerializableRunnable(""Populate mirrored region"") {
      public void run2() throws CacheException {
        RegionAttributes ra = getRegionAttributes();
        AttributesFactory factory =
          new AttributesFactory(ra);
        if (ra.getEvictionAttributes() == null
            || !ra.getEvictionAttributes().getAction().isOverflowToDisk()) {
          factory.setDiskStoreName(null);
        }
        factory.setDataPolicy(DataPolicy.REPLICATE);
        Region region =
          createRegion(name, factory.create());
        region.put(key1, value1);
        region.put(key2, value2);
        region.put(key3, value3);
        flushIfNecessary(region);
      }
    };

    vm2.invoke(create);

    // Make sure that data wasn't pushed
    vm0.invoke(new CacheSerializableRunnable(""Verify keys/values"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          Region.Entry entry1 = region.getEntry(key1);
          if (!getRegionAttributes().getDataPolicy().withReplication()) {
            if (entry1 != null) {
              getLogWriter().info(""found entry "" + entry1);
            }
            assertNull(entry1);
          }
          else {
            assertNotNull(entry1);
          }

          Region.Entry entry2 = region.getEntry(key2);
          if (!getRegionAttributes().getDataPolicy().withReplication()) {
            assertNull(entry2);
          }
          else {
            assertNotNull(entry2);
          }

          Region.Entry entry3 = region.getEntry(key3);
          if (!getRegionAttributes().getDataPolicy().withReplication()) {
            assertNull(entry3);
          }
          else {
            assertNotNull(entry3);
          }
        }
    });
  }",False
"  public void testDistributedUpdate() {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
          }
        };

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    vm0.invoke(create);
    vm1.invoke(create);

    final Object key = ""KEY"";
    final Object oldValue = ""OLD_VALUE"";
    final Object newValue = ""NEW_VALUE"";

    SerializableRunnable put =
      new CacheSerializableRunnable(""Put key/value"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            region.put(key, oldValue);
          }
      };

    vm0.invoke(put);
    vm1.invoke(put);

    pauseIfNecessary();

    vm0.invoke(new CacheSerializableRunnable(""Update"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          region.put(key, newValue);
        }
      });

    pauseIfNecessary();

    vm1.invoke(new CacheSerializableRunnable(""Validate update"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          Region.Entry entry = region.getEntry(key);
          assertNotNull(entry);
          assertEquals(newValue, entry.getValue());
        }
      });
  }",True
"  public void testDistributedUpdate() {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
          }
        };

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    vm0.invoke(create);
    vm1.invoke(create);

    final Object key = ""KEY"";
    final Object oldValue = ""OLD_VALUE"";
    final Object newValue = ""NEW_VALUE"";

    SerializableRunnable put =
      new CacheSerializableRunnable(""Put key/value"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            region.put(key, oldValue);
            flushIfNecessary(region);
          }
      };

    vm0.invoke(put);
    vm1.invoke(put);

    vm0.invoke(new CacheSerializableRunnable(""Update"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          region.put(key, newValue);
          flushIfNecessary(region);
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Validate update"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          Region.Entry entry = region.getEntry(key);
          assertNotNull(entry);
          assertEquals(newValue, entry.getValue());
        }
      });
  }",False
"  public void testDistributedDestroy() throws InterruptedException {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
//DebuggerSupport.waitForJavaDebugger(getLogWriter(), "" about to create region"");
            Region region = createRegion(name);
            assertTrue(!region.isDestroyed());
            Region root = region.getParentRegion();
            assertTrue(!root.isDestroyed());
          }
        };


    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    VM vm2 = host.getVM(2);

    vm0.invoke(create);
    vm1.invoke(create);

    // vm2 is on a different gemfire system
    vm2.invoke(create);


    Thread.sleep(250);

    final Object key = ""KEY"";
    final Object value = ""VALUE"";

    SerializableRunnable put =
      new CacheSerializableRunnable(""Put key/value"") {
          public void run2() throws CacheException {
//DebuggerSupport.waitForJavaDebugger(getLogWriter(), "" about to put"");
            Region region =
              getRootRegion().getSubregion(name);
            region.put(key, value);
            assertTrue(!region.isDestroyed());
            assertTrue(!region.getParentRegion().isDestroyed());
          }
        };

    vm0.invoke(put);
    vm1.invoke(put);
    vm2.invoke(put);

    SerializableRunnable verifyPut =
      new CacheSerializableRunnable(""Verify Put"") {
          public void run2() throws CacheException {
            Region root = getRootRegion();
            assertTrue(!root.isDestroyed());
            Region region = root.getSubregion(name);
            assertTrue(!region.isDestroyed());
//DebuggerSupport.waitForJavaDebugger(getLogWriter(), "" about to get"");
            assertEquals(value, region.getEntry(key).getValue());
          }
        };

    vm0.invoke(verifyPut);
    vm1.invoke(verifyPut);
    vm2.invoke(verifyPut);

    pauseIfNecessary(500);

    vm0.invoke(new CacheSerializableRunnable(""Destroy Entry"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.destroy(key);
        }
      });

    CacheSerializableRunnable verifyDestroy =
      new CacheSerializableRunnable(""Verify entry destruction"") {
          public void run2() throws CacheException {
            Region root = getRootRegion();
            assertTrue(!root.isDestroyed());
            Region region = root.getSubregion(name);
            assertTrue(!region.isDestroyed());
            assertNull(region.getEntry(key));
          }
        };
    invokeRepeatingIfNecessary(vm0, verifyDestroy);
    invokeRepeatingIfNecessary(vm1, verifyDestroy);
    invokeRepeatingIfNecessary(vm2, verifyDestroy);
  }",True
"  public void testDistributedDestroy() throws InterruptedException {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
//DebuggerSupport.waitForJavaDebugger(getLogWriter(), "" about to create region"");
            Region region = createRegion(name);
            assertTrue(!region.isDestroyed());
            Region root = region.getParentRegion();
            assertTrue(!root.isDestroyed());
          }
        };


    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    VM vm2 = host.getVM(2);

    vm0.invoke(create);
    vm1.invoke(create);
    vm2.invoke(create);

    final Object key = ""KEY"";
    final Object value = ""VALUE"";

    SerializableRunnable put =
      new CacheSerializableRunnable(""Put key/value"") {
          public void run2() throws CacheException {
//DebuggerSupport.waitForJavaDebugger(getLogWriter(), "" about to put"");
            Region region =
              getRootRegion().getSubregion(name);
            region.put(key, value);
            assertTrue(!region.isDestroyed());
            assertTrue(!region.getParentRegion().isDestroyed());
            flushIfNecessary(region);
          }
        };

    vm0.invoke(put);
    vm1.invoke(put);
    vm2.invoke(put);

    SerializableRunnable verifyPut =
      new CacheSerializableRunnable(""Verify Put"") {
          public void run2() throws CacheException {
            Region root = getRootRegion();
            assertTrue(!root.isDestroyed());
            Region region = root.getSubregion(name);
            assertTrue(!region.isDestroyed());
//DebuggerSupport.waitForJavaDebugger(getLogWriter(), "" about to get"");
            assertEquals(value, region.getEntry(key).getValue());
          }
        };

    vm0.invoke(verifyPut);
    vm1.invoke(verifyPut);
    vm2.invoke(verifyPut);

    vm0.invoke(new CacheSerializableRunnable(""Destroy Entry"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.destroy(key);
          flushIfNecessary(region);
        }
      });

    CacheSerializableRunnable verifyDestroy =
      new CacheSerializableRunnable(""Verify entry destruction"") {
          public void run2() throws CacheException {
            Region root = getRootRegion();
            assertTrue(!root.isDestroyed());
            Region region = root.getSubregion(name);
            assertTrue(!region.isDestroyed());
            assertNull(region.getEntry(key));
          }
        };
    vm0.invoke(verifyDestroy);
    vm1.invoke(verifyDestroy);
    vm2.invoke(verifyDestroy);
  }",False
"  public void testRemoteCacheWriter() throws InterruptedException {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
    final Object oldValue = ""OLD_VALUE"";
    final Object newValue = ""NEW_VALUE"";
    final Object arg = ""ARG"";
    final Object exception = ""EXCEPTION"";

    final Object key2 = ""KEY2"";
    final Object value2 = ""VALUE2"";

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            Region region = createRegion(name);

            // Put key2 in the region before any callbacks are
            // registered, so it can be destroyed later
            region.put(key2, value2);
            assertEquals(1, region.size());
            if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
              GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
              SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
              LocalRegion reRegion;
              reRegion = (LocalRegion) region;
              RegionEntry re = reRegion.getRegionEntry(key2);
              MemoryChunkWithRefCount mc = (MemoryChunkWithRefCount) re._getValue();
              assertEquals(1, mc.getRefCount());
              assertEquals(1, ma.getStats().getObjects());
            }
          }
        };

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    vm0.invoke(create);
    vm1.invoke(create);

    ////////  Create

    vm1.invoke(new CacheSerializableRunnable(""Set Writer"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          writer = new TestCacheWriter() {
              public void beforeCreate2(EntryEvent event)
                throws CacheWriterException {

                if (exception.equals(event.getCallbackArgument())) {
                  String s = ""Test Exception"";
                  throw new CacheWriterException(s);
                }

                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isCreate());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(key, event.getKey());
                assertEquals(null, event.getOldValue());
                assertEquals(oldValue, event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());

              }
            };
          region.getAttributesMutator().setCacheWriter(writer);
        }
      });

    // give no-ack time to propagate bookkeeping info
    pauseIfNecessary();

    vm0.invoke(new CacheSerializableRunnable(""Create with Exception"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          try {
            region.put(key, oldValue, exception);
            fail(""Should have thrown a CacheWriterException"");

          } catch (CacheWriterException ex) {
            assertNull(region.getEntry(key));
            assertEquals(1, region.size());
            if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
              GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
              SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
              assertEquals(1, ma.getStats().getObjects());
            }
          }
        }
      });

    vm1.invoke(new SerializableRunnable(""Verify callback"") {
        public void run() {
          assertTrue(writer.wasInvoked());
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Create with Argument"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.put(key, oldValue, arg);
          assertEquals(2, region.size());
          if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
            GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
            SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
            assertEquals(2, ma.getStats().getObjects());
            LocalRegion reRegion;
            reRegion = (LocalRegion) region;
            MemoryChunkWithRefCount mc = (MemoryChunkWithRefCount) reRegion.getRegionEntry(key)._getValue();
            assertEquals(1, mc.getRefCount());
          }
        }
      });
    vm1.invoke(new SerializableRunnable(""Verify callback"") {
        public void run() {
          assertTrue(writer.wasInvoked());
        }
      });

    ////////  Update

    vm1.invoke(new CacheSerializableRunnable(""Set Writer"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          writer = new TestCacheWriter() {
              public void beforeUpdate2(EntryEvent event)
                throws CacheWriterException {

                Object argument = event.getCallbackArgument();
                if (exception.equals(argument)) {
                  String s = ""Test Exception"";
                  throw new CacheWriterException(s);
                }

                assertEquals(arg, argument);

                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isUpdate());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(key, event.getKey());
                assertEquals(oldValue, event.getOldValue());
                assertEquals(newValue, event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());

              }
            };
          region.getAttributesMutator().setCacheWriter(writer);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Update with Exception"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          try {
            region.put(key, newValue, exception);
            fail(""Should have thrown a CacheWriterException"");

          } catch (CacheWriterException ex) {
            Region.Entry entry = region.getEntry(key);
            assertEquals(oldValue, entry.getValue());
            assertEquals(2, region.size());
            if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
              GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
              SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
              assertEquals(2, ma.getStats().getObjects());
              LocalRegion reRegion;
              reRegion = (LocalRegion) region;
              MemoryChunkWithRefCount mc = (MemoryChunkWithRefCount) reRegion.getRegionEntry(key)._getValue();
              assertEquals(1, mc.getRefCount());
            }
          }
        }
      });
    vm1.invoke(new SerializableRunnable(""Verify callback"") {
        public void run() {
          assertTrue(writer.wasInvoked());
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Update with Argument"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.put(key, newValue, arg);
          assertEquals(2, region.size());
          if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
            GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
            SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
            assertEquals(2, ma.getStats().getObjects());
          }
        }
      });
    vm1.invoke(new SerializableRunnable(""Verify callback"") {
        public void run() {
          assertTrue(writer.wasInvoked());
        }
      });

    ////////  Destroy

    vm1.invoke(new CacheSerializableRunnable(""Set Writer"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          writer = new TestCacheWriter() {
              public void beforeDestroy2(EntryEvent event)
                throws CacheWriterException {

                Object argument = event.getCallbackArgument();
                if (exception.equals(argument)) {
                  String s = ""Test Exception"";
                  throw new CacheWriterException(s);
                }

                assertEquals(arg, argument);

                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDestroy());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(key, event.getKey());
                assertEquals(newValue, event.getOldValue());
                assertNull(event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());
              }
            };
          region.getAttributesMutator().setCacheWriter(writer);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Destroy with Exception"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          try {
            region.destroy(key, exception);
            fail(""Should have thrown a CacheWriterException"");

          } catch (CacheWriterException ex) {
            assertNotNull(region.getEntry(key));
            assertEquals(2, region.size());
            if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
              GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
              SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
              assertEquals(2, ma.getStats().getObjects());
            }
          }
        }
      });
    vm1.invoke(new SerializableRunnable(""Verify callback"") {
        public void run() {
          assertTrue(writer.wasInvoked());
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Destroy with Argument"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.destroy(key, arg);
          assertEquals(1, region.size());
          if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
            GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
            SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
            assertEquals(1, ma.getStats().getObjects());
          }
       }
      });
    vm1.invoke(new SerializableRunnable(""Verify callback"") {
        public void run() {
          assertTrue(writer.wasInvoked());
        }
      });

    ////////  Region Destroy

    vm1.invoke(new CacheSerializableRunnable(""Set Writer"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          writer = new TestCacheWriter() {
              public void beforeRegionDestroy2(RegionEvent event)
                throws CacheWriterException {

                Object argument = event.getCallbackArgument();
                if (exception.equals(argument)) {
                  String s = ""Test Exception"";
                  throw new CacheWriterException(s);
                }

                assertEquals(arg, argument);

                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isRegionDestroy());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
              }
            };
          region.getAttributesMutator().setCacheWriter(writer);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Destroy with Exception"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          try {
            region.destroyRegion(exception);
            fail(""Should have thrown a CacheWriterException"");

          } catch (CacheWriterException ex) {
            if (region.isDestroyed()) {
              fail(""should not have an exception if region is destroyed"", ex);
            }
            assertEquals(1, region.size());
            if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
              GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
              SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
              assertEquals(1, ma.getStats().getObjects());
            }
          }
        }
      });
    vm1.invoke(new SerializableRunnable(""Verify callback"") {
        public void run() {
          assertTrue(writer.wasInvoked());
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Destroy with Argument"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          assertEquals(1, region.size());
          if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
            GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
            SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
            assertEquals(1, ma.getStats().getObjects());
          }
          region.destroyRegion(arg);
          if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
            GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
            SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
            assertEquals(0, ma.getStats().getObjects());
          }
        }
      });
    vm1.invoke(new SerializableRunnable(""Verify callback"") {
        public void run() {
          assertTrue(writer.wasInvoked());
        }
      });
  }",True
"  public void testRemoteCacheWriter() throws InterruptedException {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
    final Object oldValue = ""OLD_VALUE"";
    final Object newValue = ""NEW_VALUE"";
    final Object arg = ""ARG"";
    final Object exception = ""EXCEPTION"";

    final Object key2 = ""KEY2"";
    final Object value2 = ""VALUE2"";

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            Region region = createRegion(name);

            // Put key2 in the region before any callbacks are
            // registered, so it can be destroyed later
            region.put(key2, value2);
            assertEquals(1, region.size());
            if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
              GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
              SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
              LocalRegion reRegion;
              reRegion = (LocalRegion) region;
              RegionEntry re = reRegion.getRegionEntry(key2);
              MemoryChunkWithRefCount mc = (MemoryChunkWithRefCount) re._getValue();
              assertEquals(1, mc.getRefCount());
              assertEquals(1, ma.getStats().getObjects());
            }
          }
        };

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    vm0.invoke(create);
    vm1.invoke(create);

    ////////  Create

    vm1.invoke(new CacheSerializableRunnable(""Set Writer"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          writer = new TestCacheWriter() {
              public void beforeCreate2(EntryEvent event)
                throws CacheWriterException {

                if (exception.equals(event.getCallbackArgument())) {
                  String s = ""Test Exception"";
                  throw new CacheWriterException(s);
                }

                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isCreate());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(key, event.getKey());
                assertEquals(null, event.getOldValue());
                assertEquals(oldValue, event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());

              }
            };
          region.getAttributesMutator().setCacheWriter(writer);
          flushIfNecessary(region);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Create with Exception"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          try {
            region.put(key, oldValue, exception);
            fail(""Should have thrown a CacheWriterException"");

          } catch (CacheWriterException ex) {
            assertNull(region.getEntry(key));
            assertEquals(1, region.size());
            if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
              GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
              SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
              assertEquals(1, ma.getStats().getObjects());
            }
          }
        }
      });

    vm1.invoke(new SerializableRunnable(""Verify callback"") {
        public void run() {
          assertTrue(writer.wasInvoked());
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Create with Argument"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.put(key, oldValue, arg);
          assertEquals(2, region.size());
          if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
            GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
            SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
            assertEquals(2, ma.getStats().getObjects());
            LocalRegion reRegion;
            reRegion = (LocalRegion) region;
            MemoryChunkWithRefCount mc = (MemoryChunkWithRefCount) reRegion.getRegionEntry(key)._getValue();
            assertEquals(1, mc.getRefCount());
          }
        }
      });
    vm1.invoke(new SerializableRunnable(""Verify callback"") {
        public void run() {
          assertTrue(writer.wasInvoked());
        }
      });

    ////////  Update

    vm1.invoke(new CacheSerializableRunnable(""Set Writer"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          writer = new TestCacheWriter() {
              public void beforeUpdate2(EntryEvent event)
                throws CacheWriterException {

                Object argument = event.getCallbackArgument();
                if (exception.equals(argument)) {
                  String s = ""Test Exception"";
                  throw new CacheWriterException(s);
                }

                assertEquals(arg, argument);

                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isUpdate());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(key, event.getKey());
                assertEquals(oldValue, event.getOldValue());
                assertEquals(newValue, event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());

              }
            };
          region.getAttributesMutator().setCacheWriter(writer);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Update with Exception"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          try {
            region.put(key, newValue, exception);
            fail(""Should have thrown a CacheWriterException"");

          } catch (CacheWriterException ex) {
            Region.Entry entry = region.getEntry(key);
            assertEquals(oldValue, entry.getValue());
            assertEquals(2, region.size());
            if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
              GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
              SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
              assertEquals(2, ma.getStats().getObjects());
              LocalRegion reRegion;
              reRegion = (LocalRegion) region;
              MemoryChunkWithRefCount mc = (MemoryChunkWithRefCount) reRegion.getRegionEntry(key)._getValue();
              assertEquals(1, mc.getRefCount());
            }
          }
        }
      });
    vm1.invoke(new SerializableRunnable(""Verify callback"") {
        public void run() {
          assertTrue(writer.wasInvoked());
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Update with Argument"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.put(key, newValue, arg);
          assertEquals(2, region.size());
          if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
            GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
            SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
            assertEquals(2, ma.getStats().getObjects());
          }
        }
      });
    vm1.invoke(new SerializableRunnable(""Verify callback"") {
        public void run() {
          assertTrue(writer.wasInvoked());
        }
      });

    ////////  Destroy

    vm1.invoke(new CacheSerializableRunnable(""Set Writer"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          writer = new TestCacheWriter() {
              public void beforeDestroy2(EntryEvent event)
                throws CacheWriterException {

                Object argument = event.getCallbackArgument();
                if (exception.equals(argument)) {
                  String s = ""Test Exception"";
                  throw new CacheWriterException(s);
                }

                assertEquals(arg, argument);

                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDestroy());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(key, event.getKey());
                assertEquals(newValue, event.getOldValue());
                assertNull(event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());
              }
            };
          region.getAttributesMutator().setCacheWriter(writer);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Destroy with Exception"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          try {
            region.destroy(key, exception);
            fail(""Should have thrown a CacheWriterException"");

          } catch (CacheWriterException ex) {
            assertNotNull(region.getEntry(key));
            assertEquals(2, region.size());
            if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
              GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
              SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
              assertEquals(2, ma.getStats().getObjects());
            }
          }
        }
      });
    vm1.invoke(new SerializableRunnable(""Verify callback"") {
        public void run() {
          assertTrue(writer.wasInvoked());
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Destroy with Argument"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.destroy(key, arg);
          assertEquals(1, region.size());
          if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
            GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
            SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
            assertEquals(1, ma.getStats().getObjects());
          }
       }
      });
    vm1.invoke(new SerializableRunnable(""Verify callback"") {
        public void run() {
          assertTrue(writer.wasInvoked());
        }
      });

    ////////  Region Destroy

    vm1.invoke(new CacheSerializableRunnable(""Set Writer"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          writer = new TestCacheWriter() {
              public void beforeRegionDestroy2(RegionEvent event)
                throws CacheWriterException {

                Object argument = event.getCallbackArgument();
                if (exception.equals(argument)) {
                  String s = ""Test Exception"";
                  throw new CacheWriterException(s);
                }

                assertEquals(arg, argument);

                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isRegionDestroy());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
              }
            };
          region.getAttributesMutator().setCacheWriter(writer);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Destroy with Exception"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          try {
            region.destroyRegion(exception);
            fail(""Should have thrown a CacheWriterException"");

          } catch (CacheWriterException ex) {
            if (region.isDestroyed()) {
              fail(""should not have an exception if region is destroyed"", ex);
            }
            assertEquals(1, region.size());
            if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
              GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
              SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
              assertEquals(1, ma.getStats().getObjects());
            }
          }
        }
      });
    vm1.invoke(new SerializableRunnable(""Verify callback"") {
        public void run() {
          assertTrue(writer.wasInvoked());
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Destroy with Argument"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          assertEquals(1, region.size());
          if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
            GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
            SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
            assertEquals(1, ma.getStats().getObjects());
          }
          region.destroyRegion(arg);
          if (region.getAttributes().getOffHeap() && !(region instanceof PartitionedRegion)) {
            GemFireCacheImpl gfc = (GemFireCacheImpl) getCache();
            SimpleMemoryAllocatorImpl ma = (SimpleMemoryAllocatorImpl) gfc.getOffHeapStore();
            assertEquals(0, ma.getStats().getObjects());
          }
        }
      });
    vm1.invoke(new SerializableRunnable(""Verify callback"") {
        public void run() {
          assertTrue(writer.wasInvoked());
        }
      });
  }",False
"  public void testCacheLoaderWithNetSearch() throws CacheException {
    if (!supportsNetLoad()) {
      return;
    }
    // some tests use mirroring by default (e.g. persistBackup regions)
    // if so, then this test won't work right
    if (getRegionAttributes().getDataPolicy().withReplication()
        || getRegionAttributes().getDataPolicy().isPreloaded()) {
      return;
    }

    final String name = this.getUniqueName();
    final Object key = this.getUniqueName();
    final Object value = new Integer(42);

    Host host = Host.getHost(0);
    // use vm on other gemfire system
    VM vm1 = host.getVM(1);
    vm1.invoke(new CacheSerializableRunnable(""set remote value"") {
      public void run2() throws CacheException {
//        final TestCacheLoader remoteloader = new TestCacheLoader() {
//            public Object load2(LoaderHelper helper)
//              throws CacheLoaderException {
//
//              assertEquals(key, helper.getKey());
//              assertEquals(name, helper.getRegion().getName());
//              return value;
//            }
//          };
//
//        AttributesFactory factory =
//          new AttributesFactory(getRegionAttributes());
//        factory.setCacheLoader(remoteloader);
        Region rgn = createRegion(name);
        rgn.put(key, value);
      }
    });
    pauseIfNecessary();

    final TestCacheLoader loader1 = new TestCacheLoader() {
        public Object load2(LoaderHelper helper)
          throws CacheLoaderException {

          assertEquals(key, helper.getKey());
          assertEquals(name, helper.getRegion().getName());

          try {
            helper.getRegion().getAttributes();
            Object result = helper.netSearch(false);
            assertEquals(value, result);
            return result;
          } catch (TimeoutException ex) {
            fail(""Why did I time out?"", ex);
          }
          return null;
        }
      };

    AttributesFactory f = new AttributesFactory(getRegionAttributes());
    f.setCacheLoader(loader1);
    Region region =
      createRegion(name, f.create());

    loader1.wasInvoked();

    Region.Entry entry = region.getEntry(key);
    assertNull(entry);
    region.create(key, null);

    entry = region.getEntry(key);
    assertNotNull(entry);
    assertNull(entry.getValue());

    // make sure value is still there in vm1
    vm1.invoke(new CacheSerializableRunnable(""verify remote value"") {
      public void run2() throws CacheException {
        Region rgn = getRootRegion().getSubregion(name);
        assertEquals(value, rgn.getEntry(key).getValue());
      }
    });

//    com.gemstone.gemfire.internal.util.DebuggerSupport.waitForJavaDebugger(getLogWriter());
    assertEquals(value, region.get(key));
    // if global scope, then a netSearch is done BEFORE the loader is invoked,
    // so we get the value but the loader is never invoked.
    if (region.getAttributes().getScope().isGlobal()) {
      assertTrue(!loader1.wasInvoked());
    }
    else {
      assertTrue(loader1.wasInvoked());
    }
    assertEquals(value, region.getEntry(key).getValue());
  }",True
"  public void testCacheLoaderWithNetSearch() throws CacheException {
    if (!supportsNetLoad()) {
      return;
    }
    // some tests use mirroring by default (e.g. persistBackup regions)
    // if so, then this test won't work right
    if (getRegionAttributes().getDataPolicy().withReplication()
        || getRegionAttributes().getDataPolicy().isPreloaded()) {
      return;
    }

    final String name = this.getUniqueName();
    final Object key = this.getUniqueName();
    final Object value = new Integer(42);

    Host host = Host.getHost(0);
    // use vm on other gemfire system
    VM vm1 = host.getVM(1);
    vm1.invoke(new CacheSerializableRunnable(""set remote value"") {
      public void run2() throws CacheException {
//        final TestCacheLoader remoteloader = new TestCacheLoader() {
//            public Object load2(LoaderHelper helper)
//              throws CacheLoaderException {
//
//              assertEquals(key, helper.getKey());
//              assertEquals(name, helper.getRegion().getName());
//              return value;
//            }
//          };
//
//        AttributesFactory factory =
//          new AttributesFactory(getRegionAttributes());
//        factory.setCacheLoader(remoteloader);
        Region rgn = createRegion(name);
        rgn.put(key, value);
        flushIfNecessary(rgn);
      }
    });

    final TestCacheLoader loader1 = new TestCacheLoader() {
        public Object load2(LoaderHelper helper)
          throws CacheLoaderException {

          assertEquals(key, helper.getKey());
          assertEquals(name, helper.getRegion().getName());

          try {
            helper.getRegion().getAttributes();
            Object result = helper.netSearch(false);
            assertEquals(value, result);
            return result;
          } catch (TimeoutException ex) {
            fail(""Why did I time out?"", ex);
          }
          return null;
        }
      };

    AttributesFactory f = new AttributesFactory(getRegionAttributes());
    f.setCacheLoader(loader1);
    Region region =
      createRegion(name, f.create());

    loader1.wasInvoked();

    Region.Entry entry = region.getEntry(key);
    assertNull(entry);
    region.create(key, null);

    entry = region.getEntry(key);
    assertNotNull(entry);
    assertNull(entry.getValue());

    // make sure value is still there in vm1
    vm1.invoke(new CacheSerializableRunnable(""verify remote value"") {
      public void run2() throws CacheException {
        Region rgn = getRootRegion().getSubregion(name);
        assertEquals(value, rgn.getEntry(key).getValue());
      }
    });

//    com.gemstone.gemfire.internal.util.DebuggerSupport.waitForJavaDebugger(getLogWriter());
    assertEquals(value, region.get(key));
    // if global scope, then a netSearch is done BEFORE the loader is invoked,
    // so we get the value but the loader is never invoked.
    if (region.getAttributes().getScope().isGlobal()) {
      assertTrue(!loader1.wasInvoked());
    }
    else {
      assertTrue(loader1.wasInvoked());
    }
    assertEquals(value, region.getEntry(key).getValue());
  }",False
"  public void testNoInstantiator() {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
          }
        };


    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    VM vm2 = host.getVM(2);

    vm0.invoke(create);
    vm1.invoke(create);

    final Object key = ""KEY"";
    final Object key2 = ""KEY2"";
    final int intValue = 7201;
    final long longValue = 123612;
//    final boolean[] wasInvoked = new boolean[1];

    vm2.invoke(new SerializableRunnable(""Disconnect from DS"") {
        public void run() {
          disconnectFromDS();
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Put int"") {
        public void run2() throws CacheException {
          Instantiator.register(new DSIntWrapper.DSIntWrapperInstantiator());

          Region region = getRootRegion().getSubregion(name);
          region.put(key, new DSIntWrapper(intValue));

          pauseIfNecessary();
        }
      });

    SerializableRunnable get = new CacheSerializableRunnable(""Get int"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          DSIntWrapper.DSIntWrapperInstantiator inst =
            new DSIntWrapper.DSIntWrapperInstantiator();
          assertNotNull(InternalInstantiator.getInstantiator(inst.getId()));
          DSIntWrapper value = (DSIntWrapper) region.get(key);
          assertNotNull(value);
          assertEquals(intValue, value.intValue);
        }
      };
    try {
    vm1.invoke(get);

    // Make sure that VMs that connect after registration can get the
    // serializer
    vm2.invoke(new SerializableRunnable(""Connect to DS"") {
        public void run() {
          // Register a Instantiator before connecting to system
          Instantiator.register(new DSLongWrapper.DSLongWrapperInstantiator());

          getSystem();
        }
      });
    vm2.invoke(create);
    vm2.invoke(new CacheSerializableRunnable(""Put long"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          region.put(key2, new DSLongWrapper(longValue));

          pauseIfNecessary();
        }
      });
    vm2.invoke(get);

    SerializableRunnable get2 = new CacheSerializableRunnable(""Get long"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          DSLongWrapper.DSLongWrapperInstantiator inst =
            new DSLongWrapper.DSLongWrapperInstantiator();
          assertNotNull(InternalInstantiator.getInstantiator(inst.getId()));
          LongWrapper value = (LongWrapper) region.get(key2);
          assertNotNull(value);
          assertEquals(longValue, value.longValue);

          inst = (DSLongWrapper.DSLongWrapperInstantiator)
            InternalInstantiator.getInstantiator(inst.getId());
          assertNotNull(inst);
          assertTrue(inst.wasInvoked);
        }
      };
    vm0.invoke(get2);
    vm1.invoke(get2);

    } finally {
    // wait a little while for other netsearch requests to return
    // before unregistering the serializers that will be needed to process these
    // responses.
    pause(1500);
    unregisterAllSerializers();
    }
  }",True
"  public void testNoInstantiator() {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
          }
        };


    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    VM vm2 = host.getVM(2);

    vm0.invoke(create);
    vm1.invoke(create);

    final Object key = ""KEY"";
    final Object key2 = ""KEY2"";
    final int intValue = 7201;
    final long longValue = 123612;
//    final boolean[] wasInvoked = new boolean[1];

    vm2.invoke(new SerializableRunnable(""Disconnect from DS"") {
        public void run() {
          disconnectFromDS();
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Put int"") {
        public void run2() throws CacheException {
          Instantiator.register(new DSIntWrapper.DSIntWrapperInstantiator());

          Region region = getRootRegion().getSubregion(name);
          region.put(key, new DSIntWrapper(intValue));

          flushIfNecessary(region);
        }
      });

    SerializableRunnable get = new CacheSerializableRunnable(""Get int"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          DSIntWrapper.DSIntWrapperInstantiator inst =
            new DSIntWrapper.DSIntWrapperInstantiator();
          assertNotNull(InternalInstantiator.getInstantiator(inst.getId()));
          DSIntWrapper value = (DSIntWrapper) region.get(key);
          assertNotNull(value);
          assertEquals(intValue, value.intValue);
        }
      };
    try {
    vm1.invoke(get);

    // Make sure that VMs that connect after registration can get the
    // serializer
    vm2.invoke(new SerializableRunnable(""Connect to DS"") {
        public void run() {
          // Register a Instantiator before connecting to system
          Instantiator.register(new DSLongWrapper.DSLongWrapperInstantiator());

          getSystem();
        }
      });
    vm2.invoke(create);
    vm2.invoke(new CacheSerializableRunnable(""Put long"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          region.put(key2, new DSLongWrapper(longValue));

          flushIfNecessary(region);
        }
      });
    vm2.invoke(get);

    SerializableRunnable get2 = new CacheSerializableRunnable(""Get long"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          DSLongWrapper.DSLongWrapperInstantiator inst =
            new DSLongWrapper.DSLongWrapperInstantiator();
          assertNotNull(InternalInstantiator.getInstantiator(inst.getId()));
          LongWrapper value = (LongWrapper) region.get(key2);
          assertNotNull(value);
          assertEquals(longValue, value.longValue);

          inst = (DSLongWrapper.DSLongWrapperInstantiator)
            InternalInstantiator.getInstantiator(inst.getId());
          assertNotNull(inst);
          assertTrue(inst.wasInvoked);
        }
      };
    vm0.invoke(get2);
    vm1.invoke(get2);

    } finally {
    // wait a little while for other netsearch requests to return
    // before unregistering the serializers that will be needed to process these
    // responses.
    pause(1500);
    unregisterAllSerializers();
    }
  }",False
"  public void _ttestOrderedUpdates() throws Throwable {
    if (getRegionAttributes().getScope() ==
        Scope.DISTRIBUTED_NO_ACK) {
      return;
    }

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
    final int lastNumber = 10;

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create region entry"") {
          public void run2() throws CacheException {
            Region region = createRegion(name);
            region.create(key, null);
          }
        };

    vm0.invoke(create);
    vm1.invoke(create);

    vm1.invoke(new CacheSerializableRunnable(""Set listener"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          region.setUserAttribute(new LinkedBlockingQueue());
          region.getAttributesMutator().addCacheListener(new
            CacheListenerAdapter() {
              public void afterUpdate(EntryEvent e) {
                Region region2 = e.getRegion();
                LinkedBlockingQueue queue =
                  (LinkedBlockingQueue) region2.getUserAttribute();
                Object value = e.getNewValue();
                assertNotNull(value);
                try {
                  getLogWriter().info(""++ Adding "" + value);
                  queue.put(value);

                } catch (InterruptedException ex) {
                  fail(""Why was I interrupted?"", ex);
                }
              }
            });
        }
      });
    AsyncInvocation ai1 =
      vm1.invokeAsync(new CacheSerializableRunnable(""Verify"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            LinkedBlockingQueue queue =
              (LinkedBlockingQueue) region.getUserAttribute();
            for (int i = 0; i <= lastNumber; i++) {
              try {
                getLogWriter().info(""++ Waiting for "" + i);
                Integer value = (Integer) queue.take();
                getLogWriter().info(""++ Got "" + value);
                assertEquals(i, value.intValue());

              } catch (InterruptedException ex) {
                fail(""Why was I interrupted?"", ex);
              }
            }
          }
        });

    pauseIfNecessary();

    AsyncInvocation ai0 =
      vm0.invokeAsync(new CacheSerializableRunnable(""Populate"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            for (int i = 0; i <= lastNumber; i++) {
//              com.gemstone.gemfire.internal.GemFireVersion.waitForJavaDebugger(getLogWriter());
              region.put(key, new Integer(i));
            }
          }
        });

    DistributedTestCase.join(ai0, 30 * 1000, getLogWriter());
    DistributedTestCase.join(ai1, 30 * 1000, getLogWriter());

    if (ai0.exceptionOccurred()) {
      fail(""ai0 failed"", ai0.getException());

    } else if (ai1.exceptionOccurred()) {
      fail(""ai1 failed"", ai1.getException());
    }
  }",True
"  public void _ttestOrderedUpdates() throws Throwable {
    if (getRegionAttributes().getScope() ==
        Scope.DISTRIBUTED_NO_ACK) {
      return;
    }

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
    final int lastNumber = 10;

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create region entry"") {
          public void run2() throws CacheException {
            Region region = createRegion(name);
            region.create(key, null);
          }
        };

    vm0.invoke(create);
    vm1.invoke(create);

    vm1.invoke(new CacheSerializableRunnable(""Set listener"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          region.setUserAttribute(new LinkedBlockingQueue());
          region.getAttributesMutator().addCacheListener(new
            CacheListenerAdapter() {
              public void afterUpdate(EntryEvent e) {
                Region region2 = e.getRegion();
                LinkedBlockingQueue queue =
                  (LinkedBlockingQueue) region2.getUserAttribute();
                Object value = e.getNewValue();
                assertNotNull(value);
                try {
                  getLogWriter().info(""++ Adding "" + value);
                  queue.put(value);

                } catch (InterruptedException ex) {
                  fail(""Why was I interrupted?"", ex);
                }
              }
            });
          flushIfNecessary(region);
        }
      });
    AsyncInvocation ai1 =
      vm1.invokeAsync(new CacheSerializableRunnable(""Verify"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            LinkedBlockingQueue queue =
              (LinkedBlockingQueue) region.getUserAttribute();
            for (int i = 0; i <= lastNumber; i++) {
              try {
                getLogWriter().info(""++ Waiting for "" + i);
                Integer value = (Integer) queue.take();
                getLogWriter().info(""++ Got "" + value);
                assertEquals(i, value.intValue());

              } catch (InterruptedException ex) {
                fail(""Why was I interrupted?"", ex);
              }
            }
          }
        });

    AsyncInvocation ai0 =
      vm0.invokeAsync(new CacheSerializableRunnable(""Populate"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            for (int i = 0; i <= lastNumber; i++) {
//              com.gemstone.gemfire.internal.GemFireVersion.waitForJavaDebugger(getLogWriter());
              region.put(key, new Integer(i));
            }
          }
        });

    DistributedTestCase.join(ai0, 30 * 1000, getLogWriter());
    DistributedTestCase.join(ai1, 30 * 1000, getLogWriter());

    if (ai0.exceptionOccurred()) {
      fail(""ai0 failed"", ai0.getException());

    } else if (ai1.exceptionOccurred()) {
      fail(""ai1 failed"", ai1.getException());
    }
  }",False
"  public void testRemoteCacheListener() throws InterruptedException {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
    final Object oldValue = ""OLD_VALUE"";
    final Object newValue = ""NEW_VALUE"";
//    final Object key2 = ""KEY2"";
//    final Object value2 = ""VALUE2"";

    SerializableRunnable populate =
      new CacheSerializableRunnable(""Create Region and Put"") {
          public void run2() throws CacheException {
            Region region = createRegion(name);
            region.put(key, oldValue);
          }
        };

    Host host = Host.getHost(0);
    final VM vm0 = host.getVM(0);
    final VM vm1 = host.getVM(1);

    vm0.invoke(populate);
    vm1.invoke(populate);

    vm1.invoke(new CacheSerializableRunnable(""Set listener"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterUpdate2(EntryEvent event) {
                assertEquals(Operation.UPDATE, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
                assertEquals(key, event.getKey());
                assertEquals(oldValue, event.getOldValue());
                assertEquals(newValue, event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());
                if (event.getRegion().getAttributes().getOffHeap()) {
                  // since off heap always serializes the old value is serialized and available
                  assertEquals(oldValue, event.getSerializedOldValue().getDeserializedValue());
                } else {
                  assertEquals(null, event.getSerializedOldValue()); // since it was put originally in this VM
                }
                DataInputStream dis = new DataInputStream(new ByteArrayInputStream(event.getSerializedNewValue().getSerializedValue()));
                try {
                  assertEquals(newValue, DataSerializer.readObject(dis));
                } catch (Exception e) {
                  fail(""Unexpected Exception"", e);
                }
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    // I see no reason to pause here.
    // The test used to pause here but only if no-ack.
    // But we have no operations to wait for.
    // The last thing we did was install a listener in vm1
    // and it is possible that vm0 does not yet know we have
    // a listener but for this test it does not matter.
    // So I'm commenting out the following pause:
    //pauseIfNecessary();

    vm0.invoke(new CacheSerializableRunnable(""Update"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.put(key, newValue, getSystem().getDistributedMember());
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Verify Update"") {
        public void run2() throws CacheException {
          listener.waitForInvocation(3000, 10);

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterInvalidate2(EntryEvent event) {
                assertEquals(Operation.INVALIDATE, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
                assertEquals(key, event.getKey());
                assertEquals(newValue, event.getOldValue());
                assertNull(event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());
                assertNull(event.getSerializedNewValue());
                DataInputStream dis = new DataInputStream(new ByteArrayInputStream(event.getSerializedOldValue().getSerializedValue()));
                try {
                  assertEquals(newValue, DataSerializer.readObject(dis));
                } catch (Exception e) {
                  fail(""Unexpected Exception"", e);
                }
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Invalidate"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.invalidate(key, getSystem().getDistributedMember());
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Verify Invalidate"") {
        public void run2() throws CacheException {
          listener.waitForInvocation(3000, 10);

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterDestroy2(EntryEvent event) {
                assertTrue(event.getOperation().isDestroy());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
                assertEquals(key, event.getKey());
                assertNull(event.getOldValue());
                assertNull(event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());
                assertNull(event.getSerializedOldValue());
                assertNull(event.getSerializedNewValue());
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Destroy"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.destroy(key, getSystem().getDistributedMember());
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Verify Destroy"") {
        public void run2() throws CacheException {
          listener.waitForInvocation(3000, 10);

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterRegionInvalidate2(RegionEvent event) {
                assertEquals(Operation.REGION_INVALIDATE, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Invalidate Region"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.invalidateRegion(getSystem().getDistributedMember());
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Verify Invalidate Region"") {
        public void run2() throws CacheException {
          listener.waitForInvocation(3000, 10);

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterRegionDestroy2(RegionEvent event) {
                assertEquals(Operation.REGION_DESTROY, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Destroy Region"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.destroyRegion(getSystem().getDistributedMember());
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Verify Destroy Region"") {
        public void run2() throws CacheException {
          listener.waitForInvocation(3000, 10);
        }
      });
  }",True
"  public void testRemoteCacheListener() throws InterruptedException {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();
    final Object key = ""KEY"";
    final Object oldValue = ""OLD_VALUE"";
    final Object newValue = ""NEW_VALUE"";
//    final Object key2 = ""KEY2"";
//    final Object value2 = ""VALUE2"";

    SerializableRunnable populate =
      new CacheSerializableRunnable(""Create Region and Put"") {
          public void run2() throws CacheException {
            Region region = createRegion(name);
            region.put(key, oldValue);
          }
        };

    Host host = Host.getHost(0);
    final VM vm0 = host.getVM(0);
    final VM vm1 = host.getVM(1);

    vm0.invoke(populate);
    vm1.invoke(populate);

    vm1.invoke(new CacheSerializableRunnable(""Set listener"") {
        public void run2() throws CacheException {
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterUpdate2(EntryEvent event) {
                assertEquals(Operation.UPDATE, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
                assertEquals(key, event.getKey());
                assertEquals(oldValue, event.getOldValue());
                assertEquals(newValue, event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());
                if (event.getRegion().getAttributes().getOffHeap()) {
                  // since off heap always serializes the old value is serialized and available
                  assertEquals(oldValue, event.getSerializedOldValue().getDeserializedValue());
                } else {
                  assertEquals(null, event.getSerializedOldValue()); // since it was put originally in this VM
                }
                DataInputStream dis = new DataInputStream(new ByteArrayInputStream(event.getSerializedNewValue().getSerializedValue()));
                try {
                  assertEquals(newValue, DataSerializer.readObject(dis));
                } catch (Exception e) {
                  fail(""Unexpected Exception"", e);
                }
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    // I see no reason to pause here.
    // The test used to pause here but only if no-ack.
    // But we have no operations to wait for.
    // The last thing we did was install a listener in vm1
    // and it is possible that vm0 does not yet know we have
    // a listener but for this test it does not matter.
    // So I'm commenting out the following pause:
    //pauseIfNecessary();
    // If needed then do a flushIfNecessary(region) after adding the cache listener

    vm0.invoke(new CacheSerializableRunnable(""Update"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.put(key, newValue, getSystem().getDistributedMember());
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Verify Update"") {
        public void run2() throws CacheException {
          listener.waitForInvocation(3000, 10);

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterInvalidate2(EntryEvent event) {
                assertEquals(Operation.INVALIDATE, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
                assertEquals(key, event.getKey());
                assertEquals(newValue, event.getOldValue());
                assertNull(event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());
                assertNull(event.getSerializedNewValue());
                DataInputStream dis = new DataInputStream(new ByteArrayInputStream(event.getSerializedOldValue().getSerializedValue()));
                try {
                  assertEquals(newValue, DataSerializer.readObject(dis));
                } catch (Exception e) {
                  fail(""Unexpected Exception"", e);
                }
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Invalidate"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.invalidate(key, getSystem().getDistributedMember());
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Verify Invalidate"") {
        public void run2() throws CacheException {
          listener.waitForInvocation(3000, 10);

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterDestroy2(EntryEvent event) {
                assertTrue(event.getOperation().isDestroy());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
                assertEquals(key, event.getKey());
                assertNull(event.getOldValue());
                assertNull(event.getNewValue());
                assertFalse(event.getOperation().isLoad());
                assertFalse(event.getOperation().isLocalLoad());
                assertFalse(event.getOperation().isNetLoad());
                assertFalse(event.getOperation().isNetSearch());
                assertNull(event.getSerializedOldValue());
                assertNull(event.getSerializedNewValue());
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Destroy"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.destroy(key, getSystem().getDistributedMember());
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Verify Destroy"") {
        public void run2() throws CacheException {
          listener.waitForInvocation(3000, 10);

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterRegionInvalidate2(RegionEvent event) {
                assertEquals(Operation.REGION_INVALIDATE, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Invalidate Region"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.invalidateRegion(getSystem().getDistributedMember());
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Verify Invalidate Region"") {
        public void run2() throws CacheException {
          listener.waitForInvocation(3000, 10);

          // Setup listener for next test
          final Region region =
            getRootRegion().getSubregion(name);
          listener = new TestCacheListener() {
              public void afterRegionDestroy2(RegionEvent event) {
                assertEquals(Operation.REGION_DESTROY, event.getOperation());
                assertEquals(region, event.getRegion());
                assertTrue(event.getOperation().isDistributed());
                assertFalse(event.getOperation().isExpiration());
                assertTrue(event.isOriginRemote());
                assertEquals(event.getCallbackArgument(), event.getDistributedMember());
              }
            };
          region.getAttributesMutator().addCacheListener(listener);
        }
      });

    vm0.invoke(new CacheSerializableRunnable(""Destroy Region"") {
        public void run2() throws CacheException {
          Region region =
            getRootRegion().getSubregion(name);
          region.destroyRegion(getSystem().getDistributedMember());
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""Verify Destroy Region"") {
        public void run2() throws CacheException {
          listener.waitForInvocation(3000, 10);
        }
      });
  }",False
"  public void testNoDataSerializer() {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
          }
        };


    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    VM vm2 = host.getVM(2);

    getLogWriter().info(name + "": before creates"");
    vm0.invoke(create);
    vm1.invoke(create);
    getLogWriter().info(name + "": after creates"");

    final Object key = ""KEY"";
    final Object key2 = ""KEY2"";
    final int intValue = 3452;
    final long longValue = 213421;
//    final boolean[] wasInvoked = new boolean[1];

    vm2.invoke(new SerializableRunnable(""Disconnect from DS"") {
        public void run() {
          disconnectFromDS();
        }
      });
    getLogWriter().info(name + "": after vm2 disconnect"");

    try {
    vm0.invoke(new CacheSerializableRunnable(""Put int"") {
        public void run2() throws CacheException {
          Class c = IntWrapper.IntWrapperSerializer.class;
          IntWrapper.IntWrapperSerializer serializer =
            (IntWrapper.IntWrapperSerializer)
            DataSerializer.register(c);

          Region region = getRootRegion().getSubregion(name);
          region.put(key, new IntWrapper(intValue));

          pauseIfNecessary();
          assertTrue(serializer.wasInvoked);
        }
      });
    getLogWriter().info(name + "": after vm0 put"");

    SerializableRunnable get = new CacheSerializableRunnable(""Get int"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
//          if (region.getAttributes().getScope().isDistributedNoAck()) {
            // wait a while for the serializer to be registered
            long end = System.currentTimeMillis() + 30000;
            while (InternalDataSerializer.getSerializer((byte)120) == null) {
              assertTrue(""This test sometimes fails due to timing issues"",
                  System.currentTimeMillis() <= end);
              try {
                Thread.sleep(1000);
              }
              catch (InterruptedException e) {
                // no need to keep interrupt bit here
                throw new CacheException(""Test interrupted"") { };
              }
            }
//          }
          IntWrapper value = (IntWrapper) region.get(key);
          assertNotNull(InternalDataSerializer.getSerializer((byte)120));
          assertNotNull(value);
          assertEquals(intValue, value.intValue);
        }
      };
    vm1.invoke(get);
    getLogWriter().info(name + "": after vm1 get"");

    // Make sure that VMs that connect after registration can get the
    // serializer
    vm2.invoke(new SerializableRunnable(""Connect to DS"") {
        public void run() {
          // Register a DataSerializer before connecting to system
          Class c = LongWrapper.LongWrapperSerializer.class;
          DataSerializer.register(c);

          getSystem();
        }
      });
    vm2.invoke(create);
    getLogWriter().info(name + "": after vm2 create"");
    vm2.invoke(new CacheSerializableRunnable(""Put long"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          region.put(key2, new LongWrapper(longValue));

          pauseIfNecessary();

          LongWrapper.LongWrapperSerializer serializer =
            (LongWrapper.LongWrapperSerializer)
            InternalDataSerializer.getSerializer((byte) 121);
          assertTrue(serializer.wasInvoked);
        }
      });
    getLogWriter().info(name + "": after vm2 put"");
    vm2.invoke(get);
    getLogWriter().info(name + "": after vm2 get"");

    SerializableRunnable get2 = new CacheSerializableRunnable(""Get long"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          LongWrapper value = (LongWrapper) region.get(key2);
          assertNotNull(InternalDataSerializer.getSerializer((byte)121));
          assertNotNull(value);
          assertEquals(longValue, value.longValue);
        }
      };
    vm0.invoke(get2);
    getLogWriter().info(name + "": after vm0 get2"");
    vm1.invoke(get2);
    getLogWriter().info(name + "": after vm1 get2"");

    // wait a little while for other netsearch requests to return
    // before unregistering the serializers that will be needed to process these
    // responses.
    } finally {
    pause(1500);
    unregisterAllSerializers();
    getLogWriter().info(name + "": after unregister"");
    }
  }",True
"  public void testNoDataSerializer() {
    assertTrue(getRegionAttributes().getScope().isDistributed());

    final String name = this.getUniqueName();

    SerializableRunnable create =
      new CacheSerializableRunnable(""Create Region"") {
          public void run2() throws CacheException {
            createRegion(name);
          }
        };


    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    VM vm2 = host.getVM(2);

    getLogWriter().info(name + "": before creates"");
    vm0.invoke(create);
    vm1.invoke(create);
    getLogWriter().info(name + "": after creates"");

    final Object key = ""KEY"";
    final Object key2 = ""KEY2"";
    final int intValue = 3452;
    final long longValue = 213421;
//    final boolean[] wasInvoked = new boolean[1];

    vm2.invoke(new SerializableRunnable(""Disconnect from DS"") {
        public void run() {
          disconnectFromDS();
        }
      });
    getLogWriter().info(name + "": after vm2 disconnect"");

    try {
    vm0.invoke(new CacheSerializableRunnable(""Put int"") {
        public void run2() throws CacheException {
          Class c = IntWrapper.IntWrapperSerializer.class;
          IntWrapper.IntWrapperSerializer serializer =
            (IntWrapper.IntWrapperSerializer)
            DataSerializer.register(c);

          Region region = getRootRegion().getSubregion(name);
          region.put(key, new IntWrapper(intValue));

          flushIfNecessary(region);
          assertTrue(serializer.wasInvoked);
        }
      });
    getLogWriter().info(name + "": after vm0 put"");

    SerializableRunnable get = new CacheSerializableRunnable(""Get int"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
//          if (region.getAttributes().getScope().isDistributedNoAck()) {
            // wait a while for the serializer to be registered
            long end = System.currentTimeMillis() + 30000;
            while (InternalDataSerializer.getSerializer((byte)120) == null) {
              assertTrue(""This test sometimes fails due to timing issues"",
                  System.currentTimeMillis() <= end);
              try {
                Thread.sleep(1000);
              }
              catch (InterruptedException e) {
                // no need to keep interrupt bit here
                throw new CacheException(""Test interrupted"") { };
              }
            }
//          }
          IntWrapper value = (IntWrapper) region.get(key);
          assertNotNull(InternalDataSerializer.getSerializer((byte)120));
          assertNotNull(value);
          assertEquals(intValue, value.intValue);
        }
      };
    vm1.invoke(get);
    getLogWriter().info(name + "": after vm1 get"");

    // Make sure that VMs that connect after registration can get the
    // serializer
    vm2.invoke(new SerializableRunnable(""Connect to DS"") {
        public void run() {
          // Register a DataSerializer before connecting to system
          Class c = LongWrapper.LongWrapperSerializer.class;
          DataSerializer.register(c);

          getSystem();
        }
      });
    vm2.invoke(create);
    getLogWriter().info(name + "": after vm2 create"");
    vm2.invoke(new CacheSerializableRunnable(""Put long"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          region.put(key2, new LongWrapper(longValue));

          flushIfNecessary(region);

          LongWrapper.LongWrapperSerializer serializer =
            (LongWrapper.LongWrapperSerializer)
            InternalDataSerializer.getSerializer((byte) 121);
          assertTrue(serializer.wasInvoked);
        }
      });
    getLogWriter().info(name + "": after vm2 put"");
    vm2.invoke(get);
    getLogWriter().info(name + "": after vm2 get"");

    SerializableRunnable get2 = new CacheSerializableRunnable(""Get long"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          LongWrapper value = (LongWrapper) region.get(key2);
          assertNotNull(InternalDataSerializer.getSerializer((byte)121));
          assertNotNull(value);
          assertEquals(longValue, value.longValue);
        }
      };
    vm0.invoke(get2);
    getLogWriter().info(name + "": after vm0 get2"");
    vm1.invoke(get2);
    getLogWriter().info(name + "": after vm1 get2"");

    // wait a little while for other netsearch requests to return
    // before unregistering the serializers that will be needed to process these
    // responses.
    } finally {
    pause(1500);
    unregisterAllSerializers();
    getLogWriter().info(name + "": after unregister"");
    }
  }",False
"  protected void flushIfNecessary(Region r) {
    // Only needed for no-ack regions
  }",False
"  public void testRunningServerOutlivesForkingProcess() throws Throwable {
    // launch ServerLauncherForkingProcess which then launches server
    
//    final List<String> command = new ArrayList<String>();
//    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
//    command.add(""-cp"");
//    command.add(System.getProperty(""java.class.path""));
//    command.add(ServerLauncherDUnitTest.class.getName().concat(""$"").concat(ServerLauncherForkingProcess.class.getSimpleName()));
//
//    process = new ProcessBuilder(command).directory(temporaryFolder.getRoot()).start();
//    assertNotNull(process);
//    processOutReader = new ProcessStreamReader(process.getInputStream(), createListener(""sysout"", getUniqueName() + ""#sysout"")).start();
//    processErrReader = new ProcessStreamReader(process.getErrorStream(), createListener(""syserr"", getUniqueName() + ""#syserr"")).start();

    @SuppressWarnings(""unused"")
    File file = new File(this.temporaryFolder.getRoot(), ServerLauncherForkingProcess.class.getSimpleName().concat("".log""));
    //-logger.info(""KIRK: log file is "" + file);
    
    final ProcessWrapper pw = new ProcessWrapper.Builder().main(ServerLauncherForkingProcess.class).build();
    pw.execute(null, this.temporaryFolder.getRoot()).waitFor(true);
    //logger.info(""[testRunningServerOutlivesForkingProcess] ServerLauncherForkingProcess output is:\n\n""+pw.getOutput());
    
//    // create waiting thread since waitFor does not have a timeout 
//    Thread waiting = new Thread(new Runnable() {
//      @Override
//      public void run() {
//        try {
//          assertEquals(0, process.waitFor());
//        } catch (InterruptedException e) {
//          logger.error(""Interrupted while waiting for process"", e);
//        }
//      }
//    });

//    // start waiting thread and join to it for timeout
//    try {
//      waiting.start();
//      waiting.join(TIMEOUT_MILLISECONDS);
//      assertFalse(""ServerLauncherForkingProcess took too long and caused timeout"", waiting.isAlive());
//      
//    } catch (Throwable e) {
//      logger.error(e);
//      if (failure == null) {
//        failure = e;
//      }
//    } finally {
//      if (waiting.isAlive()) {
//        waiting.interrupt();
//      }
//    }

    // wait for server to start
    int pid = 0;
    final String serverName = ServerLauncherForkingProcess.class.getSimpleName()+""_server"";
    final ServerLauncher dirLauncher = new ServerLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForServerToStart(dirLauncher);

      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = serverName+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());
      
      // validate the status
      final ServerState actualStatus = dirLauncher.status();
      assertNotNull(actualStatus);
      assertEquals(Status.ONLINE, actualStatus.getStatus());
      assertEquals(pid, actualStatus.getPid().intValue());
      assertTrue(actualStatus.getUptime() > 0);
      assertEquals(this.temporaryFolder.getRoot().getCanonicalPath(), actualStatus.getWorkingDirectory());
      assertEquals(getJvmArguments(), actualStatus.getJvmArguments());
      assertEquals(ManagementFactory.getRuntimeMXBean().getClassPath(), actualStatus.getClasspath());
      assertEquals(GemFireVersion.getGemFireVersion(), actualStatus.getGemFireVersion());
      assertEquals(System.getProperty(""java.version""),  actualStatus.getJavaVersion());
      assertEquals(this.temporaryFolder.getRoot().getCanonicalPath() + File.separator + serverName + "".log"", actualStatus.getLogFile());
      assertEquals(InetAddress.getLocalHost().getCanonicalHostName(), actualStatus.getHost());
      assertEquals(serverName, actualStatus.getMemberName());
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the server
    try {
      assertEquals(Status.STOPPED, dirLauncher.stop().getStatus());
      waitForPidToStop(pid);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testRunningServerOutlivesForkingProcess() throws Throwable {
    // launch ServerLauncherForkingProcess which then launches server
    
//    final List<String> command = new ArrayList<String>();
//    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
//    command.add(""-cp"");
//    command.add(System.getProperty(""java.class.path""));
//    command.add(ServerLauncherDUnitTest.class.getName().concat(""$"").concat(ServerLauncherForkingProcess.class.getSimpleName()));
//
//    process = new ProcessBuilder(command).directory(temporaryFolder.getRoot()).start();
//    assertNotNull(process);
//    processOutReader = new ProcessStreamReader(process.getInputStream(), createListener(""sysout"", getUniqueName() + ""#sysout"")).start();
//    processErrReader = new ProcessStreamReader(process.getErrorStream(), createListener(""syserr"", getUniqueName() + ""#syserr"")).start();

    @SuppressWarnings(""unused"")
    File file = new File(this.temporaryFolder.getRoot(), ServerLauncherForkingProcess.class.getSimpleName().concat("".log""));
    //-logger.info(""KIRK: log file is "" + file);
    
    final ProcessWrapper pw = new ProcessWrapper.Builder().mainClass(ServerLauncherForkingProcess.class).build();
    pw.execute(null, this.temporaryFolder.getRoot()).waitFor(true);
    //logger.info(""[testRunningServerOutlivesForkingProcess] ServerLauncherForkingProcess output is:\n\n""+pw.getOutput());
    
//    // create waiting thread since waitFor does not have a timeout 
//    Thread waiting = new Thread(new Runnable() {
//      @Override
//      public void run() {
//        try {
//          assertEquals(0, process.waitFor());
//        } catch (InterruptedException e) {
//          logger.error(""Interrupted while waiting for process"", e);
//        }
//      }
//    });

//    // start waiting thread and join to it for timeout
//    try {
//      waiting.start();
//      waiting.join(TIMEOUT_MILLISECONDS);
//      assertFalse(""ServerLauncherForkingProcess took too long and caused timeout"", waiting.isAlive());
//      
//    } catch (Throwable e) {
//      logger.error(e);
//      if (failure == null) {
//        failure = e;
//      }
//    } finally {
//      if (waiting.isAlive()) {
//        waiting.interrupt();
//      }
//    }

    // wait for server to start
    int pid = 0;
    final String serverName = ServerLauncherForkingProcess.class.getSimpleName()+""_server"";
    final ServerLauncher dirLauncher = new ServerLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForServerToStart(dirLauncher);

      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = serverName+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());
      
      // validate the status
      final ServerState actualStatus = dirLauncher.status();
      assertNotNull(actualStatus);
      assertEquals(Status.ONLINE, actualStatus.getStatus());
      assertEquals(pid, actualStatus.getPid().intValue());
      assertTrue(actualStatus.getUptime() > 0);
      assertEquals(this.temporaryFolder.getRoot().getCanonicalPath(), actualStatus.getWorkingDirectory());
      assertEquals(getJvmArguments(), actualStatus.getJvmArguments());
      assertEquals(ManagementFactory.getRuntimeMXBean().getClassPath(), actualStatus.getClasspath());
      assertEquals(GemFireVersion.getGemFireVersion(), actualStatus.getGemFireVersion());
      assertEquals(System.getProperty(""java.version""),  actualStatus.getJavaVersion());
      assertEquals(this.temporaryFolder.getRoot().getCanonicalPath() + File.separator + serverName + "".log"", actualStatus.getLogFile());
      assertEquals(InetAddress.getLocalHost().getCanonicalHostName(), actualStatus.getHost());
      assertEquals(serverName, actualStatus.getMemberName());
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the server
    try {
      assertEquals(Status.STOPPED, dirLauncher.stop().getStatus());
      waitForPidToStop(pid);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public final void executeInProcess() throws IOException {
    outputLine(""Begin "" + name() + "".main"");
    outputLine(""Press Enter to continue."");
    new BufferedReader(new InputStreamReader(System.in)).readLine();
    outputProblemInProcess(problem());
    outputLine(""End "" + name() + "".main"");
  }",False
"  FailOutputTestCase(String name) {
    super(name);
  }",True
"  @Override
  protected GoldenComparator createGoldenComparator() {
    return new GoldenStringComparator(expectedProblemLines());",False
"  void execute() throws IOException {
    System.out.println(""Begin "" + name() + "".main"");
    System.out.println(""Press Enter to continue."");
    BufferedReader inputReader = new BufferedReader(new InputStreamReader(System.in));
    inputReader.readLine();
    outputProblem(problem());
    System.out.println(""End "" + name() + "".main"");
  }",True
"    new BufferedReader(new InputStreamReader(System.in)).readLine();
    outputProblemInProcess(problem());
    outputLine(""End "" + name() + "".main"");
  }
}
",False
"  public static void main(String[] args) throws Exception {
    new FailWithErrorInOutputJUnitTest().execute();
  }",True
"  void outputProblem(String message) {
    LogWriter logWriter = new LocalLogWriter(LogWriterImpl.INFO_LEVEL);
    logWriter.error(message);
  }",True
"    new FailWithErrorInOutputJUnitTest().executeInProcess();
  }
}
",False
"  void outputProblemInProcess(final String message) {
    new LocalLogWriter(LogWriterImpl.INFO_LEVEL).error(message);
  }",False
"  public FailWithErrorInOutputJUnitTest() {
    super(FailWithErrorInOutputJUnitTest.class.getSimpleName());
  }",True
"  String problem() {
    return ""ExpectedStrings: Description of a problem."";
  }",False
"  public static void main(final String[] args) throws Exception {
    new FailWithErrorInOutputJUnitTest().executeInProcess();
  }",False
"  void outputProblemInProcess(final String message) {
    System.out.println(message);
  }",False
"  public void testFailWithExtraLineInOutput() throws InterruptedException, IOException {
    // output has an extra line and should fail
    final ProcessWrapper process = createProcessWrapper(getClass());
    process.execute(createProperties());
    process.waitForOutputToMatch(""Begin "" + name() + ""\\.main"");
    process.waitForOutputToMatch(""Press Enter to continue\\."");
    process.sendInput();
    process.waitForOutputToMatch(""End "" + name() + ""\\.main"");
    process.waitFor();
    String goldenString = ""Begin "" + name() + "".main"" + ""\n"" 
        + ""Press Enter to continue."" + ""\n"" 
        + ""End "" + name() + "".main"" + ""\n"";
    innerPrintOutput(goldenString, ""GOLDEN"");
    try {
      assertOutputMatchesGoldenFile(process.getOutput(), goldenString);
      fail(""assertOutputMatchesGoldenFile should have failed due to "" + problem());
    } catch (AssertionFailedError expected) {
      assertTrue(expected.getMessage().contains(problem()));
    }
  }",True
"  public void testFailWithExtraLineInOutput() throws Exception {
    final String goldenString = 
        ""Begin "" + name() + "".main"" + ""\n"" +
        ""Press Enter to continue."" + ""\n"" + 
        ""End "" + name() + "".main"" + ""\n"";
    debug(goldenString, ""GOLDEN"");

    final ProcessWrapper process = createProcessWrapper(new ProcessWrapper.Builder(), getClass());
    process.execute(createProperties());
    process.waitForOutputToMatch(""Begin "" + name() + ""\\.main"");
    process.waitForOutputToMatch(""Press Enter to continue\\."");
    process.sendInput();
    process.waitForOutputToMatch(""End "" + name() + ""\\.main"");
    process.waitFor();
    
    try {
      assertOutputMatchesGoldenFile(process.getOutput(), goldenString);
      fail(""assertOutputMatchesGoldenFile should have failed due to "" + problem());
    } catch (AssertionError expected) {
      assertTrue(expected.getMessage().contains(problem()));
    }
  }",False
"  void outputProblem(String message) {
    System.out.println(message);
  }",True
"   * Process output has an extra line and should fail
   */
  @Test",False
"  public FailWithExtraLineInOutputJUnitTest() {
    super(""FailWithExtraLineInOutputJUnitTest"");
  }",True
"  String problem() {
    return ""This is an extra line"";
  }",False
"  public static void main(String[] args) throws Exception {
    new FailWithExtraLineInOutputJUnitTest().execute();
  }",True
"  
  public static void main(final String[] args) throws Exception {
    new FailWithExtraLineInOutputJUnitTest().executeInProcess();",False
"  public static void main(final String[] args) throws Exception {
    new FailWithExtraLineInOutputJUnitTest().executeInProcess();
  }",False
"  public void testFailWithLineMissingFromEndOfOutput() throws InterruptedException, IOException {
    final ProcessWrapper process = createProcessWrapper(getClass());
    process.execute(createProperties());
    process.waitForOutputToMatch(""Begin "" + name() + ""\\.main"");
    process.waitForOutputToMatch(""Press Enter to continue\\."");
    process.sendInput();
    process.waitForOutputToMatch(""End "" + name() + ""\\.main"");
    process.waitFor();
    String goldenString = ""Begin "" + name() + "".main"" + ""\n"" 
        + ""Press Enter to continue."" + ""\n"" 
        + ""End "" + name() + "".main"" + ""\n""
        + problem() + ""\n""; 
    innerPrintOutput(goldenString, ""GOLDEN"");
    try {
      assertOutputMatchesGoldenFile(process.getOutput(), goldenString);
      fail(""assertOutputMatchesGoldenFile should have failed due to "" + problem());
    } catch (AssertionFailedError expected) {
      assertTrue(""AssertionFailedError message should contain \"""" + problem() + ""\"""", 
          expected.getMessage().contains(problem()));
    }
  }",True
"  public void testFailWithLineMissingFromEndOfOutput() throws Exception {
    final String goldenString = 
        ""Begin "" + name() + "".main"" + ""\n"" +
        ""Press Enter to continue."" + ""\n"" +
        ""End "" + name() + "".main"" + ""\n"" +
        problem() + ""\n""; 
    debug(goldenString, ""GOLDEN"");

    final ProcessWrapper process = createProcessWrapper(new ProcessWrapper.Builder(), getClass());
    process.execute(createProperties());
    process.waitForOutputToMatch(""Begin "" + name() + ""\\.main"");
    process.waitForOutputToMatch(""Press Enter to continue\\."");
    process.sendInput();
    process.waitForOutputToMatch(""End "" + name() + ""\\.main"");
    process.waitFor();
    
    try {
      assertOutputMatchesGoldenFile(process.getOutput(), goldenString);
      fail(""assertOutputMatchesGoldenFile should have failed due to "" + problem());
    } catch (AssertionError expected) {
      assertTrue(""AssertionFailedError message should contain \"""" + problem() + ""\"""", 
          expected.getMessage().contains(problem()));
    }
  }",False
"  public static void main(String[] args) throws Exception {
    new FailWithLineMissingFromEndOfOutputJUnitTest().execute();
  }",True
"  public static void main(final String[] args) throws Exception {
    new FailWithLineMissingFromEndOfOutputJUnitTest().executeInProcess();
  }",False
"  public FailWithLineMissingFromEndOfOutputJUnitTest() {
    super(""FailWithLineMissingFromOutputJUnitTest"");
  }",True
"  String problem() {
    return ""This line is missing in actual output."";
  }",False
"  void outputProblemInProcess(final String message) {
    // this tests that the message is missing from output
  }",False
"    new FailWithLineMissingFromEndOfOutputJUnitTest().executeInProcess();
  }
}",False
"  void outputProblem(String message) {
    // this tests that the message is missing from output
  }",True
"  public void testFailWithLineMissingFromEndOfOutput() throws Exception {
    final String goldenString = 
        ""Begin "" + name() + "".main"" + ""\n"" +",False
"  public static void main(String[] args) throws Exception {
    new FailWithLineMissingFromMiddleOfOutputJUnitTest().execute();
  }",True
"  public static void main(final String[] args) throws Exception {
    new FailWithLineMissingFromMiddleOfOutputJUnitTest().executeInProcess();
  }",False
"  public FailWithLineMissingFromMiddleOfOutputJUnitTest() {
    super(""FailWithLineMissingFromMiddleOfOutputJUnitTest"");
  }",True
"  public void testFailWithLineMissingFromEndOfOutput() throws InterruptedException, IOException {
    final ProcessWrapper process = createProcessWrapper(getClass());
    process.execute(createProperties());
    process.waitForOutputToMatch(""Begin "" + name() + ""\\.main"");
    process.waitForOutputToMatch(""Press Enter to continue\\."");
    process.sendInput();
    process.waitFor();
    String goldenString = ""Begin "" + name() + "".main"" + ""\n"" 
        + ""Press Enter to continue."" + ""\n"" 
        + problem() + ""\n""
        + ""End "" + name() + "".main"" + ""\n"";
    innerPrintOutput(goldenString, ""GOLDEN"");
    try {
      assertOutputMatchesGoldenFile(process.getOutput(), goldenString);
      fail(""assertOutputMatchesGoldenFile should have failed due to "" + problem());
    } catch (AssertionFailedError expected) {
      assertTrue(""AssertionFailedError message should contain \"""" + problem() + ""\"""", 
          expected.getMessage().contains(problem()));
    }
  }",True
"  public void testFailWithLineMissingFromEndOfOutput() throws Exception {
    final String goldenString = 
        ""Begin "" + name() + "".main"" + ""\n"" +
        ""Press Enter to continue."" + ""\n"" +
        problem() + ""\n"" +
        ""End "" + name() + "".main"" + ""\n"";
    debug(goldenString, ""GOLDEN"");

    final ProcessWrapper process = createProcessWrapper(new ProcessWrapper.Builder(), getClass());
    process.execute(createProperties());
    process.waitForOutputToMatch(""Begin "" + name() + ""\\.main"");
    process.waitForOutputToMatch(""Press Enter to continue\\."");
    process.sendInput();
    process.waitFor();
    
    try {
      assertOutputMatchesGoldenFile(process.getOutput(), goldenString);
      fail(""assertOutputMatchesGoldenFile should have failed due to "" + problem());
    } catch (AssertionError expected) {
      assertTrue(""AssertionFailedError message should contain \"""" + problem() + ""\"""", 
          expected.getMessage().contains(problem()));
    }
  }",False
"    new FailWithLineMissingFromMiddleOfOutputJUnitTest().executeInProcess();
  }
}",False
"  public static void main(String[] args) throws Exception {
    new FailWithLoggerErrorInOutputJUnitTest().execute();
  }",True
"  public static void main(final String[] args) throws Exception {
    new FailWithLoggerErrorInOutputJUnitTest().executeInProcess();
  }",False
"  public FailWithLoggerErrorInOutputJUnitTest() {
    super(FailWithLoggerErrorInOutputJUnitTest.class.getSimpleName());
  }",True
"  void outputProblemInProcess(final String message) {
    LogService.getLogger().error(message);
  }",False
"  void outputProblem(String message) {
    Logger logger = LogService.getLogger();
    logger.error(message);
  }",True
"    new FailWithLoggerErrorInOutputJUnitTest().executeInProcess();
  }
}
",False
"  public static void main(String[] args) throws Exception {
    new FailWithLoggerFatalInOutputJUnitTest().execute();
  }",True
"  void outputProblemInProcess(final String message) {
    LogService.getLogger().fatal(message);
  }",False
"  public static void main(final String[] args) throws Exception {
    new FailWithLoggerFatalInOutputJUnitTest().executeInProcess();
  }",False
"  void outputProblem(String message) {
    Logger logger = LogService.getLogger();
    logger.fatal(message);
  }",True
"    new FailWithLoggerFatalInOutputJUnitTest().executeInProcess();
  }
}
",False
"  public FailWithLoggerFatalInOutputJUnitTest() {
    super(FailWithLoggerFatalInOutputJUnitTest.class.getSimpleName());
  }",True
"  public FailWithLoggerWarnInOutputJUnitTest() {
    super(FailWithLoggerWarnInOutputJUnitTest.class.getSimpleName());
  }",True
"  void outputProblem(String message) {
    Logger logger = LogService.getLogger();
    logger.warn(message);
  }",True
"    new FailWithLoggerWarnInOutputJUnitTest().executeInProcess();
  }
}
",False
"  public static void main(String[] args) throws Exception {
    new FailWithLoggerWarnInOutputJUnitTest().execute();
  }",True
"  public static void main(final String[] args) throws Exception {
    new FailWithLoggerWarnInOutputJUnitTest().executeInProcess();
  }",False
"  void outputProblemInProcess(final String message) {
    LogService.getLogger().warn(message);
  }",False
"  FailWithProblemInOutputTestCase(String name) {
    super(name);
  }",True
"  @Override
  protected String[] expectedProblemLines() {
    return new String[] { "".*"" + name() + "".*"" };",False
"  public void testFailWithProblemLogMessageInOutput() throws InterruptedException, IOException {
    final ProcessWrapper process = createProcessWrapper(getClass());
    process.execute(createProperties());
    process.waitForOutputToMatch(""Begin "" + name() + ""\\.main"");
    process.waitForOutputToMatch(""Press Enter to continue\\."");
    process.sendInput();
    process.waitForOutputToMatch(""End "" + name() + ""\\.main"");
    process.waitFor();
    String goldenString = ""Begin "" + name() + "".main"" + ""\n"" 
        + ""Press Enter to continue."" + ""\n"" 
        + ""End "" + name() + "".main"" + ""\n"";
    innerPrintOutput(goldenString, ""GOLDEN"");
    try {
      assertOutputMatchesGoldenFile(process.getOutput(), goldenString);
      fail(""assertOutputMatchesGoldenFile should have failed due to "" + problem());
    } catch (AssertionFailedError expected) {
//      System.out.println(""Problem: "" + problem());
//      System.out.println(""AssertionFailedError message: "" + expected.getMessage());
      assertTrue(expected.getMessage().contains(problem()));
    }
  }",True
"  public void testFailWithProblemLogMessageInOutput() throws Exception {
    final String goldenString = 
        ""Begin "" + name() + "".main"" + ""\n"" + 
        ""Press Enter to continue."" + ""\n"" +
        ""End "" + name() + "".main"" + ""\n"";
    debug(goldenString, ""GOLDEN"");

    final ProcessWrapper process = createProcessWrapper(new ProcessWrapper.Builder(), getClass());
    process.execute(createProperties());
    process.waitForOutputToMatch(""Begin "" + name() + ""\\.main"");
    process.waitForOutputToMatch(""Press Enter to continue\\."");
    process.sendInput();
    process.waitForOutputToMatch(""End "" + name() + ""\\.main"");
    process.waitFor();
    
    try {
      assertOutputMatchesGoldenFile(process.getOutput(), goldenString);
      fail(""assertOutputMatchesGoldenFile should have failed due to "" + problem());
    } catch (AssertionError expected) {
      assertTrue(expected.getMessage().contains(problem()));
    }
  }",False
"  public static void main(String[] args) throws Exception {
    new FailWithSevereInOutputJUnitTest().execute();
  }",True
"  void outputProblem(String message) {
    LogWriter logWriter = new LocalLogWriter(LogWriterImpl.INFO_LEVEL);
    logWriter.severe(message);
  }",True
"    new FailWithSevereInOutputJUnitTest().executeInProcess();
  }
}
",False
"  void outputProblemInProcess(final String message) {
    new LocalLogWriter(LogWriterImpl.INFO_LEVEL).severe(message);
  }",False
"  public FailWithSevereInOutputJUnitTest() {
    super(FailWithSevereInOutputJUnitTest.class.getSimpleName());
  }",True
"  public static void main(final String[] args) throws Exception {
    new FailWithSevereInOutputJUnitTest().executeInProcess();
  }",False
"  public void testFailWithTimeoutOfWaitForOutputToMatch() throws Exception {
    // output has an extra line and should fail
    final ProcessWrapper process = createProcessWrapper(getClass());
    process.execute(createProperties());
    process.waitForOutputToMatch(""Begin "" + name() + ""\\.main"");
    try {
      process.waitForOutputToMatch(problem());
      fail(""assertOutputMatchesGoldenFile should have failed due to "" + problem());
    } catch (AssertionFailedError expected) {
      assertTrue(expected.getMessage().contains(problem()));
    }
    // the following should generate no failures if timeout and tearDown are all working properly
    assertNotNull(process);
    assertTrue(process.isAlive());
    tearDown();
    process.waitFor();
  }",True
"  public void testFailWithTimeoutOfWaitForOutputToMatch() throws Exception {
    this.process = createProcessWrapper(new ProcessWrapper.Builder().timeoutMillis(timeoutMillis), getClass());
    this.process.execute(createProperties());
    this.process.waitForOutputToMatch(""Begin "" + name() + ""\\.main"");
    
    try {
      this.process.waitForOutputToMatch(problem());
      fail(""assertOutputMatchesGoldenFile should have failed due to "" + problem());
    } catch (AssertionError expected) {
      assertTrue(expected.getMessage().contains(problem()));
    }
  }",False
"  @Override
  String problem() {
    return ""This is an extra line"";",False
"  public FailWithTimeoutOfWaitForOutputToMatchJUnitTest() {
    super(""FailWithTimeoutOfWaitForOutputToMatchJUnitTest"");
  }",True
"  
  private static final long timeoutMillis = 1000;
",False
"  public void subTearDown() throws Exception {
    this.process.waitFor();
    assertFalse(this.process.isAlive());
  }",False
"  public static void main(String[] args) throws Exception {
    new FailWithTimeoutOfWaitForOutputToMatchJUnitTest().execute();
  }",True
"  public static void main(String[] args) throws Exception {
    new FailWithTimeoutOfWaitForOutputToMatchJUnitTest().executeInProcess();
  }",False
"  public FailWithWarningInOutputJUnitTest() {
    super(FailWithWarningInOutputJUnitTest.class.getSimpleName());
  }",True
"  void outputProblemInProcess(final String message) {
    new LocalLogWriter(LogWriterImpl.INFO_LEVEL).warning(message);
  }",False
"  public static void main(String[] args) throws Exception {
    new FailWithWarningInOutputJUnitTest().execute();
  }",True
"  public static void main(final String[] args) throws Exception {
    new FailWithWarningInOutputJUnitTest().executeInProcess();
  }",False
"  void outputProblem(String message) {
    LogWriter logWriter = new LocalLogWriter(LogWriterImpl.INFO_LEVEL);
    logWriter.warning(message);
  }",True
"    new FailWithWarningInOutputJUnitTest().executeInProcess();
  }
}
",False
"  protected Reader readGoldenFile(String goldenFileName) throws IOException {
    InputStream goldenStream = ClassLoader.getSystemResourceAsStream(goldenFileName);
    assertNotNull(""Golden file "" + goldenFileName + "" not found."", goldenStream);
    return new InputStreamReader(goldenStream);
  }",True
"  
  public void assertOutputMatchesGoldenFile(final String actualOutput, final String goldenFileName) throws IOException {
    debug(""GoldenComparator:assertOutputMatchesGoldenFile"");
    final BufferedReader goldenReader = new BufferedReader(readGoldenFile(goldenFileName));
    final BufferedReader actualReader = new BufferedReader(new StringReader(actualOutput));",False
"  private List<String> readLines(BufferedReader reader) throws IOException {
    List<String> listOfLines = new ArrayList<String>();
    String line = null;
    do {
      line = reader.readLine();
      listOfLines.add(line);
    } while(line != null);
    return listOfLines;
  }",True
"  private List<String> readLines(final BufferedReader reader) throws IOException {
    final List<String> listOfLines = new ArrayList<String>();
    String line = null;
    do {
      line = reader.readLine();
      listOfLines.add(line);
    } while(line != null);
    return listOfLines;
  }",False
"  public void assertOutputMatchesGoldenFile(String actualOutput, String goldenFileName) throws IOException {
    logger.debug(GoldenTestCase.GOLDEN_TEST, ""GoldenComparator:assertOutputMatchesGoldenFile"");
    BufferedReader goldenReader = new BufferedReader(readGoldenFile(goldenFileName));
    BufferedReader actualReader = new BufferedReader(new StringReader(actualOutput));
    
    List<String> goldenStrings = readLines(goldenReader);
    List<String> actualStrings = readLines(actualReader);

    scanForProblems(actualStrings);
    
    String actualLine = null;
    String goldenLine = null;
    
    int lineCount = 0;
    do {
      lineCount++;
      logger.debug(GoldenTestCase.GOLDEN_TEST, ""GoldenComparator comparing line {}"", lineCount);

      actualLine = actualStrings.get(lineCount - 1);
      goldenLine = goldenStrings.get(lineCount - 1);
      
      //checkForProblem(lineCount, actualLine);
      if (actualLine == null && goldenLine != null) {
        fail(""EOF reached in actual output but golden file, "" + goldenFileName + "", continues at line "" + lineCount + "": "" + goldenLine + new OutputFormatter(actualStrings));
      
      } else if (actualLine != null && goldenLine == null) {
        fail(""EOF reached in golden file, "" + goldenFileName + "", but actual output continues at line "" + lineCount + "": "" + actualLine + new OutputFormatter(actualStrings));
      
      } else if (actualLine != null && goldenLine != null) {
        assertTrue(""Actual output \"""" + actualLine
            + ""\"" did not match expected pattern \"""" + goldenLine
            + ""\"" at line "" + lineCount + "" in "" + goldenFileName 
            + "": "" + new OutputFormatter(actualStrings), 
            compareLines(actualLine, goldenLine));
      }
    } while (actualLine != null && goldenLine != null);
  }",True
"  public void assertOutputMatchesGoldenFile(final String actualOutput, final String goldenFileName) throws IOException {
    debug(""GoldenComparator:assertOutputMatchesGoldenFile"");
    final BufferedReader goldenReader = new BufferedReader(readGoldenFile(goldenFileName));
    final BufferedReader actualReader = new BufferedReader(new StringReader(actualOutput));
    
    final List<String> goldenStrings = readLines(goldenReader);
    final List<String> actualStrings = readLines(actualReader);

    scanForProblems(actualStrings);
    
    String actualLine = null;
    String goldenLine = null;
    
    int lineCount = 0;
    do {
      lineCount++;
      debug(""GoldenComparator comparing line "" + lineCount);

      actualLine = actualStrings.get(lineCount - 1);
      goldenLine = goldenStrings.get(lineCount - 1);
      
      if (actualLine == null && goldenLine != null) {
        fail(""EOF reached in actual output but golden file, "" + goldenFileName + "", continues at line "" + lineCount + "": "" + goldenLine + new OutputFormatter(actualStrings));
      
      } else if (actualLine != null && goldenLine == null) {
        fail(""EOF reached in golden file, "" + goldenFileName + "", but actual output continues at line "" + lineCount + "": "" + actualLine + new OutputFormatter(actualStrings));
      
      } else if (actualLine != null && goldenLine != null) {
        assertTrue(""Actual output \"""" + actualLine + ""\"" did not match expected pattern \"""" + goldenLine + ""\"" at line "" + lineCount + "" in "" + goldenFileName + "": "" + new OutputFormatter(actualStrings), compareLines(actualLine, goldenLine));
      }
    } while (actualLine != null && goldenLine != null);
  }",False
"    final List<String> goldenStrings = readLines(goldenReader);
    final List<String> actualStrings = readLines(actualReader);

    scanForProblems(actualStrings);
    
    String actualLine = null;
    String goldenLine = null;
    
    int lineCount = 0;
    do {
      lineCount++;
      debug(""GoldenComparator comparing line "" + lineCount);

      actualLine = actualStrings.get(lineCount - 1);
      goldenLine = goldenStrings.get(lineCount - 1);
      
      if (actualLine == null && goldenLine != null) {
        fail(""EOF reached in actual output but golden file, "" + goldenFileName + "", continues at line "" + lineCount + "": "" + goldenLine + new OutputFormatter(actualStrings));
      
      } else if (actualLine != null && goldenLine == null) {
        fail(""EOF reached in golden file, "" + goldenFileName + "", but actual output continues at line "" + lineCount + "": "" + actualLine + new OutputFormatter(actualStrings));
      
      } else if (actualLine != null && goldenLine != null) {
        assertTrue(""Actual output \"""" + actualLine + ""\"" did not match expected pattern \"""" + goldenLine + ""\"" at line "" + lineCount + "" in "" + goldenFileName + "": "" + new OutputFormatter(actualStrings), compareLines(actualLine, goldenLine));
      }
    } while (actualLine != null && goldenLine != null);
  }
  
  /**
   * Returns true if the line matches and is ok. Otherwise returns false.
   */
  protected abstract boolean compareLines(final String actualLine, final String goldenLine);
  
  private List<String> readLines(final BufferedReader reader) throws IOException {
    final List<String> listOfLines = new ArrayList<String>();
    String line = null;
    do {",False
"  private void scanForProblems(List<String> lines) throws IOException {
    logger.debug(GoldenTestCase.GOLDEN_TEST, ""GoldenComparator:scanForProblems"");
    int lineCount = 0;
    for (String line : lines) {
      lineCount++;
      logger.debug(GoldenTestCase.GOLDEN_TEST, ""GoldenComparator:scanForProblems scanning line {}"", lineCount);
      checkForProblem(lineCount, line);
    }
  }",True
"  private void checkForProblem(final int lineCount, final String line) {
    if (line == null) {
      return;
    }
    checkLineFor(lineCount, line, ""warning"");
    checkLineFor(lineCount, line, ""warn"");
    checkLineFor(lineCount, line, ""error"");
    checkLineFor(lineCount, line, ""fatal"");
    checkLineFor(lineCount, line, ""severe"");",False
"  protected static void debug(final String string) {
    GoldenTestCase.debug(string);
  }",False
"  private void checkForProblem(int lineCount, String line) {
    if (line == null) {
      return;
    }
    checkLineFor(lineCount, line, ""warning"");
    checkLineFor(lineCount, line, ""warn"");
    checkLineFor(lineCount, line, ""error"");
    checkLineFor(lineCount, line, ""fatal"");
    checkLineFor(lineCount, line, ""severe"");
  }",True
"  
  private void checkLineFor(final int lineCount, final String line, final String problem) {
    if (line != null && line.toLowerCase().contains(problem)) {
      if (this.expectedProblemLines != null && this.expectedProblemLines.length > 0) {
        for (int i = 0; i < this.expectedProblemLines.length; i++) {
          debug(""Comparing \"" + line + \"" against expected \"" + this.expectedProblemLines[i] + \"""");
          if (compareLines(line, this.expectedProblemLines[i])) {
            return;
          }
        }",False
"  private void scanForProblems(final List<String> lines) throws IOException {
    debug(""GoldenComparator:scanForProblems"");
    int lineCount = 0;
    for (String line : lines) {
      lineCount++;
      debug(""GoldenComparator:scanForProblems scanning line "" + lineCount);
      checkForProblem(lineCount, line);
    }
  }",False
"  protected GoldenComparator(String[] expectedProblemLines) {
    this.expectedProblemLines = expectedProblemLines;
  }",True
"    final InputStream goldenStream = ClassLoader.getSystemResourceAsStream(goldenFileName);
    assertNotNull(""Golden file "" + goldenFileName + "" not found."", goldenStream);
    return new InputStreamReader(goldenStream);",False
"  private void checkLineFor(int lineCount, String line, String problem) {
    if (line != null && line.toLowerCase().contains(problem)) {
      if (this.expectedProblemLines != null && this.expectedProblemLines.length > 0) {
        for (int i = 0; i < this.expectedProblemLines.length; i++) {
          logger.debug(GoldenTestCase.GOLDEN_TEST, ""Comparing \""{}\"" against expected \""{}\"""", line, this.expectedProblemLines[i]);
          if (compareLines(line, this.expectedProblemLines[i])) {
            return;
          }
        }
      }
      // TODO: collect up entire stack trace if there is one (might span multiple lines)
      logger.debug(GoldenTestCase.GOLDEN_TEST, ""About to fail because of {}"", line);
      fail(""Actual output contains a problem (warning/error/severe) on line "" + lineCount + "": "" + line);
    }
  }",True
"  private void checkLineFor(final int lineCount, final String line, final String problem) {
    if (line != null && line.toLowerCase().contains(problem)) {
      if (this.expectedProblemLines != null && this.expectedProblemLines.length > 0) {
        for (int i = 0; i < this.expectedProblemLines.length; i++) {
          debug(""Comparing \"" + line + \"" against expected \"" + this.expectedProblemLines[i] + \"""");
          if (compareLines(line, this.expectedProblemLines[i])) {
            return;
          }
        }
      }
      // TODO: collect up entire stack trace if there is one (might span multiple lines)
      debug(""About to fail because of "" + line);
      fail(""Actual output contains a problem (warning/error/severe) on line "" + lineCount + "": "" + line);
    }
  }",False
"  protected GoldenComparator(final String[] expectedProblemLines) {
    this.expectedProblemLines = expectedProblemLines;
  }",False
"      // TODO: collect up entire stack trace if there is one (might span multiple lines)
      debug(""About to fail because of "" + line);
      fail(""Actual output contains a problem (warning/error/severe) on line "" + lineCount + "": "" + line);
    }
  }

  protected static void debug(final String string) {
    GoldenTestCase.debug(string);
  }
}
",False
"  private void checkForProblem(final int lineCount, final String line) {
    if (line == null) {
      return;
    }
    checkLineFor(lineCount, line, ""warning"");
    checkLineFor(lineCount, line, ""warn"");
    checkLineFor(lineCount, line, ""error"");
    checkLineFor(lineCount, line, ""fatal"");
    checkLineFor(lineCount, line, ""severe"");
  }",False
"  protected Reader readGoldenFile(final String goldenFileName) throws IOException {
    final InputStream goldenStream = ClassLoader.getSystemResourceAsStream(goldenFileName);
    assertNotNull(""Golden file "" + goldenFileName + "" not found."", goldenStream);
    return new InputStreamReader(goldenStream);
  }",False
"  protected Reader readGoldenFile(String goldenFileName) throws IOException {
    return new StringReader(goldenFileName);
  }",True
"  protected Reader readGoldenFile(final String goldenFileName) throws IOException {
    return new StringReader(goldenFileName);
  }",False
"  protected GoldenStringComparator(String[] expectedProblemLines) {
    super(expectedProblemLines);
  }",True
"  protected GoldenStringComparator(final String[] expectedProblemLines) {
    super(expectedProblemLines);
  }",False
"  @Override
  protected Reader readGoldenFile(final String goldenFileName) throws IOException {
    return new StringReader(goldenFileName);",False
"  protected final void sleep(long millis) throws InterruptedException {
    Thread.sleep(millis);
  }",True
"  protected final ProcessWrapper createProcessWrapper(Class<?> main) {
    final ProcessWrapper processWrapper = new ProcessWrapper.Builder().jvmArgs(jvmArgs).main(main).build();
    this.processes.add(processWrapper);
    return processWrapper;
  }",True
"  protected final void assertOutputMatchesGoldenFile(final ProcessWrapper process, final String goldenFileName) throws IOException {
    GoldenComparator comparator = createGoldenComparator();
    comparator.assertOutputMatchesGoldenFile(process.getOutput(), goldenFileName);
  }
",False
"  public GoldenTestCase(String name) {
    super(name);
  }",True
"      this.processes.clear();
    }
    subTearDown();",False
"  protected void assertOutputMatchesGoldenFile(String actualOutput, String goldenFileName) throws IOException {
    GoldenComparator comparator = createGoldenComparator();
    comparator.assertOutputMatchesGoldenFile(actualOutput, goldenFileName);
  }",True
"  protected void assertOutputMatchesGoldenFile(final String actualOutput, final String goldenFileName) throws IOException {
    GoldenComparator comparator = createGoldenComparator();
    comparator.assertOutputMatchesGoldenFile(actualOutput, goldenFileName);
  }",False
"  public final void setUpGoldenTest() throws Exception {
    subSetUp();
  }",False
"  protected final Properties createProperties() {
    Properties properties = new Properties();
    properties.setProperty(""gemfire.mcast-port"", String.valueOf(this.mcastPort));
    properties.setProperty(""gemfire.log-level"", ""warning"");
    properties.setProperty(""file.encoding"", ""UTF-8"");
    return editProperties(properties);
  }",True
"  protected final Properties createProperties() {
    Properties properties = new Properties();
    properties.setProperty(""gemfire.mcast-port"", ""0"");
    properties.setProperty(""gemfire.log-level"", ""warning"");
    properties.setProperty(""file.encoding"", ""UTF-8"");
    return editProperties(properties);
  }",False
"  protected final void innerPrintOutput(String output, String title) {
    System.out.println(""------------------ BEGIN "" + title + "" ------------------"");
    System.out.println(output);
    System.out.println(""------------------- END "" + title + "" -------------------"");
  }",True
"  protected final int getMcastPort() {
    return this.mcastPort;
  }",True
"  public final void tearDown() throws Exception {
    super.tearDown();
    try {
      for (ProcessWrapper process : this.processes) {
        process.destroy();
        printProcessOutput(process, true);
      }
    } finally {
      this.processes.clear();
    }
    subTearDown();
  }",True
"    // override me
  }
  
  /**
   * Override this for additional tear down after destroying all processes and
   * printing output.
   * 
   * @throws Exception
   */
  public void subTearDown() throws Exception {
    // override me
  }",False
"   * 
   *(see PartitionedRegionTest which expects a WARNING log message) 
   */
  protected String[] expectedProblemLines() {
    return null;",False
"  }
  
  protected static void debug(final String output, final String title) {
    debug(""------------------ BEGIN "" + title + "" ------------------"");",False
"  protected final void printProcessOutput(ProcessWrapper process) {
    innerPrintOutput(process.getOutput(), ""OUTPUT"");
  }",True
"  protected final void printProcessOutput(final ProcessWrapper process, final boolean ignoreStopped) {
    debug(process.getOutput(ignoreStopped), ""OUTPUT"");
  }",False
"  
  protected void assertOutputMatchesGoldenFile(final String actualOutput, final String goldenFileName) throws IOException {
    GoldenComparator comparator = createGoldenComparator();
    comparator.assertOutputMatchesGoldenFile(actualOutput, goldenFileName);
  }",False
"  protected static void debug(final String string) {
    if (DEBUG) {
      System.out.println(string);
    }
  }",False
"  public final void tearDownGoldenTest() throws Exception {
    try {
      for (ProcessWrapper process : this.processes) {
        process.destroy();
        printProcessOutput(process, true);
      }
    } finally {
      this.processes.clear();
    }
    subTearDown();
  }",False
"  protected final ProcessWrapper createProcessWrapper(final ProcessWrapper.Builder processWrapperBuilder, final Class<?> main) {
    final ProcessWrapper processWrapper = processWrapperBuilder.jvmArguments(JVM_ARGS).mainClass(main).build();
    this.processes.add(processWrapper);
    return processWrapper;
  }",False
"  protected static void debug(final String output, final String title) {
    debug(""------------------ BEGIN "" + title + "" ------------------"");
    debug(output);
    debug(""------------------- END "" + title + "" -------------------"");
  }",False
"  public final void setUp() throws Exception {
    super.setUp();
    subSetUp();
  }",True
"  /**
   * Override this for additional set up.
   * 
   * @throws Exception",False
"    debug(""------------------- END "" + title + "" -------------------"");
  }
  
  protected static void debug(final String string) {",False
"  protected final void assertOutputMatchesGoldenFile(final ProcessWrapper process, final String goldenFileName) throws IOException {
    GoldenComparator comparator = createGoldenComparator();
    comparator.assertOutputMatchesGoldenFile(process.getOutput(), goldenFileName);
  }",False
"    if (configUrl != null) {
      System.setProperty(ConfigurationFactory.CONFIGURATION_FILE_PROPERTY, configUrl.toString());
    }",True
"  
  @After
  public final void tearDownGoldenTest() throws Exception {",False
"  protected final void outputLine(final String string) {
    System.out.println(string);
  }",False
"  void execute() throws IOException {
    System.out.println(""Begin "" + name() + "".main"");
    System.out.println(""Press Enter to continue."");
    BufferedReader inputReader = new BufferedReader(new InputStreamReader(System.in));
    inputReader.readLine();
    System.out.println(""End "" + name() + "".main"");
  }",True
"    assertFalse(process.getStandardOutReader().isAlive());
    assertFalse(process.getStandardErrorReader().isAlive());
  }

  @Override
  public final void executeInProcess() throws IOException {
    outputLine(""Begin "" + name() + "".main"");",False
"  public static void main(String[] args) throws Exception {
    new PassJUnitTest().execute();
  }",True
"    new BufferedReader(new InputStreamReader(System.in)).readLine();
    outputLine(""End "" + name() + "".main"");
  }",False
"  public PassJUnitTest() {
    super(""PassJUnitTest"");
  }",True
"@Category(IntegrationTest.class)
public class PassJUnitTest extends GoldenTestCase implements ExecutableProcess {
  ",False
"  public final void executeInProcess() throws IOException {
    outputLine(""Begin "" + name() + "".main"");
    outputLine(""Press Enter to continue."");
    new BufferedReader(new InputStreamReader(System.in)).readLine();
    outputLine(""End "" + name() + "".main"");
  }",False
"  public void testPass() throws InterruptedException, IOException {
    // output has no problems and should pass
    final ProcessWrapper process = createProcessWrapper(getClass());
    process.execute(createProperties());
    assertTrue(process.isAlive());
    process.waitForOutputToMatch(""Begin "" + name() + ""\\.main"");
    process.waitForOutputToMatch(""Press Enter to continue\\."");
    process.sendInput();
    process.waitForOutputToMatch(""End "" + name() + ""\\.main"");
    process.waitFor();
    String goldenString = ""Begin "" + name() + "".main"" + ""\n"" 
        + ""Press Enter to continue."" + ""\n"" 
        + ""End "" + name() + "".main"" + ""\n"";
    assertOutputMatchesGoldenFile(process, goldenString);

    assertFalse(process.isAlive());
    //assertFalse(process.getOutputReader());
    assertFalse(process.getStandardOutReader().isAlive());
    assertFalse(process.getStandardErrorReader().isAlive());
  }",True
"  public void testPass() throws Exception {
    final String goldenString = 
        ""Begin "" + name() + "".main"" + ""\n"" + 
        ""Press Enter to continue."" + ""\n"" +
        ""End "" + name() + "".main"" + ""\n"";
    
    final ProcessWrapper process = createProcessWrapper(new ProcessWrapper.Builder(), getClass());
    process.execute(createProperties());
    assertTrue(process.isAlive());
    
    process.waitForOutputToMatch(""Begin "" + name() + ""\\.main"");
    process.waitForOutputToMatch(""Press Enter to continue\\."");
    process.sendInput();
    process.waitForOutputToMatch(""End "" + name() + ""\\.main"");
    process.waitFor();
    
    assertOutputMatchesGoldenFile(process, goldenString);
    assertFalse(process.isAlive());
    assertFalse(process.getStandardOutReader().isAlive());
    assertFalse(process.getStandardErrorReader().isAlive());
  }",False
"  public static void main(final String[] args) throws Exception {
    new PassJUnitTest().executeInProcess();
  }",False
"  public static void main(String[] args) throws Exception {
    new PassWithExpectedErrorJUnitTest().execute();
  }",True
"  public static void main(final String[] args) throws Exception {
    new PassWithExpectedErrorJUnitTest().executeInProcess();
  }",False
"    new PassWithExpectedErrorJUnitTest().executeInProcess();
  }
}
",False
"  public PassWithExpectedErrorJUnitTest() {
    super(""PassWithExpectedErrorJUnitTest"");
  }",True
"  String problem() {
    return ""error"";
  }",False
"  protected String[] expectedProblemLines() {
    return new String[] { "".*"" + name() + "".*"", ""^\\["" + problem() + "".*\\] ExpectedStrings: This is an expected problem in the output"" };
  }",True
"  protected String[] expectedProblemLines() {
    this.problemLine = 1; 
    return new String[] { 
        "".*"" + name() + "".*"", 
        ""^\\["" + problem() + "".*\\] ExpectedStrings: This is an expected problem in the output"" 
    };
  }",False
"  void execute() throws IOException {
    System.out.println(""Begin "" + name() + "".main"");
    System.out.println(""Press Enter to continue."");
    BufferedReader inputReader = new BufferedReader(new InputStreamReader(System.in));
    inputReader.readLine();
    outputProblem(""ExpectedStrings: This is an expected problem in the output"");
    System.out.println(""End "" + name() + "".main"");
  }",True
"    process.waitForOutputToMatch(""End "" + name() + ""\\.main"");
    process.waitFor();
    
    assertOutputMatchesGoldenFile(process.getOutput(), goldenString);
  }
  
  @Override
  public final void executeInProcess() throws IOException {",False
"  public final void executeInProcess() throws IOException {
    outputLine(""Begin "" + name() + "".main"");
    outputLine(""Press Enter to continue."");
    new BufferedReader(new InputStreamReader(System.in)).readLine();
    outputProblemInProcess(""ExpectedStrings: This is an expected problem in the output"");
    outputLine(""End "" + name() + "".main"");
  }",False
"  public void testPassWithExpectedProblem() throws InterruptedException, IOException {
    // output has an expected warning/error/severe message and should pass
    final ProcessWrapper process = createProcessWrapper(getClass());
    process.execute(createProperties());
    process.waitForOutputToMatch(""Begin "" + name() + ""\\.main"");
    process.waitForOutputToMatch(""Press Enter to continue\\."");
    process.sendInput();
    process.waitForOutputToMatch(""End "" + name() + ""\\.main"");
    process.waitFor();
    String goldenString = ""Begin "" + name() + "".main"" + ""\n"" 
        + ""Press Enter to continue."" + ""\n"" 
        + ""\n""
        + ""^\\["" + problem() + "".*\\] ExpectedStrings: This is an expected problem in the output"" + ""\n""
        + ""End "" + name() + "".main"" + ""\n"";
    innerPrintOutput(goldenString, ""GOLDEN"");
    String[] printMe = expectedProblemLines();
    for (String str : printMe) {
      System.out.println(str);
    }
    assertOutputMatchesGoldenFile(process.getOutput(), goldenString);
  }",True
"  public void testPassWithExpectedProblem() throws Exception {
    final String goldenString = 
        ""Begin "" + name() + "".main"" + ""\n"" + 
        ""Press Enter to continue."" + ""\n"" +
        ""\n"" +
        expectedProblemLines()[this.problemLine] + ""\n"" +
        ""End "" + name() + "".main"" + ""\n"";
    debug(goldenString, ""GOLDEN"");

    final ProcessWrapper process = createProcessWrapper(new ProcessWrapper.Builder(), getClass());
    process.execute(createProperties());
    process.waitForOutputToMatch(""Begin "" + name() + ""\\.main"");
    process.waitForOutputToMatch(""Press Enter to continue\\."");
    process.sendInput();
    process.waitForOutputToMatch(""End "" + name() + ""\\.main"");
    process.waitFor();
    
    assertOutputMatchesGoldenFile(process.getOutput(), goldenString);
  }",False
"  PassWithExpectedProblemTestCase(String name) {
    super(name);
  }",True
"public abstract class PassWithExpectedProblemTestCase extends GoldenTestCase implements ExecutableProcess {

  private int problemLine; ",False
"  public static void main(String[] args) throws Exception {
    new PassWithExpectedSevereJUnitTest().execute();
  }",True
"  public static void main(final String[] args) throws Exception {
    new PassWithExpectedSevereJUnitTest().executeInProcess();
  }",False
"    new PassWithExpectedSevereJUnitTest().executeInProcess();
  }
}
",False
"  public PassWithExpectedSevereJUnitTest() {
    super(""PassWithExpectedSevereJUnitTest"");
  }",True
"  String problem() {
    return ""severe"";
  }",False
"  public PassWithExpectedWarningJUnitTest() {
    super(""PassWithExpectedWarningJUnitTest"");
  }",True
"  String problem() {
    return ""warning"";
  }",False
"  public static void main(String[] args) throws Exception {
    new PassWithExpectedWarningJUnitTest().execute();
  }",True
"  public static void main(final String[] args) throws Exception {
    new PassWithExpectedWarningJUnitTest().executeInProcess();
  }",False
"    new PassWithExpectedWarningJUnitTest().executeInProcess();
  }
}
",False
"  protected RegexGoldenComparator(String[] expectedProblemLines) {
    super(expectedProblemLines);
  }",True
"    super(expectedProblemLines);
  }
  ",False
"  protected boolean compareLines(String actualLine, String goldenLine) {
    logger.debug(GoldenTestCase.GOLDEN_TEST, ""RegexGoldenComparator:compareLines comparing \""{}\"" to \""{}\"""", actualLine, goldenLine);
    Matcher matcher = Pattern.compile(goldenLine).matcher(actualLine);
    return matcher.matches();
  }",True
"  protected boolean compareLines(final String actualLine, final String goldenLine) {
    debug(""RegexGoldenComparator:compareLines comparing \"" + actualLine + \"" to \"" + goldenLine + \"""");
    return Pattern.compile(goldenLine).matcher(actualLine).matches();
  }",False
"  protected RegexGoldenComparator(final String[] expectedProblemLines) {
    super(expectedProblemLines);
  }",False
"    debug(""RegexGoldenComparator:compareLines comparing \"" + actualLine + \"" to \"" + goldenLine + \"""");
    return Pattern.compile(goldenLine).matcher(actualLine).matches();
  }
}
",False
"  protected StringGoldenComparator(String[] expectedProblemLines) {
    super(expectedProblemLines);
  }",True
"  protected StringGoldenComparator(final String[] expectedProblemLines) {
    super(expectedProblemLines);
  }",False
"  protected boolean compareLines(String actualLine, String goldenLine) {
    if (actualLine == null) {
      return goldenLine == null;
    }
    return actualLine.equals(goldenLine);
  }",True
"  protected boolean compareLines(final String actualLine, final String goldenLine) {
    if (actualLine == null) {
      return goldenLine == null;
    }
    return actualLine.equals(goldenLine);
  }",False
"  private void exec(Properties dsProps, final File workingDirectory) {
    List<String> vmArgList = new ArrayList<String>();

    if (dsProps != null) {
      for (Map.Entry<Object, Object> entry : dsProps.entrySet()) {
        if (!entry.getKey().equals(""log-file"")) {
          vmArgList.add(""-D"" + entry.getKey() + ""="" + entry.getValue());
        }
      }
    }

    if (JAVA_AWT_HEADLESS) {
      vmArgList.add(""-Djava.awt.headless=true"");
    }
    
    if (this.jvmArgs != null) {
      for (String vmArg: this.jvmArgs) {
        vmArgList.add(vmArg);
      }
    }
    
    String[] vmArgs = vmArgList.toArray(new String[vmArgList.size()]);

    try {
      synchronized (this.exitValue) {
        String[] command = defineCommand(vmArgs);
        this.process = new ProcessBuilder(command).directory(workingDirectory).start();
        
        StringBuilder processCommand = new StringBuilder();
        boolean addSpace = false;
        for (String string : command) {
          if (addSpace) {
            processCommand.append("" "");
          }
          processCommand.append(string);
          addSpace = true;
        }
        String commandString = processCommand.toString();
        System.out.println(""Executing "" + commandString);
        final ProcessStreamReader stdOut = new ProcessStreamReader(commandString, this.process.getInputStream(), this.lineBuffer, this.allLines);
        final ProcessStreamReader stdErr = new ProcessStreamReader(commandString, this.process.getErrorStream(), this.lineBuffer, this.allLines);
  
        this.stdout = stdOut;
        this.stderr = stdErr;
  
        this.outputReader = new ProcessOutputReader(this.process, stdOut, stdErr, this.allLines);
      
        this.started = true;
      }
      
      this.outputReader.waitFor();
      int code = this.process.waitFor();
      
      synchronized (this.exitValue) {
        this.exitValue.set(code);
        this.stopped = true;
      }
      
    } catch (InterruptedException e) {
      synchronized (this.exitValue) {
        this.interrupted = true;
        this.processException = e;
      }
    } catch (Throwable t) {
      synchronized (this.exitValue) {
        this.processException = t;
      }
    }
  }",True
"
    if (this.headless) {
      jvmArgumentsList.add(""-Djava.awt.headless=true"");
    }
    
    if (this.jvmArguments != null) {
      for (String jvmArgument: this.jvmArguments) {
        jvmArgumentsList.add(jvmArgument);
      }
    }
    
    try {
      synchronized (this.exitValue) {
        final String[] command = defineCommand(jvmArgumentsList.toArray(new String[jvmArgumentsList.size()]));
        this.process = new ProcessBuilder(command).directory(workingDirectory).start();
        
        final StringBuilder processCommand = new StringBuilder();
        boolean addSpace = false;
        
        for (String string : command) {
          if (addSpace) {
            processCommand.append("" "");
          }
          processCommand.append(string);
          addSpace = true;
        }
        
        final String commandString = processCommand.toString();
        logger.debug(""Starting "" + commandString);
        
        final ProcessStreamReader stdOut = new ProcessStreamReader(commandString, this.process.getInputStream(), this.lineBuffer, this.allLines);
        final ProcessStreamReader stdErr = new ProcessStreamReader(commandString, this.process.getErrorStream(), this.lineBuffer, this.allLines);
  
        this.stdout = stdOut;
        this.stderr = stdErr;
        this.outputReader = new ProcessOutputReader(this.process, stdOut, stdErr, this.allLines);
        this.started = true;
      }
      
      this.outputReader.waitFor();
      int code = this.process.waitFor();
      
      synchronized (this.exitValue) {
        this.exitValue.set(code);
        this.stopped = true;
      }
      
    } catch (InterruptedException e) {
      synchronized (this.exitValue) {
        this.interrupted = true;
        this.processException = e;
      }
    } catch (Throwable t) {
      synchronized (this.exitValue) {
        this.processException = t;
      }
    }
  }
  
  private String[] defineCommand(final String[] jvmArguments) {
    final File javaBinDir = new File(System.getProperty(""java.home""), ""bin"");
    final File javaExe = new File(javaBinDir, ""java"");

    final List<String> argumentList = new ArrayList<String>();
    argumentList.add(javaExe.getPath());
    argumentList.add(""-classpath"");
    argumentList.add(System.getProperty(""java.class.path""));

    // -d64 is not a valid option for windows and results in failure",False
"    public Builder headless(final boolean headless) {
      this.headless = headless;
      return this;
    }",False
"    public ProcessWrapper build() {
      return new ProcessWrapper(jvmArgs, main, mainArgs, useMainLauncher);
    }",True
"    public ProcessWrapper build() {
      return new ProcessWrapper(jvmArguments, mainClass, mainArguments, useMainLauncher, headless, timeoutMillis);
    }",False
"  private String[] defineCommand(String[] vmArgs) {
    File javabindir = new File(System.getProperty(""java.home""), ""bin"");
    File javaexe = new File(javabindir, ""java"");

    List<String> argList = new ArrayList<String>();
    argList.add(javaexe.getPath());
    argList.add(""-classpath"");
    argList.add(System.getProperty(""java.class.path""));

    // -d64 is not a valid option for windows and results in failure
    int bits = Integer.getInteger(""sun.arch.data.model"", 0).intValue();
    if (bits == 64 && !(System.getProperty(""os.name"").toLowerCase().contains(""windows""))) {
      argList.add(""-d64"");
    }

    argList.add(""-Djava.library.path="" + System.getProperty(""java.library.path""));

    if (vmArgs != null) {
      argList.addAll(Arrays.asList(vmArgs));
    }

    if (this.useMainLauncher) {
      argList.add(MainLauncher.class.getName());
    }
    argList.add(mainClass.getName());
    
    if (mainArgs != null) {
      argList.addAll(Arrays.asList(mainArgs));
    }

    String[] cmd = argList.toArray(new String[argList.size()]);
    return cmd;
  }",True
"    if (bits == 64 && !(System.getProperty(""os.name"").toLowerCase().contains(""windows""))) {
      argumentList.add(""-d64"");
    }

    argumentList.add(""-Djava.library.path="" + System.getProperty(""java.library.path""));

    if (jvmArguments != null) {
      argumentList.addAll(Arrays.asList(jvmArguments));
    }

    if (this.useMainLauncher) {
      argumentList.add(MainLauncher.class.getName());
    }
    argumentList.add(mainClass.getName());
    
    if (mainArguments != null) {
      argumentList.addAll(Arrays.asList(mainArguments));
    }

    final String[] command = argumentList.toArray(new String[argumentList.size()]);
    return command;
  }
  
  private void checkStarting() throws IllegalStateException {
    synchronized (this.exitValue) {
      if (!this.starting) {
        throw new IllegalStateException(""Process has not been launched"");
      }
    }
  }
  
  private void checkStopped() throws IllegalStateException {
    synchronized (this.exitValue) {",False
"  private void waitForProcessStart() throws InterruptedException {
    long start = System.currentTimeMillis();
    boolean done = false;
    while (!done) {
      synchronized (this.exitValue) {
        done = (this.process != null || this.processException != null) && 
            (this.started || this.exitValue.get() > -1 || this.interrupted);
      }
      if (!done && System.currentTimeMillis() > start + TIMEOUT_MILLIS) {
        fail(""Timed out launching process"");
      }
      Thread.sleep(100);
    }
  }",True
"  private void waitForProcessStart() throws InterruptedException, TimeoutException {
    final long start = System.currentTimeMillis();
    boolean done = false;
    while (!done) {
      synchronized (this.exitValue) {
        done = (this.process != null || this.processException != null) && (this.started || this.exitValue.get() > -1 || this.interrupted);
      }
      if (!done && System.currentTimeMillis() > start + timeoutMillis) {
        throw new TimeoutException(""Timed out launching process"");
      }
      Thread.sleep(DELAY);
    }
  }",False
"  public ProcessWrapper execute() throws InterruptedException {
    return execute(null, new File(System.getProperty(""user.dir"")));
  }",True
"      this.processThread = new Thread(new Runnable() {
        public void run() {
          start(properties, workingDirectory);",False
"  public ProcessWrapper sendInput() {
    checkStarting();
    sendInput("""");
    return this;
  }",True
"  public ProcessWrapper sendInput(final String input) {
    checkStarting();
    final PrintStream ps = new PrintStream(this.process.getOutputStream());
    ps.println(input);
    ps.flush();
    return this;
  }",False
"  public int waitFor(long timeout, boolean throwOnTimeout) throws InterruptedException {
    checkStarting();
    Thread thread = getThread();
    thread.join(timeout);
    synchronized (this.exitValue) {
      if (throwOnTimeout) {
        checkStopped();
      }
      return this.exitValue.get();
    }
  }",True
"  public int waitFor(final long timeout) throws InterruptedException {
    return waitFor(timeout, false);
  }",False
"  public ProcessWrapper(Class<?> main, String[] mainArgs) {
    this(main, mainArgs, true);
  }",True
"    
    this.lineBuffer = new LinkedBlockingQueue<String>();
    this.allLines = Collections.synchronizedList(new ArrayList<String>());
  }
  
  public ProcessStreamReader getStandardOutReader() {
    synchronized (this.exitValue) {
      return stdout;
    }
  }
  ",False
"  private String[] defineCommand(final String[] jvmArguments) {
    final File javaBinDir = new File(System.getProperty(""java.home""), ""bin"");
    final File javaExe = new File(javaBinDir, ""java"");

    final List<String> argumentList = new ArrayList<String>();
    argumentList.add(javaExe.getPath());
    argumentList.add(""-classpath"");
    argumentList.add(System.getProperty(""java.class.path""));

    // -d64 is not a valid option for windows and results in failure
    final int bits = Integer.getInteger(""sun.arch.data.model"", 0).intValue();
    if (bits == 64 && !(System.getProperty(""os.name"").toLowerCase().contains(""windows""))) {
      argumentList.add(""-d64"");
    }

    argumentList.add(""-Djava.library.path="" + System.getProperty(""java.library.path""));

    if (jvmArguments != null) {
      argumentList.addAll(Arrays.asList(jvmArguments));
    }

    if (this.useMainLauncher) {
      argumentList.add(MainLauncher.class.getName());
    }
    argumentList.add(mainClass.getName());
    
    if (mainArguments != null) {
      argumentList.addAll(Arrays.asList(mainArguments));
    }

    final String[] command = argumentList.toArray(new String[argumentList.size()]);
    return command;
  }",False
"  public int waitFor() throws InterruptedException {
    return waitFor(timeoutMillis, false);
  }",False
"  private ProcessWrapper(final String[] jvmArguments, final Class<?> mainClass, final String[] mainArguments, final boolean useMainLauncher, final boolean headless, final long timeoutMillis) {
    this.jvmArguments = jvmArguments;
    this.mainClass = mainClass;
    this.mainArguments = mainArguments;
    this.useMainLauncher = useMainLauncher;
    this.headless = headless;
    this.timeoutMillis = timeoutMillis;
    
    this.lineBuffer = new LinkedBlockingQueue<String>();
    this.allLines = Collections.synchronizedList(new ArrayList<String>());
  }",False
"  public String getOutput() { 
    return getOutput(false);
  }",True
"      sb.append(iterator.next() + ""\n"");
    }
    return sb.toString();
  }

  public ProcessWrapper sendInput() {
    checkStarting();
    sendInput("""");
    return this;
  }

  public ProcessWrapper sendInput(final String input) {",False
"  public String getOutput() { 
    return getOutput(false);
  }",False
"  public ProcessWrapper execute() throws InterruptedException, TimeoutException {
    return execute(null, new File(System.getProperty(""user.dir"")));
  }",False
"    public Builder main(Class<?> main) { 
      this.main = main;
      return this;
    }",True
"    }
    public Builder inline(final boolean inline) {
      this.inline = inline;
      return this;",False
"  public ProcessWrapper execute(final Properties properties) throws InterruptedException, TimeoutException {
    return execute(properties, new File(System.getProperty(""user.dir"")));
  }",False
"  public ProcessWrapper execute(final Properties properties, final File workingDirectory) throws InterruptedException, TimeoutException {
    synchronized (this.exitValue) {
      if (this.starting) {
        throw new IllegalStateException(""ProcessWrapper can only be executed once"");
      }
      this.starting = true;
      this.processThread = new Thread(new Runnable() {
        public void run() {
          start(properties, workingDirectory);
        }
      }, ""ProcessWrapper Process Thread"");
    }
    this.processThread.start();

    waitForProcessStart();

    synchronized (this.exitValue) {
      if (this.processException != null) {
        logger.error(""ProcessWrapper:execute failed with "" + this.processException);
        this.processException.printStackTrace();
      }
    }

    if (this.useMainLauncher) {
      sendInput(); // to trigger MainLauncher delegation to inner main
    }
    return this;
  }",False
"    public Builder inline(final boolean inline) {
      this.inline = inline;
      return this;
    }",False
"  public int waitFor(final long timeout, final boolean throwOnTimeout) throws InterruptedException {
    checkStarting();
    final Thread thread = getThread();
    thread.join(timeout);
    synchronized (this.exitValue) {
      if (throwOnTimeout) {
        checkStopped();
      }
      return this.exitValue.get();
    }
  }",False
"  public ProcessWrapper waitForOutputToMatch(String patternString, long timeoutMillis) throws InterruptedException {
    checkStarting();
    checkOk();

    Pattern pattern = Pattern.compile(patternString);
    
    logger.debug(""ProcessWrapper:waitForOutputToMatch waiting for \""{}\""..."", patternString);
    while(true) {
      String line = this.lineBuffer.poll(timeoutMillis, TimeUnit.MILLISECONDS);

      if (line == null) {
        fail(""Timed out waiting for output \"""" + patternString + ""\"" after "" + TIMEOUT_MILLIS + "" ms. Output: "" + new OutputFormatter(this.allLines));
      }
      
      if (pattern.matcher(line).matches()) {
        logger.debug(""ProcessWrapper:waitForOutputToMatch Matched pattern \""{}\"" against output \""{}\"""", patternString, line);
        break;
      } else {
        logger.debug(""ProcessWrapper:waitForOutputToMatch Did not match pattern \""{}\"" against output \""{}\"""", patternString, line);
      }
    }
    return this;
  }",True
"  }
  
  public ProcessWrapper execute(final Properties properties, final File workingDirectory) throws InterruptedException, TimeoutException {",False
"  private String toString(String[] strings) {
    if (strings == null || strings.length < 1) {
      return null;
    }
    StringBuilder sb = new StringBuilder();
    for (String string : strings) {
      sb.append(string).append(""\n"");
    }
    return sb.toString();
  }",True
"        throw new IllegalStateException(""Process has not stopped"");
      }
    }
  }
  
  private void checkOk() throws RuntimeException {
    if (this.processException != null) {
      throw new RuntimeException(""Failed to launch process"", this.processException);
    }
  }",False
"  public ProcessWrapper failIfOutputMatches(String patternString, long timeoutMillis) throws InterruptedException {
    checkStarting();
    checkOk();

    Pattern pattern = Pattern.compile(patternString);
    
    logger.debug(""failIfOutputMatches waiting for \""{}\""..."", patternString);
    long start = System.currentTimeMillis();
    while(System.currentTimeMillis() <= start+timeoutMillis) {
      String line = lineBuffer.poll(timeoutMillis, TimeUnit.MILLISECONDS);

      if (line != null && pattern.matcher(line).matches()) {
        fail(""failIfOutputMatches Matched pattern \"""" + patternString + ""\"" against output \"""" + line + ""\"". Output: "" + this.allLines);
      }
    }
    return this;
  }",True
"  public ProcessWrapper failIfOutputMatches(final String patternString, final long timeoutMillis) throws InterruptedException {
    checkStarting();
    checkOk();
    
    final Pattern pattern = Pattern.compile(patternString);
    logger.debug(""failIfOutputMatches waiting for \""{}\""..."", patternString);
    final long start = System.currentTimeMillis();
    
    while(System.currentTimeMillis() <= start+timeoutMillis) {
      final String line = lineBuffer.poll(timeoutMillis, TimeUnit.MILLISECONDS);
      if (line != null && pattern.matcher(line).matches()) {
        fail(""failIfOutputMatches Matched pattern \"""" + patternString + ""\"" against output \"""" + line + ""\"". Output: "" + this.allLines);
      }
    }
    return this;
  }",False
"    public Builder useMainLauncher(boolean useMainLauncher) {
      this.useMainLauncher = useMainLauncher;
      return this;
    }",True
"  public ProcessWrapper waitForOutputToMatch(final String patternString) throws InterruptedException {
    return waitForOutputToMatch(patternString, timeoutMillis);
  }",False
"    public Builder mainClass(final Class<?> mainClass) { 
      this.mainClass = mainClass;
      return this;
    }",False
"  
  private ProcessWrapper(final String[] jvmArguments, final Class<?> mainClass, final String[] mainArguments, final boolean useMainLauncher, final boolean headless, final long timeoutMillis) {
    this.jvmArguments = jvmArguments;",False
"  public int waitFor(final boolean throwOnTimeout) throws InterruptedException {
    return waitFor(timeoutMillis, throwOnTimeout);
  }",False
"      return this.exitValue.get();
    }
  }
  
  public int waitFor(final long timeout) throws InterruptedException {
    return waitFor(timeout, false);
  }
  
  public int waitFor(final boolean throwOnTimeout) throws InterruptedException {
    return waitFor(timeoutMillis, throwOnTimeout);
  }",False
"  public boolean isAlive() throws InterruptedException {
    checkStarting();
    waitForProcessStart();
    
    synchronized (this.exitValue) {
      if (this.interrupted) { // TODO: do we want to do this?
        throw new InterruptedException(""Process was interrupted"");
      }
      return this.exitValue.get() == -1 && this.started && !this.stopped && !this.interrupted && this.processThread.isAlive();
    }
  }",True
"  public boolean isAlive() throws InterruptedException, TimeoutException {
    checkStarting();
    waitForProcessStart();
    
    synchronized (this.exitValue) {
      if (this.interrupted) { // TODO: do we want to do this?
        throw new InterruptedException(""Process was interrupted"");
      }
      return this.exitValue.get() == -1 && this.started && !this.stopped && !this.interrupted && this.processThread.isAlive();
    }
  }",False
"      if (line == null) {
        fail(""Timed out waiting for output \"""" + patternString + ""\"" after "" + timeoutMillis + "" ms. Output: "" + new OutputFormatter(this.allLines));
      }
      
      if (pattern.matcher(line).matches()) {
        logger.debug(""ProcessWrapper:waitForOutputToMatch Matched pattern \""{}\"" against output \""{}\"""", patternString, line);
        break;
      } else {
        logger.debug(""ProcessWrapper:waitForOutputToMatch Did not match pattern \""{}\"" against output \""{}\"""", patternString, line);
      }
    }
    return this;
  }
  
  /*
   * Waits for the process stdout or stderr stream to contain the specified 
   * text. Uses the default timeout.
   */
  public ProcessWrapper waitForOutputToMatch(final String patternString) throws InterruptedException {
    return waitForOutputToMatch(patternString, timeoutMillis);
  }

  public ProcessWrapper execute() throws InterruptedException, TimeoutException {",False
"    public Builder timeoutMillis(final long timeoutMillis) {
      this.timeoutMillis = timeoutMillis;
      return this;
    }",False
"    public Builder jvmArguments(final String[] jvmArguments) {
      this.jvmArguments = jvmArguments;
      return this;
    }",False
"  public ProcessStreamReader getStandardOutReader() { // TODO:protected
    synchronized (this.exitValue) {
      return stdout;
    }
  }",True
"  public ProcessStreamReader getStandardOutReader() {
    synchronized (this.exitValue) {
      return stdout;
    }
  }",False
"    public Builder mainArguments(final String[] mainArguments) {
      this.mainArguments = mainArguments;
      return this;
    }",False
"  public ProcessWrapper failIfOutputMatches(final String patternString, final long timeoutMillis) throws InterruptedException {
    checkStarting();
    checkOk();
    
    final Pattern pattern = Pattern.compile(patternString);
    logger.debug(""failIfOutputMatches waiting for \""{}\""..."", patternString);
    final long start = System.currentTimeMillis();",False
"    public Builder mainArgs(String[] mainArgs) {
      this.mainArgs = mainArgs;
      return this;
    }",True
"    }
    public ProcessWrapper build() {
      return new ProcessWrapper(jvmArguments, mainClass, mainArguments, useMainLauncher, headless, timeoutMillis);
    }",False
"    public Builder useMainLauncher(final boolean useMainLauncher) {
      this.useMainLauncher = useMainLauncher;
      return this;
    }",False
"    this.mainArguments = mainArguments;
    this.useMainLauncher = useMainLauncher;
    this.headless = headless;",False
"  private void checkOk() throws RuntimeException {
    if (this.processException != null) {
      RuntimeException rt = new RuntimeException(""Failed to launch process"", this.processException);
      throw rt;
    }
  }",True
"  private void checkOk() throws RuntimeException {
    if (this.processException != null) {
      throw new RuntimeException(""Failed to launch process"", this.processException);
    }
  }",False
"  public ProcessWrapper waitForOutputToMatch(final String patternString, final long timeoutMillis) throws InterruptedException {
    checkStarting();
    checkOk();

    final Pattern pattern = Pattern.compile(patternString);
    logger.debug(""ProcessWrapper:waitForOutputToMatch waiting for \""{}\""..."", patternString);
    
    while(true) {
      final String line = this.lineBuffer.poll(timeoutMillis, TimeUnit.MILLISECONDS);
      if (line == null) {
        fail(""Timed out waiting for output \"""" + patternString + ""\"" after "" + timeoutMillis + "" ms. Output: "" + new OutputFormatter(this.allLines));
      }
      
      if (pattern.matcher(line).matches()) {
        logger.debug(""ProcessWrapper:waitForOutputToMatch Matched pattern \""{}\"" against output \""{}\"""", patternString, line);
        break;
      } else {
        logger.debug(""ProcessWrapper:waitForOutputToMatch Did not match pattern \""{}\"" against output \""{}\"""", patternString, line);
      }
    }
    return this;
  }",False
"  private void start(final Properties properties, final File workingDirectory) {
    final List<String> jvmArgumentsList = new ArrayList<String>();

    if (properties != null) {
      for (Map.Entry<Object, Object> entry : properties.entrySet()) {
        if (!entry.getKey().equals(""log-file"")) {
          jvmArgumentsList.add(""-D"" + entry.getKey() + ""="" + entry.getValue());
        }
      }
    }

    if (this.headless) {
      jvmArgumentsList.add(""-Djava.awt.headless=true"");
    }
    
    if (this.jvmArguments != null) {
      for (String jvmArgument: this.jvmArguments) {
        jvmArgumentsList.add(jvmArgument);
      }
    }
    
    try {
      synchronized (this.exitValue) {
        final String[] command = defineCommand(jvmArgumentsList.toArray(new String[jvmArgumentsList.size()]));
        this.process = new ProcessBuilder(command).directory(workingDirectory).start();
        
        final StringBuilder processCommand = new StringBuilder();
        boolean addSpace = false;
        
        for (String string : command) {
          if (addSpace) {
            processCommand.append("" "");
          }
          processCommand.append(string);
          addSpace = true;
        }
        
        final String commandString = processCommand.toString();
        logger.debug(""Starting "" + commandString);
        
        final ProcessStreamReader stdOut = new ProcessStreamReader(commandString, this.process.getInputStream(), this.lineBuffer, this.allLines);
        final ProcessStreamReader stdErr = new ProcessStreamReader(commandString, this.process.getErrorStream(), this.lineBuffer, this.allLines);
  
        this.stdout = stdOut;
        this.stderr = stdErr;
        this.outputReader = new ProcessOutputReader(this.process, stdOut, stdErr, this.allLines);
        this.started = true;
      }
      
      this.outputReader.waitFor();
      int code = this.process.waitFor();
      
      synchronized (this.exitValue) {
        this.exitValue.set(code);
        this.stopped = true;
      }
      
    } catch (InterruptedException e) {
      synchronized (this.exitValue) {
        this.interrupted = true;
        this.processException = e;
      }
    } catch (Throwable t) {
      synchronized (this.exitValue) {
        this.processException = t;
      }
    }
  }",False
"    while(System.currentTimeMillis() <= start+timeoutMillis) {
      final String line = lineBuffer.poll(timeoutMillis, TimeUnit.MILLISECONDS);
      if (line != null && pattern.matcher(line).matches()) {
        fail(""failIfOutputMatches Matched pattern \"""" + patternString + ""\"" against output \"""" + line + ""\"". Output: "" + this.allLines);
      }
    }
    return this;
  }
  
  /*
   * Waits for the process stdout or stderr stream to contain the specified 
   * text. Uses the specified timeout for debugging purposes.
   */
  public ProcessWrapper waitForOutputToMatch(final String patternString, final long timeoutMillis) throws InterruptedException {
    checkStarting();
    checkOk();
",False
"      }, ""ProcessWrapper Process Thread"");
    }
    this.processThread.start();

    waitForProcessStart();

    synchronized (this.exitValue) {
      if (this.processException != null) {
        logger.error(""ProcessWrapper:execute failed with "" + this.processException);
        this.processException.printStackTrace();
      }
    }

    if (this.useMainLauncher) {
      sendInput(); // to trigger MainLauncher delegation to inner main
    }
    return this;
  }

  private void start(final Properties properties, final File workingDirectory) {
    final List<String> jvmArgumentsList = new ArrayList<String>();

    if (properties != null) {
      for (Map.Entry<Object, Object> entry : properties.entrySet()) {
        if (!entry.getKey().equals(""log-file"")) {
          jvmArgumentsList.add(""-D"" + entry.getKey() + ""="" + entry.getValue());
        }
      }",False
"  public ProcessStreamReader getStandardErrorReader() { // TODO:protected
    synchronized (this.exitValue) {
      return stderr;
    }
  }",True
"  public ProcessStreamReader getStandardErrorReader() {
    synchronized (this.exitValue) {
      return stderr;
    }
  }",False
"  public String getOutput(final boolean ignoreStopped) { 
    checkStarting();
    if (!ignoreStopped) {
      checkStopped();
    }
    final StringBuffer sb = new StringBuffer();
    final Iterator<String> iterator = this.allLines.iterator();
    while (iterator.hasNext()) {
      sb.append(iterator.next() + ""\n"");
    }
    return sb.toString();
  }",False
"  public String toString() {
    final StringBuilder sb = new StringBuilder(getClass().getSimpleName());
    sb.append(""@"").append(System.identityHashCode(this)).append(""{"");
    sb.append(this.mainClass);
    sb.append(""}"");
    return sb.toString();
  }",False
"    public Builder jvmArgs(String[] jvmArgs) {
      this.jvmArgs = jvmArgs;
      return this;
    }",True
"    }
    public Builder timeoutMillis(final long timeoutMillis) {
      this.timeoutMillis = timeoutMillis;
      return this;",False
"  public void testInvokeWithNullArgs() throws Exception {
    this.process = new ProcessWrapper.Builder().main(getClass()).build();
    this.process.execute();
    this.process.waitFor();
    assertTrue(process.getOutput().contains(OUTPUT_OF_MAIN));
  }",True
"  public void testInvokeWithNullArgs() throws Exception {
    this.process = new ProcessWrapper.Builder().mainClass(getClass()).build();
    this.process.execute();
    this.process.waitFor();
    assertTrue(process.getOutput().contains(OUTPUT_OF_MAIN));
  }",False
"  public void testClassPath() throws Exception {
    final String classPath = System.getProperty(""java.class.path"");
    System.out.println(""Classpath: "" + classPath);
    assertTrue(""Classpath is missing log4j-api: "" + classPath, classPath.toLowerCase().contains(""log4j-api""));
    assertTrue(""Classpath is missing log4j-core: "" + classPath, classPath.toLowerCase().contains(""log4j-core""));
    assertTrue(""Classpath is missing fastutil: "" + classPath, classPath.toLowerCase().contains(""fastutil""));
  
    System.out.println(String.valueOf(Integer.MAX_VALUE));
    
    this.process = new ProcessWrapper.Builder().main(getClass()).build();
    this.process.execute();
    this.process.waitFor();
    System.out.println(""Output: "" + process.getOutput());
    assertTrue(""Output is wrong: "" + process.getOutput(), process.getOutput().contains(OUTPUT_OF_MAIN));
  }",True
"  public void testClassPath() throws Exception {
    final String classPath = System.getProperty(""java.class.path"");
    assertTrue(""Classpath is missing log4j-api: "" + classPath, classPath.toLowerCase().contains(""log4j-api""));
    assertTrue(""Classpath is missing log4j-core: "" + classPath, classPath.toLowerCase().contains(""log4j-core""));
    assertTrue(""Classpath is missing fastutil: "" + classPath, classPath.toLowerCase().contains(""fastutil""));
  
    this.process = new ProcessWrapper.Builder().mainClass(getClass()).build();
    this.process.execute();
    this.process.waitFor();
    
    assertTrue(""Output is wrong: "" + process.getOutput(), process.getOutput().contains(OUTPUT_OF_MAIN));
  }",False
"  public void setUp() throws Exception
  {
    super.setUp();
    diskProps1.setDiskDirs(dirs);
    diskProps2.setDiskDirs(dirs);
    DiskStoreImpl.SET_IGNORE_PREALLOCATE = true;
  }",True
"  public void tearDown() throws Exception
  {
    super.tearDown();
    DiskStoreImpl.SET_IGNORE_PREALLOCATE = false;
  }",True
"  public void populateData2()
  {
    //  Put for validation.
    putForValidation(region2);
    final byte[] value = new byte[ENTRY_SIZE];
    Arrays.fill(value, (byte)77);
    //warm up the system
    for (int i = 0; i < OP_COUNT; i++) {
      region2.put("""" + i, value);
     }
    long startTime = System.currentTimeMillis();
    for (int i = 0; i < OP_COUNT; i++) {
      region2.put("""" + i, value);
     }
    long endTime = System.currentTimeMillis();
    if(logWriter.fineEnabled())  logWriter.fine("" done with putting"");
    float et = endTime - startTime;
    float etSecs = et / 1000f;
    opPerSec2 = etSecs == 0 ? 0 : (OP_COUNT / (et / 1000f));
    float bytesPerSec = etSecs == 0 ? 0
        : ((OP_COUNT * ENTRY_SIZE) / (et / 1000f));
    stats2 = ""et="" + et + ""ms writes/sec="" + opPerSec2 + "" bytes/sec=""
        + bytesPerSec;
    logWriter.info(stats2);
   //  validate put operation
    validatePut(region2);
  }",True
"  public void testpersistASync()
  {

    // test-persistASync-ByteThreshold
    try {
     
      diskProps1.setTimeInterval(10);
      diskProps1.setBytesThreshold(Integer.MAX_VALUE); // now a queue size
      diskProps1.setRegionName(""region1"");
      region1 = DiskRegionHelperFactory.getAsyncPersistOnlyRegion(cache, diskProps1);
      
    }
    catch (Exception e) {
      if(logWriter.fineEnabled()){
        e.printStackTrace();
      }
      fail(""failed : test-persistASync-ByteThreshold.Exception=""+e);
    }
    //Perf test for 1kb writes
    populateData1();
    if(logWriter.infoEnabled()){
    logWriter.info(""testpersistASyncByteThreshold:: Stats for 1 kb writes :""
        + stats1);
    }
   //  close region1
    region1.close();
 
  
    try {      
      diskProps2.setTimeInterval(150000000l);
      diskProps2.setBytesThreshold(32); // now a queue size
      diskProps2.setRegionName(""region2"");
      region2 = DiskRegionHelperFactory.getAsyncPersistOnlyRegion(cache, diskProps2);
    }
    catch (Exception e) {
      if(logWriter.fineEnabled()) e.printStackTrace();
      fail(""Failed : test-persistASync-TimeInterval. Exception = ""+e);
    }
    //Perf test for 1kb writes
    populateData2();
    if(logWriter.infoEnabled()) logWriter.info(""testpersistASyncTimeInterval:: Stats for 1 kb writes :""
        + stats2);
     //close region2
     region2.close();
    
     
   
     
   
    
    
    //validate that the pus/sec in both cases do not differ by twice 
     if(logWriter.infoEnabled()) logWriter.info(""opPerSec1= ""+opPerSec1+""_________opPerSec2= ""+opPerSec2);
    assertTrue(opPerSec1/opPerSec2 < 3.0 );
    assertTrue(opPerSec2/opPerSec1 < 3.0) ;
        
  } //end of testpersistASyncTimeInterva",True
"  public void populateData1 ()
  {
    //Put for validation.
    putForValidation(region1);
   
    final byte[] value = new byte[ENTRY_SIZE];
    Arrays.fill(value, (byte)77);
    //warm up the system
    for (int i = 0; i < OP_COUNT; i++) {
      region1.put("""" + i, value);
     }
    long startTime = System.currentTimeMillis();
    for (int i = 0; i < OP_COUNT; i++) {
      region1.put("""" + i, value);
     }
    long endTime = System.currentTimeMillis();
    if(logWriter.fineEnabled()) logWriter.fine("" done with putting"");
    float et = endTime - startTime;
    float etSecs = et / 1000f;
    opPerSec1 = etSecs == 0 ? 0 : (OP_COUNT / (et / 1000f));
    float bytesPerSec = etSecs == 0 ? 0
        : ((OP_COUNT * ENTRY_SIZE) / (et / 1000f));
    stats1 = ""et="" + et + ""ms writes/sec="" + opPerSec1 + "" bytes/sec=""
        + bytesPerSec;
    logWriter.info(stats1);
   //  validate put operation
    validatePut(region1);
    
  }",True
"  public void testEventsExpiryBug() throws Exception
  {
    addExpectedException(""Connection reset"");
    server.invoke(Bug36853EventsExpiryDUnitTest.class, ""generateEvents"");
    client.invoke(Bug36853EventsExpiryDUnitTest.class,
        ""validateEventCountAtClient"");
  }",True
"  public void testEventsExpiryBug() throws Exception
  {
    addExpectedException(""Unexpected IOException"");
    addExpectedException(""Connection reset"");
    server.invoke(Bug36853EventsExpiryDUnitTest.class, ""generateEvents"");
    client.invoke(Bug36853EventsExpiryDUnitTest.class,
        ""validateEventCountAtClient"");
  }",False
"  public void setDistTxEntryStates(
      ArrayList<DistTxThinEntryState> entryEventList) {
    String regionFullPath = this.getRegion().getFullPath();
    int entryModsSize = this.entryMods.size();
    int entryEventListSize = entryEventList.size();
    if (entryModsSize != entryEventListSize) {
      throw new UnsupportedOperationInTransactionException(
          LocalizedStrings.DISTTX_TX_EXPECTED.toLocalizedString(
              ""entry size of "" + entryModsSize + "" for region ""
                  + regionFullPath, entryEventListSize));
    }

    int index = 0;
    // [DISTTX] TODO Sort this first
    for (Entry<Object, TXEntryState> em : this.entryMods.entrySet()) {
      Object mKey = em.getKey();
      TXEntryState txes = em.getValue();
      DistTxThinEntryState thinEntryState = entryEventList.get(index++);
      txes.setDistTxEntryStates(thinEntryState);
      if (logger.isDebugEnabled()) {
        logger.debug(""TxRegionState.setDistTxEntryStates Added ""
            + thinEntryState + "" for key="" + mKey + "" ,op="" + txes.opToString()
            + "" ,region="" + regionFullPath);
      }
    }
  }",True
"  public void setDistTxEntryStates(
      ArrayList<DistTxThinEntryState> entryEventList) {
    String regionFullPath = this.getRegion().getFullPath();
    int entryModsSize = this.entryMods.size();
    int entryEventListSize = entryEventList.size();
    /*
     * [DISTTX] TODO
     * This assertion is not working for PutAll and RemoveAll operations 
     * and thus guarding within Debug flags. May be enabled at later stage.
     */
    if (logger.isDebugEnabled()) {
      if (entryModsSize != entryEventListSize) {
        throw new UnsupportedOperationInTransactionException(
            LocalizedStrings.DISTTX_TX_EXPECTED
                .toLocalizedString(""entry size of "" + entryModsSize
                    + "" for region "" + regionFullPath, entryEventListSize));
      }
    }

    int index = 0;
    // [DISTTX] TODO Sort this first
    for (Entry<Object, TXEntryState> em : this.entryMods.entrySet()) {
      Object mKey = em.getKey();
      TXEntryState txes = em.getValue();
      DistTxThinEntryState thinEntryState = entryEventList.get(index++);
      txes.setDistTxEntryStates(thinEntryState);
      if (logger.isDebugEnabled()) {
        logger.debug(""TxRegionState.setDistTxEntryStates Added ""
            + thinEntryState + "" for key="" + mKey + "" ,op="" + txes.opToString()
            + "" ,region="" + regionFullPath);
      }
    }
  }",False
"  public void tearDown2() throws Exception {
    super.tearDown2();
    invokeInEveryVM(new SerializableRunnable() {
      public void run() {
        InternalResourceManager.setResourceObserver(null);
      }
    });
    InternalResourceManager.setResourceObserver(null);
  }",True
"  public void tearDown2() throws Exception {
    super.tearDown2();
    invokeInEveryVM(new SerializableRunnable() {
      public void run() {
        InternalResourceManager.setResourceObserver(null);
      }
    });
    InternalResourceManager.setResourceObserver(null);
    if (cache != null) {
      cache.close();
    }
  }",False
"  protected String reduceLogging() {
    return ""config"";
  }",True
"  public int startServer(VM vm) {
    return (Integer) vm.invoke(new SerializableCallable() {
      public Object call() throws Exception {",False
"  public void setUp() throws Exception{
    super.setUp();
    this.invokeInEveryVM(new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        System.setProperty(""gemfire.sync-commits"", ""true"");
        return null;
      }
    });
    
    this.invokeInEveryVM(new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        System.setProperty(""gemfire.log-level"", ""fine"");
        return null;
      }
    }); 

    this.invokeInEveryVM(new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        //System.setProperty(""gemfire.ALLOW_PERSISTENT_TRANSACTIONS"", ""true"");
        TXManagerImpl.ALLOW_PERSISTENT_TRANSACTIONS = true;
        return null;
      }
    }); 
  }",True
"  public void setUp() throws Exception{
    super.setUp();
    this.invokeInEveryVM(new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        System.setProperty(""gemfire.sync-commits"", ""true"");
        return null;
      }
    });
    
//    this.invokeInEveryVM(new SerializableCallable() {
//      @Override
//      public Object call() throws Exception {
//        System.setProperty(""gemfire.log-level"", ""fine"");
//        return null;
//      }
//    });

    this.invokeInEveryVM(new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        //System.setProperty(""gemfire.ALLOW_PERSISTENT_TRANSACTIONS"", ""true"");
        TXManagerImpl.ALLOW_PERSISTENT_TRANSACTIONS = true;
        return null;
      }
    }); 
  }",False
"  private List<Chunk> getRegionLiveChunks() {
    ArrayList<Chunk> result = new ArrayList<Chunk>();
    GemFireCacheImpl gfc = GemFireCacheImpl.getInstance();
    if (gfc != null) {
      Iterator rootIt = gfc.rootRegions().iterator();
      while (rootIt.hasNext()) {
        Region rr = (Region) rootIt.next();
        getRegionLiveChunks(rr, result);
        Iterator srIt = rr.subregions(true).iterator();
        while (srIt.hasNext()) {
          Region sr = (Region)srIt.next();
          getRegionLiveChunks(sr, result);
        }
      }
    }
    return result;
  }",True
"  private void getRegionLiveChunks(Region r, List<Chunk> result) {
    if (r.getAttributes().getOffHeap()) {

      if (r instanceof PartitionedRegion) {
        PartitionedRegionDataStore prs = ((PartitionedRegion) r).getDataStore();
        if (prs != null) {
          Set<BucketRegion> brs = prs.getAllLocalBucketRegions();
          if (brs != null) {
            for (BucketRegion br : brs) {
              if (br != null && !br.isDestroyed()) {
                this.basicGetRegionLiveChunks(br, result);
              }

            }
          }
        }
      } else {
        this.basicGetRegionLiveChunks((LocalRegion) r, result);
      }

    }

  }",False
"  public void postPutAll(DistributedPutAllOperation putallOp,
      VersionedObjectList successfulPuts, LocalRegion region) {
    if (putallOp.putAllData.length == 0) {
      return;
    }
    if (region instanceof DistributedRegion) {
      super.postPutAll(putallOp, successfulPuts, region);
    } else {
      region.getCancelCriterion().checkCancelInProgress(null); // fix for bug
                                                               // #43651

      if (logger.isDebugEnabled()) {
        logger.debug(""DistTXStateProxyImplOnCoordinator.postPutAll ""
            + ""processing putAll op for region {}, size of putAllOp ""
            + ""is {}"", region, putallOp.putAllData.length);
      }


      //map of bucketId to putall op for this bucket
      HashMap<Integer, DistributedPutAllOperation> bucketToPutallMap = 
          new HashMap<Integer, DistributedPutAllOperation>();
      //map of bucketId to TXStateStub for target that hosts this bucket
      HashMap<Integer, DistTXCoordinatorInterface> bucketToTxStateStubMap = 
          new HashMap<Integer, DistTXCoordinatorInterface>();
      
      //separate the putall op per bucket
      for (int i=0; i<putallOp.putAllData.length; i++) {
        assert (putallOp.putAllData[i] != null);
        Object key = putallOp.putAllData[i].key;
        int bucketId = putallOp.putAllData[i].getBucketId();
        
        DistributedPutAllOperation putAllForBucket = 
            bucketToPutallMap.get(bucketId);;
        if (putAllForBucket == null) {
          EntryEventImpl event = EntryEventImpl.createPutAllEvent(null, region,
              Operation.PUTALL_CREATE, key,
              putallOp.putAllData[i].getValue());
          event.setEventId(putallOp.putAllData[i].getEventID());
          putAllForBucket = new DistributedPutAllOperation(
              event, putallOp.putAllDataSize, putallOp.isBridgeOp);
          bucketToPutallMap.put(bucketId, putAllForBucket);
        } 
        putAllForBucket.addEntry(putallOp.putAllData[i]);

        KeyInfo ki = new KeyInfo(key, null, null);
        DistTXCoordinatorInterface tsi = (DistTXCoordinatorInterface) getRealDeal(ki, region);
        bucketToTxStateStubMap.put(bucketId, tsi);
      }
      
      // fire a putAll operation for each bucket using appropriate TXStateStub
      // (for target that host this bucket)

      // [DISTTX] [TODO] Perf: Can this be further optimized?
      // This sends putAll in a loop to each target bucket (and waits for ack)
      // one after another.Could we send respective putAll messages to all
      // targets using same reply processor and wait on it?
      for (Entry<Integer, DistTXCoordinatorInterface> e : bucketToTxStateStubMap
          .entrySet()) {
        Integer bucketId = e.getKey();
        DistTXCoordinatorInterface dtsi = e.getValue();
        DistributedPutAllOperation putAllForBucket = bucketToPutallMap
            .get(bucketId);
        
        if (logger.isDebugEnabled()) {
          logger.debug(""DistTXStateProxyImplOnCoordinator.postPutAll processing""
              + "" putAll for ##bucketId = {}, ##txStateStub = {}, ""
              + ""##putAllOp = {}""
              , bucketId, dtsi, putAllForBucket);
        }
        dtsi.postPutAll(putAllForBucket, successfulPuts, region);
      }
    }
  }",True
"  public void postPutAll(DistributedPutAllOperation putallOp,
      VersionedObjectList successfulPuts, LocalRegion region) {
    if (putallOp.putAllData.length == 0) {
      return;
    }
    if (region instanceof DistributedRegion) {
      super.postPutAll(putallOp, successfulPuts, region);
    } else {
      region.getCancelCriterion().checkCancelInProgress(null); // fix for bug
                                                               // #43651

      if (logger.isDebugEnabled()) {
        logger.debug(""DistTXStateProxyImplOnCoordinator.postPutAll ""
            + ""processing putAll op for region {}, size of putAllOp ""
            + ""is {}"", region, putallOp.putAllData.length);
      }


      //map of bucketId to putall op for this bucket
      HashMap<Integer, DistributedPutAllOperation> bucketToPutallMap = 
          new HashMap<Integer, DistributedPutAllOperation>();
      //map of bucketId to TXStateStub for target that hosts this bucket
      HashMap<Integer, DistTXCoordinatorInterface> bucketToTxStateStubMap = 
          new HashMap<Integer, DistTXCoordinatorInterface>();
      
      //separate the putall op per bucket
      for (int i=0; i<putallOp.putAllData.length; i++) {
        assert (putallOp.putAllData[i] != null);
        Object key = putallOp.putAllData[i].key;
        int bucketId = putallOp.putAllData[i].getBucketId();
        
        DistributedPutAllOperation putAllForBucket = 
            bucketToPutallMap.get(bucketId);;
        if (putAllForBucket == null) {
          EntryEventImpl event = EntryEventImpl.createPutAllEvent(null, region,
              Operation.PUTALL_CREATE, key,
              putallOp.putAllData[i].getValue());
          event.setEventId(putallOp.putAllData[i].getEventID());
          putAllForBucket = new DistributedPutAllOperation(
              event, putallOp.putAllDataSize, putallOp.isBridgeOp);
          bucketToPutallMap.put(bucketId, putAllForBucket);
        } 
        putallOp.putAllData[i].setFakeEventID();
        putAllForBucket.addEntry(putallOp.putAllData[i]);

        KeyInfo ki = new KeyInfo(key, null, null);
        DistTXCoordinatorInterface tsi = (DistTXCoordinatorInterface) getRealDeal(ki, region);
        bucketToTxStateStubMap.put(bucketId, tsi);
      }
      
      // fire a putAll operation for each bucket using appropriate TXStateStub
      // (for target that host this bucket)

      // [DISTTX] [TODO] Perf: Can this be further optimized?
      // This sends putAll in a loop to each target bucket (and waits for ack)
      // one after another.Could we send respective putAll messages to all
      // targets using same reply processor and wait on it?
      for (Entry<Integer, DistTXCoordinatorInterface> e : bucketToTxStateStubMap
          .entrySet()) {
        Integer bucketId = e.getKey();
        DistTXCoordinatorInterface dtsi = e.getValue();
        DistributedPutAllOperation putAllForBucket = bucketToPutallMap
            .get(bucketId);
        
        if (logger.isDebugEnabled()) {
          logger.debug(""DistTXStateProxyImplOnCoordinator.postPutAll processing""
              + "" putAll for ##bucketId = {}, ##txStateStub = {}, ""
              + ""##putAllOp = {}""
              , bucketId, dtsi, putAllForBucket);
        }
        dtsi.postPutAll(putAllForBucket, successfulPuts, region);
      }
    }
  }",False
"  public void postRemoveAll(DistributedRemoveAllOperation op,
      VersionedObjectList successfulOps, LocalRegion region) {
    if (op.removeAllData.length == 0) {
      return;
    }
    if (region instanceof DistributedRegion) {
      super.postRemoveAll(op, successfulOps, region);
    } else {
      region.getCancelCriterion().checkCancelInProgress(null); // fix for bug
                                                               // #43651
      if (logger.isDebugEnabled()) {
        logger.debug(""DistTXStateProxyImplOnCoordinator.postRemoveAll ""
            + ""processing removeAll op for region {}, size of removeAll ""
            + ""is {}"", region, op.removeAllDataSize);
      }
      
      //map of bucketId to removeAll op for this bucket
      HashMap<Integer, DistributedRemoveAllOperation> bucketToRemoveAllMap = 
          new HashMap<Integer, DistributedRemoveAllOperation>();
      //map of bucketId to TXStateStub for target that hosts this bucket
      HashMap<Integer, DistTXCoordinatorInterface> bucketToTxStateStubMap = 
          new HashMap<Integer, DistTXCoordinatorInterface>();
      
      //separate the removeAll op per bucket
      for (int i=0; i<op.removeAllData.length; i++) {
        assert (op.removeAllData[i] != null);
        Object key = op.removeAllData[i].key;
        int bucketId = op.removeAllData[i].getBucketId();
        
        DistributedRemoveAllOperation removeAllForBucket = 
            bucketToRemoveAllMap.get(bucketId);
        if (removeAllForBucket == null) {
          EntryEventImpl event = EntryEventImpl.createRemoveAllEvent(op, region, key);
          event.setEventId(op.removeAllData[i].getEventID());
          removeAllForBucket = new DistributedRemoveAllOperation(
              event, op.removeAllDataSize, op.isBridgeOp);
          bucketToRemoveAllMap.put(bucketId, removeAllForBucket);
        } 
        removeAllForBucket.addEntry(op.removeAllData[i]);

        KeyInfo ki = new KeyInfo(key, null, null);
        DistTXCoordinatorInterface tsi = (DistTXCoordinatorInterface) getRealDeal(ki, region);
        bucketToTxStateStubMap.put(bucketId, tsi);
      }
      
      // fire a removeAll operation for each bucket using appropriate TXStateStub
      // (for target that host this bucket)

      // [DISTTX] [TODO] Perf: Can this be further optimized?
      // This sends putAll in a loop to each target bucket (and waits for ack)
      // one after another.Could we send respective putAll messages to all
      // targets using same reply processor and wait on it?
      for (Entry<Integer, DistTXCoordinatorInterface> e : bucketToTxStateStubMap
          .entrySet()) {
        Integer bucketId = e.getKey();
        DistTXCoordinatorInterface dtsi = e.getValue();
        DistributedRemoveAllOperation removeAllForBucket = bucketToRemoveAllMap
            .get(bucketId);
        
        if (logger.isDebugEnabled()) {
          logger.debug(""DistTXStateProxyImplOnCoordinator.postRemoveAll processing""
              + "" removeAll for ##bucketId = {}, ##txStateStub = {}, ""
              + ""##removeAllOp = {}""
              , bucketId, dtsi, removeAllForBucket);
        }
        dtsi.postRemoveAll(removeAllForBucket, successfulOps, region);
      }

    }
  }",True
"  public void postRemoveAll(DistributedRemoveAllOperation op,
      VersionedObjectList successfulOps, LocalRegion region) {
    if (op.removeAllData.length == 0) {
      return;
    }
    if (region instanceof DistributedRegion) {
      super.postRemoveAll(op, successfulOps, region);
    } else {
      region.getCancelCriterion().checkCancelInProgress(null); // fix for bug
                                                               // #43651
      if (logger.isDebugEnabled()) {
        logger.debug(""DistTXStateProxyImplOnCoordinator.postRemoveAll ""
            + ""processing removeAll op for region {}, size of removeAll ""
            + ""is {}"", region, op.removeAllDataSize);
      }
      
      //map of bucketId to removeAll op for this bucket
      HashMap<Integer, DistributedRemoveAllOperation> bucketToRemoveAllMap = 
          new HashMap<Integer, DistributedRemoveAllOperation>();
      //map of bucketId to TXStateStub for target that hosts this bucket
      HashMap<Integer, DistTXCoordinatorInterface> bucketToTxStateStubMap = 
          new HashMap<Integer, DistTXCoordinatorInterface>();
      
      //separate the removeAll op per bucket
      for (int i=0; i<op.removeAllData.length; i++) {
        assert (op.removeAllData[i] != null);
        Object key = op.removeAllData[i].key;
        int bucketId = op.removeAllData[i].getBucketId();
        
        DistributedRemoveAllOperation removeAllForBucket = 
            bucketToRemoveAllMap.get(bucketId);
        if (removeAllForBucket == null) {
          EntryEventImpl event = EntryEventImpl.createRemoveAllEvent(op, region, key);
          event.setEventId(op.removeAllData[i].getEventID());
          removeAllForBucket = new DistributedRemoveAllOperation(
              event, op.removeAllDataSize, op.isBridgeOp);
          bucketToRemoveAllMap.put(bucketId, removeAllForBucket);
        } 
        op.removeAllData[i].setFakeEventID();
        removeAllForBucket.addEntry(op.removeAllData[i]);

        KeyInfo ki = new KeyInfo(key, null, null);
        DistTXCoordinatorInterface tsi = (DistTXCoordinatorInterface) getRealDeal(ki, region);
        bucketToTxStateStubMap.put(bucketId, tsi);
      }
      
      // fire a removeAll operation for each bucket using appropriate TXStateStub
      // (for target that host this bucket)

      // [DISTTX] [TODO] Perf: Can this be further optimized?
      // This sends putAll in a loop to each target bucket (and waits for ack)
      // one after another.Could we send respective putAll messages to all
      // targets using same reply processor and wait on it?
      for (Entry<Integer, DistTXCoordinatorInterface> e : bucketToTxStateStubMap
          .entrySet()) {
        Integer bucketId = e.getKey();
        DistTXCoordinatorInterface dtsi = e.getValue();
        DistributedRemoveAllOperation removeAllForBucket = bucketToRemoveAllMap
            .get(bucketId);
        
        if (logger.isDebugEnabled()) {
          logger.debug(""DistTXStateProxyImplOnCoordinator.postRemoveAll processing""
              + "" removeAll for ##bucketId = {}, ##txStateStub = {}, ""
              + ""##removeAllOp = {}""
              , bucketId, dtsi, removeAllForBucket);
        }
        dtsi.postRemoveAll(removeAllForBucket, successfulOps, region);
      }

    }
  }",False
"  public void setDistTxEntryStates(
      ArrayList<DistTxThinEntryState> entryEventList) {
    String regionFullPath = this.getRegion().getFullPath();
    int entryModsSize = this.entryMods.size();
    int entryEventListSize = entryEventList.size();
    /*
     * [DISTTX] TODO
     * This assertion is not working for PutAll and RemoveAll operations 
     * and thus guarding within Debug flags. May be enabled at later stage.
     */
    if (logger.isDebugEnabled()) {
      if (entryModsSize != entryEventListSize) {
        throw new UnsupportedOperationInTransactionException(
            LocalizedStrings.DISTTX_TX_EXPECTED
                .toLocalizedString(""entry size of "" + entryModsSize
                    + "" for region "" + regionFullPath, entryEventListSize));
      }
    }

    int index = 0;
    // [DISTTX] TODO Sort this first
    for (Entry<Object, TXEntryState> em : this.entryMods.entrySet()) {
      Object mKey = em.getKey();
      TXEntryState txes = em.getValue();
      DistTxThinEntryState thinEntryState = entryEventList.get(index++);
      txes.setDistTxEntryStates(thinEntryState);
      if (logger.isDebugEnabled()) {
        logger.debug(""TxRegionState.setDistTxEntryStates Added ""
            + thinEntryState + "" for key="" + mKey + "" ,op="" + txes.opToString()
            + "" ,region="" + regionFullPath);
      }
    }
  }",True
"  public void setDistTxEntryStates(
      ArrayList<DistTxThinEntryState> entryEventList) {
    String regionFullPath = this.getRegion().getFullPath();
    int entryModsSize = this.entryMods.size();
    int entryEventListSize = entryEventList.size();
    if (entryModsSize != entryEventListSize) {
      throw new UnsupportedOperationInTransactionException(
          LocalizedStrings.DISTTX_TX_EXPECTED.toLocalizedString(
              ""entry size of "" + entryModsSize + "" for region ""
                  + regionFullPath, entryEventListSize));
    }

    int index = 0;
    // [DISTTX] TODO Sort this first
    for (Entry<Object, TXEntryState> em : this.entryMods.entrySet()) {
      Object mKey = em.getKey();
      TXEntryState txes = em.getValue();
      DistTxThinEntryState thinEntryState = entryEventList.get(index++);
      txes.setDistTxEntryStates(thinEntryState);
      if (logger.isDebugEnabled()) {
        logger.debug(""TxRegionState.setDistTxEntryStates Added ""
            + thinEntryState + "" for key="" + mKey + "" ,op="" + txes.opToString()
            + "" ,region="" + regionFullPath);
      }
    }
  }",False
"  public Logger getExtendedLogger() {
    return super.logger;
  }",True
"  public ExtendedLogger getExtendedLogger() {
    return super.logger;
  }",False
"  public void close() {
    close(false);
  }",True
"  public void close(String reason, Throwable systemFailureCause, boolean keepalive, boolean keepDS) {
    if (isClosed()) {
      return;
    }
    final boolean isDebugEnabled = logger.isDebugEnabled();
    
    synchronized (GemFireCacheImpl.class) {
      // bugfix for bug 36512 ""GemFireCache.close is not thread safe""
      // ALL CODE FOR CLOSE SHOULD NOW BE UNDER STATIC SYNCHRONIZATION
      // OF synchronized (GemFireCache.class) {
      // static synchronization is necessary due to static resources
      if (isClosed()) {
        return;
      }

      /**
       * First close the ManagementService as it uses a lot of infra which will be closed by cache.close()
       **/
      system.handleResourceEvent(ResourceEvent.CACHE_REMOVE, this);
      if (this.listener != null) {
        this.system.removeResourceListener(listener);
        this.listener = null;
      }

      if (systemFailureCause != null) {
        this.forcedDisconnect = systemFailureCause instanceof ForcedDisconnectException;
        if (this.forcedDisconnect) {
          this.disconnectCause = new ForcedDisconnectException(reason);
        } else {
          this.disconnectCause = systemFailureCause;
        }
      }

      isClosing = true;
      logger.info(LocalizedMessage.create(LocalizedStrings.GemFireCache_0_NOW_CLOSING, this));

      // Before anything else...make sure that this instance is not
      // available to anyone ""fishing"" for a cache...
      if (GemFireCacheImpl.instance == this) {
        GemFireCacheImpl.instance = null;
      }

      // we don't clear the prID map if there is a system failure. Other
      // threads may be hung trying to communicate with the map locked
      if (systemFailureCause == null) {
        PartitionedRegion.clearPRIdMap();
      }
      TXStateProxy tx = null;
      try {
        this.keepAlive = keepalive;
        PoolManagerImpl.setKeepAlive(keepalive);

        if (this.txMgr != null) {
          tx = this.txMgr.internalSuspend();
        }

        // do this before closing regions
        resourceManager.close();

        try {
          this.resourceAdvisor.close();
        } catch (CancelException e) {
          // ignore
        } 
        try {
          this.jmxAdvisor.close();
        } catch (CancelException e) {
          // ignore
        }

        try {
          GatewaySenderAdvisor advisor = null;
          for (GatewaySender sender : this.getAllGatewaySenders()) {
            ((AbstractGatewaySender) sender).stop();
            advisor = ((AbstractGatewaySender) sender).getSenderAdvisor();
            if (advisor != null) {
              if (isDebugEnabled) {
                logger.debug(""Stopping the GatewaySender advisor"");
              }
              advisor.close();
            }
          }
          ParallelGatewaySenderQueue.cleanUpStatics(null);
        } catch (CancelException ce) {

        }
        
        destroyGatewaySenderLockService();

        if (ASYNC_EVENT_LISTENERS) {
          if (isDebugEnabled) {
            logger.debug(""{}: stopping event thread pool..."", this);
          }
          this.eventThreadPool.shutdown();
        }

        /*
         * IMPORTANT: any operation during shut down that can time out (create a CancelException) must be inside of this
         * try block. If all else fails, we *must* ensure that the cache gets closed!
         */
        try {                              
          this.stopServers();

          stopMemcachedServer();
          
          stopRedisServer();

          // no need to track PR instances since we won't create any more
          // bridgeServers or gatewayHubs
          if (this.partitionedRegions != null) {
            if (isDebugEnabled) {
              logger.debug(""{}: clearing partitioned regions..."", this);
            }
            synchronized (this.partitionedRegions) {
              int prSize = -this.partitionedRegions.size();
              this.partitionedRegions.clear();
              getCachePerfStats().incPartitionedRegions(prSize);
            }
          }

          prepareDiskStoresForClose();
          if (GemFireCacheImpl.pdxInstance == this) {
            GemFireCacheImpl.pdxInstance = null;
          }

          List rootRegionValues = null;
          synchronized (this.rootRegions) {
            rootRegionValues = new ArrayList(this.rootRegions.values());
          }
          {
            final Operation op;
            if (this.forcedDisconnect) {
              op = Operation.FORCED_DISCONNECT;
            } else if (isReconnecting()) {
              op = Operation.CACHE_RECONNECT;
            } else {
              op = Operation.CACHE_CLOSE;
            }

            LocalRegion prRoot = null;
            
            for (Iterator itr = rootRegionValues.iterator(); itr.hasNext();) {
              LocalRegion lr = (LocalRegion) itr.next();
              if (isDebugEnabled) {
                logger.debug(""{}: processing region {}"", this, lr.getFullPath());
              }
              if (PartitionedRegionHelper.PR_ROOT_REGION_NAME.equals(lr.getName())) {
                prRoot = lr;
              } else {
                if(lr.getName().contains(ParallelGatewaySenderQueue.QSTRING)){
                  continue; //this region will be closed internally by parent region
                }
                if (isDebugEnabled) {
                  logger.debug(""{}: closing region {}..."", this, lr.getFullPath());
                }
                try {
                  lr.handleCacheClose(op);
                } catch (Exception e) {
                  if (isDebugEnabled || !forcedDisconnect) {
                    logger.warn(LocalizedMessage.create(LocalizedStrings.GemFireCache_0_ERROR_CLOSING_REGION_1,
                        new Object[] { this, lr.getFullPath() }), e);
                  }
                }
              }
            } // for

            try {
              if (isDebugEnabled) {
                logger.debug(""{}: finishing partitioned region close..."", this);
              }
              PartitionedRegion.afterRegionsClosedByCacheClose(this);
              if (prRoot != null) {
                // do the PR meta root region last
                prRoot.handleCacheClose(op);
              }
            } catch (CancelException e) {
              logger.warn(LocalizedMessage.create(LocalizedStrings.GemFireCache_0_ERROR_IN_LAST_STAGE_OF_PARTITIONEDREGION_CACHE_CLOSE,
                  this), e);
            }
            destroyPartitionedRegionLockService();
          }

          closeDiskStores();
          diskMonitor.close();
          
          closeHDFSStores();
          
          // Close the CqService Handle.
          try {
            if (isDebugEnabled) {
              logger.debug(""{}: closing CQ service..."", this);
            }
            cqService.close();
          } catch (Exception ex) {
            logger.info(LocalizedMessage.create(LocalizedStrings.GemFireCache_FAILED_TO_GET_THE_CQSERVICE_TO_CLOSE_DURING_CACHE_CLOSE_1));
          }

          PoolManager.close(keepalive);

          if (isDebugEnabled) {
            logger.debug(""{}: closing reliable message queue..."", this);
          }
          try {
            getReliableMessageQueueFactory().close(true);
          } catch (CancelException e) {
            if (isDebugEnabled) {
              logger.debug(""Ignored cancellation while closing reliable message queue"", e);
            }
          }

          if (isDebugEnabled) {
            logger.debug(""{}: notifying admins of close..."", this);
          }
          try {
            SystemMemberCacheEventProcessor.send(this, Operation.CACHE_CLOSE);
          } catch (CancelException e) {
            if (logger.isDebugEnabled()) {
              logger.debug(""Ignored cancellation while notifying admins"");
            }
          }

          if (isDebugEnabled) {
            logger.debug(""{}: stopping destroyed entries processor..."", this);
          }
          this.tombstoneService.stop();

          // NOTICE: the CloseCache message is the *last* message you can send!
          DM dm = null;
          try {
            dm = system.getDistributionManager();
            dm.removeMembershipListener(this.txMgr);
          } catch (CancelException e) {
            // dm = null;
          }

          if (dm != null) { // Send CacheClosedMessage (and NOTHING ELSE) here
            if (isDebugEnabled) {
              logger.debug(""{}: sending CloseCache to peers..."", this);
            }
            Set otherMembers = dm.getOtherDistributionManagerIds();
            ReplyProcessor21 processor = new ReplyProcessor21(system, otherMembers);
            CloseCacheMessage msg = new CloseCacheMessage();
            // [bruce] if multicast is available, use it to send the message to
            // avoid race conditions with cache content operations that might
            // also be multicast
            msg.setMulticast(system.getConfig().getMcastPort() != 0);
            msg.setRecipients(otherMembers);
            msg.setProcessorId(processor.getProcessorId());
            dm.putOutgoing(msg);
            try {
              processor.waitForReplies();
            } catch (InterruptedException ex) {
              // Thread.currentThread().interrupt(); // TODO ??? should we reset this bit later?
              // Keep going, make best effort to shut down.
            } catch (ReplyException ex) {
              // keep going
            }
            // set closed state after telling others and getting responses
            // to avoid complications with others still in the process of
            // sending messages
          }
          // NO MORE Distributed Messaging AFTER THIS POINT!!!!

          {
            ClientMetadataService cms = this.clientMetadatService;
            if (cms != null) {
              cms.close();
            }
            HeapEvictor he = this.heapEvictor;
            if (he != null) {
              he.close();
            }
          }
        } catch (CancelException e) {
          // make sure the disk stores get closed
          closeDiskStores();
          closeHDFSStores();
          // NO DISTRIBUTED MESSAGING CAN BE DONE HERE!

          // okay, we're taking too long to do this stuff, so let's
          // be mean to other processes and skip the rest of the messaging
          // phase
          // [bruce] the following code is unnecessary since someone put the
          // same actions in a finally block
          // if (!this.closed) {
          // this.closed = true;
          // this.txMgr.close();
          // if (GemFireCache.instance == this) {
          // GemFireCache.instance = null;
          // }
          // ((DynamicRegionFactoryImpl)DynamicRegionFactory.get()).close();
          // }
        }

        // Close the CqService Handle.
        try {
          cqService.close();
        } catch (Exception ex) {
          logger.info(LocalizedMessage.create(LocalizedStrings.GemFireCache_FAILED_TO_GET_THE_CQSERVICE_TO_CLOSE_DURING_CACHE_CLOSE_2));
        }

        this.cachePerfStats.close();
        TXLockService.destroyServices();

        EventTracker.stopTrackerServices(this);

        synchronized (ccpTimerMutex) {
          if (this.ccpTimer != null) {
            this.ccpTimer.cancel();
          }
        }

        this.expirationScheduler.cancel();

        // Stop QueryMonitor if running.
        if (this.queryMonitor != null) {
          this.queryMonitor.stopMonitoring();
        }
        stopDiskStoreTaskPool();        

      } finally {
        // NO DISTRIBUTED MESSAGING CAN BE DONE HERE!
        if (this.txMgr != null) {
          this.txMgr.close();
        }
        ((DynamicRegionFactoryImpl) DynamicRegionFactory.get()).close();
        if (this.txMgr != null) {
          this.txMgr.resume(tx);
        }
        TXCommitMessage.getTracker().clearForCacheClose();
      }
      // Added to close the TransactionManager's cleanup thread
      TransactionManagerImpl.refresh();
      
      if (!keepDS) {
        // keepDS is used by ShutdownAll. It will override DISABLE_DISCONNECT_DS_ON_CACHE_CLOSE
        if (!DISABLE_DISCONNECT_DS_ON_CACHE_CLOSE) {
          this.system.disconnect();
        }
      }
      TypeRegistry.close();
      // do this late to prevent 43412
      TypeRegistry.setPdxSerializer(null);
      
      for (Iterator iter = cacheLifecycleListeners.iterator(); iter.hasNext();) {
        CacheLifecycleListener listener = (CacheLifecycleListener) iter.next();
        listener.cacheClosed(this);
      }      
      stopRestAgentServer();
      // Fix for #49856
      SequenceLoggerImpl.signalCacheClose();
      SystemFailure.signalCacheClose();
      
      SocketIOWithTimeout.stopSelectorCleanUpThread();
    } // static synchronization on GemFireCache.class

  }",False
"  private void cleanupConflationThreadPool() {
    conflationExecutor.shutdown();// Disable new tasks from being submitted
    
    try {
    if (!conflationExecutor.awaitTermination(1, TimeUnit.SECONDS)) {
      conflationExecutor.shutdownNow(); // Cancel currently executing tasks
      // Wait a while for tasks to respond to being cancelled
      if (!conflationExecutor.awaitTermination(1, TimeUnit.SECONDS))
        logger.warn(LocalizedMessage.create(LocalizedStrings.ParallelGatewaySenderQueue_COULD_NOT_TERMINATE_CONFLATION_THREADPOOL, this.sender));
    }
    } catch (InterruptedException e) {
      // (Re-)Cancel if current thread also interrupted
      conflationExecutor.shutdownNow();
      // Preserve interrupt status
      Thread.currentThread().interrupt();
    }
  }",True
"  private static void cleanupConflationThreadPool(AbstractGatewaySender sender) {
    conflationExecutor.shutdown();// Disable new tasks from being submitted
    
    try {
    if (!conflationExecutor.awaitTermination(1, TimeUnit.SECONDS)) {
      conflationExecutor.shutdownNow(); // Cancel currently executing tasks
      // Wait a while for tasks to respond to being cancelled
        if (!conflationExecutor.awaitTermination(1, TimeUnit.SECONDS)) {
          logger
              .warn(LocalizedMessage
                  .create(
                      LocalizedStrings.ParallelGatewaySenderQueue_COULD_NOT_TERMINATE_CONFLATION_THREADPOOL,
                      (sender == null ? ""all"" : sender)));
        }
    }
    } catch (InterruptedException e) {
      // (Re-)Cancel if current thread also interrupted
      conflationExecutor.shutdownNow();
      // Preserve interrupt status
      Thread.currentThread().interrupt();
    }
  }",False
"  public static void cleanUpStatics(AbstractGatewaySender sender) {
    if (buckToDispatchLock != null) {
      buckToDispatchLock = null;
    }
    if (regionToDispatchedKeysMapEmpty != null) {
      regionToDispatchedKeysMapEmpty = null;
    }
    regionToDispatchedKeysMap.clear();
    synchronized (ParallelGatewaySenderQueue.class) {
      if (removalThread != null) {
        removalThread.shutdown();
        removalThread = null;
      }
    }
    if (conflationExecutor != null) {
      cleanupConflationThreadPool(sender);
      conflationExecutor = null;
    }
  }",False
"  private static void cleanupConflationThreadPool(AbstractGatewaySender sender) {
    conflationExecutor.shutdown();// Disable new tasks from being submitted
    
    try {
    if (!conflationExecutor.awaitTermination(1, TimeUnit.SECONDS)) {
      conflationExecutor.shutdownNow(); // Cancel currently executing tasks
      // Wait a while for tasks to respond to being cancelled
        if (!conflationExecutor.awaitTermination(1, TimeUnit.SECONDS)) {
          logger
              .warn(LocalizedMessage
                  .create(
                      LocalizedStrings.ParallelGatewaySenderQueue_COULD_NOT_TERMINATE_CONFLATION_THREADPOOL,
                      (sender == null ? ""all"" : sender)));
        }
    }
    } catch (InterruptedException e) {
      // (Re-)Cancel if current thread also interrupted",False
"  public void cleanUp() {
    if(buckToDispatchLock != null){
      this.buckToDispatchLock = null;
    }
    if(regionToDispatchedKeysMapEmpty != null) {
      this.regionToDispatchedKeysMapEmpty = null;
    }
    this.regionToDispatchedKeysMap.clear();
    synchronized (ParallelGatewaySenderQueue.class) {
      if (this.removalThread != null) {
        this.removalThread.shutdown();
        this.removalThread = null;
      }
    }
    if (conflationExecutor != null) {
      cleanupConflationThreadPool();
      this.conflationExecutor = null;
    }
  }",True
"  public void cleanUp() {
    cleanUpStatics(this.sender);
  }",False
"  protected AsyncInvocation doAsyncPuts(VM vm, final String regionName,
      final int start, final int end, final String suffix) throws Exception {
    return doAsyncPuts(vm, regionName, start, end, suffix, """");
  }",True
"  protected AsyncInvocation doAsyncPuts(VM vm, final String regionName,
      final int start, final int end, final String suffix, final String value)
      throws Exception {
    return vm.invokeAsync(new SerializableCallable(""doAsyncPuts"") {
      public Object call() throws Exception {
        Region r = getRootRegion(regionName);
        String v = ""V"";
        if (!value.equals("""")) {
          v = value;
        }
        logger.info(""Putting entries "");
        for (int i = start; i < end; i++) {
          r.put(""K"" + i, v + i + suffix);
        }
        return null;
      }

    });
  }",False
"  public void testWOTimeForRollOverParam() throws Throwable {
    disconnectFromDS();
    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    String homeDir = ""./testWOTimeForRollOverParam"";
    final String uniqueName = getName();

    createServerRegion(vm0, 1, 1,  500, homeDir, uniqueName, 5, true, false, 4, 1);
    createServerRegion(vm1, 1, 1,  500, homeDir, uniqueName, 5, true, false, 4, 1);

    AsyncInvocation a1 = doAsyncPuts(vm0, uniqueName, 1, 8, ""vm0"");
    AsyncInvocation a2 = doAsyncPuts(vm1, uniqueName, 4, 10, ""vm1"");

    a1.join();
    a2.join();

    Thread.sleep(8000);

    a1 = doAsyncPuts(vm0, uniqueName, 10, 18, ""vm0"");
    a2 = doAsyncPuts(vm1, uniqueName, 14, 20, ""vm1"");

    a1.join();
    a2.join();

    Thread.sleep(8000);

    cacheClose(vm0, false);
    cacheClose(vm1, false);

    AsyncInvocation async1 = createServerRegionAsync(vm0, 1, 1,  500, homeDir, uniqueName, 5, true, false, 4, 1);
    AsyncInvocation async2 = createServerRegionAsync(vm1, 1, 1,  500, homeDir, uniqueName, 5, true, false, 4, 1);
    async1.getResult();
    async2.getResult();

    // There should be two files in bucket 0.
    // Each should have entry 1 to 10 and duplicate from 4 to 7
    verifyTwoHDFSFiles(vm0, uniqueName);

    cacheClose(vm0, false);
    cacheClose(vm1, false);

    disconnectFromDS();

  }",True
"  public void testWOTimeForRollOverParam() throws Throwable {
    disconnectFromDS();
    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    String homeDir = ""./testWOTimeForRollOverParam"";
    final String uniqueName = getName();

    createServerRegion(vm0, 1, 1, 500, homeDir, uniqueName, 5, true, false, 5, 1);
    createServerRegion(vm1, 1, 1, 500, homeDir, uniqueName, 5, true, false, 5, 1);

    AsyncInvocation a1 = doAsyncPuts(vm0, uniqueName, 1, 8, ""vm0"");
    AsyncInvocation a2 = doAsyncPuts(vm1, uniqueName, 4, 10, ""vm1"");

    a1.join();
    a2.join();

    Thread.sleep(7000);

    a1 = doAsyncPuts(vm0, uniqueName, 10, 18, ""vm0"");
    a2 = doAsyncPuts(vm1, uniqueName, 14, 20, ""vm1"");

    a1.join();
    a2.join();

    Thread.sleep(7000);

    cacheClose(vm0, false);
    cacheClose(vm1, false);

    AsyncInvocation async1 = createServerRegionAsync(vm0, 1, 1, 500, homeDir, uniqueName, 5, true, false, 5, 1);
    AsyncInvocation async2 = createServerRegionAsync(vm1, 1, 1, 500, homeDir, uniqueName, 5, true, false, 5, 1);
    async1.getResult();
    async2.getResult();

    // There should be two files in bucket 0.
    // Each should have entry 1 to 10 and duplicate from 4 to 7
    verifyTwoHDFSFiles(vm0, uniqueName);

    cacheClose(vm0, false);
    cacheClose(vm1, false);

    disconnectFromDS();

  }",False
"  protected SerializableCallable getCreateRegionCallable(
      final int totalnumOfBuckets, final int batchSizeMB,
      final int maximumEntries, final String folderPath,
      final String uniqueName, final int batchInterval,
      final boolean queuePersistent, final boolean writeonly,
      final long timeForRollover, final long maxFileSize) {
    SerializableCallable createRegion = new SerializableCallable() {
      public Object call() throws Exception {
        AttributesFactory af = new AttributesFactory();
        af.setDataPolicy(DataPolicy.HDFS_PARTITION);
        PartitionAttributesFactory paf = new PartitionAttributesFactory();
        paf.setTotalNumBuckets(totalnumOfBuckets);
        paf.setRedundantCopies(1);

        af.setHDFSStoreName(uniqueName);

        af.setPartitionAttributes(paf.create());
        HDFSStoreFactory hsf = getCache().createHDFSStoreFactory();
        // Going two level up to avoid home directories getting created in
        // VM-specific directory. This avoids failures in those tests where
        // datastores are restarted and bucket ownership changes between VMs.
        homeDir = new File(tmpDir + ""/../../"" + folderPath).getCanonicalPath();
        logger.info(""Setting homeDir to {}"", homeDir);
        hsf.setHomeDir(homeDir);
        hsf.setBatchSize(batchSizeMB);
        hsf.setBufferPersistent(queuePersistent);
        hsf.setMaxMemory(3);
        hsf.setBatchInterval(batchInterval);
        if (timeForRollover != -1) {
          hsf.setWriteOnlyFileRolloverInterval((int) timeForRollover);
          System.setProperty(""gemfire.HDFSRegionDirector.FILE_ROLLOVER_TASK_INTERVAL_SECONDS"", ""1"");
        }
        if (maxFileSize != -1) {
          hsf.setWriteOnlyFileRolloverSize((int) maxFileSize);
        }
        hsf.create(uniqueName);

        af.setEvictionAttributes(EvictionAttributes.createLRUEntryAttributes(maximumEntries, EvictionAction.LOCAL_DESTROY));

        af.setHDFSWriteOnly(writeonly);
        Region r = createRootRegion(uniqueName, af.create());
        ((LocalRegion) r).setIsTest();

        return 0;
      }
    };
    return createRegion;
  }",True
"  protected SerializableCallable getCreateRegionCallable(
      final int totalnumOfBuckets, final int batchSizeMB,
      final int maximumEntries, final String folderPath,
      final String uniqueName, final int batchInterval,
      final boolean queuePersistent, final boolean writeonly,
      final long timeForRollover, final long maxFileSize) {
    SerializableCallable createRegion = new SerializableCallable(""Create HDFS region"") {
      public Object call() throws Exception {
        AttributesFactory af = new AttributesFactory();
        af.setDataPolicy(DataPolicy.HDFS_PARTITION);
        PartitionAttributesFactory paf = new PartitionAttributesFactory();
        paf.setTotalNumBuckets(totalnumOfBuckets);
        paf.setRedundantCopies(1);

        af.setHDFSStoreName(uniqueName);
        af.setPartitionAttributes(paf.create());

        HDFSStoreFactory hsf = getCache().createHDFSStoreFactory();
        // Going two level up to avoid home directories getting created in
        // VM-specific directory. This avoids failures in those tests where
        // datastores are restarted and bucket ownership changes between VMs.
        homeDir = new File(tmpDir + ""/../../"" + folderPath).getCanonicalPath();
        logger.info(""Setting homeDir to {}"", homeDir);
        hsf.setHomeDir(homeDir);
        hsf.setBatchSize(batchSizeMB);
        hsf.setBufferPersistent(queuePersistent);
        hsf.setMaxMemory(3);
        hsf.setBatchInterval(batchInterval);
        if (timeForRollover != -1) {
          hsf.setWriteOnlyFileRolloverInterval((int) timeForRollover);
          System.setProperty(""gemfire.HDFSRegionDirector.FILE_ROLLOVER_TASK_INTERVAL_SECONDS"", ""1"");
        }
        if (maxFileSize != -1) {
          hsf.setWriteOnlyFileRolloverSize((int) maxFileSize);
        }
        hsf.create(uniqueName);

        af.setEvictionAttributes(EvictionAttributes.createLRUEntryAttributes(maximumEntries, EvictionAction.LOCAL_DESTROY));

        af.setHDFSWriteOnly(writeonly);
        Region r = createRootRegion(uniqueName, af.create());
        ((LocalRegion) r).setIsTest();

        return 0;
      }
    };
    return createRegion;
  }",False
"  public void tearDown2() throws Exception {
    SerializableRunnable checkOrphans = new SerializableRunnable() {

      @Override
      public void run() {
        if(hasCache()) {
          OffHeapTestUtil.checkOrphans();
        }
      }
    };
    checkOrphans.run();
    invokeInEveryVM(checkOrphans);
    super.tearDown2();
  }",True
"  public void tearDown2() throws Exception {
    SerializableRunnable checkOrphans = new SerializableRunnable() {

      @Override
      public void run() {
        if(hasCache()) {
          OffHeapTestUtil.checkOrphans();
        }
      }
    };
    try {
      checkOrphans.run();
      invokeInEveryVM(checkOrphans);
    } finally {
      // proceed with tearDown2 anyway.
      super.tearDown2();
    }
  }",False
" protected SerializableCallable validateEmpty(VM vm0, final int numEntries, final String uniqueName) {
    SerializableCallable validateEmpty = new SerializableCallable(""validate"") {
      public Object call() throws Exception {
        Region r = getRootRegion(uniqueName);
        
        assertTrue(r.isEmpty());
        
        //validate region is empty on peer as well
        assertFalse(r.entrySet().iterator().hasNext());
        //Make sure the region is empty
        for (int i =0; i< numEntries; i++) {
          assertEquals(""failure on key K"" + i , null, r.get(""K"" + i));
        }
        
        return null;
      }
    };
    
    vm0.invoke(validateEmpty);
    return validateEmpty;
  }",True
" protected SerializableCallable validateEmpty(VM vm0, final int numEntries, final String uniqueName) {
    SerializableCallable validateEmpty = new SerializableCallable(""validateEmpty"") {
      public Object call() throws Exception {
        Region r = getRootRegion(uniqueName);
        
        assertTrue(r.isEmpty());
        
        //validate region is empty on peer as well
        assertFalse(r.entrySet().iterator().hasNext());
        //Make sure the region is empty
        for (int i =0; i< numEntries; i++) {
          assertEquals(""failure on key K"" + i , null, r.get(""K"" + i));
        }
        
        return null;
      }
    };
    
    vm0.invoke(validateEmpty);
    return validateEmpty;
  }",False
"  public SerializableCallable cleanUpStoresAndDisconnect() throws Exception {
    SerializableCallable cleanUp = new SerializableCallable() {
      public Object call() throws Exception {
        File file;
        if (homeDir != null) {
          file = new File(homeDir);
          FileUtil.delete(file);
          homeDir = null;
        }
        file = new File(tmpDir);
        FileUtil.delete(file);
        disconnectFromDS();
        return 0;
      }
    };
    return cleanUp;
  }",True
"  public SerializableCallable cleanUpStoresAndDisconnect() throws Exception {
    SerializableCallable cleanUp = new SerializableCallable(""cleanUpStoresAndDisconnect"") {
      public Object call() throws Exception {
        disconnectFromDS();
        File file;
        if (homeDir != null) {
          file = new File(homeDir);
          FileUtil.delete(file);
          homeDir = null;
        }
        file = new File(tmpDir);
        FileUtil.delete(file);
        return 0;
      }
    };
    return cleanUp;
  }",False
"  public TransactionId suspend() {
    TXStateProxy result = getTXState();
    if (result != null) {
      TransactionId txId = result.getTransactionId();
      internalSuspend();
      this.suspendedTXs.put(txId, result);
      // wake up waiting threads
      Queue<Thread> waitingThreads = this.waitMap.get(txId);
      if (waitingThreads != null) {
        Thread waitingThread = null;
        while (true) {
          waitingThread = waitingThreads.poll();
          if (waitingThread == null
              || !Thread.currentThread().equals(waitingThread)) {
            break;
          }
        }
        if (waitingThread != null) {
          LockSupport.unpark(waitingThread);
        }
      }
      scheduleExpiry(txId);
      return txId;
    }
    return null;
  }",True
"  TransactionId suspend(TimeUnit expiryTimeUnit) {
    TXStateProxy result = getTXState();
    if (result != null) {
      TransactionId txId = result.getTransactionId();
      internalSuspend();
      this.suspendedTXs.put(txId, result);
      // wake up waiting threads
      Queue<Thread> waitingThreads = this.waitMap.get(txId);
      if (waitingThreads != null) {
        Thread waitingThread = null;
        while (true) {
          waitingThread = waitingThreads.poll();
          if (waitingThread == null
              || !Thread.currentThread().equals(waitingThread)) {
            break;
          }
        }
        if (waitingThread != null) {
          LockSupport.unpark(waitingThread);
        }
      }
      scheduleExpiry(txId, expiryTimeUnit);
      return txId;
    }
    return null;
  }",False
"  public TransactionId suspend() {
    return suspend(TimeUnit.MINUTES);
  }",False
"  private void scheduleExpiry(TransactionId txId) {
    final GemFireCacheImpl cache = (GemFireCacheImpl) this.cache;
    if (suspendedTXTimeout < 0) {
      if (logger.isDebugEnabled()) {
        logger.debug(""TX: transaction: {} not scheduled to expire"", txId);
      }
      return;
    }
    SystemTimerTask task = new TXExpiryTask(txId);
    if (logger.isDebugEnabled()) {
      logger.debug(""TX: scheduling transaction: {} to expire after:{}"", txId, suspendedTXTimeout);
    }
    cache.getCCPTimer().schedule(task, suspendedTXTimeout*60*1000);
    this.expiryTasks.put(txId, task);
  }",True
"  /**
   * schedules the transaction to expire after {@link #suspendedTXTimeout}
   * @param txId
   * @param expiryTimeUnit the time unit to use when scheduling the expiration
   */
  private void scheduleExpiry(TransactionId txId, TimeUnit expiryTimeUnit) {
    final GemFireCacheImpl cache = (GemFireCacheImpl) this.cache;
    if (suspendedTXTimeout < 0) {
      if (logger.isDebugEnabled()) {
        logger.debug(""TX: transaction: {} not scheduled to expire"", txId);
      }
      return;
    }
    SystemTimerTask task = new TXExpiryTask(txId);
    if (logger.isDebugEnabled()) {",False
"  private void scheduleExpiry(TransactionId txId, TimeUnit expiryTimeUnit) {
    final GemFireCacheImpl cache = (GemFireCacheImpl) this.cache;
    if (suspendedTXTimeout < 0) {
      if (logger.isDebugEnabled()) {
        logger.debug(""TX: transaction: {} not scheduled to expire"", txId);
      }
      return;
    }
    SystemTimerTask task = new TXExpiryTask(txId);
    if (logger.isDebugEnabled()) {
      logger.debug(""TX: scheduling transaction: {} to expire after:{}"", txId, suspendedTXTimeout);
    }
    cache.getCCPTimer().schedule(task, TimeUnit.MILLISECONDS.convert(suspendedTXTimeout, expiryTimeUnit));
    this.expiryTasks.put(txId, task);
  }",False
"  public void testClientCommitsWithPutAllAndRI() throws Exception {
	    Host host = Host.getHost(0);
	    VM accessor = host.getVM(0);
	    VM datastore = host.getVM(1);
	    VM client = host.getVM(2);
	    
	    initAccessorAndDataStore(accessor, datastore, 0);
	    int port = startServer(accessor);
	    
	    createClientRegion(client, port, false, true);
	    
	    datastore.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region custRegion = getCache().getRegion(CUSTOMER);
	        custRegion.getAttributesMutator().addCacheListener(new ClientListener());
	        return null;
	      }
	    });
	    
	    
	    client.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//	        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//	        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
	        CustId custId = new CustId(1);
//	        OrderId orderId = new OrderId(1, custId);
	        getCache().getCacheTransactionManager().begin();
	        Map map = new HashMap();
	        map.put(custId, new Customer(""foo"", ""bar""));
	        custRegion.putAll(map);
//	        orderRegion.put(orderId, new Order(""fooOrder""));
//	        refRegion.put(custId, new Customer(""foo"", ""bar""));
	        getCache().getCacheTransactionManager().commit();
	        return null;
	      }
	    });
	    
	    Thread.sleep(10000);
	    client.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//	        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//	        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
	        ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
	        getCache().getLogger().info(""SWAP:CLIENTinvoked:""+cl.invoked);
	        assertTrue(cl.invoked);
	        assertTrue(cl.putAllOp);
	        assertFalse(cl.isOriginRemote);
	        assertEquals(""it should be 1 but its:""+cl.invokeCount,1,cl.invokeCount);
	        return null;
	      }
	    });
	  }",True
"	    VM datastore = host.getVM(1);
	    VM client = host.getVM(2);
	    
	    initAccessorAndDataStore(accessor, datastore, 0);
	    int port = startServer(accessor);
	    
	    createClientRegion(client, port, false, true);
	    
	    datastore.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region custRegion = getCache().getRegion(CUSTOMER);
	        custRegion.getAttributesMutator().addCacheListener(new ClientListener());
	        return null;
	      }
	    });
	    
	    
	    client.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//	        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//	        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
	        CustId custId = new CustId(1);
//	        OrderId orderId = new OrderId(1, custId);
	        getCache().getCacheTransactionManager().begin();
	        Map map = new HashMap();
	        map.put(custId, new Customer(""foo"", ""bar""));
	        custRegion.putAll(map);
//	        orderRegion.put(orderId, new Order(""fooOrder""));
//	        refRegion.put(custId, new Customer(""foo"", ""bar""));
	        getCache().getCacheTransactionManager().commit();
	        return null;
	      }
	    });
	    
	    client.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//	        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//	        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
	        ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
	        assertTrue(cl.invoked);
	        assertTrue(cl.putAllOp);
	        assertFalse(cl.isOriginRemote);
	        assertEquals(""it should be 1 but its:""+cl.invokeCount,1,cl.invokeCount);
	        return null;
	      }
	    });
	  }
  
  
  public void testClientRollsbackWithPutAllAndRI() throws Exception {
	    Host host = Host.getHost(0);
	    VM accessor = host.getVM(0);",False
"  private void doTxWithPRAccessor(final boolean commit) {
    Host host = Host.getHost(0);
    VM server1 = host.getVM(0);
    VM server2 = host.getVM(1);
    VM client = host.getVM(2);
    
    final int port1 = createRegionsAndStartServer(server1, true);
    createRegionOnServer(server2);
    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        ClientCacheFactory ccf = new ClientCacheFactory();
        ccf.addPoolServer(""localhost""/*getServerHostName(Host.getHost(0))*/, port1);
        ccf.setPoolSubscriptionEnabled(false);
        ccf.set(""log-level"", getDUnitLogLevel());
        ClientCache cCache = getClientCache(ccf);
        ClientRegionFactory<CustId, Customer> custrf = cCache
            .createClientRegionFactory(ClientRegionShortcut.PROXY);
        ClientRegionFactory<Integer, String> refrf = cCache
        .createClientRegionFactory(ClientRegionShortcut.PROXY);
        Region<Integer, String> r = refrf.create(D_REFERENCE);
        Region<CustId, Customer> pr = custrf.create(CUSTOMER);
//        Region<Integer, String> order = refrf.create(ORDER);
        
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        mgr.begin();
        for (int i=0; i<10; i++) {
          CustId custId = new CustId(i);
          Customer cust = new Customer(""name""+i, ""address""+i);
          pr.put(custId, cust);
          r.put(i, ""value""+i);
          Thread.sleep(100);
        }
        return null;
      }
    });
    
    SerializableCallable countActiveTx = new SerializableCallable() {
      public Object call() throws Exception {
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        return mgr.hostedTransactionsInProgressForTest();
      }
    };
    
    int serv1TxCount = (Integer) server1.invoke(countActiveTx);
    int serv2TxCount = (Integer) server2.invoke(countActiveTx);
    
    assertEquals(2, serv1TxCount + serv2TxCount);
    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        Region<Integer, String> r = getGemfireCache().getRegion(D_REFERENCE);
        Region<CustId, Customer> pr = getGemfireCache().getRegion(CUSTOMER);
        if (commit) {
          mgr.commit();
          for (int i=0;i<10;i++) {
            assertEquals(new Customer(""name""+i, ""address""+i), pr.get(new CustId(i)));
            assertEquals(""value""+i, r.get(i));
          }
        } else {
          mgr.rollback();
          for (int i=0;i<10;i++) {
            assertNull(pr.get(new CustId(i)));
            assertNull(r.get(i));
          }
        }
        return null;
      }
    });
    
    serv1TxCount = (Integer) server1.invoke(countActiveTx);
    serv2TxCount = (Integer) server2.invoke(countActiveTx);
    assertEquals(0, serv1TxCount + serv2TxCount);
  }",True
"      public Object call() throws Exception {
        ClientCacheFactory ccf = new ClientCacheFactory();
        ccf.addPoolServer(""localhost""/*getServerHostName(Host.getHost(0))*/, port1);
        ccf.setPoolSubscriptionEnabled(false);
        ccf.set(""log-level"", getDUnitLogLevel());
        ClientCache cCache = getClientCache(ccf);
        ClientRegionFactory<CustId, Customer> custrf = cCache
            .createClientRegionFactory(ClientRegionShortcut.PROXY);
        ClientRegionFactory<Integer, String> refrf = cCache
        .createClientRegionFactory(ClientRegionShortcut.PROXY);
        Region<Integer, String> r = refrf.create(D_REFERENCE);
        Region<CustId, Customer> pr = custrf.create(CUSTOMER);
//        Region<Integer, String> order = refrf.create(ORDER);
        
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        mgr.begin();
        for (int i=0; i<10; i++) {
          CustId custId = new CustId(i);
          Customer cust = new Customer(""name""+i, ""address""+i);
          pr.put(custId, cust);
          r.put(i, ""value""+i);
        }
        return null;
      }
    });
    
    SerializableCallable countActiveTx = new SerializableCallable() {
      public Object call() throws Exception {
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        return mgr.hostedTransactionsInProgressForTest();
      }
    };
    
    int serv1TxCount = (Integer) server1.invoke(countActiveTx);
    int serv2TxCount = (Integer) server2.invoke(countActiveTx);
    
    assertEquals(2, serv1TxCount + serv2TxCount);
    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        Region<Integer, String> r = getGemfireCache().getRegion(D_REFERENCE);
        Region<CustId, Customer> pr = getGemfireCache().getRegion(CUSTOMER);
        if (commit) {
          mgr.commit();
          for (int i=0;i<10;i++) {
            assertEquals(new Customer(""name""+i, ""address""+i), pr.get(new CustId(i)));
            assertEquals(""value""+i, r.get(i));
          }
        } else {
          mgr.rollback();
          for (int i=0;i<10;i++) {
            assertNull(pr.get(new CustId(i)));
            assertNull(r.get(i));
          }
        }
        return null;
      }
    });
    
    serv1TxCount = (Integer) server1.invoke(countActiveTx);
    serv2TxCount = (Integer) server2.invoke(countActiveTx);
    assertEquals(0, serv1TxCount + serv2TxCount);
  }
  
  /**
   * there is one txState and zero or more txProxyStates
   * @throws Exception
   */
  public void testConnectionAffinity() throws Exception {
    Host host = Host.getHost(0);
    VM server1 = host.getVM(0);
    VM server2 = host.getVM(1);
    VM client = host.getVM(2);
    ",False
"  public void testClientRollsbackWithPutAllAndRI() throws Exception {
	    Host host = Host.getHost(0);
	    VM accessor = host.getVM(0);
	    VM datastore = host.getVM(1);
	    VM client = host.getVM(2);
	    
	    initAccessorAndDataStore(accessor, datastore, 0);
	    int port = startServer(accessor);
	    
	    createClientRegion(client, port, false, true);
	    
	    datastore.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region custRegion = getCache().getRegion(CUSTOMER);
	        custRegion.getAttributesMutator().addCacheListener(new ClientListener());
	        return null;
	      }
	    });
	    
	    
	    client.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//	        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//	        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
	        CustId custId = new CustId(1);
//	        OrderId orderId = new OrderId(1, custId);
	        getCache().getCacheTransactionManager().begin();
	        Map map = new HashMap();
	        map.put(custId, new Customer(""foo"", ""bar""));
	        custRegion.putAll(map);
//	        orderRegion.put(orderId, new Order(""fooOrder""));
//	        refRegion.put(custId, new Customer(""foo"", ""bar""));
	        getCache().getCacheTransactionManager().rollback();
	        return null;
	      }
	    });
	    
	    Thread.sleep(10000);
	    client.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//	        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//	        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
	        ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
	        getCache().getLogger().info(""SWAP:CLIENTinvoked:""+cl.invoked);
	        assertTrue(!cl.invoked);
	        assertTrue(!cl.putAllOp);
	        assertEquals(""it should be 0 but its:""+cl.invokeCount,0,cl.invokeCount);
	        return null;
	      }
	    });
	  }",True
"	    
	    initAccessorAndDataStore(accessor, datastore, 0);
	    int port = startServer(accessor);
	    
	    createClientRegion(client, port, false, true);
	    
	    datastore.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region custRegion = getCache().getRegion(CUSTOMER);
	        custRegion.getAttributesMutator().addCacheListener(new ClientListener());
	        return null;
	      }
	    });
	    
	    
	    client.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//	        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//	        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
	        CustId custId = new CustId(1);
//	        OrderId orderId = new OrderId(1, custId);
	        getCache().getCacheTransactionManager().begin();
	        Map map = new HashMap();
	        map.put(custId, new Customer(""foo"", ""bar""));
	        custRegion.putAll(map);
//	        orderRegion.put(orderId, new Order(""fooOrder""));
//	        refRegion.put(custId, new Customer(""foo"", ""bar""));
	        getCache().getCacheTransactionManager().rollback();
	        return null;
	      }
	    });
	    
	    client.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//	        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//	        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
	        ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
	        getCache().getLogger().info(""SWAP:CLIENTinvoked:""+cl.invoked);
	        assertTrue(!cl.invoked);
	        assertTrue(!cl.putAllOp);
	        assertEquals(""it should be 0 but its:""+cl.invokeCount,0,cl.invokeCount);
	        return null;
	      }
	    });
	  }
  
  public void testClientInitiatedInvalidates() throws Exception {
    Host host = Host.getHost(0);
    VM accessor = host.getVM(0);
    VM datastore = host.getVM(1);
    VM client = host.getVM(2);",False
"  public void testClientInitiatedInvalidates() throws Exception {
    Host host = Host.getHost(0);
    VM accessor = host.getVM(0);
    VM datastore = host.getVM(1);
    VM client = host.getVM(2);
    
    initAccessorAndDataStore(accessor, datastore, 0);
    int port = startServer(accessor);
    
    createClientRegion(client, port, false, true);
    
    datastore.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region custRegion = getCache().getRegion(CUSTOMER);
        custRegion.getAttributesMutator().addCacheListener(new ClientListener());
        return null;
      }
    });
    
    
    /*
     * Test a no-op commit: put/invalidate
     */
    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        CustId custId = new CustId(1777777777);
        getCache().getCacheTransactionManager().begin();
        custRegion.put(custId, new Customer(""foo"", ""bar""));
        custRegion.invalidate(custId);
//        orderRegion.put(orderId, new Order(""fooOrder""));
//        refRegion.put(custId, new Customer(""foo"", ""bar""));
        getCache().getCacheTransactionManager().commit();
        return null;
      }
    });
    
    Thread.sleep(10000);
    
    
    /*
     * Validate nothing came through
     */
    client.invoke(new SerializableCallable() {
        public Object call() throws Exception {
      	  Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//            Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//            Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
            ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
            getCache().getLogger().info(""SWAP:CLIENTinvoked:""+cl.invoked);
            assertTrue(cl.invoked);
            assertEquals(1,cl.putCount);
            assertEquals(1,cl.invokeCount);
            assertEquals(0, cl.invalidateCount);
            CustId custId = new CustId(1777777777);
            assertTrue(custRegion.containsKey(custId));
            assertTrue(!custRegion.containsValueForKey(custId));
            cl.reset();
            return null;
          }
        });
    
    datastore.invoke(new SerializableCallable() {
        public Object call() throws Exception {
      	  Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//            Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//            Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
            ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
            getCache().getLogger().info(""SWAP:CLIENTinvoked:""+cl.invoked);
            assertTrue(cl.invoked);
            assertEquals(1,cl.putCount);
            assertEquals(1,cl.invokeCount);
            CustId custId = new CustId(1777777777);
            assertTrue(custRegion.containsKey(custId));
            assertTrue(!custRegion.containsValueForKey(custId));
            cl.reset();
            return null;
          }
        });
    
    /*
     * Ok lets do a put in tx, then an invalidate in a another tx and make sure it invalidates on client and server
     */
    
    client.invoke(doAPutInTx);
    client.invoke(doAnInvalidateInTx);
    Thread.sleep(10000);
    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
    	  Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//          Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//          Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
          ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
          getCache().getLogger().info(""SWAP:CLIENTinvoked:""+cl.invoked);
          assertTrue(cl.invoked);
          assertEquals(""totalEvents should be 2 but its:""+cl.invokeCount,2,cl.invokeCount);
          assertEquals(""it should be 1 but its:""+cl.invalidateCount,1,cl.invalidateCount);
          assertEquals(""it should be 1 but its:""+cl.putCount,1,cl.putCount);
          CustId custId = new CustId(1);
          assertTrue(custRegion.containsKey(custId));
          assertFalse(custRegion.containsValueForKey(custId));
          return null;
        }
      });
    
    datastore.invoke(new SerializableCallable() {
        public Object call() throws Exception {
      	  Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//            Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//            Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
            ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
            getCache().getLogger().info(""SWAP:CLIENTinvoked:""+cl.invoked);
            assertTrue(cl.invoked);
            assertEquals(""totalEvents should be 2 but its:""+cl.invokeCount,2,cl.invokeCount);
            assertEquals(""it should be 1 but its:""+cl.invalidateCount,1,cl.invalidateCount);
            assertEquals(""it should be 1 but its:""+cl.putCount,1,cl.putCount);
            return null;
          }
        });
      
    
    
    
  }",True
"    initAccessorAndDataStore(accessor, datastore, 0);
    int port = startServer(accessor);
    
    createClientRegion(client, port, false, true);
    
    datastore.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region custRegion = getCache().getRegion(CUSTOMER);
        custRegion.getAttributesMutator().addCacheListener(new ClientListener());
        return null;
      }
    });
    
    
    /*
     * Test a no-op commit: put/invalidate
     */
    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        CustId custId = new CustId(1777777777);
        getCache().getCacheTransactionManager().begin();
        custRegion.put(custId, new Customer(""foo"", ""bar""));
        custRegion.invalidate(custId);
//        orderRegion.put(orderId, new Order(""fooOrder""));
//        refRegion.put(custId, new Customer(""foo"", ""bar""));
        getCache().getCacheTransactionManager().commit();
        return null;
      }
    });
    
    /*
     * Validate nothing came through
     */
    client.invoke(new SerializableCallable() {
        public Object call() throws Exception {
      	  Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//            Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//            Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
            ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
            getCache().getLogger().info(""SWAP:CLIENTinvoked:""+cl.invoked);
            assertTrue(cl.invoked);
            assertEquals(1,cl.putCount);
            assertEquals(1,cl.invokeCount);
            assertEquals(0, cl.invalidateCount);
            CustId custId = new CustId(1777777777);
            assertTrue(custRegion.containsKey(custId));
            assertTrue(!custRegion.containsValueForKey(custId));
            cl.reset();
            return null;
          }
        });
    
    datastore.invoke(new SerializableCallable() {
        public Object call() throws Exception {
      	  Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//            Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//            Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
            ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
            getCache().getLogger().info(""SWAP:CLIENTinvoked:""+cl.invoked);
            assertTrue(cl.invoked);
            assertEquals(1,cl.putCount);
            assertEquals(1,cl.invokeCount);
            CustId custId = new CustId(1777777777);
            assertTrue(custRegion.containsKey(custId));
            assertTrue(!custRegion.containsValueForKey(custId));
            cl.reset();
            return null;
          }
        });
    
    /*
     * Ok lets do a put in tx, then an invalidate in a another tx and make sure it invalidates on client and server
     */
    
    client.invoke(doAPutInTx);
    client.invoke(doAnInvalidateInTx);
    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
    	  Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//          Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//          Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
          ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
          getCache().getLogger().info(""SWAP:CLIENTinvoked:""+cl.invoked);
          assertTrue(cl.invoked);
          assertEquals(""totalEvents should be 2 but its:""+cl.invokeCount,2,cl.invokeCount);
          assertEquals(""it should be 1 but its:""+cl.invalidateCount,1,cl.invalidateCount);
          assertEquals(""it should be 1 but its:""+cl.putCount,1,cl.putCount);
          CustId custId = new CustId(1);
          assertTrue(custRegion.containsKey(custId));
          assertFalse(custRegion.containsValueForKey(custId));
          return null;
        }
      });
    
    datastore.invoke(new SerializableCallable() {
        public Object call() throws Exception {
      	  Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//            Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//            Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
            ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
            getCache().getLogger().info(""SWAP:CLIENTinvoked:""+cl.invoked);
            assertTrue(cl.invoked);
            assertEquals(""totalEvents should be 2 but its:""+cl.invokeCount,2,cl.invokeCount);
            assertEquals(""it should be 1 but its:""+cl.invalidateCount,1,cl.invalidateCount);
            assertEquals(""it should be 1 but its:""+cl.putCount,1,cl.putCount);
            return null;
          }
        });
      
    
    
    
  }
  
  
  
  SerializableCallable validateNoEvents = new SerializableCallable() {
      public Object call() throws Exception {
    	  Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//          Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//          Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
          ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
          getCache().getLogger().info(""SWAP:CLIENTinvoked:""+cl.invoked);",False
"public void testClientCommitAndDataStoreGetsEvent() throws Exception {
    Host host = Host.getHost(0);
    VM accessor = host.getVM(0);
    VM datastore = host.getVM(1);
    VM client = host.getVM(2);
    
    initAccessorAndDataStore(accessor, datastore, 0);
    int port = startServer(accessor);
    
    createClientRegion(client, port, false, true);
    
    datastore.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region custRegion = getCache().getRegion(CUSTOMER);
        custRegion.getAttributesMutator().addCacheListener(new ServerListener());
        return null;
      }
    });
    
    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        CustId custId = new CustId(1);
//        OrderId orderId = new OrderId(1, custId);
        getCache().getCacheTransactionManager().begin();
        custRegion.put(custId, new Customer(""foo"", ""bar""));
//        orderRegion.put(orderId, new Order(""fooOrder""));
//        refRegion.put(custId, new Customer(""foo"", ""bar""));
        getCache().getCacheTransactionManager().commit();
        return null;
      }
    });
    
    Thread.sleep(10000);
    datastore.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        ServerListener l = (ServerListener) custRegion.getAttributes().getCacheListeners()[0];
        getCache().getLogger().info(""SWAP:CLIENTinvoked:""+l.invoked);
        assertTrue(l.invoked);
        return null;
      }
    });
  }",True
"  }

public void testClientCommitAndDataStoreGetsEvent() throws Exception {
    Host host = Host.getHost(0);
    VM accessor = host.getVM(0);
    VM datastore = host.getVM(1);
    VM client = host.getVM(2);
    
    initAccessorAndDataStore(accessor, datastore, 0);
    int port = startServer(accessor);
    
    createClientRegion(client, port, false, true);
    
    datastore.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region custRegion = getCache().getRegion(CUSTOMER);
        custRegion.getAttributesMutator().addCacheListener(new ServerListener());
        return null;
      }
    });
    
    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        CustId custId = new CustId(1);
//        OrderId orderId = new OrderId(1, custId);
        getCache().getCacheTransactionManager().begin();
        custRegion.put(custId, new Customer(""foo"", ""bar""));
//        orderRegion.put(orderId, new Order(""fooOrder""));
//        refRegion.put(custId, new Customer(""foo"", ""bar""));
        getCache().getCacheTransactionManager().commit();
        return null;
      }
    });
    
    datastore.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        ServerListener l = (ServerListener) custRegion.getAttributes().getCacheListeners()[0];
        getCache().getLogger().info(""SWAP:CLIENTinvoked:""+l.invoked);
        assertTrue(l.invoked);
        return null;
      }
    });",False
"  public void testClientCommitsWithRIAndOnlyGetsOneEvent() throws Exception {
    Host host = Host.getHost(0);
    VM accessor = host.getVM(0);
    VM datastore = host.getVM(1);
    VM client = host.getVM(2);
    
    initAccessorAndDataStore(accessor, datastore, 0);
    int port = startServer(accessor);
    
    createClientRegion(client, port, false, true);
    
    datastore.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region custRegion = getCache().getRegion(CUSTOMER);
        custRegion.getAttributesMutator().addCacheListener(new ClientListener());
        return null;
      }
    });
    
    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        CustId custId = new CustId(1);
//        OrderId orderId = new OrderId(1, custId);
        getCache().getCacheTransactionManager().begin();
        custRegion.put(custId, new Customer(""foo"", ""bar""));
//        orderRegion.put(orderId, new Order(""fooOrder""));
//        refRegion.put(custId, new Customer(""foo"", ""bar""));
        getCache().getCacheTransactionManager().commit();
        return null;
      }
    });
    
    Thread.sleep(10000);
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
        getCache().getLogger().info(""SWAP:CLIENTinvoked:""+cl.invoked);
        assertTrue(cl.invoked);
        assertEquals(""it should be 1 but its:""+cl.invokeCount,1,cl.invokeCount);
        return null;
      }
    });
  }",True
"  
  public void testClientCommitsWithRIAndOnlyGetsOneEvent() throws Exception {
    Host host = Host.getHost(0);
    VM accessor = host.getVM(0);
    VM datastore = host.getVM(1);
    VM client = host.getVM(2);
    
    initAccessorAndDataStore(accessor, datastore, 0);
    int port = startServer(accessor);
    
    createClientRegion(client, port, false, true);
    
    datastore.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region custRegion = getCache().getRegion(CUSTOMER);
        custRegion.getAttributesMutator().addCacheListener(new ClientListener());
        return null;
      }
    });
    
    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        CustId custId = new CustId(1);
//        OrderId orderId = new OrderId(1, custId);
        getCache().getCacheTransactionManager().begin();
        custRegion.put(custId, new Customer(""foo"", ""bar""));
//        orderRegion.put(orderId, new Order(""fooOrder""));
//        refRegion.put(custId, new Customer(""foo"", ""bar""));
        getCache().getCacheTransactionManager().commit();
        return null;
      }
    });
    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
        assertTrue(cl.invoked);
        assertEquals(""it should be 1 but its:""+cl.invokeCount,1,cl.invokeCount);
        return null;
      }
    });
  }
  ",False
"  public void testSuspendTimeout() throws Exception {
    Host host = Host.getHost(0);
    VM server = host.getVM(0);
    VM client = host.getVM(1);
    
    final int port = createRegionsAndStartServer(server, false);
    createClientRegion(client, port, true);
    
    final TransactionId txId = (TransactionId) client.invoke(new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        TXManagerImpl mgr = (TXManagerImpl) getCache().getCacheTransactionManager();
        mgr.setSuspendedTransactionTimeout(1);
        Region r = getCache().getRegion(CUSTOMER);
        assertNull(r.get(new CustId(101)));
        mgr.begin();
        r.put(new CustId(101), new Customer(""name101"", ""address101""));
        TransactionId txId = mgr.suspend();
        Thread.sleep(70*1000);
        try {
          mgr.resume(txId);
          fail(""expected exception not thrown"");
        } catch (IllegalStateException expected) {
        }
        assertNull(r.get(new CustId(101)));
        return txId;
      }
    });
    server.invoke(new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        TXManagerImpl mgr = (TXManagerImpl) getCache().getCacheTransactionManager();
        assertNull(mgr.getHostedTXState((TXId) txId));
        assertEquals(0, mgr.hostedTransactionsInProgressForTest());
        return null;
      }
    });
  }",True
"  public void testSuspendTimeout() throws Exception {
    Host host = Host.getHost(0);
    VM server = host.getVM(0);
    VM client = host.getVM(1);
    
    final int port = createRegionsAndStartServer(server, false);
    createClientRegion(client, port, true);
    
    final TransactionId txId = (TransactionId) client.invoke(new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        TXManagerImpl mgr = (TXManagerImpl) getCache().getCacheTransactionManager();
        mgr.setSuspendedTransactionTimeout(1);
        Region r = getCache().getRegion(CUSTOMER);
        assertNull(r.get(new CustId(101)));
        mgr.begin();
        final TXStateProxy txState = mgr.getTXState();
        assertTrue(txState.isInProgress());
        r.put(new CustId(101), new Customer(""name101"", ""address101""));
        TransactionId txId = mgr.suspend(TimeUnit.MILLISECONDS);
        WaitCriterion waitForTxTimeout = new WaitCriterion() {
          public boolean done() {
            return !txState.isInProgress();
          }
          public String description() {
            return ""txState stayed in progress indicating that the suspend did not timeout"";
          }
        };
        // tx should timeout after 1 ms but to deal with loaded machines and thread
        // scheduling latency wait for 10 seconds before reporting an error.
        DistributedTestCase.waitForCriterion(waitForTxTimeout, 10 * 1000, 10, true);
        try {
          mgr.resume(txId);
          fail(""expected exception not thrown"");
        } catch (IllegalStateException expected) {
        }
        assertNull(r.get(new CustId(101)));
        return txId;
      }
    });
    server.invoke(new SerializableCallable() {
      @Override
      public Object call() throws Exception {
        TXManagerImpl mgr = (TXManagerImpl) getCache().getCacheTransactionManager();
        assertNull(mgr.getHostedTXState((TXId) txId));
        assertEquals(0, mgr.hostedTransactionsInProgressForTest());
        return null;
      }
    });
  }",False
"  public void testConnectionAffinity() throws Exception {
    Host host = Host.getHost(0);
    VM server1 = host.getVM(0);
    VM server2 = host.getVM(1);
    VM client = host.getVM(2);
    
    addExpectedException(""java.net.SocketException"");
    
    final int port1 = createRegionsAndStartServer(server1, true);
    final int port2 = createRegionsAndStartServer(server2, false);
    
    
    SerializableCallable hostedSize = new SerializableCallable() {
        public Object call() throws Exception {
         TXManagerImpl mgr = getGemfireCache().getTxManager();
         return mgr.hostedTransactionsInProgressForTest();
        }
      };
      
    int txcount = (Integer) server1.invoke(hostedSize) + (Integer)server2.invoke(hostedSize);
    assertTrue(""expected count to be 0""+txcount, txcount==0);
    
    
    
    final TXId txid = (TXId) client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        ClientCacheFactory ccf = new ClientCacheFactory();
        ccf.addPoolServer(""localhost""/*getServerHostName(Host.getHost(0))*/, port1);
        ccf.addPoolServer(""localhost"", port2);
        ccf.setPoolLoadConditioningInterval(1);
        ccf.setPoolSubscriptionEnabled(false);
        ccf.set(""log-level"", getDUnitLogLevel());
        ClientCache cCache = getClientCache(ccf);
        ClientRegionFactory<CustId, Customer> custrf = cCache
            .createClientRegionFactory(ClientRegionShortcut.PROXY);
        ClientRegionFactory<Integer, String> refrf = cCache
        .createClientRegionFactory(ClientRegionShortcut.PROXY);
        Region<Integer, String> r = refrf.create(D_REFERENCE);
        Region<CustId, Customer> pr = custrf.create(CUSTOMER);
//        Region<Integer, String> order = refrf.create(ORDER);
        
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        mgr.begin();
        int i=0;
        for (int j=0; j<10; j++) {
          CustId custId = new CustId(i);
          Customer cust = new Customer(""name""+i, ""address""+i);
          getGemfireCache().getLogger().info(""SWAP:putting:""+custId);
          pr.put(custId, cust);
          r.put(i, ""value""+i);
          Thread.sleep(100);
        }
        return mgr.getTransactionId();
      }
    });
    
    SerializableCallable activeTx = new SerializableCallable() {
      public Object call() throws Exception {
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        TXStateProxy tx = mgr.getHostedTXState(txid);
        mgr.getCache().getLogger().info(""SWAP:activeTx:""+tx);
        // rather than returning strings representing objects
        // return different ints to represent different objects
        if (tx != null) {
          TXStateInterface realtx = ((TXStateProxyImpl)tx).getRealDeal(null, null);
          if (realtx instanceof TXState) {
            return 11;
          }
        }
        return 1;
      }
    };
    
   
    
    int myCount = (Integer) server1.invoke(activeTx) + (Integer)server2.invoke(activeTx);
    assertTrue(""expected count to be 11 or 12 but was ""+myCount, myCount >= 11 && myCount <= 12);
    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        mgr.commit();
        return null;
      }
    });
  }",True
"    
    SerializableCallable hostedSize = new SerializableCallable() {
        public Object call() throws Exception {
         TXManagerImpl mgr = getGemfireCache().getTxManager();
         return mgr.hostedTransactionsInProgressForTest();
        }
      };
      
    int txcount = (Integer) server1.invoke(hostedSize) + (Integer)server2.invoke(hostedSize);
    assertTrue(""expected count to be 0""+txcount, txcount==0);
    
    
    
    final TXId txid = (TXId) client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        ClientCacheFactory ccf = new ClientCacheFactory();
        ccf.addPoolServer(""localhost""/*getServerHostName(Host.getHost(0))*/, port1);
        ccf.addPoolServer(""localhost"", port2);
        ccf.setPoolLoadConditioningInterval(1);
        ccf.setPoolSubscriptionEnabled(false);
        ccf.set(""log-level"", getDUnitLogLevel());
        ClientCache cCache = getClientCache(ccf);
        ClientRegionFactory<CustId, Customer> custrf = cCache
            .createClientRegionFactory(ClientRegionShortcut.PROXY);
        ClientRegionFactory<Integer, String> refrf = cCache
        .createClientRegionFactory(ClientRegionShortcut.PROXY);
        Region<Integer, String> r = refrf.create(D_REFERENCE);
        Region<CustId, Customer> pr = custrf.create(CUSTOMER);
//        Region<Integer, String> order = refrf.create(ORDER);
        
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        mgr.begin();
        int i=0;
        for (int j=0; j<10; j++) {
          CustId custId = new CustId(i);
          Customer cust = new Customer(""name""+i, ""address""+i);
          getGemfireCache().getLogger().info(""SWAP:putting:""+custId);
          pr.put(custId, cust);
          r.put(i, ""value""+i);
        }
        return mgr.getTransactionId();
      }
    });
    
    SerializableCallable activeTx = new SerializableCallable() {
      public Object call() throws Exception {
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        TXStateProxy tx = mgr.getHostedTXState(txid);
        mgr.getCache().getLogger().info(""SWAP:activeTx:""+tx);
        // rather than returning strings representing objects
        // return different ints to represent different objects
        if (tx != null) {
          TXStateInterface realtx = ((TXStateProxyImpl)tx).getRealDeal(null, null);
          if (realtx instanceof TXState) {
            return 11;
          }
        }
        return 1;
      }
    };
    
   
    
    int myCount = (Integer) server1.invoke(activeTx) + (Integer)server2.invoke(activeTx);
    assertTrue(""expected count to be 11 or 12 but was ""+myCount, myCount >= 11 && myCount <= 12);
    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        mgr.commit();
        return null;
      }
    });
  }
  
  /**
   * client has a client, an accessor and a datastore
   * pool connects to the accessor and datastore
   * we then close the server in the accessor and verify failover
   */
  public void testFailover() {
    Host host = Host.getHost(0);
    VM accessor = host.getVM(0);
    VM datastore = host.getVM(1);
    VM client = host.getVM(2);
    ",False
"  public void testDatastoreCommitsWithPutAllAndRI() throws Exception {
	    Host host = Host.getHost(0);
	    VM accessor = host.getVM(0);
	    VM datastore = host.getVM(1);
	    VM client = host.getVM(2);
	    
	    initAccessorAndDataStore(accessor, datastore, 0);
	    int port = startServer(accessor);
	    
	    createClientRegion(client, port, false, true);
	    
	    datastore.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region custRegion = getCache().getRegion(CUSTOMER);
	        custRegion.getAttributesMutator().addCacheListener(new ClientListener());
	        return null;
	      }
	    });
	    
	    
	    datastore.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//	        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//	        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
	        CustId custId = new CustId(1);
//	        OrderId orderId = new OrderId(1, custId);
	        getCache().getCacheTransactionManager().begin();
	        Map map = new HashMap();
	        map.put(custId, new Customer(""foo"", ""bar""));
	        custRegion.putAll(map);
//	        orderRegion.put(orderId, new Order(""fooOrder""));
//	        refRegion.put(custId, new Customer(""foo"", ""bar""));
	        getCache().getCacheTransactionManager().commit();
	        return null;
	      }
	    });
	    
	    Thread.sleep(10000);
	    client.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//	        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//	        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
	        ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
	        getCache().getLogger().info(""SWAP:CLIENTinvoked:""+cl.invoked);
	        assertTrue(cl.invoked);
	        assertEquals(""it should be 1 but its:""+cl.invokeCount,1,cl.invokeCount);
	        return null;
	      }
	    });
	  }",True
"	    Host host = Host.getHost(0);
	    VM accessor = host.getVM(0);
	    VM datastore = host.getVM(1);
	    VM client = host.getVM(2);
	    
	    initAccessorAndDataStore(accessor, datastore, 0);
	    int port = startServer(accessor);
	    
	    createClientRegion(client, port, false, true);
	    
	    datastore.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region custRegion = getCache().getRegion(CUSTOMER);
	        custRegion.getAttributesMutator().addCacheListener(new ClientListener());
	        return null;
	      }
	    });
	    
	    
	    datastore.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//	        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//	        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
	        CustId custId = new CustId(1);
//	        OrderId orderId = new OrderId(1, custId);
	        getCache().getCacheTransactionManager().begin();
	        Map map = new HashMap();
	        map.put(custId, new Customer(""foo"", ""bar""));
	        custRegion.putAll(map);
//	        orderRegion.put(orderId, new Order(""fooOrder""));
//	        refRegion.put(custId, new Customer(""foo"", ""bar""));
	        getCache().getCacheTransactionManager().commit();
	        return null;
	      }
	    });
	    
	    client.invoke(new SerializableCallable() {
	      public Object call() throws Exception {
	        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
//	        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
//	        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
	        ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
	        assertTrue(cl.invoked);
	        assertEquals(""it should be 1 but its:""+cl.invokeCount,1,cl.invokeCount);
	        return null;
	      }
	    });
	  }


  ",False
"  public void tearDown2() throws Exception {
//    try { Thread.sleep(5000); } catch (InterruptedException e) { } // FOR MANUAL TESTING OF STATS - DON""T KEEP THIS
    try {
      invokeInEveryVM(verifyNoTxState);
    } finally {
      closeAllCache();
      super.tearDown2();
    }
  }",True
"  @Override
  public void tearDown2() throws Exception {
    try {
      invokeInEveryVM(verifyNoTxState);
    } finally {
      closeAllCache();
      super.tearDown2();
    }
  }",False
"  public void testTXWithRI() throws Exception {
    Host host = Host.getHost(0);
    VM accessor = host.getVM(0);
    VM datastore = host.getVM(1);
    VM client = host.getVM(2);
    
    initAccessorAndDataStore(accessor, datastore, 0);
    int port = startServer(datastore);
    
    createClientRegion(client, port, false, true);
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        CustId custId = new CustId(1);
        OrderId orderId = new OrderId(1, custId);
        getCache().getCacheTransactionManager().begin();
        custRegion.put(custId, new Customer(""foo"", ""bar""));
        orderRegion.put(orderId, new Order(""fooOrder""));
        refRegion.put(custId, new Customer(""foo"", ""bar""));
        getCache().getCacheTransactionManager().commit();
        return null;
      }
    });
    
    Thread.sleep(10000);
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
        getCache().getLogger().info(""SWAP:CLIENTinvoked:""+cl.invoked);
        assertTrue(cl.invoked);
        return null;
      }
    });
  }",True
"  public void testTXWithRI() throws Exception {
    Host host = Host.getHost(0);
    VM accessor = host.getVM(0);
    VM datastore = host.getVM(1);
    VM client = host.getVM(2);
    
    initAccessorAndDataStore(accessor, datastore, 0);
    int port = startServer(datastore);
    
    createClientRegion(client, port, false, true);
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        CustId custId = new CustId(1);
        OrderId orderId = new OrderId(1, custId);
        getCache().getCacheTransactionManager().begin();
        custRegion.put(custId, new Customer(""foo"", ""bar""));
        orderRegion.put(orderId, new Order(""fooOrder""));
        refRegion.put(custId, new Customer(""foo"", ""bar""));
        getCache().getCacheTransactionManager().commit();
        return null;
      }
    });
    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        final ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
        WaitCriterion waitForListenerInvocation = new WaitCriterion() {
          public boolean done() {
            return cl.invoked;
          }
          public String description() {
            return ""listener was never invoked"";
          }
        };
        DistributedTestCase.waitForCriterion(waitForListenerInvocation, 10 * 1000, 10, true);
        return null;
      }
    });
  }",False
"  public void testTXWithRICommitInDatastore() throws Exception {
    Host host = Host.getHost(0);
    VM accessor = host.getVM(0);
    VM datastore = host.getVM(1);
    VM client = host.getVM(2);
    
    initAccessorAndDataStore(accessor, datastore, 0);
    int port = startServer(datastore);
    
    createClientRegion(client, port, false, true);
    datastore.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        CustId custId = new CustId(1);
        OrderId orderId = new OrderId(1, custId);
        getCache().getCacheTransactionManager().begin();
        custRegion.put(custId, new Customer(""foo"", ""bar""));
        orderRegion.put(orderId, new Order(""fooOrder""));
        refRegion.put(custId, new Customer(""foo"", ""bar""));
        getCache().getCacheTransactionManager().commit();
        return null;
      }
    });
    
    Thread.sleep(10000);
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
        getCache().getLogger().info(""SWAP:CLIENTinvoked:""+cl.invoked);
        assertTrue(cl.invoked);
        return null;
      }
    });
  }",True
"  public void testTXWithRICommitInDatastore() throws Exception {
    Host host = Host.getHost(0);
    VM accessor = host.getVM(0);
    VM datastore = host.getVM(1);
    VM client = host.getVM(2);
    
    initAccessorAndDataStore(accessor, datastore, 0);
    int port = startServer(datastore);
    
    createClientRegion(client, port, false, true);
    datastore.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        CustId custId = new CustId(1);
        OrderId orderId = new OrderId(1, custId);
        getCache().getCacheTransactionManager().begin();
        custRegion.put(custId, new Customer(""foo"", ""bar""));
        orderRegion.put(orderId, new Order(""fooOrder""));
        refRegion.put(custId, new Customer(""foo"", ""bar""));
        getCache().getCacheTransactionManager().commit();
        return null;
      }
    });
    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region<CustId, Customer> custRegion = getCache().getRegion(CUSTOMER);
        Region<OrderId, Order> orderRegion = getCache().getRegion(ORDER);
        Region<CustId,Customer> refRegion = getCache().getRegion(D_REFERENCE);
        final ClientListener cl = (ClientListener) custRegion.getAttributes().getCacheListeners()[0];
        WaitCriterion waitForListenerInvocation = new WaitCriterion() {
          public boolean done() {
            return cl.invoked;
          }
          public String description() {
            return ""listener was never invoked"";
          }
        };
        DistributedTestCase.waitForCriterion(waitForListenerInvocation, 10 * 1000, 10, true);
        return null;
      }
    });
  }",False
"  private void setUsageThresholdOnMXBean(final long bytesUsed) {
    if (testDisableMemoryUpdates) {
      return;
    }
    
    final MemoryPoolMXBean memoryPoolMXBean = getTenuredMemoryPoolMXBean();
    final MemoryThresholds saveThresholds = this.thresholds;

    if (bytesUsed < saveThresholds.getEvictionThresholdBytes()) {
      memoryPoolMXBean.setUsageThreshold(saveThresholds.getEvictionThresholdBytes());
    } else {
      memoryPoolMXBean.setUsageThreshold(saveThresholds.getCriticalThresholdBytes());
    }
  }",True
"  private void setUsageThresholdOnMXBean(final long bytesUsed) {
	  //// this method has been made a no-op to fix bug 49064 
  }",False
"  public String toString() {
    String expTtl = ""<unavailable>"";
    String expIdle = ""<unavailable>"";
    try {
      if (getTTLAttributes() != null) {
        expTtl = String.valueOf(getTTLExpirationTime());
      }
      if (getIdleAttributes() != null) {
        expIdle = String.valueOf(getIdleExpirationTime());
      }
    } 
    catch (VirtualMachineError err) {
      SystemFailure.initiateFailure(err);
      // If this ever returns, rethrow the error.  We're poisoned
      // now, so don't let this thread continue.
      throw err;
    }
    catch (Throwable t) {
      // Whenever you catch Error or Throwable, you must also
      // catch VirtualMachineError (see above).  However, there is
      // _still_ a possibility that you are dealing with a cascading
      // error condition, so you also need to check to see if the JVM
      // is still usable:
      SystemFailure.checkFailure();
    }
    return super.toString() + "" for "" + getLocalRegion()
      + "", ttl expiration time: "" + expTtl
      + "", idle expiration time: "" + expIdle +
      (""[now:"" + System.currentTimeMillis() + ""]"");
  }",True
"  public String toString() {
    String expTtl = ""<unavailable>"";
    String expIdle = ""<unavailable>"";
    try {
      if (getTTLAttributes() != null) {
        expTtl = String.valueOf(getTTLExpirationTime());
      }
      if (getIdleAttributes() != null) {
        expIdle = String.valueOf(getIdleExpirationTime());
      }
    } 
    catch (VirtualMachineError err) {
      SystemFailure.initiateFailure(err);
      // If this ever returns, rethrow the error.  We're poisoned
      // now, so don't let this thread continue.
      throw err;
    }
    catch (Throwable t) {
      // Whenever you catch Error or Throwable, you must also
      // catch VirtualMachineError (see above).  However, there is
      // _still_ a possibility that you are dealing with a cascading
      // error condition, so you also need to check to see if the JVM
      // is still usable:
      SystemFailure.checkFailure();
    }
    return super.toString() + "" for "" + getLocalRegion()
      + "", ttl expiration time: "" + expTtl
      + "", idle expiration time: "" + expIdle +
      (""[now:"" + calculateNow() + ""]"");
  }",False
"  public long getExpirationTime() throws EntryNotFoundException {
    // if this is an invalidate action and region has already been invalidated,
    // then don't expire again until the full timeout from now.
    ExpirationAction action = getAction();
    if (action == ExpirationAction.INVALIDATE ||
        action == ExpirationAction.LOCAL_INVALIDATE) {
      if (getLocalRegion().regionInvalid) {
        int timeout = getIdleAttributes().getTimeout();
        if (timeout == 0) return 0L;
        if (!getLocalRegion().EXPIRY_UNITS_MS) {
          timeout *= 1000;
        }
        return  timeout + System.currentTimeMillis();
      }
    }
    // otherwise, expire at timeout plus last accessed time
    return getIdleExpirationTime();
  }",True
"  public long getExpirationTime() throws EntryNotFoundException {
    // if this is an invalidate action and region has already been invalidated,
    // then don't expire again until the full timeout from now.
    ExpirationAction action = getAction();
    if (action == ExpirationAction.INVALIDATE ||
        action == ExpirationAction.LOCAL_INVALIDATE) {
      if (getLocalRegion().regionInvalid) {
        int timeout = getIdleAttributes().getTimeout();
        if (timeout == 0) return 0L;
        if (!getLocalRegion().EXPIRY_UNITS_MS) {
          timeout *= 1000;
        }
        // Expiration should always use the DSClock instead of the System clock.
        return  timeout + getLocalRegion().cacheTimeMillis();
      }
    }
    // otherwise, expire at timeout plus last accessed time
    return getIdleExpirationTime();
  }",False
"  public void testRegionIdleInvalidate()
  throws InterruptedException, CacheException {

    if (getRegionAttributes().getPartitionAttributes() != null) {
      // PR does not support INVALID ExpirationAction
      return;
    }
    
    final String name = this.getUniqueName();
    final String subname = this.getUniqueName() + ""-SUB"";
    final int timeout = 22; // ms
    final Object key = ""KEY"";
    final Object value = ""VALUE"";
    
    
    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    vm0.invoke(new CacheSerializableRunnable(""testRegionIdleInvalidate"") {
      public void run2() throws CacheException {
        TestCacheListener list = new TestCacheListener() {
            private int createCount = 0;
          public void afterInvalidate2(EntryEvent e) { e.getRegion().getCache().getLogger().info(""invalidate2 key=""+e.getKey()); }
          public void afterRegionInvalidate2(RegionEvent e) {}
          public void afterUpdate2(EntryEvent e) {
            this.wasInvoked();  // Clear the flag
          }
          public void afterCreate2(EntryEvent e) {
            this.createCount++;
            // we only expect one create; all the rest should be updates
            assertEquals(1, this.createCount);
            this.wasInvoked();  // Clear the flag
          }
        };
        AttributesFactory factory = new AttributesFactory(getRegionAttributes());
        ExpirationAttributes expire =
                new ExpirationAttributes(timeout, ExpirationAction.INVALIDATE);
        factory.setRegionIdleTimeout(expire);
        factory.setStatisticsEnabled(true);
        RegionAttributes subRegAttrs = factory.create();
        factory.setCacheListener(list);
        RegionAttributes attrs = factory.create();
        
        Region region = null;
        Region sub = null;
        Region.Entry entry = null;
        long tilt;
        System.setProperty(LocalRegion.EXPIRY_MS_PROPERTY, ""true"");
        ExpiryTask.suspendExpiration();
        try {
          region = createRegion(name, attrs);
          region.put(key, value);
          tilt = System.currentTimeMillis() + timeout;
          entry = region.getEntry(key);
          assertEquals(value, entry.getValue());
          sub = region.createSubregion(subname, subRegAttrs);
        } 
        finally {
          System.getProperties().remove(LocalRegion.EXPIRY_MS_PROPERTY);
          ExpiryTask.permitExpiration();
        }
        waitForInvalidate(entry, tilt, 10);
        
        assertTrue(list.waitForInvocation(333));
        

        // The next phase of the test verifies that a get will cause the
        // expiration time to be extended.
        // For this phase we don't worry about actually expiring but just
        // making sure the expiration time gets extended.
        region.getAttributesMutator().setRegionIdleTimeout(new ExpirationAttributes(9000/*ms*/, ExpirationAction.INVALIDATE));
        
        LocalRegion lr = (LocalRegion) region;
        {
          ExpiryTask expiryTask = lr.getRegionIdleExpiryTask();
          region.put(key, value);
          long createExpiry = expiryTask.getExpirationTime();
          waitForExpiryClockToChange(lr);
          region.put(key, ""VALUE2"");
          long putExpiry = expiryTask.getExpirationTime();
          assertTrue(""expected putExpiry="" + putExpiry + "" to be > than createExpiry="" + createExpiry, (putExpiry - createExpiry) > 0);
          waitForExpiryClockToChange(lr);
          region.get(key);
          long getExpiry = expiryTask.getExpirationTime();
          assertTrue(""expected getExpiry="" + getExpiry + "" to be > than putExpiry="" + putExpiry, (getExpiry - putExpiry) > 0);
        
          waitForExpiryClockToChange(lr);
          sub.put(key, value);
          long subPutExpiry = expiryTask.getExpirationTime();
          assertTrue(""expected subPutExpiry="" + subPutExpiry + "" to be > than getExpiry="" + getExpiry, (subPutExpiry - getExpiry) > 0);
          waitForExpiryClockToChange(lr);
          sub.get(key);
          long subGetExpiry = expiryTask.getExpirationTime();
          assertTrue(""expected subGetExpiry="" + subGetExpiry + "" to be > than subPutExpiry="" + subPutExpiry, (subGetExpiry - subPutExpiry) > 0);
        }
      }
    });
  }",True
"  public void testRegionIdleInvalidate()
  throws InterruptedException, CacheException {

    if (getRegionAttributes().getPartitionAttributes() != null) {
      // PR does not support INVALID ExpirationAction
      return;
    }
    
    final String name = this.getUniqueName();
    final String subname = this.getUniqueName() + ""-SUB"";
    final int timeout = 22; // ms
    final Object key = ""KEY"";
    final Object value = ""VALUE"";
    
    
    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    vm0.invoke(new CacheSerializableRunnable(""testRegionIdleInvalidate"") {
      public void run2() throws CacheException {
        TestCacheListener list = new TestCacheListener() {
            private int createCount = 0;
          public void afterInvalidate2(EntryEvent e) { e.getRegion().getCache().getLogger().info(""invalidate2 key=""+e.getKey()); }
          public void afterRegionInvalidate2(RegionEvent e) {}
          public void afterUpdate2(EntryEvent e) {
            this.wasInvoked();  // Clear the flag
          }
          public void afterCreate2(EntryEvent e) {
            this.createCount++;
            // we only expect one create; all the rest should be updates
            assertEquals(1, this.createCount);
            this.wasInvoked();  // Clear the flag
          }
        };
        AttributesFactory factory = new AttributesFactory(getRegionAttributes());
        ExpirationAttributes expire =
                new ExpirationAttributes(timeout, ExpirationAction.INVALIDATE);
        factory.setRegionIdleTimeout(expire);
        factory.setStatisticsEnabled(true);
        RegionAttributes subRegAttrs = factory.create();
        factory.setCacheListener(list);
        RegionAttributes attrs = factory.create();
        
        Region region = null;
        Region sub = null;
        Region.Entry entry = null;
        long tilt;
        System.setProperty(LocalRegion.EXPIRY_MS_PROPERTY, ""true"");
        ExpiryTask.suspendExpiration();
        try {
          region = createRegion(name, attrs);
          region.put(key, value);
          tilt = System.currentTimeMillis() + timeout;
          entry = region.getEntry(key);
          assertEquals(value, entry.getValue());
          sub = region.createSubregion(subname, subRegAttrs);
        } 
        finally {
          System.getProperties().remove(LocalRegion.EXPIRY_MS_PROPERTY);
          ExpiryTask.permitExpiration();
        }
        waitForInvalidate(entry, tilt, 10);
        
        assertTrue(list.waitForInvocation(333));
        

        // The next phase of the test verifies that a get will cause the
        // expiration time to be extended.
        // For this phase we don't worry about actually expiring but just
        // making sure the expiration time gets extended.
        final int EXPIRATION_MS = 9000;
        region.getAttributesMutator().setRegionIdleTimeout(new ExpirationAttributes(EXPIRATION_MS, ExpirationAction.INVALIDATE));
        
        LocalRegion lr = (LocalRegion) region;
        {
          ExpiryTask expiryTask = lr.getRegionIdleExpiryTask();
          region.put(key, value);
          long createExpiry = expiryTask.getExpirationTime();
          long changeTime = waitForExpiryClockToChange(lr, createExpiry-EXPIRATION_MS);
          region.put(key, ""VALUE2"");
          long putExpiry = expiryTask.getExpirationTime();
          assertTrue(""CLOCK went back in time! Expected putBaseExpiry="" + (putExpiry-EXPIRATION_MS) + "" to be >= than changeTime="" + changeTime, (putExpiry-EXPIRATION_MS - changeTime) >= 0);
          assertTrue(""expected putExpiry="" + putExpiry + "" to be > than createExpiry="" + createExpiry, (putExpiry - createExpiry) > 0);
          changeTime = waitForExpiryClockToChange(lr, putExpiry-EXPIRATION_MS);
          region.get(key);
          long getExpiry = expiryTask.getExpirationTime();
          assertTrue(""CLOCK went back in time! Expected getBaseExpiry="" + (getExpiry-EXPIRATION_MS) + "" to be >= than changeTime="" + changeTime, (getExpiry-EXPIRATION_MS - changeTime) >= 0);
          assertTrue(""expected getExpiry="" + getExpiry + "" to be > than putExpiry="" + putExpiry, (getExpiry - putExpiry) > 0);
        
          changeTime = waitForExpiryClockToChange(lr, getExpiry-EXPIRATION_MS);
          sub.put(key, value);
          long subPutExpiry = expiryTask.getExpirationTime();
          assertTrue(""CLOCK went back in time! Expected subPutBaseExpiry="" + (subPutExpiry-EXPIRATION_MS) + "" to be >= than changeTime="" + changeTime, (subPutExpiry-EXPIRATION_MS - changeTime) >= 0);
          assertTrue(""expected subPutExpiry="" + subPutExpiry + "" to be > than getExpiry="" + getExpiry, (subPutExpiry - getExpiry) > 0);
          changeTime = waitForExpiryClockToChange(lr, subPutExpiry-EXPIRATION_MS);
          sub.get(key);
          long subGetExpiry = expiryTask.getExpirationTime();
          assertTrue(""CLOCK went back in time! Expected subGetBaseExpiry="" + (subGetExpiry-EXPIRATION_MS) + "" to be >= than changeTime="" + changeTime, (subGetExpiry-EXPIRATION_MS - changeTime) >= 0);
          assertTrue(""expected subGetExpiry="" + subGetExpiry + "" to be > than subPutExpiry="" + subPutExpiry, (subGetExpiry - subPutExpiry) > 0);
        }
      }
    });
  }",False
"  public static final void waitForExpiryClockToChange(LocalRegion lr) {
    long startTime = lr.cacheTimeMillis();
    do {
      Thread.yield();
    } while (startTime == lr.cacheTimeMillis());
  }",True
"  public static final long waitForExpiryClockToChange(LocalRegion lr, final long baseTime) {
    long nowTime;
    do {
      Thread.yield();
      nowTime = lr.cacheTimeMillis();
    } while ((nowTime - baseTime) <= 0L);
    return nowTime;
  }",False
"  public static final long waitForExpiryClockToChange(LocalRegion lr) {
    return waitForExpiryClockToChange(lr, lr.cacheTimeMillis());
  }",False
"  private static int parseCurrentNumber(ByteBuf buffer) {
    int number = 0;
    int readerIndex = buffer.readerIndex();
    byte b = 0;
    while (true) {
      if (!buffer.isReadable())
        return Integer.MIN_VALUE;
      b = buffer.readByte();
      if (Character.isDigit(b)) {
        number = number * 10 + (int) (b - '0');
        readerIndex++;
      } else {
        buffer.readerIndex(readerIndex);
        break;
      }
    }
    return number;
  }",True
"  private int parseCurrentNumber(ByteBuf buffer) {
    int number = 0;
    int readerIndex = buffer.readerIndex();
    byte b = 0;
    while (true) {
      if (!buffer.isReadable())
        return Integer.MIN_VALUE;
      b = buffer.readByte();
      if (Character.isDigit(b)) {
        number = number * 10 + (int) (b - '0');
        readerIndex++;
      } else {
        buffer.readerIndex(readerIndex);
        break;
      }
    }
    return number;
  }",False
"  private static byte[] parseBulkString(ByteBuf buffer) throws RedisCommandParserException {
    int bulkStringLength = parseCurrentNumber(buffer);
    if (bulkStringLength == Integer.MIN_VALUE)
      return null;
    if (bulkStringLength > MAX_BULK_STRING_LENGTH)
      throw new RedisCommandParserException(""invalid bulk length, cannot exceed max length of "" + MAX_BULK_STRING_LENGTH);
    if (!parseRN(buffer))
      return null;

    if (!buffer.isReadable(bulkStringLength))
      return null;
    byte[] bulkString = new byte[bulkStringLength];
    buffer.readBytes(bulkString);

    if (!parseRN(buffer))
      return null;

    return bulkString;
  }",True
"  private byte[] parseBulkString(ByteBuf buffer) throws RedisCommandParserException {
    int bulkStringLength = parseCurrentNumber(buffer);
    if (bulkStringLength == Integer.MIN_VALUE)
      return null;
    if (bulkStringLength > MAX_BULK_STRING_LENGTH)
      throw new RedisCommandParserException(""invalid bulk length, cannot exceed max length of "" + MAX_BULK_STRING_LENGTH);
    if (!parseRN(buffer))
      return null;

    if (!buffer.isReadable(bulkStringLength))
      return null;
    byte[] bulkString = new byte[bulkStringLength];
    buffer.readBytes(bulkString);

    if (!parseRN(buffer))
      return null;

    return bulkString;
  }",False
"  private static boolean parseArray(ArrayList<byte[]> commandElems, ByteBuf buffer) throws RedisCommandParserException { 
    byte currentChar;
    int arrayLength = parseCurrentNumber(buffer);
    if (arrayLength == Integer.MIN_VALUE || !parseRN(buffer))
      return false;
    if (arrayLength < 0 || arrayLength > 1000000000)
      throw new RedisCommandParserException(""invalid multibulk length"");

    for (int i = 0; i < arrayLength; i++) {
      if (!buffer.isReadable())
        return false;
      currentChar = buffer.readByte();
      if (currentChar == bulkStringID) {
        byte[] newBulkString = parseBulkString(buffer);
        if (newBulkString == null)
          return false;
        commandElems.add(newBulkString);
      } else
        throw new RedisCommandParserException(""expected: \'$\', got \'"" + (char) currentChar + ""\'"");
    }
    return true;
  }",True
"  private boolean parseArray(ArrayList<byte[]> commandElems, ByteBuf buffer) throws RedisCommandParserException { 
    byte currentChar;
    int arrayLength = parseCurrentNumber(buffer);
    if (arrayLength == Integer.MIN_VALUE || !parseRN(buffer))
      return false;
    if (arrayLength < 0 || arrayLength > 1000000000)
      throw new RedisCommandParserException(""invalid multibulk length"");

    for (int i = 0; i < arrayLength; i++) {
      if (!buffer.isReadable())
        return false;
      currentChar = buffer.readByte();
      if (currentChar == bulkStringID) {
        byte[] newBulkString = parseBulkString(buffer);
        if (newBulkString == null)
          return false;
        commandElems.add(newBulkString);
      } else
        throw new RedisCommandParserException(""expected: \'$\', got \'"" + (char) currentChar + ""\'"");
    }
    return true;
  }",False
"  public static Command parse(ByteBuf buffer) throws RedisCommandParserException {
    if (buffer == null)
      throw new NullPointerException();
    if (!buffer.isReadable())
      return null;

    byte firstB = buffer.readByte();
    if (firstB != arrayID)
      throw new RedisCommandParserException(""Expected: "" + (char) arrayID + "" Actual: "" + (char) firstB);
    ArrayList<byte[]> commandElems = new ArrayList<byte[]>();

    if (!parseArray(commandElems, buffer))
      return null;

    return new Command(commandElems);
  }",True
"  private Command parse(ByteBuf buffer) throws RedisCommandParserException {
    if (buffer == null)
      throw new NullPointerException();
    if (!buffer.isReadable())
      return null;

    byte firstB = buffer.readByte();
    if (firstB != arrayID)
      throw new RedisCommandParserException(""Expected: "" + (char) arrayID + "" Actual: "" + (char) firstB);
    ArrayList<byte[]> commandElems = new ArrayList<byte[]>();

    if (!parseArray(commandElems, buffer))
      return null;

    return new Command(commandElems);
  }",False
"  private static boolean parseRN(ByteBuf buffer) throws RedisCommandParserException {
    if (!buffer.isReadable(2))
      return false;
    byte b = buffer.readByte();
    if (b != rID)
      throw new RedisCommandParserException(""expected \'"" + (char) rID + ""\', got \'"" + (char) b + ""\'"");
    b = buffer.readByte();
    if (b != nID)
      throw new RedisCommandParserException(""expected: \'"" + (char) nID + ""\', got \'"" + (char) b + ""\'"");
    return true;
  }",True
"  private boolean parseRN(ByteBuf buffer) throws RedisCommandParserException {
    if (!buffer.isReadable(2))
      return false;
    byte b = buffer.readByte();
    if (b != rID)
      throw new RedisCommandParserException(""expected \'"" + (char) rID + ""\', got \'"" + (char) b + ""\'"");
    b = buffer.readByte();
    if (b != nID)
      throw new RedisCommandParserException(""expected: \'"" + (char) nID + ""\', got \'"" + (char) b + ""\'"");
    return true;
  }",False
"  public static final ByteBuf getBulkStringArrayResponse(ByteBufAllocator alloc, Set<String> items) {
    Iterator<String> it = items.iterator();
    ByteBuf response = alloc.buffer();
    response.writeByte(ARRAY_ID);
    response.writeBytes(intToBytes(items.size()));
    response.writeBytes(CRLFar);
    while(it.hasNext()) {
      String next = it.next();
      response.writeByte(BULK_STRING_ID);
      response.writeBytes(intToBytes(next.length()));
      response.writeBytes(CRLFar);
      response.writeBytes(stringToBytes(next));
      response.writeBytes(CRLFar);
    }
    return response;
  }",True
"    response.writeBytes(valueAr);
    response.writeBytes(CRLFar);
    return response;
  }

  public static final ByteBuf getBulkStringArrayResponse(ByteBufAllocator alloc, List<String> items) {
    Iterator<String> it = items.iterator();
    ByteBuf response = alloc.buffer();
    response.writeByte(ARRAY_ID);
    response.writeBytes(intToBytes(items.size()));
    response.writeBytes(CRLFar);
    while(it.hasNext()) {
      String next = it.next();
      response.writeByte(BULK_STRING_ID);
      response.writeBytes(intToBytes(next.length()));
      response.writeBytes(CRLFar);",False
"  public String getStringKey() {
    if (this.commandElems.size() > 1) {
      if (this.key == null) {
        this.bytes = new ByteArrayWrapper(this.commandElems.get(1));
        this.key = this.bytes.toString();
      }
      return this.key;
    } else 
      return null;
  }",True
"  public String getStringKey() {
    if (this.commandElems.size() > 1) {
      if (this.bytes == null) {
        this.bytes = new ByteArrayWrapper(this.commandElems.get(1));
        this.key = this.bytes.toString();
      } else if (this.key == null)
        this.key = this.bytes.toString();
      return this.key;
    } else 
      return null;
  }",False
"  public String toString() {
    StringBuilder b = new StringBuilder();
    for (byte[] bs : this.commandElems) {
      b.append(Coder.bytesToString(bs));
      b.append(' ');
    }
    return b.toString();
  }",False
"  public int compareTo(Object arg0) {
    Double other;
    if (arg0 instanceof DoubleWrapper) {
      other = ((DoubleWrapper) arg0).score;
    } else if (arg0 instanceof String) {
      String arg = (String) arg0;
      if (arg.equalsIgnoreCase(""INFINITY""))
        other = Double.POSITIVE_INFINITY;
      else if (arg.equalsIgnoreCase(""-INFINITY""))
        other = Double.NEGATIVE_INFINITY;
      else
        return 0;
    } else if (arg0 instanceof Double) {
      other = (Double) arg0;
    } else
      return 0;
    Double diff = this.score - other;
    if (diff > 0)
      return 1;
    else if (diff < 0)
      return -1;
    else
      return 0;
  }",True
"  @Override
  public void fromData(DataInput in) throws IOException, ClassNotFoundException {
    this.score = DataSerializer.readDouble(in);
  }

  @Override
  public int compareTo(Object arg0) {
    Double other;
    if (arg0 instanceof DoubleWrapper) {
      other = ((DoubleWrapper) arg0).score;
    } else if (arg0 instanceof Double) {
      other = (Double) arg0;
    } else
      return 0;
    Double diff = this.score - other;
    if (diff > 0)
      return 1;
    else if (diff < 0)
      return -1;
    else
      return 0;
  }

  public String toString() {",False
"  private ByteBuf getExceptionResponse(ChannelHandlerContext ctx, Throwable cause) {
    ByteBuf response; 
    if (cause instanceof RedisDataTypeMismatchException)
      response = Coder.getWrongTypeResponse(this.byteBufAllocator, cause.getMessage());
    else if (cause instanceof DecoderException && cause.getCause() instanceof RedisCommandParserException)
      response = Coder.getErrorResponse(this.byteBufAllocator, RedisConstants.PARSING_EXCEPTION_MESSAGE);
    else if (cause instanceof RegionCreationException)
      response = Coder.getErrorResponse(this.byteBufAllocator, RedisConstants.ERROR_REGION_CREATION);
    else if (cause instanceof InterruptedException)
      response = Coder.getErrorResponse(this.byteBufAllocator, RedisConstants.SERVER_ERROR_SHUTDOWN);
    else if (cause instanceof IllegalStateException) {
      response = Coder.getErrorResponse(this.byteBufAllocator,  cause.getMessage());
    } else {
      if (this.logger.errorEnabled())
        this.logger.error(""GemFireRedisServer-Unexpected error handler"", cause);
      response = Coder.getErrorResponse(this.byteBufAllocator, RedisConstants.SERVER_ERROR_MESSAGE);
    }
    return response;
  }",True
"  private ByteBuf getExceptionResponse(ChannelHandlerContext ctx, Throwable cause) {
    ByteBuf response; 
    if (cause instanceof RedisDataTypeMismatchException)
      response = Coder.getWrongTypeResponse(this.byteBufAllocator, cause.getMessage());
    else if (cause instanceof DecoderException && cause.getCause() instanceof RedisCommandParserException)
      response = Coder.getErrorResponse(this.byteBufAllocator, RedisConstants.PARSING_EXCEPTION_MESSAGE);
    else if (cause instanceof RegionCreationException) {
      this.logger.error(cause);
      response = Coder.getErrorResponse(this.byteBufAllocator, RedisConstants.ERROR_REGION_CREATION);
    } else if (cause instanceof InterruptedException || cause instanceof CacheClosedException)
      response = Coder.getErrorResponse(this.byteBufAllocator, RedisConstants.SERVER_ERROR_SHUTDOWN);
    else if (cause instanceof IllegalStateException) {
      response = Coder.getErrorResponse(this.byteBufAllocator, cause.getMessage());
    } else {
      if (this.logger.errorEnabled())
        this.logger.error(""GemFireRedisServer-Unexpected error handler for "" + ctx.channel(), cause);
      response = Coder.getErrorResponse(this.byteBufAllocator, RedisConstants.SERVER_ERROR_MESSAGE);
    }
    return response;
  }",False
"  private void writeToChannel(Object message) {
    channel.write(message, channel.voidPromise());
    if (!needChannelFlush.getAndSet(true)) {
      this.lastExecutor.execute(flusher);
    }
  }",True
"    this.server = server;
    this.logger = cache.getLogger();
    this.channel = ch;
    this.needChannelFlush  = new AtomicBoolean(false);
    this.flusher = new Runnable() {
",False
"  private void executeWithoutTransaction(final Executor exec, Command command, int n) throws Exception {
    try {
      exec.executeCommand(command, this);
    } catch (RegionDestroyedException e) {
      if (n > 0)
        executeWithoutTransaction(exec, command, n - 1);
      else
        throw e;
    }
  }",True
"  private void executeWithoutTransaction(final Executor exec, Command command) throws Exception {
    Exception cause = null;
    for (int i = 0; i < MAXIMUM_NUM_RETRIES; i++) {
      try {
        exec.executeCommand(command, this);
        return;
      } catch (Exception e) {
        cause = e;
        if (e instanceof RegionDestroyedException || e.getCause() instanceof QueryInvocationTargetException)
          Thread.sleep(WAIT_REGION_DSTRYD_MILLIS);
      }
    }
    throw cause;
  }",False
"  private void writeToChannel(ByteBuf message) {
    channel.write(message, channel.voidPromise());
    if (!needChannelFlush.getAndSet(true)) {
      this.lastExecutor.execute(flusher);
    }
  }",False
"  public RegionCache getRegionCache() {
    return this.regionCache;
  }",True
"
  /**
   * Getter for transaction command queue",False
"  public ExecutionHandlerContext(Channel ch, Cache cache, RegionCache regions, GemFireRedisServer server, byte[] pwd) {
    this.cache = cache;
    this.server = server;
    this.logger = cache.getLogger();
    this.channel = ch;
    this.needChannelFlush  = new AtomicBoolean(false);
    this.flusher = new Runnable() {

      @Override
      public void run() {
        flushChannel();
      }

    };
    this.lastExecutor = channel.pipeline().lastContext().executor();
    this.byteBufAllocator = channel.alloc();
    this.transactionID = null;
    this.transactionQueue = null; // Lazy
    this.regionCache = regions;
    this.authPwd = pwd;
    this.isAuthenticated = pwd != null ? false : true;
  }",True
"  public ExecutionHandlerContext(Channel ch, Cache cache, RegionProvider regionProvider, GemFireRedisServer server, byte[] pwd) {
    if (ch == null || cache == null || regionProvider == null || server == null)
      throw new IllegalArgumentException(""Only the authentication password may be null"");
    this.cache = cache;
    this.server = server;
    this.logger = cache.getLogger();
    this.channel = ch;
    this.needChannelFlush  = new AtomicBoolean(false);
    this.flusher = new Runnable() {

      @Override
      public void run() {
        flushChannel();
      }

    };
    this.lastExecutor = channel.pipeline().lastContext().executor();
    this.byteBufAllocator = channel.alloc();
    this.transactionID = null;
    this.transactionQueue = null; // Lazy
    this.regionProvider = regionProvider;
    this.authPwd = pwd;
    this.isAuthenticated = pwd != null ? false : true;
  }",False
"  public RegionProvider getRegionProvider() {
    return this.regionProvider;
  }",False
"  public void executeCommand(ChannelHandlerContext ctx, Command command) throws Exception {
    RedisCommandType type = command.getCommandType();
    Executor exec = type.getExecutor();
    if (isAuthenticated) {
      if (type == RedisCommandType.SHUTDOWN) {
        this.server.shutdown();
        return;
      }
      if (hasTransaction() && !(exec instanceof TransactionExecutor))
        executeWithTransaction(ctx, exec, command);
      else
        executeWithoutTransaction(exec, command, MAXIMUM_NUM_RETRIES); 

      if (hasTransaction() && command.getCommandType() != RedisCommandType.MULTI) {
        writeToChannel(Coder.getSimpleStringResponse(this.byteBufAllocator, RedisConstants.COMMAND_QUEUED));
      } else {
        ByteBuf response = command.getResponse();
        writeToChannel(response);
      }
    } else if (type == RedisCommandType.QUIT) {
      exec.executeCommand(command, this);
      ByteBuf response = command.getResponse();
      writeToChannel(response);
      channelInactive(ctx);
    } else if (type == RedisCommandType.AUTH) {
      exec.executeCommand(command, this);
      ByteBuf response = command.getResponse();
      writeToChannel(response);
    } else {
      ByteBuf r = Coder.getNoAuthResponse(this.byteBufAllocator, RedisConstants.ERROR_NOT_AUTH);
      writeToChannel(r);
    }
  }",True
"  private void executeCommand(ChannelHandlerContext ctx, Command command) throws Exception {
    RedisCommandType type = command.getCommandType();
    Executor exec = type.getExecutor();
    if (isAuthenticated) {
      if (type == RedisCommandType.SHUTDOWN) {
        this.server.shutdown();
        return;
      }
      if (hasTransaction() && !(exec instanceof TransactionExecutor))
        executeWithTransaction(ctx, exec, command);
      else
        executeWithoutTransaction(exec, command); 

      if (hasTransaction() && command.getCommandType() != RedisCommandType.MULTI) {
        writeToChannel(Coder.getSimpleStringResponse(this.byteBufAllocator, RedisConstants.COMMAND_QUEUED));
      } else {
        ByteBuf response = command.getResponse();
        writeToChannel(response);
      }
    } else if (type == RedisCommandType.QUIT) {
      exec.executeCommand(command, this);
      ByteBuf response = command.getResponse();
      writeToChannel(response);
      channelInactive(ctx);
    } else if (type == RedisCommandType.AUTH) {
      exec.executeCommand(command, this);
      ByteBuf response = command.getResponse();
      writeToChannel(response);
    } else {
      ByteBuf r = Coder.getNoAuthResponse(this.byteBufAllocator, RedisConstants.ERROR_NOT_AUTH);
      writeToChannel(r);
    }
  }",False
"      ByteBuf response = command.getResponse();
      writeToChannel(response);
      channelInactive(ctx);
    } else if (type == RedisCommandType.AUTH) {
      exec.executeCommand(command, this);
      ByteBuf response = command.getResponse();
      writeToChannel(response);
    } else {
      ByteBuf r = Coder.getNoAuthResponse(this.byteBufAllocator, RedisConstants.ERROR_NOT_AUTH);
      writeToChannel(r);",False
"  private final EventExecutor lastExecutor;
  private final ByteBufAllocator byteBufAllocator;
  /**
   * TransactionId for any transactions started by this client
   */
  private TransactionId transactionID;

  /**
   * Queue of commands for a given transaction
   */
  private Queue<Command> transactionQueue;
  private final RegionProvider regionProvider;
  private final byte[] authPwd;

  private boolean isAuthenticated;

  /**
   * Default constructor for execution contexts. 
   * 
   * @param ch Channel used by this context, should be one to one
   * @param cache The Geode cache instance of this vm
   * @param regionProvider The region provider of this context",False
"  public Region<String, Integer> getListsMetaRegion() {
    return this.listsMetaRegion;
  }",True
"        return false;
      } finally {
        removeRegionState(key, type);",False
"  public void createRemoteRegionLocally(ByteArrayWrapper key, RedisDataType type) {
    if (type == null || type == RedisDataType.REDIS_STRING || type == RedisDataType.REDIS_HLL)
      return;
    Region<?, ?> r = this.regions.get(key);
    if (r != null)
      return;
    if (!this.regions.contains(key)) {
      String stringKey = key.toString();
      Lock lock = this.locks.get(stringKey);
      if (lock == null) {
        this.locks.putIfAbsent(stringKey, new ReentrantLock());
        lock = this.locks.get(stringKey);
      }
      boolean locked = false;
      try {
        locked = lock.tryLock();
        // If we cannot get the lock then this remote even may have been initialized
        // independently on this machine, so if we wait on the lock it is more than
        // likely we will deadlock just to do the same task, this even can be ignored
        if (locked) {
          r = cache.getRegion(key.toString());
          if (type == RedisDataType.REDIS_LIST)
            doInitializeList(key, r);
          else if (type == RedisDataType.REDIS_SORTEDSET)
            doInitializeSortedSet(key, r);
          this.regions.put(key, r);
        }
      } finally {
        if (locked) {
          lock.unlock();
        }
      }
    }
  }",False
"  public RegionProvider(Region<ByteArrayWrapper, ByteArrayWrapper> stringsRegion, Region<ByteArrayWrapper, HyperLogLogPlus> hLLRegion, Region<String, RedisDataType> redisMetaRegion, ConcurrentMap<ByteArrayWrapper, ScheduledFuture<?>> expirationsMap, ScheduledExecutorService expirationExecutor, RegionShortcut defaultShortcut) {
    if (stringsRegion == null || hLLRegion == null || redisMetaRegion == null)
      throw new NullPointerException();
    this.regions = new ConcurrentHashMap<ByteArrayWrapper, Region<?, ?>>();
    this.stringsRegion = stringsRegion;
    this.hLLRegion = hLLRegion;
    this.redisMetaRegion = redisMetaRegion;
    this.cache = GemFireCacheImpl.getInstance();
    this.queryService = cache.getQueryService();
    this.expirationsMap = expirationsMap;
    this.expirationExecutor = expirationExecutor;
    this.defaultRegionType = defaultShortcut;
    this.locks = new ConcurrentHashMap<String, Lock>();
    this.logger = this.cache.getLogger();
  }",False
"  private boolean destroyRegion(ByteArrayWrapper key, RedisDataType type) {
    String stringKey = key.toString();
    Region<?, ?> r = this.regions.get(key);
    if (r != null) {
      synchronized (stringKey) { // This object will be interned across the vm
        try {
          r.destroyRegion();
        } catch (Exception e) {
          return false;
        } finally {
          this.preparedQueries.remove(key);
          metaRemoveEntry(key);
          if (type == RedisDataType.REDIS_LIST) {
            this.listsMetaRegion.remove(stringKey + ""head"");
            this.listsMetaRegion.remove(stringKey + ""tail"");
          }
          this.regions.remove(key);
        }
      }
    }
    return true;
  }",True
"
  public void createRemoteRegionLocally(ByteArrayWrapper key, RedisDataType type) {
    if (type == null || type == RedisDataType.REDIS_STRING || type == RedisDataType.REDIS_HLL)
      return;
    Region<?, ?> r = this.regions.get(key);
    if (r != null)
      return;
    if (!this.regions.contains(key)) {
      String stringKey = key.toString();
      Lock lock = this.locks.get(stringKey);
      if (lock == null) {
        this.locks.putIfAbsent(stringKey, new ReentrantLock());
        lock = this.locks.get(stringKey);
      }
      boolean locked = false;
      try {
        locked = lock.tryLock();
        // If we cannot get the lock then this remote even may have been initialized
        // independently on this machine, so if we wait on the lock it is more than
        // likely we will deadlock just to do the same task, this even can be ignored
        if (locked) {
          r = cache.getRegion(key.toString());",False
"  private Region<?, ?> createRegionGlobally(String key) {
    Region<?, ?> r = null;
    Result result = cliCmds.createRegion(key, GemFireRedisServer.DEFAULT_REGION_TYPE, null, null, true, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null);
    r = cache.getRegion(key);
    if (result.getStatus() == Status.ERROR && r == null) {
      String err = """";
      while(result.hasNextLine())
        err += result.nextLine();
      throw new RegionCreationException(err);
    }
    if (r == null)
      throw new RegionCreationException();
    return r;
  }",True
"              concurrentCreateDestroyException = null;
              r = createRegionGlobally(stringKey);
              try {
                if (type == RedisDataType.REDIS_LIST)
                  doInitializeList(key, r);
                else if (type == RedisDataType.REDIS_SORTEDSET)
                  doInitializeSortedSet(key, r);
              } catch (QueryInvalidException e) {
                if (e.getCause() instanceof RegionNotFoundException) {
                  concurrentCreateDestroyException = e;
                }
              }
            } while(concurrentCreateDestroyException != null);
            this.regions.put(key, r);            ",False
"  public void removeRegionReferenceLocally(ByteArrayWrapper key, RedisDataType type) {
    cancelKeyExpiration(key);
    this.regions.remove(key);
  }",True
"  }

  public RedisDataType metaPut(ByteArrayWrapper key, RedisDataType value) {
    return this.redisMetaRegion.put(key.toString(), value);",False
"  private Region<?, ?> createRegionGlobally(String key) {
    Region<?, ?> r = null;
    r = cache.getRegion(key);
    if (r != null) return r;
    do {
      Result result = cliCmds.createRegion(key, defaultRegionType, null, null, true, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null);
      r = cache.getRegion(key);
      if (result.getStatus() == Status.ERROR && r == null) {
        String err = """";
        while(result.hasNextLine())
          err += result.nextLine();
        if (this.logger.errorEnabled()) {
          this.logger.error(""Region creation failure- ""+ err);
        }
        throw new RegionCreationException(err);
      }
    } while(r == null); // The region can be null in the case that it is concurrently destroyed by
    // a remote even triggered internally by Geode
    return r;
  }",False
"  private void doInitializeList(ByteArrayWrapper key, Region r) {
    r.put(""head"", Integer.valueOf(0));
    r.put(""tail"", Integer.valueOf(0));
    String fullpath = r.getFullPath();
    HashMap<Enum<?>, Query> queryList = new HashMap<Enum<?>, Query>();
    for (ListQuery lq: ListQuery.values()) {
      String queryString = lq.getQueryString(fullpath);
      Query query = this.queryService.newQuery(queryString);
      queryList.put(lq, query);
    }
    this.preparedQueries.put(key, queryList);
  }",False
"  public boolean removeKey(ByteArrayWrapper key, RedisDataType type, boolean cancelExpiration) {
    if (type == null || type == RedisDataType.REDIS_PROTECTED)
      return false;
    Lock lock = this.locks.get(key.toString());
    try {
      if (lock != null)  {// Strings/hlls will not have locks
        lock.lock();
      }
      metaRemoveEntry(key);
      try {
        if (type == RedisDataType.REDIS_STRING) {
          return this.stringsRegion.remove(key) != null;
        } else if (type == RedisDataType.REDIS_HLL) {
          return this.hLLRegion.remove(key) != null;
        } else {
          return destroyRegion(key, type);
        }
      } catch (Exception exc) {
        return false;
      } finally {
        if (cancelExpiration)
          cancelKeyExpiration(key);
        else
          removeKeyExpiration(key);
        if (lock != null)
          this.locks.remove(key.toString());
      }
    } finally {
      if (lock != null) {
        lock.unlock();
      }
    }
  }",False
"  public void removeRegionReferenceLocally(ByteArrayWrapper key, RedisDataType type) {
    Lock lock = this.locks.get(key.toString());
    boolean locked = false;
    try {
      locked = lock.tryLock();
      // If we cannot get the lock we ignore this remote event, this key has local event
      // that started independently, ignore this event to prevent deadlock
      if (locked) {
        cancelKeyExpiration(key);
        removeRegionState(key, type);
      }
    } finally {
      if (locked) {
        lock.unlock();
      }
    }
  }",False
"  public Query getQuery(ByteArrayWrapper key, Enum<?> query) {
    return this.preparedQueries.get(key).get(query);
    /*
    if (query instanceof ListQuery) {
      return this.queryService.newQuery(((ListQuery)query).getQueryString(this.regions.get(key).getFullPath()));
    } else {
      return this.queryService.newQuery(((SortedSetQuery)query).getQueryString(this.regions.get(key).getFullPath()));
    }
    */
  }",False
"  public boolean removeKey(ByteArrayWrapper key) {
    RedisDataType type = getRedisDataType(key);
    return removeKey(key, type);
  }",True
"  public void removeRegionReferenceLocally(ByteArrayWrapper key, RedisDataType type) {
    Lock lock = this.locks.get(key.toString());
    boolean locked = false;
    try {
      locked = lock.tryLock();
      // If we cannot get the lock we ignore this remote event, this key has local event
      // that started independently, ignore this event to prevent deadlock
      if (locked) {
        cancelKeyExpiration(key);
        removeRegionState(key, type);
      }
    } finally {
      if (locked) {
        lock.unlock();
      }
    }
  }

  public boolean removeKey(ByteArrayWrapper key) {
    RedisDataType type = getRedisDataType(key);
    return removeKey(key, type);",False
"  private void doInitializeList(ByteArrayWrapper key, String fullpath) {
    listsMetaRegion.put(key + ""head"", Integer.valueOf(0));
    listsMetaRegion.put(key + ""tail"", Integer.valueOf(0));
    HashMap<Enum<?>, Query> queryList = new HashMap<Enum<?>, Query>();
    for (ListQuery lq: ListQuery.values()) {
      String queryString = lq.getQueryString(fullpath);
      Query query = this.queryService.newQuery(queryString);
      queryList.put(lq, query);
    }
    this.preparedQueries.put(key, queryList);
  }",True
"      Lock lock = this.locks.get(stringKey);
      if (lock == null) {
        this.locks.putIfAbsent(stringKey, new ReentrantLock());
        lock = this.locks.get(stringKey);
      }

      try {
        lock.lock();
        r = regions.get(key);
        if (r == null) {
          boolean hasTransaction = context != null && context.hasTransaction(); // Can create without context",False
"  private void doInitializeSortedSet(ByteArrayWrapper key, Region<?, ?> r) {
    String fullpath = r.getFullPath();
    try {
      queryService.createIndex(""scoreIndex"", ""value.score"", r.getFullPath() + "".entrySet entry"");
      queryService.createIndex(""scoreIndex2"", ""value.score"", r.getFullPath() + "".values value"");
    } catch (Exception e) {
      if (!(e instanceof IndexNameConflictException)) {
        LogWriter logger = cache.getLogger();
        if (logger.errorEnabled()) {
          logger.error(e);
        }
      }
    }
    HashMap<Enum<?>, Query> queryList = new HashMap<Enum<?>, Query>();
    for (SortedSetQuery lq: SortedSetQuery.values()) {
      String queryString = lq.getQueryString(fullpath);
      Query query = this.queryService.newQuery(queryString);
      queryList.put(lq, query);
    }
    this.preparedQueries.put(key, queryList);
  }",True
"            doInitializeList(key, r);
          else if (type == RedisDataType.REDIS_SORTEDSET)
            doInitializeSortedSet(key, r);
          this.regions.put(key, r);
        }
      } finally {
        if (locked) {
          lock.unlock();
        }
      }
    }
  }

  private Region<?, ?> getOrCreateRegion0(ByteArrayWrapper key, RedisDataType type, ExecutionHandlerContext context, boolean addToMeta) {
    checkDataType(key, type);
    Region<?, ?> r = this.regions.get(key);
    if (r != null && r.isDestroyed()) {
      removeKey(key, type);
      r = null;
    }
    if (r == null) {",False
"  private boolean destroyRegion(ByteArrayWrapper key, RedisDataType type) {
    Region<?, ?> r = this.regions.get(key);
    if (r != null) {
      try {
        r.destroyRegion();
      } catch (Exception e) {
        return false;
      } finally {
        removeRegionState(key, type);
      }
    }
    return true;
  }",False
"  public RegionCache(Region<ByteArrayWrapper, ByteArrayWrapper> stringsRegion, Region<ByteArrayWrapper, HyperLogLogPlus> hLLRegion, Region<String, RedisDataType> redisMetaRegion, Region<String, Integer> listsMetaRegion, ConcurrentMap<ByteArrayWrapper, ScheduledFuture<?>> expirationsMap, ScheduledExecutorService expirationExecutor) {
    if (stringsRegion == null || hLLRegion == null || redisMetaRegion == null || listsMetaRegion == null)
      throw new NullPointerException();
    this.regions = new ConcurrentHashMap<ByteArrayWrapper, Region<?, ?>>();
    this.stringsRegion = stringsRegion;
    this.hLLRegion = hLLRegion;
    this.redisMetaRegion = redisMetaRegion;
    this.listsMetaRegion = listsMetaRegion;
    this.cache = GemFireCacheImpl.getInstance();
    this.queryService = cache.getQueryService();
    this.expirationsMap = expirationsMap;
    this.expirationExecutor = expirationExecutor;
  }",True
"  private final Region<ByteArrayWrapper, HyperLogLogPlus> hLLRegion;

  private final Cache cache;
  private final QueryService queryService;
  private final ConcurrentMap<ByteArrayWrapper, Map<Enum<?>, Query>> preparedQueries = new ConcurrentHashMap<ByteArrayWrapper, Map<Enum<?>, Query>>();
  private final ConcurrentMap<ByteArrayWrapper, ScheduledFuture<?>> expirationsMap;
  private final ScheduledExecutorService expirationExecutor;
  private final RegionShortcut defaultRegionType;
  private static final CreateAlterDestroyRegionCommands cliCmds = new CreateAlterDestroyRegionCommands();
  private final ConcurrentHashMap<String, Lock> locks;
  private final LogWriter logger;

  public RegionProvider(Region<ByteArrayWrapper, ByteArrayWrapper> stringsRegion, Region<ByteArrayWrapper, HyperLogLogPlus> hLLRegion, Region<String, RedisDataType> redisMetaRegion, ConcurrentMap<ByteArrayWrapper, ScheduledFuture<?>> expirationsMap, ScheduledExecutorService expirationExecutor, RegionShortcut defaultShortcut) {",False
"  private void doInitializeSortedSet(ByteArrayWrapper key, Region<?, ?> r) {
    String fullpath = r.getFullPath();
    try {
      queryService.createIndex(""scoreIndex"", ""entry.value.score"", r.getFullPath() + "".entrySet entry"");
      queryService.createIndex(""scoreIndex2"", ""value.score"", r.getFullPath() + "".values value"");
    } catch (Exception e) {
      if (!(e instanceof IndexNameConflictException)) {
        if (logger.errorEnabled()) {
          logger.error(e);
        }
      }
    }
    HashMap<Enum<?>, Query> queryList = new HashMap<Enum<?>, Query>();
    for (SortedSetQuery lq: SortedSetQuery.values()) {
      String queryString = lq.getQueryString(fullpath);
      Query query = this.queryService.newQuery(queryString);
      queryList.put(lq, query);
    }
    this.preparedQueries.put(key, queryList);
  }",False
"  private Region<?, ?> getOrCreateRegion0(ByteArrayWrapper key, RedisDataType type, ExecutionHandlerContext context, boolean addToMeta) {
    checkDataType(key, type);
    Region<?, ?> r = this.regions.get(key);
    if (r == null) {
      String stringKey = key.toString();
      synchronized (stringKey) { // This object will be interned across the vm
        r = regions.get(key);
        if (r == null) {
          boolean hasTransaction = context != null && context.hasTransaction(); // Can create without context
          CacheTransactionManager txm = null;
          TransactionId transactionId = null;
          try {
            if (hasTransaction) {
              txm = cache.getCacheTransactionManager();
              transactionId = txm.suspend();
            }
            r = createRegionGlobally(stringKey);
            if (addToMeta)
              metaPut(key, type);
            if (type == RedisDataType.REDIS_LIST)
              doInitializeList(key, r.getFullPath());
            else if (type == RedisDataType.REDIS_SORTEDSET)
              doInitializeSortedSet(key, r);
            this.regions.put(key, r);
          } finally {
            if (hasTransaction)
              txm.resume(transactionId);
          }
        }
      }
    }
    return r;
  }",True
"    Lock lock = this.locks.get(key.toString());
    try {
      if (lock != null)  {// Strings/hlls will not have locks
        lock.lock();
      }
      metaRemoveEntry(key);
      try {
        if (type == RedisDataType.REDIS_STRING) {
          return this.stringsRegion.remove(key) != null;
        } else if (type == RedisDataType.REDIS_HLL) {
          return this.hLLRegion.remove(key) != null;
        } else {
          return destroyRegion(key, type);
        }
      } catch (Exception exc) {
        return false;
      } finally {
        if (cancelExpiration)
          cancelKeyExpiration(key);
        else
          removeKeyExpiration(key);
        if (lock != null)
          this.locks.remove(key.toString());
      }
    } finally {
      if (lock != null) {
        lock.unlock();
      }
    }
  }

  public Region<?, ?> getOrCreateRegion(ByteArrayWrapper key, RedisDataType type, ExecutionHandlerContext context) {
    return getOrCreateRegion0(key, type, context, true);",False
"  public String dumpRegionsCache() {
    StringBuilder builder = new StringBuilder();
    for (Entry<ByteArrayWrapper, Region<?, ?>> e : this.regions.entrySet()) {
      builder.append(e.getKey() + "" --> {"" + e.getValue() + ""}\n"");
    }
    return builder.toString();
  }",False
"  private void removeRegionState(ByteArrayWrapper key, RedisDataType type) {
    this.preparedQueries.remove(key);
    this.regions.remove(key);
  }",False
"  private Region<?, ?> getOrCreateRegion0(ByteArrayWrapper key, RedisDataType type, ExecutionHandlerContext context, boolean addToMeta) {
    checkDataType(key, type);
    Region<?, ?> r = this.regions.get(key);
    if (r != null && r.isDestroyed()) {
      removeKey(key, type);
      r = null;
    }
    if (r == null) {
      String stringKey = key.toString();
      Lock lock = this.locks.get(stringKey);
      if (lock == null) {
        this.locks.putIfAbsent(stringKey, new ReentrantLock());
        lock = this.locks.get(stringKey);
      }

      try {
        lock.lock();
        r = regions.get(key);
        if (r == null) {
          boolean hasTransaction = context != null && context.hasTransaction(); // Can create without context
          CacheTransactionManager txm = null;
          TransactionId transactionId = null;
          try {
            if (hasTransaction) {
              txm = cache.getCacheTransactionManager();
              transactionId = txm.suspend();
            }
            Exception concurrentCreateDestroyException = null;
            do {
              concurrentCreateDestroyException = null;
              r = createRegionGlobally(stringKey);
              try {
                if (type == RedisDataType.REDIS_LIST)
                  doInitializeList(key, r);
                else if (type == RedisDataType.REDIS_SORTEDSET)
                  doInitializeSortedSet(key, r);
              } catch (QueryInvalidException e) {
                if (e.getCause() instanceof RegionNotFoundException) {
                  concurrentCreateDestroyException = e;
                }
              }
            } while(concurrentCreateDestroyException != null);
            this.regions.put(key, r);            
            if (addToMeta) {
              RedisDataType existingType = metaPutIfAbsent(key, type);
              if (existingType != null && existingType != type)
                throw new RedisDataTypeMismatchException(""The key name \"""" + key + ""\"" is already used by a "" + existingType.toString());
            }
          } finally {
            if (hasTransaction)
              txm.resume(transactionId);
          }
        }
      } finally {
        lock.unlock();
      }
    }
    return r;
  }",False
"  public Region<?, ?> createRemoteRegionLocally(ByteArrayWrapper key, RedisDataType type) {
    return getOrCreateRegion0(key, type, null, false);
  }",True
"
  public boolean removeKey(ByteArrayWrapper key, RedisDataType type, boolean cancelExpiration) {
    if (type == null || type == RedisDataType.REDIS_PROTECTED)",False
"  protected Query getQuery(ByteArrayWrapper key, Enum<?> type, ExecutionHandlerContext context) {
    return context.getRegionCache().getQuery(key, type);
  }",True
"  protected Query getQuery(ByteArrayWrapper key, Enum<?> type, ExecutionHandlerContext context) {
    return context.getRegionProvider().getQuery(key, type);
  }",False
"  protected void checkDataType(ByteArrayWrapper key, RedisDataType type, ExecutionHandlerContext context) {
    RedisDataType currentType = context.getRegionCache().getRedisDataType(key);
    if (currentType == null)
      return;
    if (currentType == RedisDataType.REDIS_PROTECTED)
      throw new RedisDataTypeMismatchException(""The key name \"""" + key + ""\"" is protected"");
    if (currentType != type)
      throw new RedisDataTypeMismatchException(""The key name \"""" + key + ""\"" is already used by a "" + currentType.toString());
  }",True
"  protected void checkDataType(ByteArrayWrapper key, RedisDataType type, ExecutionHandlerContext context) {
    RedisDataType currentType = context.getRegionProvider().getRedisDataType(key);
    if (currentType == null)
      return;
    if (currentType == RedisDataType.REDIS_PROTECTED)
      throw new RedisDataTypeMismatchException(""The key name \"""" + key + ""\"" is protected"");
    if (currentType != type)
      throw new RedisDataTypeMismatchException(""The key name \"""" + key + ""\"" is already used by a "" + currentType.toString());
  }",False
"  protected boolean removeEntry(ByteArrayWrapper key, RedisDataType type, ExecutionHandlerContext context) {
    if (type == null || type == RedisDataType.REDIS_PROTECTED)
      return false;
    RegionCache rC = context.getRegionCache();
    return rC.removeKey(key, type);
  }",True
"  protected boolean removeEntry(ByteArrayWrapper key, RedisDataType type, ExecutionHandlerContext context) {
    if (type == null || type == RedisDataType.REDIS_PROTECTED)
      return false;
    RegionProvider rC = context.getRegionProvider();
    return rC.removeKey(key, type);
  }",False
"  protected Region<?, ?> getOrCreateRegion(ExecutionHandlerContext context, ByteArrayWrapper key, RedisDataType type) {
    return context.getRegionCache().getOrCreateRegion(key, type, context);
  }",True
"  protected Region<?, ?> getOrCreateRegion(ExecutionHandlerContext context, ByteArrayWrapper key, RedisDataType type) {
    return context.getRegionProvider().getOrCreateRegion(key, type, context);
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    int size = context.getRegionCache().getMetaSize();
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), size));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    int size = context.getRegionProvider().getMetaSize();
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), size));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    if (context.hasTransaction())
      throw new UnsupportedOperationInTransactionException();

    List<byte[]> commandElems = command.getProcessedCommand();
    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.DEL));
      return;
    }

    int numRemoved = 0;

    for (int i = 1; i < commandElems.size(); i++) {
      byte[] byteKey = commandElems.get(i);
      ByteArrayWrapper key = new ByteArrayWrapper(byteKey);
      RedisDataType type = context.getRegionCache().getRedisDataType(key); 
      if (removeEntry(key, type, context))
        numRemoved++;
    }

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), numRemoved));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    if (context.hasTransaction())
      throw new UnsupportedOperationInTransactionException();

    List<byte[]> commandElems = command.getProcessedCommand();
    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.DEL));
      return;
    }

    int numRemoved = 0;

    for (int i = 1; i < commandElems.size(); i++) {
      byte[] byteKey = commandElems.get(i);
      ByteArrayWrapper key = new ByteArrayWrapper(byteKey);
      RedisDataType type = context.getRegionProvider().getRedisDataType(key); 
      if (removeEntry(key, type, context))
        numRemoved++;
    }

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), numRemoved));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();
    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.EXISTS));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    boolean exists = context.getRegionCache().existsKey(key);

    if (exists)
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), EXISTS));
    else
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_EXISTS));

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();
    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.EXISTS));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    boolean exists = context.getRegionProvider().existsKey(key);

    if (exists)
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), EXISTS));
    else
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_EXISTS));

  }",False
"  public ExpirationExecutor(ByteArrayWrapper k, RedisDataType type, RegionCache rC) {
    this.key = k;
    this.type = type;
    this.rC = rC;
  }",True
"  public ExpirationExecutor(ByteArrayWrapper k, RedisDataType type, RegionProvider rC) {
    this.key = k;
    this.type = type;
    this.rC = rC;
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), getArgsError()));
      return;
    }
    RegionCache rC = context.getRegionCache();
    ByteArrayWrapper wKey = command.getKey();

    byte[] timestampByteArray = commandElems.get(TIMESTAMP_INDEX);
    long timestamp;
    try {
      timestamp = Coder.bytesToLong(timestampByteArray);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_TIMESTAMP_NOT_USABLE));
      return;
    }

    if (!timeUnitMillis())
      timestamp = timestamp * millisInSecond;

    long currentTimeMillis = System.currentTimeMillis();
    
    if (timestamp <= currentTimeMillis) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_SET));
      return;
    }

    long delayMillis = timestamp - currentTimeMillis;

    boolean expirationSet = false;

    if (rC.hasExpiration(wKey))
      expirationSet = rC.modifyExpiration(wKey, delayMillis);
    else
      expirationSet = rC.setExpiration(wKey, delayMillis);

    if (expirationSet)
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), SET));
    else
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_SET));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), getArgsError()));
      return;
    }
    RegionProvider rC = context.getRegionProvider();
    ByteArrayWrapper wKey = command.getKey();

    byte[] timestampByteArray = commandElems.get(TIMESTAMP_INDEX);
    long timestamp;
    try {
      timestamp = Coder.bytesToLong(timestampByteArray);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_TIMESTAMP_NOT_USABLE));
      return;
    }

    if (!timeUnitMillis())
      timestamp = timestamp * millisInSecond;

    long currentTimeMillis = System.currentTimeMillis();
    
    if (timestamp <= currentTimeMillis) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_SET));
      return;
    }

    long delayMillis = timestamp - currentTimeMillis;

    boolean expirationSet = false;

    if (rC.hasExpiration(wKey))
      expirationSet = rC.modifyExpiration(wKey, delayMillis);
    else
      expirationSet = rC.setExpiration(wKey, delayMillis);

    if (expirationSet)
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), SET));
    else
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_SET));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), getArgsError()));
      return;
    }
    ByteArrayWrapper wKey = command.getKey();
    RegionCache rC = context.getRegionCache();
        byte[] delayByteArray = commandElems.get(SECONDS_INDEX);
    long delay;
    try {
      delay = Coder.bytesToLong(delayByteArray);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_SECONDS_NOT_USABLE));
      return;
    } 

    if (delay <= 0) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_SET));
      return;
    }

    // If time unit given is not in millis convert to millis
    if (!timeUnitMillis())
      delay = delay * millisInSecond;

    boolean expirationSet = false;

    if (rC.hasExpiration(wKey))
      expirationSet = rC.modifyExpiration(wKey, delay);
    else
      expirationSet = rC.setExpiration(wKey, delay);


    if (expirationSet)
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), SET));
    else
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_SET));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), getArgsError()));
      return;
    }
    ByteArrayWrapper wKey = command.getKey();
    RegionProvider rC = context.getRegionProvider();
        byte[] delayByteArray = commandElems.get(SECONDS_INDEX);
    long delay;
    try {
      delay = Coder.bytesToLong(delayByteArray);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_SECONDS_NOT_USABLE));
      return;
    } 

    if (delay <= 0) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_SET));
      return;
    }

    // If time unit given is not in millis convert to millis
    if (!timeUnitMillis())
      delay = delay * millisInSecond;

    boolean expirationSet = false;

    if (rC.hasExpiration(wKey))
      expirationSet = rC.modifyExpiration(wKey, delay);
    else
      expirationSet = rC.setExpiration(wKey, delay);


    if (expirationSet)
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), SET));
    else
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_SET));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    if (context.hasTransaction())
      throw new UnsupportedOperationInTransactionException();

    for (Entry<String, RedisDataType> e: context.getRegionCache().metaEntrySet()) {
      String skey = e.getKey();
      RedisDataType type = e.getValue();
      removeEntry(Coder.stringToByteWrapper(skey), type, context);
        
    }

    command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), ""OK""));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    if (context.hasTransaction())
      throw new UnsupportedOperationInTransactionException();

    for (Entry<String, RedisDataType> e: context.getRegionProvider().metaEntrySet()) {
      try {
        String skey = e.getKey();
        RedisDataType type = e.getValue();
        removeEntry(Coder.stringToByteWrapper(skey), type, context);
      } catch (EntryDestroyedException e1) {
        continue;
      }

    }

    command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), ""OK""));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();
    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.KEYS));
      return;
    }

    String glob = Coder.bytesToString(commandElems.get(1));
    Set<String> allKeys = context.getRegionCache().metaKeySet();
    List<String> matchingKeys = new ArrayList<String>();

    Pattern pattern;
    try {
      pattern = GlobPattern.compile(glob);
    } catch (PatternSyntaxException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), RedisConstants.ERROR_ILLEGAL_GLOB));
      return;
    }

    for (String key: allKeys) {
      if (!(key.equals(GemFireRedisServer.LISTS_META_DATA_REGION) ||
              key.equals(GemFireRedisServer.REDIS_META_DATA_REGION) ||
              key.equals(GemFireRedisServer.STRING_REGION) ||
              key.equals(GemFireRedisServer.HLL_REGION))
              && pattern.matcher(key).matches())
        matchingKeys.add(key);
    }

    if (matchingKeys.isEmpty()) 
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
    else
      command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), matchingKeys));


  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();
    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.KEYS));
      return;
    }

    String glob = Coder.bytesToString(commandElems.get(1));
    Set<String> allKeys = context.getRegionProvider().metaKeySet();
    List<String> matchingKeys = new ArrayList<String>();

    Pattern pattern;
    try {
      pattern = GlobPattern.compile(glob);
    } catch (PatternSyntaxException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), RedisConstants.ERROR_ILLEGAL_GLOB));
      return;
    }

    for (String key: allKeys) {
      if (!(key.equals(GemFireRedisServer.REDIS_META_DATA_REGION) ||
              key.equals(GemFireRedisServer.STRING_REGION) ||
              key.equals(GemFireRedisServer.HLL_REGION))
              && pattern.matcher(key).matches())
        matchingKeys.add(key);
    }

    if (matchingKeys.isEmpty()) 
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
    else
      command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), matchingKeys));


  }",False
"    public String getQueryString(String fullpath) {
      return ""SELECT DISTINCT entry.key, entry.value FROM "" + fullpath + "".entrySet entry ORDER BY key asc LIMIT $1"";
    }",True
"    public String getQueryString(String fullpath) {
      return ""SELECT DISTINCT entry.key, entry.value FROM "" + fullpath + "".entrySet entry WHERE key != 'head' AND key != 'tail' ORDER BY key asc LIMIT $1"";
    }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.PERSIST));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    
    boolean canceled = context.getRegionCache().cancelKeyExpiration(key);
    
    if (canceled)
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), TIMEOUT_REMOVED));
    else
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), KEY_NOT_EXIST_OR_NO_TIMEOUT));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.PERSIST));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    
    boolean canceled = context.getRegionProvider().cancelKeyExpiration(key);
    
    if (canceled)
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), TIMEOUT_REMOVED));
    else
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), KEY_NOT_EXIST_OR_NO_TIMEOUT));
  }",False
"  protected List<?> getIteration(Collection<?> list, Pattern matchPattern, int count, int cursor) {
    List<String> returnList = new ArrayList<String>();
    int size = list.size();
    int beforeCursor = 0;
    int numElements = 0;
    int i = -1;
    for (String key: (Collection<String>) list) {
      if (key.equals(GemFireRedisServer.REDIS_META_DATA_REGION) || key.equals(GemFireRedisServer.LISTS_META_DATA_REGION) || key.equals(GemFireRedisServer.STRING_REGION) || key.equals(GemFireRedisServer.HLL_REGION))
        continue;
      i++;
      if (beforeCursor < cursor) {
        beforeCursor++;
        continue;
      } else if (numElements < count) {
        if (matchPattern != null) {
          if (matchPattern.matcher(key).matches()) {
            returnList.add(key);
            numElements++;
          }
        } else {
          returnList.add(key);
          numElements++;
        }
      } else
        break;
    }

    if (i == size - (NUM_DEFAULT_REGIONS + 1))
      returnList.add(0, String.valueOf(0));
    else
      returnList.add(0, String.valueOf(i));
    return returnList;
  }",True
"  protected List<?> getIteration(Collection<?> list, Pattern matchPattern, int count, int cursor) {
    List<String> returnList = new ArrayList<String>();
    int size = list.size();
    int beforeCursor = 0;
    int numElements = 0;
    int i = -1;
    for (String key: (Collection<String>) list) {
      if (key.equals(GemFireRedisServer.REDIS_META_DATA_REGION) || key.equals(GemFireRedisServer.STRING_REGION) || key.equals(GemFireRedisServer.HLL_REGION))
        continue;
      i++;
      if (beforeCursor < cursor) {
        beforeCursor++;
        continue;
      } else if (numElements < count) {
        if (matchPattern != null) {
          if (matchPattern.matcher(key).matches()) {
            returnList.add(key);
            numElements++;
          }
        } else {
          returnList.add(key);
          numElements++;
        }
      } else
        break;
    }

    if (i == size - (NUM_DEFAULT_REGIONS + 1))
      returnList.add(0, String.valueOf(0));
    else
      returnList.add(0, String.valueOf(i));
    return returnList;
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SCAN));
      return;
    }

    String cursorString = command.getStringKey();
    int cursor = 0;
    Pattern matchPattern = null;
    String globMatchString = null;
    int count = DEFUALT_COUNT;
    try {
      cursor = Integer.parseInt(cursorString);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_CURSOR));
      return;
    }
    if (cursor < 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_CURSOR));
      return;
    }

    if (commandElems.size() > 3) {
      try {
        byte[] bytes = commandElems.get(2);
        String tmp = Coder.bytesToString(bytes);
        if (tmp.equalsIgnoreCase(""MATCH"")) {
          bytes = commandElems.get(3);
          globMatchString = Coder.bytesToString(bytes);
        } else if (tmp.equalsIgnoreCase(""COUNT"")) {
          bytes = commandElems.get(3);
          count = Coder.bytesToInt(bytes);
        }
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
        return;
      }
    }

    if (commandElems.size() > 5) {
      try {
        byte[] bytes = commandElems.get(4);
        String tmp = Coder.bytesToString(bytes);
        if (tmp.equalsIgnoreCase(""COUNT"")) {
          bytes = commandElems.get(5);
          count = Coder.bytesToInt(bytes);
        }
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
        return;
      }
    }

    if (count < 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
      return;
    }

    try {
      matchPattern = convertGlobToRegex(globMatchString);
    } catch (PatternSyntaxException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), RedisConstants.ERROR_ILLEGAL_GLOB));
      return;
    }

    @SuppressWarnings(""unchecked"")
    List<String> returnList = (List<String>) getIteration(context.getRegionCache().metaKeySet(), matchPattern, count, cursor);

    command.setResponse(Coder.getScanResponse(context.getByteBufAllocator(), returnList));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SCAN));
      return;
    }

    String cursorString = command.getStringKey();
    int cursor = 0;
    Pattern matchPattern = null;
    String globMatchString = null;
    int count = DEFUALT_COUNT;
    try {
      cursor = Integer.parseInt(cursorString);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_CURSOR));
      return;
    }
    if (cursor < 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_CURSOR));
      return;
    }

    if (commandElems.size() > 3) {
      try {
        byte[] bytes = commandElems.get(2);
        String tmp = Coder.bytesToString(bytes);
        if (tmp.equalsIgnoreCase(""MATCH"")) {
          bytes = commandElems.get(3);
          globMatchString = Coder.bytesToString(bytes);
        } else if (tmp.equalsIgnoreCase(""COUNT"")) {
          bytes = commandElems.get(3);
          count = Coder.bytesToInt(bytes);
        }
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
        return;
      }
    }

    if (commandElems.size() > 5) {
      try {
        byte[] bytes = commandElems.get(4);
        String tmp = Coder.bytesToString(bytes);
        if (tmp.equalsIgnoreCase(""COUNT"")) {
          bytes = commandElems.get(5);
          count = Coder.bytesToInt(bytes);
        }
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
        return;
      }
    }

    if (count < 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
      return;
    }

    try {
      matchPattern = convertGlobToRegex(globMatchString);
    } catch (PatternSyntaxException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), RedisConstants.ERROR_ILLEGAL_GLOB));
      return;
    }

    @SuppressWarnings(""unchecked"")
    List<String> returnList = (List<String>) getIteration(context.getRegionProvider().metaKeySet(), matchPattern, count, cursor);

    command.setResponse(Coder.getScanResponse(context.getByteBufAllocator(), returnList));
  }",False
"    public String getQueryString(String fullpath) {
      return ""SELECT COUNT(*) FROM "" + fullpath + "".values value WHERE value.score <= $1"";
    }",True
"    public String getQueryString(String fullpath) {
      return ""SELECT DISTINCT entry.key, entry.value FROM "" + fullpath + "".entrySet entry WHERE value.score <= $1 ORDER BY entry.value asc LIMIT $2"";
    }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), getArgsError()));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    RegionCache rC = context.getRegionCache();
    boolean exists = false;
    RedisDataType val = rC.getRedisDataType(key);
    if (val != null)
      exists = true;

    if (!exists) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_EXISTS));
      return;
    }
    long ttl = rC.getExpirationDelayMillis(key);
    
    if (ttl == 0L) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NO_TIMEOUT));
      return;
    }
    
    if(!timeUnitMillis())
      ttl = ttl / millisInSecond;

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), ttl));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), getArgsError()));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    RegionProvider rC = context.getRegionProvider();
    boolean exists = false;
    RedisDataType val = rC.getRedisDataType(key);
    if (val != null)
      exists = true;

    if (!exists) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_EXISTS));
      return;
    }
    long ttl = rC.getExpirationDelayMillis(key);
    
    if (ttl == 0L) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NO_TIMEOUT));
      return;
    }
    
    if(!timeUnitMillis())
      ttl = ttl / millisInSecond;

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), ttl));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();
    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.TYPE));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    RedisDataType type = context.getRegionCache().getRedisDataType(key);

    if (type == null)
      command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), ""none""));
    else 
      command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), type.toString()));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();
    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.TYPE));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    RedisDataType type = context.getRegionProvider().getRedisDataType(key);

    if (type == null)
      command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), ""none""));
    else 
      command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), type.toString()));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.HDEL));
      return;
    }

    int numDeleted = 0;
    
    ByteArrayWrapper key = command.getKey();

    checkDataType(key, RedisDataType.REDIS_HASH, context);
    Region<ByteArrayWrapper, ByteArrayWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), numDeleted));
      return;
    }

    
    for (int i = START_FIELDS_INDEX; i < commandElems.size(); i++) {
      ByteArrayWrapper field = new ByteArrayWrapper(commandElems.get(i));
      Object oldValue = keyRegion.remove(field);
      if (oldValue != null)
        numDeleted++;
    }
    if (keyRegion.isEmpty()) {
      context.getRegionCache().removeKey(key, RedisDataType.REDIS_HASH);
    }
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), numDeleted));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.HDEL));
      return;
    }

    int numDeleted = 0;
    
    ByteArrayWrapper key = command.getKey();

    checkDataType(key, RedisDataType.REDIS_HASH, context);
    Region<ByteArrayWrapper, ByteArrayWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), numDeleted));
      return;
    }

    
    for (int i = START_FIELDS_INDEX; i < commandElems.size(); i++) {
      ByteArrayWrapper field = new ByteArrayWrapper(commandElems.get(i));
      Object oldValue = keyRegion.remove(field);
      if (oldValue != null)
        numDeleted++;
    }
    if (keyRegion.isEmpty()) {
      context.getRegionProvider().removeKey(key, RedisDataType.REDIS_HASH);
    }
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), numDeleted));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.HGETALL));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    checkDataType(key, RedisDataType.REDIS_HASH, context);
    Region<ByteArrayWrapper, ByteArrayWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      return;
    }

    Set<Map.Entry<ByteArrayWrapper,ByteArrayWrapper>> entries = keyRegion.entrySet();
   
   if (entries.isEmpty()) {
     command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
     return;
   }

   command.setResponse(Coder.getKeyValArrayResponse(context.getByteBufAllocator(), entries));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.HGETALL));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    checkDataType(key, RedisDataType.REDIS_HASH, context);
    Region<ByteArrayWrapper, ByteArrayWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      return;
    }

    Collection<Map.Entry<ByteArrayWrapper,ByteArrayWrapper>> entries = new ArrayList(keyRegion.entrySet()); // This creates a CopyOnRead behavior
   
   if (entries.isEmpty()) {
     command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
     return;
   }

   command.setResponse(Coder.getKeyValArrayResponse(context.getByteBufAllocator(), entries));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.HKEYS));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    checkDataType(key, RedisDataType.REDIS_HASH, context);
    Region<ByteArrayWrapper, ByteArrayWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      return;
    }

   Set<ByteArrayWrapper> keys = keyRegion.keySet();
   
   if (keys.isEmpty()) {
     command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
     return;
   }
   
   // String response = getBulkStringArrayResponse(keys);

   command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), keys));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.HKEYS));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    checkDataType(key, RedisDataType.REDIS_HASH, context);
    Region<ByteArrayWrapper, ByteArrayWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      return;
    }

   Set<ByteArrayWrapper> keys = new HashSet(keyRegion.keySet());
   
   if (keys.isEmpty()) {
     command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
     return;
   }
   
   // String response = getBulkStringArrayResponse(keys);

   command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), keys));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.HSCAN));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, ByteArrayWrapper> keyRegion = (Region<ByteArrayWrapper, ByteArrayWrapper>) context.getRegionCache().getRegion(key);
    checkDataType(key, RedisDataType.REDIS_HASH, context);
    if (keyRegion == null) {
      command.setResponse(Coder.getScanResponse(context.getByteBufAllocator(), new ArrayList<String>()));
      return;
    }
    byte[] cAr = commandElems.get(2);
    String cursorString = Coder.bytesToString(cAr);

    int cursor = 0;
    Pattern matchPattern = null;
    String globMatchPattern = null;
    int count = DEFUALT_COUNT;
    try {
      cursor = Integer.parseInt(cursorString);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_CURSOR));
      return;
    }
    if (cursor < 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_CURSOR));
      return;
    }

    if (commandElems.size() > 4) {
      try {
        byte[] bytes = commandElems.get(3);
        String tmp = Coder.bytesToString(bytes);
        if (tmp.equalsIgnoreCase(""MATCH"")) {
          bytes = commandElems.get(4);
          globMatchPattern = Coder.bytesToString(bytes);
        } else if (tmp.equalsIgnoreCase(""COUNT"")) {
          bytes = commandElems.get(4);
          count = Coder.bytesToInt(bytes);
        }
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
        return;
      }
    }

    if (commandElems.size() > 6) {
      try {
        byte[] bytes = commandElems.get(5);
        String tmp = Coder.bytesToString(bytes);
        if (tmp.equalsIgnoreCase(""MATCH"")) {
          bytes = commandElems.get(6);
          globMatchPattern = Coder.bytesToString(bytes);
        } else if (tmp.equalsIgnoreCase(""COUNT"")) {
          bytes = commandElems.get(6);
          count = Coder.bytesToInt(bytes);
        }
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
        return;
      }
    }

    if (count < 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
      return;
    }

    try {
      matchPattern = convertGlobToRegex(globMatchPattern);
    } catch (PatternSyntaxException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), RedisConstants.ERROR_ILLEGAL_GLOB));
      return;
    }

    List<Object> returnList = getIteration(keyRegion.entrySet(), matchPattern, count, cursor);

    command.setResponse(Coder.getScanResponse(context.getByteBufAllocator(), returnList));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.HSCAN));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, ByteArrayWrapper> keyRegion = (Region<ByteArrayWrapper, ByteArrayWrapper>) context.getRegionProvider().getRegion(key);
    checkDataType(key, RedisDataType.REDIS_HASH, context);
    if (keyRegion == null) {
      command.setResponse(Coder.getScanResponse(context.getByteBufAllocator(), new ArrayList<String>()));
      return;
    }
    byte[] cAr = commandElems.get(2);
    String cursorString = Coder.bytesToString(cAr);

    int cursor = 0;
    Pattern matchPattern = null;
    String globMatchPattern = null;
    int count = DEFUALT_COUNT;
    try {
      cursor = Integer.parseInt(cursorString);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_CURSOR));
      return;
    }
    if (cursor < 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_CURSOR));
      return;
    }

    if (commandElems.size() > 4) {
      try {
        byte[] bytes = commandElems.get(3);
        String tmp = Coder.bytesToString(bytes);
        if (tmp.equalsIgnoreCase(""MATCH"")) {
          bytes = commandElems.get(4);
          globMatchPattern = Coder.bytesToString(bytes);
        } else if (tmp.equalsIgnoreCase(""COUNT"")) {
          bytes = commandElems.get(4);
          count = Coder.bytesToInt(bytes);
        }
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
        return;
      }
    }

    if (commandElems.size() > 6) {
      try {
        byte[] bytes = commandElems.get(5);
        String tmp = Coder.bytesToString(bytes);
        if (tmp.equalsIgnoreCase(""MATCH"")) {
          bytes = commandElems.get(6);
          globMatchPattern = Coder.bytesToString(bytes);
        } else if (tmp.equalsIgnoreCase(""COUNT"")) {
          bytes = commandElems.get(6);
          count = Coder.bytesToInt(bytes);
        }
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
        return;
      }
    }

    if (count < 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
      return;
    }

    try {
      matchPattern = convertGlobToRegex(globMatchPattern);
    } catch (PatternSyntaxException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), RedisConstants.ERROR_ILLEGAL_GLOB));
      return;
    }

    List<Object> returnList = getIteration(new HashSet(keyRegion.entrySet()), matchPattern, count, cursor);

    command.setResponse(Coder.getScanResponse(context.getByteBufAllocator(), returnList));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.HVALS));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, RedisDataType.REDIS_HASH, context);

    Region<ByteArrayWrapper, ByteArrayWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      return;
    }

    Collection<ByteArrayWrapper> vals = keyRegion.values();

    if (vals.isEmpty()) {
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      return;
    }

    command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), vals));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.HVALS));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, RedisDataType.REDIS_HASH, context);

    Region<ByteArrayWrapper, ByteArrayWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      return;
    }
    
    Collection<ByteArrayWrapper> vals = new ArrayList(keyRegion.values());

    if (vals.isEmpty()) {
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      return;
    }

    command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), vals));
  }",False
"  protected Region<ByteArrayWrapper, ByteArrayWrapper> getOrCreateRegion(ExecutionHandlerContext context, ByteArrayWrapper key, RedisDataType type) {
   return (Region<ByteArrayWrapper, ByteArrayWrapper>) context.getRegionCache().getOrCreateRegion(key, type, context);
  }",True
"  protected Region<ByteArrayWrapper, ByteArrayWrapper> getOrCreateRegion(ExecutionHandlerContext context, ByteArrayWrapper key, RedisDataType type) {
   return (Region<ByteArrayWrapper, ByteArrayWrapper>) context.getRegionProvider().getOrCreateRegion(key, type, context);
  }",False
"  protected Region<ByteArrayWrapper, ByteArrayWrapper> getRegion(ExecutionHandlerContext context, ByteArrayWrapper key) {
   return (Region<ByteArrayWrapper, ByteArrayWrapper>) context.getRegionCache().getRegion(key);
  }",True
"  protected Region<ByteArrayWrapper, ByteArrayWrapper> getRegion(ExecutionHandlerContext context, ByteArrayWrapper key) {
   return (Region<ByteArrayWrapper, ByteArrayWrapper>) context.getRegionProvider().getRegion(key);
  }",False
"  protected final void checkAndSetDataType(ByteArrayWrapper key, ExecutionHandlerContext context) {
    Object oldVal = context.getRegionCache().metaPutIfAbsent(key, RedisDataType.REDIS_HLL);
    if (oldVal == RedisDataType.REDIS_PROTECTED)
      throw new RedisDataTypeMismatchException(""The key name \"""" + key + ""\"" is protected"");
    if (oldVal != null && oldVal != RedisDataType.REDIS_HLL)
      throw new RedisDataTypeMismatchException(""The key name \"""" + key + ""\"" is already used by a "" + oldVal.toString());
  }",True
"  protected final void checkAndSetDataType(ByteArrayWrapper key, ExecutionHandlerContext context) {
    Object oldVal = context.getRegionProvider().metaPutIfAbsent(key, RedisDataType.REDIS_HLL);
    if (oldVal == RedisDataType.REDIS_PROTECTED)
      throw new RedisDataTypeMismatchException(""The key name \"""" + key + ""\"" is protected"");
    if (oldVal != null && oldVal != RedisDataType.REDIS_HLL)
      throw new RedisDataTypeMismatchException(""The key name \"""" + key + ""\"" is already used by a "" + oldVal.toString());
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.PFADD));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    Region<ByteArrayWrapper, HyperLogLogPlus> keyRegion = context.getRegionCache().gethLLRegion();

    HyperLogLogPlus hll = keyRegion.get(key);

    boolean changed = false;

    if (hll == null)
      hll = new HyperLogLogPlus(DEFAULT_HLL_DENSE);

    for (int i = 2; i < commandElems.size(); i++) {
      byte[] bytes = commandElems.get(i);
      boolean offerChange = hll.offer(bytes);
      if (offerChange)
        changed = true;
    }

    keyRegion.put(key, hll);

    if (changed)
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 1));
    else
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.PFADD));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    Region<ByteArrayWrapper, HyperLogLogPlus> keyRegion = context.getRegionProvider().gethLLRegion();

    HyperLogLogPlus hll = keyRegion.get(key);

    boolean changed = false;

    if (hll == null)
      hll = new HyperLogLogPlus(DEFAULT_HLL_DENSE);

    for (int i = 2; i < commandElems.size(); i++) {
      byte[] bytes = commandElems.get(i);
      boolean offerChange = hll.offer(bytes);
      if (offerChange)
        changed = true;
    }

    keyRegion.put(key, hll);

    if (changed)
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 1));
    else
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.PFCOUNT));
      return;
    }

    Region<ByteArrayWrapper, HyperLogLogPlus> keyRegion = context.getRegionCache().gethLLRegion();

    List<HyperLogLogPlus> hlls = new ArrayList<HyperLogLogPlus>();

    for (int i = 1; i < commandElems.size(); i++) {
      ByteArrayWrapper k = new ByteArrayWrapper(commandElems.get(i));
      checkDataType(k, RedisDataType.REDIS_HLL, context);
      HyperLogLogPlus h = keyRegion.get(k);
      if (h != null)
        hlls.add(h);
    }
    if (hlls.isEmpty()) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      return;
    }

    HyperLogLogPlus tmp = hlls.remove(0);
    HyperLogLogPlus[] estimators = hlls.toArray(new HyperLogLogPlus[hlls.size()]);
    try {
      tmp = (HyperLogLogPlus) tmp.merge(estimators);
    } catch (CardinalityMergeException e) {
      throw new RuntimeException(e);
    }
    long cardinality = tmp.cardinality();
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), cardinality));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.PFCOUNT));
      return;
    }

    Region<ByteArrayWrapper, HyperLogLogPlus> keyRegion = context.getRegionProvider().gethLLRegion();

    List<HyperLogLogPlus> hlls = new ArrayList<HyperLogLogPlus>();

    for (int i = 1; i < commandElems.size(); i++) {
      ByteArrayWrapper k = new ByteArrayWrapper(commandElems.get(i));
      checkDataType(k, RedisDataType.REDIS_HLL, context);
      HyperLogLogPlus h = keyRegion.get(k);
      if (h != null)
        hlls.add(h);
    }
    if (hlls.isEmpty()) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      return;
    }

    HyperLogLogPlus tmp = hlls.remove(0);
    HyperLogLogPlus[] estimators = hlls.toArray(new HyperLogLogPlus[hlls.size()]);
    try {
      tmp = (HyperLogLogPlus) tmp.merge(estimators);
    } catch (CardinalityMergeException e) {
      throw new RuntimeException(e);
    }
    long cardinality = tmp.cardinality();
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), cardinality));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.PFMERGE));
      return;
    }

    ByteArrayWrapper destKey = command.getKey();
    checkAndSetDataType(destKey, context);
    Region<ByteArrayWrapper, HyperLogLogPlus> keyRegion = context.getRegionCache().gethLLRegion();
    HyperLogLogPlus mergedHLL = keyRegion.get(destKey);
    if (mergedHLL == null)
      mergedHLL = new HyperLogLogPlus(DEFAULT_HLL_DENSE);
    List<HyperLogLogPlus> hlls = new ArrayList<HyperLogLogPlus>();

    for (int i = 2; i < commandElems.size(); i++) {
      ByteArrayWrapper k = new ByteArrayWrapper(commandElems.get(i));
      checkDataType(k, RedisDataType.REDIS_HLL, context);
      HyperLogLogPlus h = keyRegion.get(k);
      if (h != null)
        hlls.add(h);
    }
    if (hlls.isEmpty()) {
      context.getRegionCache().removeKey(destKey);
      command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), ""OK""));
      return;
    }

    HyperLogLogPlus[] estimators = hlls.toArray(new HyperLogLogPlus[hlls.size()]);
    try {
      mergedHLL = (HyperLogLogPlus) mergedHLL.merge(estimators);
    } catch (CardinalityMergeException e) {
      throw new RuntimeException(e);
    }
    keyRegion.put(destKey, mergedHLL);
    command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), ""OK""));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.PFMERGE));
      return;
    }

    ByteArrayWrapper destKey = command.getKey();
    checkAndSetDataType(destKey, context);
    Region<ByteArrayWrapper, HyperLogLogPlus> keyRegion = context.getRegionProvider().gethLLRegion();
    HyperLogLogPlus mergedHLL = keyRegion.get(destKey);
    if (mergedHLL == null)
      mergedHLL = new HyperLogLogPlus(DEFAULT_HLL_DENSE);
    List<HyperLogLogPlus> hlls = new ArrayList<HyperLogLogPlus>();

    for (int i = 2; i < commandElems.size(); i++) {
      ByteArrayWrapper k = new ByteArrayWrapper(commandElems.get(i));
      checkDataType(k, RedisDataType.REDIS_HLL, context);
      HyperLogLogPlus h = keyRegion.get(k);
      if (h != null)
        hlls.add(h);
    }
    if (hlls.isEmpty()) {
      context.getRegionProvider().removeKey(destKey);
      command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), ""OK""));
      return;
    }

    HyperLogLogPlus[] estimators = hlls.toArray(new HyperLogLogPlus[hlls.size()]);
    try {
      mergedHLL = (HyperLogLogPlus) mergedHLL.merge(estimators);
    } catch (CardinalityMergeException e) {
      throw new RuntimeException(e);
    }
    keyRegion.put(destKey, mergedHLL);
    command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), ""OK""));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.LINDEX));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    byte[] indexArray = commandElems.get(2);

    checkDataType(key, RedisDataType.REDIS_LIST, context);
    Region<Integer, ByteArrayWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }

    int listSize = keyRegion.size();

    Integer redisIndex;

    try {
      redisIndex = Coder.bytesToInt(indexArray);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_NUMERIC));
      return;
    } 

    /*
     * Now the fun part, converting the redis index into our index.
     * The redis index is 0 based but negative values count from the tail
     */

    if (redisIndex < 0)
      // Since the redisIndex is negative here, this will reset it to be a standard 0 based index
      redisIndex = listSize + redisIndex;

    /*
     * If the index is still less than 0 that means the index has shot off
     * back past the beginning, which means the index isn't real and a nil is returned
     */
    if (redisIndex < 0) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }

    /*
     * Now we must get that element from the region
     */
    Struct entry;
    try {
      entry = getEntryAtIndex(context, key, redisIndex);
    } catch (Exception e) {
      throw new RuntimeException(e);
    }
    if (entry == null) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }

    Object[] entryArray = entry.getFieldValues();
    ByteArrayWrapper valueWrapper = (ByteArrayWrapper) entryArray[1];
    command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), valueWrapper.toBytes()));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.LINDEX));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    byte[] indexArray = commandElems.get(2);

    checkDataType(key, RedisDataType.REDIS_LIST, context);
    Region<Integer, ByteArrayWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }

    int listSize = keyRegion.size() - LIST_EMPTY_SIZE;

    Integer redisIndex;

    try {
      redisIndex = Coder.bytesToInt(indexArray);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_NUMERIC));
      return;
    } 

    /*
     * Now the fun part, converting the redis index into our index.
     * The redis index is 0 based but negative values count from the tail
     */

    if (redisIndex < 0)
      // Since the redisIndex is negative here, this will reset it to be a standard 0 based index
      redisIndex = listSize + redisIndex;

    /*
     * If the index is still less than 0 that means the index has shot off
     * back past the beginning, which means the index isn't real and a nil is returned
     */
    if (redisIndex < 0) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }

    /*
     * Now we must get that element from the region
     */
    Struct entry;
    try {
      entry = getEntryAtIndex(context, key, redisIndex);
    } catch (Exception e) {
      throw new RuntimeException(e);
    }
    if (entry == null) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }

    Object[] entryArray = entry.getFieldValues();
    ByteArrayWrapper valueWrapper = (ByteArrayWrapper) entryArray[1];
    command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), valueWrapper.toBytes()));
  }",False
"  private Struct getEntryAtIndex(ExecutionHandlerContext context, ByteArrayWrapper key, int index) throws Exception {

    Query query = getQuery(key, ListQuery.LINDEX, context);

    Object[] params = {new Integer(index + 1)};

    SelectResults<?> results = (SelectResults<?>) query.execute(params);

    if (results == null || results.size() == 0 || results.size() <= index)
      return null;
    else
      return (Struct) results.asList().get(index);
  }",True
"  private Struct getEntryAtIndex(ExecutionHandlerContext context, ByteArrayWrapper key, int index) throws Exception {

    Query query = getQuery(key, ListQuery.LINDEX, context);

    Object[] params = {Integer.valueOf(index + 1)};

    SelectResults<?> results = (SelectResults<?>) query.execute(params);

    if (results == null || results.size() == 0 || results.size() <= index)
      return null;
    else
      return (Struct) results.asList().get(index);
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.LLEN));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    int listSize = 0;
    
    checkDataType(key, RedisDataType.REDIS_LIST, context);
    Region<Integer, ByteArrayWrapper> keyRegion = getRegion(context, key);
    
    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_EXISTS));
      return;
    }
    
    listSize = keyRegion.size();

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), listSize));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.LLEN));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    int listSize = 0;
    
    checkDataType(key, RedisDataType.REDIS_LIST, context);
    Region<Integer, ByteArrayWrapper> keyRegion = getRegion(context, key);
    
    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_EXISTS));
      return;
    }
    
    listSize = keyRegion.size() - LIST_EMPTY_SIZE;

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), listSize));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.LRANGE));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    byte[] startArray = commandElems.get(2);
    byte[] stopArray = commandElems.get(3);

    int redisStart;
    int redisStop;


    checkDataType(key, RedisDataType.REDIS_LIST, context);
    Region<Integer, ByteArrayWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      return;
    }

    int listSize = keyRegion.size();
    if (listSize == 0) {
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      return;
    }

    try {
      redisStart = Coder.bytesToInt(startArray);
      redisStop =  Coder.bytesToInt(stopArray);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_NUMERIC));
      return;
    }


    redisStart = getBoundedStartIndex(redisStart, listSize);
    redisStop = getBoundedEndIndex(redisStop, listSize);
    if (redisStart > redisStop) {
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      return;
    }
    redisStart = Math.min(redisStart, listSize - 1);
    redisStop = Math.min(redisStop, listSize - 1);
   
    
    List<Struct> range;
    try {
      range = getRange(context, key, redisStart, redisStop);
    } catch (Exception e) {
      throw new RuntimeException(e);
    }

    if (range == null)
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
    else
      command.setResponse(Coder.getBulkStringArrayResponseOfValues(context.getByteBufAllocator(), range));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.LRANGE));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    byte[] startArray = commandElems.get(2);
    byte[] stopArray = commandElems.get(3);

    int redisStart;
    int redisStop;


    checkDataType(key, RedisDataType.REDIS_LIST, context);
    Region<Integer, ByteArrayWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      return;
    }

    int listSize = keyRegion.size() - LIST_EMPTY_SIZE;
    if (listSize == 0) {
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      return;
    }

    try {
      redisStart = Coder.bytesToInt(startArray);
      redisStop =  Coder.bytesToInt(stopArray);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_NUMERIC));
      return;
    }


    redisStart = getBoundedStartIndex(redisStart, listSize);
    redisStop = getBoundedEndIndex(redisStop, listSize);
    if (redisStart > redisStop) {
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      return;
    }
    redisStart = Math.min(redisStart, listSize - 1);
    redisStop = Math.min(redisStop, listSize - 1);
   
    
    List<Struct> range;
    try {
      range = getRange(context, key, redisStart, redisStop, keyRegion);
    } catch (Exception e) {
      throw new RuntimeException(e);
    }

    if (range == null)
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
    else
      command.setResponse(Coder.getBulkStringArrayResponseOfValues(context.getByteBufAllocator(), range));
  }",False
"  private List<Struct> getRange(ExecutionHandlerContext context, ByteArrayWrapper key, int start, int stop) throws Exception {

    Query query = getQuery(key, ListQuery.LRANGE, context);

    Object[] params = {new Integer(stop + 1)};

    SelectResults<Struct> results = (SelectResults<Struct>) query.execute(params);

    int size = results.size();
    if (results == null || size <= start) {
      return null;
    }

    return results.asList().subList(start, size);
  }",True
"  private List<Struct> getRange(ExecutionHandlerContext context, ByteArrayWrapper key, int start, int stop, Region r) throws Exception {

    Query query = getQuery(key, ListQuery.LRANGE, context);

    Object[] params = {Integer.valueOf(stop + 1)};
    SelectResults<Struct> results = (SelectResults<Struct>) query.execute(params);
    int size = results.size();
    if (results == null || size <= start) {
      return null;
    }

    return results.asList().subList(start, size);
  }",False
"  private List<Struct> getRange(ExecutionHandlerContext context, ByteArrayWrapper key, int start, int stop, Region r) throws Exception {

    Query query = getQuery(key, ListQuery.LRANGE, context);

    Object[] params = {Integer.valueOf(stop + 1)};
    SelectResults<Struct> results = (SelectResults<Struct>) query.execute(params);
    int size = results.size();
    if (results == null || size <= start) {
      return null;
    }

    return results.asList().subList(start, size);
  }
}
",False
"  private List<Struct> getRemoveList(ExecutionHandlerContext context, ByteArrayWrapper key, ByteArrayWrapper value, int count) throws Exception {
    Object[] params;
    Query query;
    if (count > 0) {
      query = getQuery(key, ListQuery.LREMG, context);
      params = new Object[]{value, new Integer(count)};
    } else if (count < 0) {
      query = getQuery(key, ListQuery.LREML, context);
      params = new Object[]{value, new Integer(-count)};
    } else {
      query = getQuery(key, ListQuery.LREME, context);
      params = new Object[]{value};
    }

    
    SelectResults<Struct> results = (SelectResults<Struct>) query.execute(params);

    if (results == null || results.isEmpty()) {
      return null;
    }

    return results.asList();
  }",True
"  private List<Struct> getRemoveList(ExecutionHandlerContext context, ByteArrayWrapper key, ByteArrayWrapper value, int count) throws Exception {
    Object[] params;
    Query query;
    if (count > 0) {
      query = getQuery(key, ListQuery.LREMG, context);
      params = new Object[]{value, Integer.valueOf(count)};
    } else if (count < 0) {
      query = getQuery(key, ListQuery.LREML, context);
      params = new Object[]{value, Integer.valueOf(-count)};
    } else {
      query = getQuery(key, ListQuery.LREME, context);
      params = new Object[]{value};
    }

    
    SelectResults<Struct> results = (SelectResults<Struct>) query.execute(params);

    if (results == null || results.isEmpty()) {
      return null;
    }

    return results.asList();
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.LSET));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    byte[] indexArray = commandElems.get(2);
    byte[] value = commandElems.get(3);

    int index;


    checkDataType(key, RedisDataType.REDIS_LIST, context);
    Region<Integer, ByteArrayWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_INDEX));
      return;
    }

    try {
      index = Coder.bytesToInt(indexArray);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_NUMERIC));
      return;
    }

    int listSize = keyRegion.size();
    if (index < 0)
      index += listSize;
    if (index < 0 || index > listSize) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_INDEX));
      return;
    }

    Integer indexKey;
    try {
      indexKey = getIndexKey(context, key, index);
    } catch (Exception e) {
      throw new RuntimeException(e);
    }
    if (indexKey == null) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_INDEX));
      return;
    }
    if (index == listSize)
      indexKey++;
    keyRegion.put(indexKey, new ByteArrayWrapper(value));
    command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), SUCCESS));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.LSET));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    byte[] indexArray = commandElems.get(2);
    byte[] value = commandElems.get(3);

    int index;


    checkDataType(key, RedisDataType.REDIS_LIST, context);
    Region<Integer, ByteArrayWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_INDEX));
      return;
    }

    try {
      index = Coder.bytesToInt(indexArray);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_NUMERIC));
      return;
    }

    int listSize = keyRegion.size() - LIST_EMPTY_SIZE;
    if (index < 0)
      index += listSize;
    if (index < 0 || index > listSize) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_INDEX));
      return;
    }

    Integer indexKey;
    try {
      indexKey = getIndexKey(context, key, index);
    } catch (Exception e) {
      throw new RuntimeException(e);
    }
    if (indexKey == null) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_INDEX));
      return;
    }
    if (index == listSize)
      indexKey++;
    keyRegion.put(indexKey, new ByteArrayWrapper(value));
    command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), SUCCESS));
  }",False
"  private Integer getIndexKey(ExecutionHandlerContext context, ByteArrayWrapper key, int index) throws Exception {
    Query query = getQuery(key, ListQuery.LSET, context);

    Object[] params = {new Integer(index + 1)};
    
    SelectResults<Integer> results = (SelectResults<Integer>) query.execute(params);
    int size = results.size();
    if (results == null || size == 0) {
      return null;
    }

    return results.asList().get(size - 1);
  }",True
"  private Integer getIndexKey(ExecutionHandlerContext context, ByteArrayWrapper key, int index) throws Exception {
    Query query = getQuery(key, ListQuery.LSET, context);

    Object[] params = {Integer.valueOf(index + 1)};
    
    SelectResults<Integer> results = (SelectResults<Integer>) query.execute(params);
    int size = results.size();
    if (results == null || size == 0) {
      return null;
    }

    return results.asList().get(size - 1);
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.LTRIM));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    byte[] startArray = commandElems.get(2);
    byte[] stopArray = commandElems.get(3);

    int redisStart;
    int redisStop;


    checkDataType(key, RedisDataType.REDIS_LIST, context);
    Region<Integer, ByteArrayWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_KEY_NOT_EXISTS));
      return;
    }

    int listSize = keyRegion.size();
    if (listSize == 0) {
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      return;
    }

    try {
      redisStart = Coder.bytesToInt(startArray);
      redisStop =  Coder.bytesToInt(stopArray);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_NUMERIC));
      return;
    }

    redisStart = getBoundedStartIndex(redisStart, listSize);
    redisStop = getBoundedEndIndex(redisStop, listSize);
    redisStart = Math.min(redisStart, listSize - 1);
    redisStop = Math.min(redisStop, listSize - 1);

    if (redisStart == 0 && redisStop == listSize - 1) {
      command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), SUCCESS));
      return;
    } else if (redisStart == 0 && redisStop < redisStart) {
      context.getRegionCache().removeKey(key, RedisDataType.REDIS_LIST);
      command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), SUCCESS));
      return;
    }

    List<Integer> keepList;
    try {
      keepList = getRange(context, key, redisStart, redisStop);
    } catch (Exception e) {
      throw new RuntimeException(e);
    }
    
    for (Integer keyElement: keyRegion.keySet()) {
      if (!keepList.contains(keyElement))
        keyRegion.remove(keyElement);
    }
    
    // Reset indexes in meta data region
    Region<String, Integer> meta = context.getRegionCache().getListsMetaRegion();
    meta.put(key + ""head"", keepList.get(0));
    meta.put(key + ""tail"", keepList.get(keepList.size() - 1));
    command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), SUCCESS));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.LTRIM));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    byte[] startArray = commandElems.get(2);
    byte[] stopArray = commandElems.get(3);

    int redisStart;
    int redisStop;


    checkDataType(key, RedisDataType.REDIS_LIST, context);
    Region keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_KEY_NOT_EXISTS));
      return;
    }

    int listSize = keyRegion.size() - LIST_EMPTY_SIZE;
    if (listSize == 0) {
      command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), SUCCESS));
      return;
    }

    try {
      redisStart = Coder.bytesToInt(startArray);
      redisStop =  Coder.bytesToInt(stopArray);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_NUMERIC));
      return;
    }

    redisStart = getBoundedStartIndex(redisStart, listSize);
    redisStop = getBoundedEndIndex(redisStop, listSize);
    redisStart = Math.min(redisStart, listSize - 1);
    redisStop = Math.min(redisStop, listSize - 1);

    if (redisStart == 0 && redisStop == listSize - 1) {
      command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), SUCCESS));
      return;
    } else if (redisStart == 0 && redisStop < redisStart) {
      context.getRegionProvider().removeKey(key, RedisDataType.REDIS_LIST);
      command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), SUCCESS));
      return;
    }

    List<Integer> keepList;
    try {
      keepList = getRange(context, key, redisStart, redisStop, keyRegion);
    } catch (Exception e) {
      throw new RuntimeException(e);
    }
    
    for (Object keyElement: keyRegion.keySet()) {
      if (!keepList.contains(keyElement) && keyElement instanceof Integer)
        keyRegion.remove(keyElement);
    }
    
    // Reset indexes in meta data region
    keyRegion.put(""head"", keepList.get(0));
    keyRegion.put(""tail"", keepList.get(keepList.size() - 1));
    command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), SUCCESS));
  }",False
"  private List<Integer> getRange(ExecutionHandlerContext context, ByteArrayWrapper key, int start, int stop) throws Exception {
    Query query = getQuery(key, ListQuery.LTRIM, context);

    Object[] params = {new Integer(stop + 1)};

    SelectResults<Integer> results = (SelectResults<Integer>) query.execute(params);

    if (results == null || results.size() <= start) {
      return null;
    }

    return results.asList().subList(start, results.size());
  }",True
"    Query query = getQuery(key, ListQuery.LTRIM, context);

    Object[] params = {Integer.valueOf(stop + 1)};
    
    SelectResults<Integer> results = (SelectResults<Integer>) query.execute(params);
    if (results == null || results.size() <= start) {
      return null;
    }

    return results.asList().subList(start, results.size());
  }
}
",False
"  private List<Integer> getRange(ExecutionHandlerContext context, ByteArrayWrapper key, int start, int stop, Region r) throws Exception {
    Query query = getQuery(key, ListQuery.LTRIM, context);

    Object[] params = {Integer.valueOf(stop + 1)};
    
    SelectResults<Integer> results = (SelectResults<Integer>) query.execute(params);
    if (results == null || results.size() <= start) {
      return null;
    }

    return results.asList().subList(start, results.size());
  }",False
"  protected Region<Integer, ByteArrayWrapper> getRegion(ExecutionHandlerContext context, ByteArrayWrapper key) {
    return (Region<Integer, ByteArrayWrapper>) context.getRegionCache().getRegion(key);
  }",True
"  protected Region<Integer, ByteArrayWrapper> getRegion(ExecutionHandlerContext context, ByteArrayWrapper key) {
    return (Region<Integer, ByteArrayWrapper>) context.getRegionProvider().getRegion(key);
  }",False
"  protected void pushElements(ByteArrayWrapper key, List<byte[]> commandElems, int startIndex, int endIndex,
      Region<Integer, ByteArrayWrapper> keyRegion, ListDirection pushType, ExecutionHandlerContext context) {
    Region<String, Integer> meta = context.getRegionCache().getListsMetaRegion();

    String indexKey = pushType == ListDirection.LEFT ? key + ""head"" : key + ""tail"";
    String oppositeKey = pushType == ListDirection.RIGHT ? key + ""head"" : key + ""tail"";
    Integer index = meta.get(indexKey);
    Integer opp = meta.get(oppositeKey);

    if (index != opp)
      index += pushType == ListDirection.LEFT ? -1 : 1; // Subtract index if left push, add if right push

    /**
     * Multi push command
     * 
     * For every element that needs to be added
     */

    for (int i = startIndex; i < endIndex; i++) {
      byte[] value = commandElems.get(i);
      ByteArrayWrapper wrapper = new ByteArrayWrapper(value);

      /**
       * 
       * First, use the start index to attempt to insert the
       * value into the Region
       * 
       */

      Object oldValue;
      do {
        oldValue = keyRegion.putIfAbsent(index, wrapper);
        if (oldValue != null)
          index += pushType == ListDirection.LEFT ? -1 : 1; // Subtract index if left push, add if right push
      } while (oldValue != null);

      /**
       * 
       * Next, update the index in the meta data region. Keep trying
       * to replace the existing index unless the index is further out
       * than previously inserted, that's ok. Example below:
       * 
       * ********************** LPUSH/LPUSH ***************************
       *   Push occurring at the same time, further index update first
       *   |    This push
       *   |      |
       *   |      |
       *   V      V
       * [-4]   [-3]    [-2]    [-1]    [0]     [1]     [2]
       * 
       * In this case, -4 would already exist in the meta data region, therefore
       * we do not try to put -3 in the meta data region because a further
       * index is already there.
       * ***************************************************************
       * 
       * Another example
       * 
       * ********************** LPUSH/LPOP *****************************
       *   This push
       *   |    Simultaneous LPOP, meta data head index already updated to -2
       *   |     |
       *   |     |
       *   V     V
       * [-4]   [X]    [-2]    [-1]    [0]     [1]     [2]
       * 
       * In this case, -2 would already exist in the meta data region, but
       * we need to make sure the element at -4 is visible to all other threads
       * so we will attempt to change the index to -4 as long as it is greater
       * than -4
       * ***************************************************************
       * 
       */

      boolean indexSet = false;
      do {
        Integer existingIndex = meta.get(indexKey);
        if ((pushType == ListDirection.RIGHT && existingIndex < index) || (pushType == ListDirection.LEFT && existingIndex > index))
          indexSet = meta.replace(indexKey, existingIndex, index);
        else
          break;
      } while (!indexSet);

    }
  }",True
"  protected void pushElements(ByteArrayWrapper key, List<byte[]> commandElems, int startIndex, int endIndex,
      Region keyRegion, ListDirection pushType, ExecutionHandlerContext context) {

    String indexKey = pushType == ListDirection.LEFT ? ""head"" : ""tail"";
    String oppositeKey = pushType == ListDirection.RIGHT ? ""head"" : ""tail"";
    Integer index = (Integer) keyRegion.get(indexKey);
    Integer opp = (Integer) keyRegion.get(oppositeKey);
    if (index != opp)
      index += pushType == ListDirection.LEFT ? -1 : 1; // Subtract index if left push, add if right push

    /**
     * Multi push command
     * 
     * For every element that needs to be added
     */

    for (int i = startIndex; i < endIndex; i++) {
      byte[] value = commandElems.get(i);
      ByteArrayWrapper wrapper = new ByteArrayWrapper(value);

      /**
       * 
       * First, use the start index to attempt to insert the
       * value into the Region
       * 
       */

      Object oldValue;
      do {
        oldValue = keyRegion.putIfAbsent(index, wrapper);
        if (oldValue != null) {
          index += pushType == ListDirection.LEFT ? -1 : 1; // Subtract index if left push, add if right push
        }
      } while (oldValue != null);

      /**
       * 
       * Next, update the index in the meta data region. Keep trying
       * to replace the existing index unless the index is further out
       * than previously inserted, that's ok. Example below:
       * 
       * ********************** LPUSH/LPUSH ***************************
       *   Push occurring at the same time, further index update first
       *   |    This push
       *   |      |
       *   |      |
       *   V      V
       * [-4]   [-3]    [-2]    [-1]    [0]     [1]     [2]
       * 
       * In this case, -4 would already exist in the meta data region, therefore
       * we do not try to put -3 in the meta data region because a further
       * index is already there.
       * ***************************************************************
       * 
       * Another example
       * 
       * ********************** LPUSH/LPOP *****************************
       *   This push
       *   |    Simultaneous LPOP, meta data head index already updated to -2
       *   |     |
       *   |     |
       *   V     V
       * [-4]   [X]    [-2]    [-1]    [0]     [1]     [2]
       * 
       * In this case, -2 would already exist in the meta data region, but
       * we need to make sure the element at -4 is visible to all other threads
       * so we will attempt to change the index to -4 as long as it is greater
       * than -4
       * ***************************************************************
       * 
       */

      boolean indexSet = false;
      do {
        Integer existingIndex = (Integer) keyRegion.get(indexKey);
        if ((pushType == ListDirection.RIGHT && existingIndex < index) || (pushType == ListDirection.LEFT && existingIndex > index))
          indexSet = keyRegion.replace(indexKey, existingIndex, index);
        else
          break;
      } while (!indexSet);

    }
  }",False
"  protected Region<Integer, ByteArrayWrapper> getOrCreateRegion(ExecutionHandlerContext context, ByteArrayWrapper key, RedisDataType type) {
    return (Region<Integer, ByteArrayWrapper>) context.getRegionCache().getOrCreateRegion(key, type, context);
  }",True
"  protected Region<Integer, ByteArrayWrapper> getOrCreateRegion(ExecutionHandlerContext context, ByteArrayWrapper key, RedisDataType type) {
    return (Region<Integer, ByteArrayWrapper>) context.getRegionProvider().getOrCreateRegion(key, type, context);
  }",False
"   * @param pushType ListDirection.LEFT || ListDirection.RIGHT
   * @param context Context of this push
   */
  protected void pushElements(ByteArrayWrapper key, List<byte[]> commandElems, int startIndex, int endIndex,
      Region keyRegion, ListDirection pushType, ExecutionHandlerContext context) {

    String indexKey = pushType == ListDirection.LEFT ? ""head"" : ""tail"";
    String oppositeKey = pushType == ListDirection.RIGHT ? ""head"" : ""tail"";
    Integer index = (Integer) keyRegion.get(indexKey);
    Integer opp = (Integer) keyRegion.get(oppositeKey);
    if (index != opp)
      index += pushType == ListDirection.LEFT ? -1 : 1; // Subtract index if left push, add if right push

    /**
     * Multi push command
     * 
     * For every element that needs to be added
     */

    for (int i = startIndex; i < endIndex; i++) {
      byte[] value = commandElems.get(i);
      ByteArrayWrapper wrapper = new ByteArrayWrapper(value);

      /**
       * 
       * First, use the start index to attempt to insert the
       * value into the Region
       * 
       */

      Object oldValue;
      do {
        oldValue = keyRegion.putIfAbsent(index, wrapper);
        if (oldValue != null) {
          index += pushType == ListDirection.LEFT ? -1 : 1; // Subtract index if left push, add if right push
        }
      } while (oldValue != null);

      /**
       * 
       * Next, update the index in the meta data region. Keep trying
       * to replace the existing index unless the index is further out
       * than previously inserted, that's ok. Example below:
       * 
       * ********************** LPUSH/LPUSH ***************************
       *   Push occurring at the same time, further index update first
       *   |    This push
       *   |      |
       *   |      |
       *   V      V
       * [-4]   [-3]    [-2]    [-1]    [0]     [1]     [2]
       * 
       * In this case, -4 would already exist in the meta data region, therefore
       * we do not try to put -3 in the meta data region because a further
       * index is already there.
       * ***************************************************************
       * 
       * Another example
       * 
       * ********************** LPUSH/LPOP *****************************
       *   This push
       *   |    Simultaneous LPOP, meta data head index already updated to -2
       *   |     |
       *   |     |
       *   V     V
       * [-4]   [X]    [-2]    [-1]    [0]     [1]     [2]
       * 
       * In this case, -2 would already exist in the meta data region, but
       * we need to make sure the element at -4 is visible to all other threads
       * so we will attempt to change the index to -4 as long as it is greater
       * than -4
       * ***************************************************************
       * 
       */

      boolean indexSet = false;
      do {
        Integer existingIndex = (Integer) keyRegion.get(indexKey);
        if ((pushType == ListDirection.RIGHT && existingIndex < index) || (pushType == ListDirection.LEFT && existingIndex > index))
          indexSet = keyRegion.replace(indexKey, existingIndex, index);
        else
          break;
      } while (!indexSet);
",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), getArgsError()));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    checkDataType(key, RedisDataType.REDIS_LIST, context);
    Region<Integer, ByteArrayWrapper> keyRegion = getRegion(context, key);
    Region<String, Integer> meta = context.getRegionCache().getListsMetaRegion();

    if (keyRegion == null || keyRegion.size() == 0) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }

    String indexKey = popType() == ListDirection.LEFT ? key + ""head"" : key + ""tail"";
    String oppositeKey = popType() == ListDirection.RIGHT ? key + ""head"" : key + ""tail"";
    Integer index = 0;
    int originalIndex = index;
    int incr = popType() == ListDirection.LEFT ? 1 : -1;
    ByteArrayWrapper valueWrapper = null;
    
    /**
     * 
     * First attempt to hop over an index by moving the index 
     * down one in the meta data region. The desired index to 
     * remove is held within the field index
     * 
     */
    
    boolean indexChanged = false;
    do {
      index = meta.get(indexKey);
      if (index == meta.get(oppositeKey))
        break;
      indexChanged = meta.replace(indexKey, index, index + incr);
    } while(!indexChanged);
    
    /**
     * 
     * Now attempt to remove the value of the index. We must do a
     * get to ensure a returned value and then call remove with the
     * value to ensure no one else has removed it first. Otherwise, 
     * try other indexes 
     * 
     */
    
    boolean removed = false;
    int i = 0;
    do {
      valueWrapper = keyRegion.get(index);
      if (valueWrapper != null)
        removed = keyRegion.remove(index, valueWrapper);
      
      /**
       * 
       * If remove has passed, our job is done and we can break and
       * stop looking for a value
       * 
       */
      
      if (removed)
        break;

      /**
       * 
       * If the index has not been removed, we need to look at other indexes.
       * Two cases exist:
       * 
       * ************************** FIRST MISS ***********************************
       *   Push occurring at the same time, further index update first
       *   |    This is location of miss
       *   |      |
       *   |      |
       *   V      V
       * [-4]    [X]    [-2]    [-1]    [0]     [1]     [2]
       *        <-- Direction of index update
       * If this is the first miss, the index is re obtained from the meta region
       * and that index is trying. However, if the index in the meta data region
       * is not further out, that index is not used and moves on to the second case
       * **************************************************************************
       * 
       * ************************* SUBSEQUENT MISSES ******************************
       *   Push occurring at the same time, further index update first
       *   |    This is location of miss
       *   |      |
       *   |      |
       *   V      V
       * [-4]    [X]    [-2]    [-1]    [0]     [1]     [2]
       * Direction of index update -->
       * If this is not the first miss then we move down to the other end of the list
       * which means the next not empty index will be attempted to be removed
       * **************************************************************************
       * 
       * If it is the case that the list is empty, it will exit this loop
       * 
       */
      
      index += incr;
      int metaIndex = meta.get(indexKey);
      if (i < 1 && (popType() == ListDirection.LEFT && metaIndex < originalIndex ||
          popType() == ListDirection.RIGHT && metaIndex > originalIndex))
        index = metaIndex;
      i++;
    } while (!removed && keyRegion.size() != 0);
    if (valueWrapper != null)
      command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), valueWrapper.toBytes()));
    else
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), getArgsError()));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    checkDataType(key, RedisDataType.REDIS_LIST, context);
    Region keyRegion = getRegion(context, key);

    if (keyRegion == null || keyRegion.size() == LIST_EMPTY_SIZE) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }

    String indexKey = popType() == ListDirection.LEFT ? ""head"" : ""tail"";
    String oppositeKey = popType() == ListDirection.RIGHT ? ""head"" : ""tail"";
    Integer index = 0;
    int originalIndex = index;
    int incr = popType() == ListDirection.LEFT ? 1 : -1;
    ByteArrayWrapper valueWrapper = null;
    
    /**
     * 
     * First attempt to hop over an index by moving the index 
     * down one in the meta data region. The desired index to 
     * remove is held within the field index
     * 
     */
    
    boolean indexChanged = false;
    do {
      index = (Integer) keyRegion.get(indexKey);
      Integer opp = (Integer) keyRegion.get(oppositeKey);
      if (index.equals(opp))
        break;
      indexChanged = keyRegion.replace(indexKey, index, index + incr);
    } while(!indexChanged);
    
    /**
     * 
     * Now attempt to remove the value of the index. We must do a
     * get to ensure a returned value and then call remove with the
     * value to ensure no one else has removed it first. Otherwise, 
     * try other indexes 
     * 
     */
    
    boolean removed = false;
    int i = 0;
    do {
      valueWrapper = (ByteArrayWrapper) keyRegion.get(index);
      if (valueWrapper != null)
        removed = keyRegion.remove(index, valueWrapper);
      
      /**
       * 
       * If remove has passed, our job is done and we can break and
       * stop looking for a value
       * 
       */
      
      if (removed)
        break;

      /**
       * 
       * If the index has not been removed, we need to look at other indexes.
       * Two cases exist:
       * 
       * ************************** FIRST MISS ***********************************
       *   Push occurring at the same time, further index update first
       *   |    This is location of miss
       *   |      |
       *   |      |
       *   V      V
       * [-4]    [X]    [-2]    [-1]    [0]     [1]     [2]
       *        <-- Direction of index update
       * If this is the first miss, the index is re obtained from the meta region
       * and that index is trying. However, if the index in the meta data region
       * is not further out, that index is not used and moves on to the second case
       * **************************************************************************
       * 
       * ************************* SUBSEQUENT MISSES ******************************
       *   Push occurring at the same time, further index update first
       *   |    This is location of miss
       *   |      |
       *   |      |
       *   V      V
       * [-4]    [X]    [-2]    [-1]    [0]     [1]     [2]
       * Direction of index update -->
       * If this is not the first miss then we move down to the other end of the list
       * which means the next not empty index will be attempted to be removed
       * **************************************************************************
       * 
       * If it is the case that the list is empty, it will exit this loop
       * 
       */
      
      index += incr;
      Integer metaIndex = (Integer) keyRegion.get(indexKey);
      if (i < 1 && (popType() == ListDirection.LEFT && metaIndex < originalIndex ||
          popType() == ListDirection.RIGHT && metaIndex > originalIndex))
        index = metaIndex;
      i++;
    } while (!removed && keyRegion.size() != LIST_EMPTY_SIZE);
    if (valueWrapper != null)
      command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), valueWrapper.toBytes()));
    else
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), getArgsError()));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    Region<Integer, ByteArrayWrapper> keyRegion = getOrCreateRegion(context, key, RedisDataType.REDIS_LIST);
    pushElements(key, commandElems, START_VALUES_INDEX, commandElems.size(), keyRegion, pushType(), context);
    int listSize = keyRegion.size();
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), listSize));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), getArgsError()));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    Region<Integer, ByteArrayWrapper> keyRegion = getOrCreateRegion(context, key, RedisDataType.REDIS_LIST);
    pushElements(key, commandElems, START_VALUES_INDEX, commandElems.size(), keyRegion, pushType(), context);
    int listSize = keyRegion.size() - LIST_EMPTY_SIZE;
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), listSize));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), getArgsError()));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    Region<Integer, ByteArrayWrapper> keyRegion = getRegion(context, key);
    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_EXISTS));
      return;
    }
    checkDataType(key, RedisDataType.REDIS_LIST, context);    
    pushElements(key, commandElems, 2, 3, keyRegion, pushType(), context);
    
    int listSize = keyRegion.size();

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), listSize));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), getArgsError()));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    Region<Integer, ByteArrayWrapper> keyRegion = getRegion(context, key);
    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_EXISTS));
      return;
    }
    checkDataType(key, RedisDataType.REDIS_LIST, context);    
    pushElements(key, commandElems, 2, 3, keyRegion, pushType(), context);
    
    int listSize = keyRegion.size() - LIST_EMPTY_SIZE;

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), listSize));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SADD));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> keyRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionCache().getOrCreateRegion(key, RedisDataType.REDIS_SET, context);

    if (commandElems.size() >= 4) {
      Map<ByteArrayWrapper, Boolean> entries = new HashMap<ByteArrayWrapper, Boolean>();
      for (int i = 2; i < commandElems.size(); i++)
        entries.put(new ByteArrayWrapper(commandElems.get(i)), true);

      keyRegion.putAll(entries);
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), entries.size()));
    } else {
      Object v = keyRegion.put(new ByteArrayWrapper(commandElems.get(2)), true);
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), v == null ? 1 : 0));
    }

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SADD));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> keyRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionProvider().getOrCreateRegion(key, RedisDataType.REDIS_SET, context);

    if (commandElems.size() >= 4) {
      Map<ByteArrayWrapper, Boolean> entries = new HashMap<ByteArrayWrapper, Boolean>();
      for (int i = 2; i < commandElems.size(); i++)
        entries.put(new ByteArrayWrapper(commandElems.get(i)), true);

      keyRegion.putAll(entries);
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), entries.size()));
    } else {
      Object v = keyRegion.put(new ByteArrayWrapper(commandElems.get(2)), true);
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), v == null ? 1 : 0));
    }

  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SCARD));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, RedisDataType.REDIS_SET, context);
    Region<ByteArrayWrapper, Boolean> keyRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionCache().getRegion(key);

    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_EXISTS));
      return;
    }

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), keyRegion.size()));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SCARD));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, RedisDataType.REDIS_SET, context);
    Region<ByteArrayWrapper, Boolean> keyRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionProvider().getRegion(key);

    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_EXISTS));
      return;
    }

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), keyRegion.size()));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SISMEMBER));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    ByteArrayWrapper member = new ByteArrayWrapper(commandElems.get(2));
    
    checkDataType(key, RedisDataType.REDIS_SET, context);
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> keyRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionCache().getRegion(key);

    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_EXISTS));
      return;
    }

    if (keyRegion.containsKey(member))
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), EXISTS));
    else
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_EXISTS));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SISMEMBER));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    ByteArrayWrapper member = new ByteArrayWrapper(commandElems.get(2));
    
    checkDataType(key, RedisDataType.REDIS_SET, context);
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> keyRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionProvider().getRegion(key);

    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_EXISTS));
      return;
    }

    if (keyRegion.containsKey(member))
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), EXISTS));
    else
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_EXISTS));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SMEMBERS));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, RedisDataType.REDIS_SET, context);
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> keyRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionCache().getRegion(key);
    
    if (keyRegion == null) {
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      return;
    }
    
    Set<ByteArrayWrapper> members = keyRegion.keySet();
    
    command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), members));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SMEMBERS));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, RedisDataType.REDIS_SET, context);
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> keyRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionProvider().getRegion(key);
    
    if (keyRegion == null) {
      command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      return;
    }
    
    Set<ByteArrayWrapper> members = new HashSet(keyRegion.keySet()); // Emulate copy on read
    
    command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), members));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SMOVE));
      return;
    }

    ByteArrayWrapper source = command.getKey();
    ByteArrayWrapper destination = new ByteArrayWrapper(commandElems.get(2));
    ByteArrayWrapper mem = new ByteArrayWrapper(commandElems.get(3));

    checkDataType(source, RedisDataType.REDIS_SET, context);
    checkDataType(destination, RedisDataType.REDIS_SET, context);
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> sourceRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionCache().getRegion(source);

    if (sourceRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_MOVED));
      return;
    }

    Object oldVal = sourceRegion.get(mem); sourceRegion.remove(mem);

    if (oldVal == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_MOVED));
      return;
    }

    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> destinationRegion = (Region<ByteArrayWrapper, Boolean>) getOrCreateRegion(context, destination, RedisDataType.REDIS_SET);
    destinationRegion.put(mem, true);

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), MOVED));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SMOVE));
      return;
    }

    ByteArrayWrapper source = command.getKey();
    ByteArrayWrapper destination = new ByteArrayWrapper(commandElems.get(2));
    ByteArrayWrapper mem = new ByteArrayWrapper(commandElems.get(3));

    checkDataType(source, RedisDataType.REDIS_SET, context);
    checkDataType(destination, RedisDataType.REDIS_SET, context);
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> sourceRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionProvider().getRegion(source);

    if (sourceRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_MOVED));
      return;
    }

    Object oldVal = sourceRegion.get(mem); sourceRegion.remove(mem);

    if (oldVal == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_MOVED));
      return;
    }

    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> destinationRegion = (Region<ByteArrayWrapper, Boolean>) getOrCreateRegion(context, destination, RedisDataType.REDIS_SET);
    destinationRegion.put(mem, true);

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), MOVED));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SPOP));
      return;
    }
    
    ByteArrayWrapper key = command.getKey();
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> keyRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionCache().getRegion(key);
    if (keyRegion == null || keyRegion.isEmpty()) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }
    
    Random rand = new Random();
    
    ByteArrayWrapper[] entries = keyRegion.keySet().toArray(new ByteArrayWrapper[keyRegion.size()]);
    
    ByteArrayWrapper pop = entries[rand.nextInt(entries.length)];
    
    keyRegion.remove(pop);
    if (keyRegion.isEmpty()) {
      context.getRegionCache().removeKey(key);
    }
    command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), pop.toBytes()));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SPOP));
      return;
    }
    
    ByteArrayWrapper key = command.getKey();
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> keyRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionProvider().getRegion(key);
    if (keyRegion == null || keyRegion.isEmpty()) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }
    
    Random rand = new Random();
    
    ByteArrayWrapper[] entries = keyRegion.keySet().toArray(new ByteArrayWrapper[keyRegion.size()]);
    
    ByteArrayWrapper pop = entries[rand.nextInt(entries.length)];
    
    keyRegion.remove(pop);
    if (keyRegion.isEmpty()) {
      context.getRegionProvider().removeKey(key);
    }
    command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), pop.toBytes()));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SRANDMEMBER));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> keyRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionCache().getRegion(key);

    int count = 1;

    if (commandElems.size() > 2) {
      try {
        count = Coder.bytesToInt(commandElems.get(2));
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_NUMERIC));
        return;
      }
    }

    if (keyRegion == null || count == 0) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }

    int members = keyRegion.size();

    if (members <= count && count != 1) {
      command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), keyRegion.keySet()));
      return;
    }

    Random rand = new Random();

    ByteArrayWrapper[] entries = keyRegion.keySet().toArray(new ByteArrayWrapper[members]);

    if (count == 1) {
      ByteArrayWrapper randEntry = entries[rand.nextInt(entries.length)];
      command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), randEntry.toBytes()));
    } else if (count > 0) {
      Set<ByteArrayWrapper> randEntries = new HashSet<ByteArrayWrapper>();
      do {
        ByteArrayWrapper s = entries[rand.nextInt(entries.length)];
        randEntries.add(s);
      } while(randEntries.size() < count);
      command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), randEntries));
    } else {
      count = -count;
      List<ByteArrayWrapper> randEntries = new ArrayList<ByteArrayWrapper>();
      for (int i = 0; i < count; i++) {
        ByteArrayWrapper s = entries[rand.nextInt(entries.length)];
        randEntries.add(s);
      }
      command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), randEntries));
    }
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SRANDMEMBER));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> keyRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionProvider().getRegion(key);

    int count = 1;

    if (commandElems.size() > 2) {
      try {
        count = Coder.bytesToInt(commandElems.get(2));
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_NUMERIC));
        return;
      }
    }

    if (keyRegion == null || count == 0) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }

    int members = keyRegion.size();

    if (members <= count && count != 1) {
      command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), new HashSet<ByteArrayWrapper>(keyRegion.keySet())));
      return;
    }

    Random rand = new Random();

    ByteArrayWrapper[] entries = keyRegion.keySet().toArray(new ByteArrayWrapper[members]);

    if (count == 1) {
      ByteArrayWrapper randEntry = entries[rand.nextInt(entries.length)];
      command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), randEntry.toBytes()));
    } else if (count > 0) {
      Set<ByteArrayWrapper> randEntries = new HashSet<ByteArrayWrapper>();
      do {
        ByteArrayWrapper s = entries[rand.nextInt(entries.length)];
        randEntries.add(s);
      } while(randEntries.size() < count);
      command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), randEntries));
    } else {
      count = -count;
      List<ByteArrayWrapper> randEntries = new ArrayList<ByteArrayWrapper>();
      for (int i = 0; i < count; i++) {
        ByteArrayWrapper s = entries[rand.nextInt(entries.length)];
        randEntries.add(s);
      }
      command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), randEntries));
    }
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SREM));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, RedisDataType.REDIS_SET, context);
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> keyRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionCache().getRegion(key);
    
    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NONE_REMOVED));
      return;
    }
    
    int numRemoved = 0;
    
    for (int i = 2; i < commandElems.size(); i++) {
      Object oldVal;
      oldVal = keyRegion.remove(new ByteArrayWrapper(commandElems.get(i)));
      if (oldVal != null)
        numRemoved++;
    }
    
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), numRemoved));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SREM));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, RedisDataType.REDIS_SET, context);
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> keyRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionProvider().getRegion(key);
    
    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NONE_REMOVED));
      return;
    }
    
    int numRemoved = 0;
    
    for (int i = 2; i < commandElems.size(); i++) {
      Object oldVal;
      oldVal = keyRegion.remove(new ByteArrayWrapper(commandElems.get(i)));
      if (oldVal != null)
        numRemoved++;
    }
    
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), numRemoved));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SSCAN));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, RedisDataType.REDIS_SET, context);
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> keyRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionCache().getRegion(key);
    if (keyRegion == null) {
      command.setResponse(Coder.getScanResponse(context.getByteBufAllocator(), new ArrayList<String>()));
      return;
    }
    byte[] cAr = commandElems.get(2);
    String cursorString = Coder.bytesToString(cAr);
    int cursor = 0;
    Pattern matchPattern = null;
    String globMatchPattern = null;
    int count = DEFUALT_COUNT;
    try {
      cursor = Integer.parseInt(cursorString);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_CURSOR));
      return;
    }
    if (cursor < 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_CURSOR));
      return;
    }

    if (commandElems.size() > 4) {
      try {
        byte[] bytes = commandElems.get(3);
        String tmp = Coder.bytesToString(bytes);
        if (tmp.equalsIgnoreCase(""MATCH"")) {
          bytes = commandElems.get(4);
          globMatchPattern = Coder.bytesToString(bytes);
        } else if (tmp.equalsIgnoreCase(""COUNT"")) {
          bytes = commandElems.get(4);
          count = Coder.bytesToInt(bytes);
        }
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
        return;
      }
    }

    if (commandElems.size() > 6) {
      try {
        byte[] bytes = commandElems.get(5);
        String tmp = Coder.bytesToString(bytes);
        if (tmp.equalsIgnoreCase(""COUNT"")) {
          bytes = commandElems.get(6);
          count = Coder.bytesToInt(bytes);
        }
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
        return;
      }
    }

    if (count < 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
      return;
    }

    try {
      matchPattern = convertGlobToRegex(globMatchPattern);
    } catch (PatternSyntaxException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), RedisConstants.ERROR_ILLEGAL_GLOB));
      return;
    }

    @SuppressWarnings(""unchecked"")
    List<ByteArrayWrapper> returnList = (List<ByteArrayWrapper>) getIteration(keyRegion.keySet(), matchPattern, count, cursor);

    command.setResponse(Coder.getScanResponse(context.getByteBufAllocator(), returnList));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SSCAN));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, RedisDataType.REDIS_SET, context);
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, Boolean> keyRegion = (Region<ByteArrayWrapper, Boolean>) context.getRegionProvider().getRegion(key);
    if (keyRegion == null) {
      command.setResponse(Coder.getScanResponse(context.getByteBufAllocator(), new ArrayList<String>()));
      return;
    }
    byte[] cAr = commandElems.get(2);
    String cursorString = Coder.bytesToString(cAr);
    int cursor = 0;
    Pattern matchPattern = null;
    String globMatchPattern = null;
    int count = DEFUALT_COUNT;
    try {
      cursor = Integer.parseInt(cursorString);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_CURSOR));
      return;
    }
    if (cursor < 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_CURSOR));
      return;
    }

    if (commandElems.size() > 4) {
      try {
        byte[] bytes = commandElems.get(3);
        String tmp = Coder.bytesToString(bytes);
        if (tmp.equalsIgnoreCase(""MATCH"")) {
          bytes = commandElems.get(4);
          globMatchPattern = Coder.bytesToString(bytes);
        } else if (tmp.equalsIgnoreCase(""COUNT"")) {
          bytes = commandElems.get(4);
          count = Coder.bytesToInt(bytes);
        }
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
        return;
      }
    }

    if (commandElems.size() > 6) {
      try {
        byte[] bytes = commandElems.get(5);
        String tmp = Coder.bytesToString(bytes);
        if (tmp.equalsIgnoreCase(""COUNT"")) {
          bytes = commandElems.get(6);
          count = Coder.bytesToInt(bytes);
        }
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
        return;
      }
    }

    if (count < 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
      return;
    }

    try {
      matchPattern = convertGlobToRegex(globMatchPattern);
    } catch (PatternSyntaxException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), RedisConstants.ERROR_ILLEGAL_GLOB));
      return;
    }

    @SuppressWarnings(""unchecked"")
    List<ByteArrayWrapper> returnList = (List<ByteArrayWrapper>) getIteration(new ArrayList(keyRegion.keySet()), matchPattern, count, cursor);

    command.setResponse(Coder.getScanResponse(context.getByteBufAllocator(), returnList));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();
    int setsStartIndex = isStorage() ? 2 : 1;
    if (commandElems.size() < setsStartIndex + 1) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), getArgsError()));
      return;
    }
    RegionCache rC = context.getRegionCache();
    ByteArrayWrapper destination = null;
    if (isStorage())
      destination = command.getKey();


    ByteArrayWrapper firstSetKey = new ByteArrayWrapper(commandElems.get(setsStartIndex++));
    if (!isStorage())
      checkDataType(firstSetKey, RedisDataType.REDIS_SET, context);
    Region<ByteArrayWrapper, Boolean> region = (Region<ByteArrayWrapper, Boolean>) rC.getRegion(firstSetKey);
    Set<ByteArrayWrapper> firstSet = null;
    if (region != null) {
      firstSet = new HashSet<ByteArrayWrapper>(region.keySet());
    }
    ArrayList<Set<ByteArrayWrapper>> setList = new ArrayList<Set<ByteArrayWrapper>>();
    for (int i = setsStartIndex; i < commandElems.size(); i++) {
      ByteArrayWrapper key = new ByteArrayWrapper(commandElems.get(i));
      checkDataType(key, RedisDataType.REDIS_SET, context);
      region = (Region<ByteArrayWrapper, Boolean>) rC.getRegion(key);
      if (region != null)
        setList.add(region.keySet());
      else if (this instanceof SInterExecutor)
        setList.add(null);
    }
    if (setList.isEmpty()) {
      if (isStorage()) {
        if (firstSet == null) {
          command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
          context.getRegionCache().removeKey(destination);
        }
      } else {
        if (firstSet == null)
          command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
        else
          command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), firstSet));
      }
      return;
    }

    Set<ByteArrayWrapper> resultSet = setOp(firstSet, setList);
    if (isStorage()) {
      Region<ByteArrayWrapper, Boolean> newRegion = null; // (Region<ByteArrayWrapper, Boolean>) rC.getRegion(destination);
      rC.removeKey(destination);
      if (resultSet != null) {
        Map<ByteArrayWrapper, Boolean> map = new HashMap<ByteArrayWrapper, Boolean>();
        for (ByteArrayWrapper entry : resultSet)
          map.put(entry, Boolean.TRUE);
        if (!map.isEmpty()) {
          newRegion = (Region<ByteArrayWrapper, Boolean>) rC.getOrCreateRegion(destination, RedisDataType.REDIS_SET, context);
          newRegion.putAll(map);
        }
        command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), resultSet.size()));
      } else {
        command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      }
    } else {
      if (resultSet == null || resultSet.isEmpty())
        command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      else
        command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), resultSet));
    }
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();
    int setsStartIndex = isStorage() ? 2 : 1;
    if (commandElems.size() < setsStartIndex + 1) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), getArgsError()));
      return;
    }
    RegionProvider rC = context.getRegionProvider();
    ByteArrayWrapper destination = null;
    if (isStorage())
      destination = command.getKey();

    ByteArrayWrapper firstSetKey = new ByteArrayWrapper(commandElems.get(setsStartIndex++));
    if (!isStorage())
      checkDataType(firstSetKey, RedisDataType.REDIS_SET, context);
    Region<ByteArrayWrapper, Boolean> region = (Region<ByteArrayWrapper, Boolean>) rC.getRegion(firstSetKey);
    Set<ByteArrayWrapper> firstSet = null;
    if (region != null) {
      firstSet = new HashSet<ByteArrayWrapper>(region.keySet());
    }
    ArrayList<Set<ByteArrayWrapper>> setList = new ArrayList<Set<ByteArrayWrapper>>();
    for (int i = setsStartIndex; i < commandElems.size(); i++) {
      ByteArrayWrapper key = new ByteArrayWrapper(commandElems.get(i));
      checkDataType(key, RedisDataType.REDIS_SET, context);
      region = (Region<ByteArrayWrapper, Boolean>) rC.getRegion(key);
      if (region != null)
        setList.add(region.keySet());
      else if (this instanceof SInterExecutor)
        setList.add(null);
    }
    if (setList.isEmpty()) {
      if (isStorage()) {
          command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
          context.getRegionProvider().removeKey(destination);
      } else {
        if (firstSet == null)
          command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
        else
          command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), firstSet));
      }
      return;
    }

    Set<ByteArrayWrapper> resultSet = setOp(firstSet, setList);
    if (isStorage()) {
      Region<ByteArrayWrapper, Boolean> newRegion = null; // (Region<ByteArrayWrapper, Boolean>) rC.getRegion(destination);
      rC.removeKey(destination);
      if (resultSet != null) {
        Map<ByteArrayWrapper, Boolean> map = new HashMap<ByteArrayWrapper, Boolean>();
        for (ByteArrayWrapper entry : resultSet)
          map.put(entry, Boolean.TRUE);
        if (!map.isEmpty()) {
          newRegion = (Region<ByteArrayWrapper, Boolean>) rC.getOrCreateRegion(destination, RedisDataType.REDIS_SET, context);
          newRegion.putAll(map);
        }
        command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), resultSet.size()));
      } else {
        command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      }
    } else {
      if (resultSet == null || resultSet.isEmpty())
        command.setResponse(Coder.getEmptyArrayResponse(context.getByteBufAllocator()));
      else
        command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), resultSet));
    }
  }",False
"  protected Region<ByteArrayWrapper, DoubleWrapper> getOrCreateRegion(ExecutionHandlerContext context, ByteArrayWrapper key, RedisDataType type) {
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, DoubleWrapper> r = (Region<ByteArrayWrapper, DoubleWrapper>) context.getRegionCache().getOrCreateRegion(key, type, context);
    return r;
  }",True
"  protected Region<ByteArrayWrapper, DoubleWrapper> getOrCreateRegion(ExecutionHandlerContext context, ByteArrayWrapper key, RedisDataType type) {
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, DoubleWrapper> r = (Region<ByteArrayWrapper, DoubleWrapper>) context.getRegionProvider().getOrCreateRegion(key, type, context);
    return r;
  }",False
"  protected Region<ByteArrayWrapper, DoubleWrapper> getRegion(ExecutionHandlerContext context, ByteArrayWrapper key) {
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, DoubleWrapper> r = (Region<ByteArrayWrapper, DoubleWrapper>) context.getRegionCache().getRegion(key);
    return r;
  }",True
"  protected Region<ByteArrayWrapper, DoubleWrapper> getRegion(ExecutionHandlerContext context, ByteArrayWrapper key) {
    @SuppressWarnings(""unchecked"")
    Region<ByteArrayWrapper, DoubleWrapper> r = (Region<ByteArrayWrapper, DoubleWrapper>) context.getRegionProvider().getRegion(key);
    return r;
  }",False
"  private List<ByteArrayWrapper> getRange(ByteArrayWrapper key, Region<ByteArrayWrapper, DoubleWrapper> keyRegion, ExecutionHandlerContext context, ByteArrayWrapper start, ByteArrayWrapper stop, boolean startInclusive, boolean stopInclusive, int offset, int limit) throws FunctionDomainException, TypeMismatchException, NameResolutionException, QueryInvocationTargetException {
    if (start.equals(""-"") && stop.equals(""+"")) {
      List<ByteArrayWrapper> l = new ArrayList<ByteArrayWrapper>(keyRegion.keySet());
      int size = l.size();
      Collections.sort(l);
      if (limit == 0) limit += size;
      l = l.subList(Math.min(size, offset), Math.min(offset + limit, size));
      return l;
    } else if (start.equals(""+"") || stop.equals(""-""))
      return null;

    Query query;
    Object[] params;
    if (start.equals(""-"")) {
      if (stopInclusive) {
        query = getQuery(key, SortedSetQuery.ZRANGEBYLEXNINFI, context);
      } else {
        query = getQuery(key, SortedSetQuery.ZRANGEBYLEXNINF, context);
      }
      params = new Object[]{stop, INFINITY_LIMIT};
    } else if (stop.equals(""+"")) {
      if (startInclusive) {
        query = getQuery(key, SortedSetQuery.ZRANGEBYLEXPINFI, context);
      } else {
        query = getQuery(key, SortedSetQuery.ZRANGEBYLEXPINF, context);
      }
      params = new Object[]{start, INFINITY_LIMIT};
    } else {
      if (startInclusive) {
        if(stopInclusive) {
          query = getQuery(key, SortedSetQuery.ZRANGEBYLEXSTISI, context);
        } else {
          query = getQuery(key, SortedSetQuery.ZRANGEBYLEXSTI, context);
        }
      } else {
        if (stopInclusive) {
          query = getQuery(key, SortedSetQuery.ZRANGEBYLEXSI, context);
        } else {
          query = getQuery(key, SortedSetQuery.ZRANGEBYLEX, context);
        }
      }
      params = new Object[]{start, stop, INFINITY_LIMIT};
    }
    if (limit > 0)
      params[params.length - 1] =  (limit + offset);

    SelectResults<ByteArrayWrapper> results = (SelectResults<ByteArrayWrapper>) query.execute(params);

    List<ByteArrayWrapper> list = results.asList();
    int size = list.size();
    return list.subList(Math.min(size, offset), size);

  }",True
"  private List<ByteArrayWrapper> getRange(ByteArrayWrapper key, Region<ByteArrayWrapper, DoubleWrapper> keyRegion, ExecutionHandlerContext context, ByteArrayWrapper start, ByteArrayWrapper stop, boolean startInclusive, boolean stopInclusive, int offset, int limit) throws FunctionDomainException, TypeMismatchException, NameResolutionException, QueryInvocationTargetException {
    if (start.equals(""-"") && stop.equals(""+"")) {
      List<ByteArrayWrapper> l = new ArrayList<ByteArrayWrapper>(keyRegion.keySet());
      int size = l.size();
      Collections.sort(l);
      if (limit == 0) limit += size;
      l = l.subList(Math.min(size, offset), Math.min(offset + limit, size));
      return l;
    } else if (start.equals(""+"") || stop.equals(""-""))
      return null;

    Query query;
    Object[] params;
    if (start.equals(""-"")) {
      if (stopInclusive) {
        query = getQuery(key, SortedSetQuery.ZRANGEBYLEXNINFI, context);
      } else {
        query = getQuery(key, SortedSetQuery.ZRANGEBYLEXNINF, context);
      }
      params = new Object[]{stop, INFINITY_LIMIT};
    } else if (stop.equals(""+"")) {
      if (startInclusive) {
        query = getQuery(key, SortedSetQuery.ZRANGEBYLEXPINFI, context);
      } else {
        query = getQuery(key, SortedSetQuery.ZRANGEBYLEXPINF, context);
      }
      params = new Object[]{start, INFINITY_LIMIT};
    } else {
      if (startInclusive) {
        if(stopInclusive) {
          query = getQuery(key, SortedSetQuery.ZRANGEBYLEXSTISI, context);
        } else {
          query = getQuery(key, SortedSetQuery.ZRANGEBYLEXSTI, context);
        }
      } else {
        if (stopInclusive) {
          query = getQuery(key, SortedSetQuery.ZRANGEBYLEXSI, context);
        } else {
          query = getQuery(key, SortedSetQuery.ZRANGEBYLEX, context);
        }
      }
      params = new Object[]{start, stop, INFINITY_LIMIT};
    }
    if (limit > 0)
      params[params.length - 1] =  (limit + offset);
    SelectResults<ByteArrayWrapper> results = (SelectResults<ByteArrayWrapper>) query.execute(params);
    List<ByteArrayWrapper> list = results.asList();
    int size = list.size();
    return list.subList(Math.min(size, offset), size);

  }

  private final ByteBuf getCustomBulkStringArrayResponse(Collection<ByteArrayWrapper> items, ExecutionHandlerContext context) {",False
"  private Collection<?> getKeys(ByteArrayWrapper key, Region<ByteArrayWrapper, DoubleWrapper> keyRegion, ExecutionHandlerContext context, double start, double stop, boolean startInclusive, boolean stopInclusive, int offset, int limit) throws FunctionDomainException, TypeMismatchException, NameResolutionException, QueryInvocationTargetException {
    if (start == Double.POSITIVE_INFINITY || stop == Double.NEGATIVE_INFINITY || start > stop || (start == stop && (!startInclusive || !stopInclusive)))
      return null;
    if (start == Double.NEGATIVE_INFINITY && stop == Double.POSITIVE_INFINITY)
      return keyRegion.entrySet();

    Query query;
    Object[] params;
    if (isReverse()) {
      if (startInclusive) {
        if(stopInclusive) {
          query = getQuery(key, SortedSetQuery.ZREVRBSSTISI, context);
        } else {
          query = getQuery(key, SortedSetQuery.ZREVRBSSTI, context);
        }
      } else {
        if (stopInclusive) {
          query = getQuery(key, SortedSetQuery.ZREVRBSSI, context);
        } else {
          query = getQuery(key, SortedSetQuery.ZREVRBS, context);
        }
      }
      params = new Object[]{start, stop, INFINITY_LIMIT};
    } else {
      if (startInclusive) {
        if(stopInclusive) {
          query = getQuery(key, SortedSetQuery.ZRBSSTISI, context);
        } else {
          query = getQuery(key, SortedSetQuery.ZRBSSTI, context);
        }
      } else {
        if (stopInclusive) {
          query = getQuery(key, SortedSetQuery.ZRBSSI, context);
        } else {
          query = getQuery(key, SortedSetQuery.ZRBS, context);
        }
      }
      params = new Object[]{start, stop, INFINITY_LIMIT};
    }
    if (limit > 0)
      params[params.length - 1] =  (limit + offset);

    SelectResults<?> results = (SelectResults<?>) query.execute(params);
    if (offset < results.size())
      return (Collection<Struct>) results.asList().subList(offset, results.size());
    else 
      return null;
  }",True
"  private Collection<?> getKeys(ByteArrayWrapper key, Region<ByteArrayWrapper, DoubleWrapper> keyRegion, ExecutionHandlerContext context, double start, double stop, boolean startInclusive, boolean stopInclusive, int offset, int limit) throws FunctionDomainException, TypeMismatchException, NameResolutionException, QueryInvocationTargetException {
    if (start == Double.POSITIVE_INFINITY || stop == Double.NEGATIVE_INFINITY || start > stop || (start == stop && (!startInclusive || !stopInclusive)))
      return null;
    if (start == Double.NEGATIVE_INFINITY && stop == Double.POSITIVE_INFINITY)
      return new HashSet(keyRegion.entrySet());

    Query query;
    Object[] params;
    if (isReverse()) {
      if (startInclusive) {
        if(stopInclusive) {
          query = getQuery(key, SortedSetQuery.ZREVRBSSTISI, context);
        } else {
          query = getQuery(key, SortedSetQuery.ZREVRBSSTI, context);
        }
      } else {
        if (stopInclusive) {
          query = getQuery(key, SortedSetQuery.ZREVRBSSI, context);
        } else {
          query = getQuery(key, SortedSetQuery.ZREVRBS, context);
        }
      }
      params = new Object[]{start, stop, INFINITY_LIMIT};
    } else {
      if (startInclusive) {
        if(stopInclusive) {
          query = getQuery(key, SortedSetQuery.ZRBSSTISI, context);
        } else {
          query = getQuery(key, SortedSetQuery.ZRBSSTI, context);
        }
      } else {
        if (stopInclusive) {
          query = getQuery(key, SortedSetQuery.ZRBSSI, context);
        } else {
          query = getQuery(key, SortedSetQuery.ZRBS, context);
        }
      }
      params = new Object[]{start, stop, INFINITY_LIMIT};
    }
    if (limit > 0)
      params[params.length - 1] =  (limit + offset);

    SelectResults<?> results = (SelectResults<?>) query.execute(params);
    if (offset < results.size())
      return (Collection<Struct>) results.asList().subList(offset, results.size());
    else 
      return null;
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.ZREM));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    checkDataType(key, RedisDataType.REDIS_SORTEDSET, context);
    Region<ByteArrayWrapper, DoubleWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      return;
    }

    int numDeletedMembers = 0;
    
    for (int i = 2; i < commandElems.size(); i++) {
      byte[] memberArray = commandElems.get(i);
      ByteArrayWrapper member = new ByteArrayWrapper(memberArray);
      Object oldVal = keyRegion.remove(member);
      if (oldVal != null)
        numDeletedMembers++;
    }
    if (keyRegion.isEmpty())
      context.getRegionCache().removeKey(key);
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), numDeletedMembers));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.ZREM));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    checkDataType(key, RedisDataType.REDIS_SORTEDSET, context);
    Region<ByteArrayWrapper, DoubleWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      return;
    }

    int numDeletedMembers = 0;
    
    for (int i = 2; i < commandElems.size(); i++) {
      byte[] memberArray = commandElems.get(i);
      ByteArrayWrapper member = new ByteArrayWrapper(memberArray);
      Object oldVal = keyRegion.remove(member);
      if (oldVal != null)
        numDeletedMembers++;
    }
    if (keyRegion.isEmpty())
      context.getRegionProvider().removeKey(key);
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), numDeletedMembers));
  }",False
"  private Collection<ByteArrayWrapper> getRange(ByteArrayWrapper key, Region<ByteArrayWrapper, DoubleWrapper> keyRegion, ExecutionHandlerContext context, ByteArrayWrapper start, ByteArrayWrapper stop, boolean startInclusive, boolean stopInclusive) throws Exception {
    if (start.equals(""-"") && stop.equals(""+""))
      return keyRegion.keySet();
    else if (start.equals(""+"") || stop.equals(""-""))
      return null;

    Query query;
    Object[] params;
    if (start.equals(""-"")) {
      if (stopInclusive) {
        query = getQuery(key, SortedSetQuery.ZRANGEBYLEXNINFI, context);
      } else {
        query = getQuery(key, SortedSetQuery.ZRANGEBYLEXNINF, context);
      }
      params = new Object[]{stop, INFINITY_LIMIT};
    } else if (stop.equals(""+"")) {
      if (startInclusive) {
        query = getQuery(key, SortedSetQuery.ZRANGEBYLEXPINFI, context);
      } else {
        query = getQuery(key, SortedSetQuery.ZRANGEBYLEXPINF, context);
      }
      params = new Object[]{start, INFINITY_LIMIT};
    } else {
      if (startInclusive) {
        if(stopInclusive) {
          query = getQuery(key, SortedSetQuery.ZRANGEBYLEXSTISI, context);
        } else {
          query = getQuery(key, SortedSetQuery.ZRANGEBYLEXSTI, context);
        }
      } else {
        if (stopInclusive) {
          query = getQuery(key, SortedSetQuery.ZRANGEBYLEXSI, context);
        } else {
          query = getQuery(key, SortedSetQuery.ZRANGEBYLEX, context);
        }
      }
      params = new Object[]{start, stop, INFINITY_LIMIT};
    }

    @SuppressWarnings(""unchecked"")
    SelectResults<ByteArrayWrapper> results = (SelectResults<ByteArrayWrapper>) query.execute(params);

    return results.asList();
  }",True
"  private Collection<ByteArrayWrapper> getRange(ByteArrayWrapper key, Region<ByteArrayWrapper, DoubleWrapper> keyRegion, ExecutionHandlerContext context, ByteArrayWrapper start, ByteArrayWrapper stop, boolean startInclusive, boolean stopInclusive) throws Exception {
    if (start.equals(""-"") && stop.equals(""+""))
      return new ArrayList<ByteArrayWrapper>(keyRegion.keySet());
    else if (start.equals(""+"") || stop.equals(""-""))
      return null;

    Query query;
    Object[] params;
    if (start.equals(""-"")) {
      if (stopInclusive) {
        query = getQuery(key, SortedSetQuery.ZRANGEBYLEXNINFI, context);
      } else {
        query = getQuery(key, SortedSetQuery.ZRANGEBYLEXNINF, context);
      }
      params = new Object[]{stop, INFINITY_LIMIT};
    } else if (stop.equals(""+"")) {
      if (startInclusive) {
        query = getQuery(key, SortedSetQuery.ZRANGEBYLEXPINFI, context);
      } else {
        query = getQuery(key, SortedSetQuery.ZRANGEBYLEXPINF, context);
      }
      params = new Object[]{start, INFINITY_LIMIT};
    } else {
      if (startInclusive) {
        if(stopInclusive) {
          query = getQuery(key, SortedSetQuery.ZRANGEBYLEXSTISI, context);
        } else {
          query = getQuery(key, SortedSetQuery.ZRANGEBYLEXSTI, context);
        }
      } else {
        if (stopInclusive) {
          query = getQuery(key, SortedSetQuery.ZRANGEBYLEXSI, context);
        } else {
          query = getQuery(key, SortedSetQuery.ZRANGEBYLEX, context);
        }
      }
      params = new Object[]{start, stop, INFINITY_LIMIT};
    }

    @SuppressWarnings(""unchecked"")
    SelectResults<ByteArrayWrapper> results = (SelectResults<ByteArrayWrapper>) query.execute(params);

    return results.asList();
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.ZREMRANGEBYRANK));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    checkDataType(key, RedisDataType.REDIS_SORTEDSET, context);
    Region<ByteArrayWrapper, DoubleWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NONE_REMOVED));
      return;
    }

    int startRank;
    int stopRank;

    try {
      startRank = Coder.bytesToInt(commandElems.get(2));
      stopRank = Coder.bytesToInt(commandElems.get(3));
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_NUMERIC));
      return;
    }

    int sSetSize = keyRegion.size();

    startRank = getBoundedStartIndex(startRank, sSetSize);
    stopRank = getBoundedEndIndex(stopRank, sSetSize);
    if (stopRank > sSetSize - 1)
      stopRank = sSetSize - 1;

    if (startRank > stopRank) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      return;
    }

    int numRemoved = 0;
    List<?> removeList = null;
    try {
      if (startRank == 0 && stopRank == sSetSize- 1) {
        numRemoved = keyRegion.size();
        context.getRegionCache().removeKey(key);
      } else {
        removeList = getRemoveKeys(context, key, startRank, stopRank);
      }
    } catch (Exception e) {
      throw new RuntimeException(e);
    }

    if (removeList != null) {
      for (Object entry: removeList) {
        ByteArrayWrapper removeKey;
        if (entry instanceof Entry)
          removeKey = (ByteArrayWrapper) ((Entry<?, ?>) entry).getKey();
        else
          removeKey = (ByteArrayWrapper) ((Struct) entry).getFieldValues()[0];
        Object oldVal = keyRegion.remove(removeKey);
        if (oldVal != null)
          numRemoved++;
      }
      if (keyRegion.isEmpty())
        context.getRegionCache().removeKey(key);
    }
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), numRemoved));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.ZREMRANGEBYRANK));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    checkDataType(key, RedisDataType.REDIS_SORTEDSET, context);
    Region<ByteArrayWrapper, DoubleWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NONE_REMOVED));
      return;
    }

    int startRank;
    int stopRank;

    try {
      startRank = Coder.bytesToInt(commandElems.get(2));
      stopRank = Coder.bytesToInt(commandElems.get(3));
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_NUMERIC));
      return;
    }

    int sSetSize = keyRegion.size();

    startRank = getBoundedStartIndex(startRank, sSetSize);
    stopRank = getBoundedEndIndex(stopRank, sSetSize);
    if (stopRank > sSetSize - 1)
      stopRank = sSetSize - 1;

    if (startRank > stopRank) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      return;
    }

    int numRemoved = 0;
    List<?> removeList = null;
    try {
      if (startRank == 0 && stopRank == sSetSize- 1) {
        numRemoved = keyRegion.size();
        context.getRegionProvider().removeKey(key);
      } else {
        removeList = getRemoveKeys(context, key, startRank, stopRank);
      }
    } catch (Exception e) {
      throw new RuntimeException(e);
    }

    if (removeList != null) {
      for (Object entry: removeList) {
        ByteArrayWrapper removeKey;
        if (entry instanceof Entry)
          removeKey = (ByteArrayWrapper) ((Entry<?, ?>) entry).getKey();
        else
          removeKey = (ByteArrayWrapper) ((Struct) entry).getFieldValues()[0];
        Object oldVal = keyRegion.remove(removeKey);
        if (oldVal != null)
          numRemoved++;
      }
      if (keyRegion.isEmpty())
        context.getRegionProvider().removeKey(key);
    }
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), numRemoved));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.ZREMRANGEBYSCORE));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    checkDataType(key, RedisDataType.REDIS_SORTEDSET, context);
    Region<ByteArrayWrapper, DoubleWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_EXISTS));
      return;
    }

    boolean startInclusive = true;
    boolean stopInclusive = true;
    double start;
    double stop;

    byte[] startArray = commandElems.get(2);
    byte[] stopArray = commandElems.get(3);
    String startString = Coder.bytesToString(startArray);
    String stopString = Coder.bytesToString(stopArray);
    if (startArray[0] == Coder.OPEN_BRACE_ID) {
      startString = startString.substring(1);
      startInclusive = false;
    }
    if (stopArray[0] == Coder.OPEN_BRACE_ID) {
      stopString = stopString.substring(1);
      stopInclusive = false;
    }

    try {
      start = Coder.stringToDouble(startString);
      stop = Coder.stringToDouble(stopString);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_NUMERIC));
      return;
    }

    int numRemoved = 0;

    Collection<?> removeList = null;
    try {
      if (start == Double.NEGATIVE_INFINITY && stop == Double.POSITIVE_INFINITY && startInclusive && stopInclusive) {
        numRemoved = keyRegion.size();
        context.getRegionCache().removeKey(key);
      } else {
        removeList = getKeys(context, key, keyRegion, start, stop, startInclusive, stopInclusive);
      }
    } catch (Exception e) {
      throw new RuntimeException(e);
    }

    if (removeList != null) {
      for (Object entry: removeList) {
        ByteArrayWrapper remove = null;
        if (entry instanceof Entry)
          remove = (ByteArrayWrapper) ((Entry<?, ?>) entry).getKey();
        else if (entry instanceof Struct)
          remove = (ByteArrayWrapper) ((Struct) entry).getFieldValues()[0];
        Object oldVal = keyRegion.remove(remove);
        if (oldVal != null)
          numRemoved++;
        if (keyRegion.isEmpty())
          context.getRegionCache().removeKey(key);
      }
    }
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), numRemoved));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.ZREMRANGEBYSCORE));
      return;
    }

    ByteArrayWrapper key = command.getKey();

    checkDataType(key, RedisDataType.REDIS_SORTEDSET, context);
    Region<ByteArrayWrapper, DoubleWrapper> keyRegion = getRegion(context, key);

    if (keyRegion == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_EXISTS));
      return;
    }

    boolean startInclusive = true;
    boolean stopInclusive = true;
    double start;
    double stop;

    byte[] startArray = commandElems.get(2);
    byte[] stopArray = commandElems.get(3);
    String startString = Coder.bytesToString(startArray);
    String stopString = Coder.bytesToString(stopArray);
    if (startArray[0] == Coder.OPEN_BRACE_ID) {
      startString = startString.substring(1);
      startInclusive = false;
    }
    if (stopArray[0] == Coder.OPEN_BRACE_ID) {
      stopString = stopString.substring(1);
      stopInclusive = false;
    }

    try {
      start = Coder.stringToDouble(startString);
      stop = Coder.stringToDouble(stopString);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_NUMERIC));
      return;
    }

    int numRemoved = 0;

    Collection<?> removeList = null;
    try {
      if (start == Double.NEGATIVE_INFINITY && stop == Double.POSITIVE_INFINITY && startInclusive && stopInclusive) {
        numRemoved = keyRegion.size();
        context.getRegionProvider().removeKey(key);
      } else {
        removeList = getKeys(context, key, keyRegion, start, stop, startInclusive, stopInclusive);
      }
    } catch (Exception e) {
      throw new RuntimeException(e);
    }

    if (removeList != null) {
      for (Object entry: removeList) {
        ByteArrayWrapper remove = null;
        if (entry instanceof Entry)
          remove = (ByteArrayWrapper) ((Entry<?, ?>) entry).getKey();
        else if (entry instanceof Struct)
          remove = (ByteArrayWrapper) ((Struct) entry).getFieldValues()[0];
        Object oldVal = keyRegion.remove(remove);
        if (oldVal != null)
          numRemoved++;
        if (keyRegion.isEmpty())
          context.getRegionProvider().removeKey(key);
      }
    }
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), numRemoved));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.ZSCAN));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    Region<ByteArrayWrapper, DoubleWrapper> keyRegion = (Region<ByteArrayWrapper, DoubleWrapper>) context.getRegionCache().getRegion(key);
    checkDataType(key, RedisDataType.REDIS_SORTEDSET, context);
    if (keyRegion == null) {
      command.setResponse(Coder.getScanResponse(context.getByteBufAllocator(), new ArrayList<String>()));
      return;
    }
    byte[] cAr = commandElems.get(2);
    //String cursorString = ResponseToByteEncoder.bytesToString(cAr);

    int cursor = 0;
    Pattern matchPattern = null;
    String globMatchPattern = null;
    int count = DEFUALT_COUNT;
    try {
      cursor = Coder.bytesToInt(cAr);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_CURSOR));
      return;
    }
    if (cursor < 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_CURSOR));
      return;
    }

    if (commandElems.size() > 4) {
      try {
        byte[] bytes = commandElems.get(3);
        if (Coder.bytesToString(bytes).equalsIgnoreCase(""MATCH"")) {
          bytes = commandElems.get(4);
          globMatchPattern = Coder.bytesToString(bytes);
        } else if (Coder.bytesToString(bytes).equalsIgnoreCase(""COUNT"")) {
          bytes = commandElems.get(4);
          count = Coder.bytesToInt(bytes);
        }
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
        return;
      }
    }

    if (commandElems.size() > 6) {
      try {
        byte[] bytes = commandElems.get(5);
        if (Coder.bytesToString(bytes).equalsIgnoreCase(""COUNT"")) {
          bytes = commandElems.get(6);
          count = Coder.bytesToInt(bytes);
        }
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
        return;
      }
    }

    if (count < 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
      return;
    }

    try {
      matchPattern = convertGlobToRegex(globMatchPattern);
    } catch (PatternSyntaxException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), RedisConstants.ERROR_ILLEGAL_GLOB));
      return;
    }

    List<ByteArrayWrapper> returnList = (List<ByteArrayWrapper>) getIteration(keyRegion.entrySet(), matchPattern, count, cursor);

    command.setResponse(Coder.getScanResponse(context.getByteBufAllocator(), returnList));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.ZSCAN));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    Region<ByteArrayWrapper, DoubleWrapper> keyRegion = (Region<ByteArrayWrapper, DoubleWrapper>) context.getRegionProvider().getRegion(key);
    checkDataType(key, RedisDataType.REDIS_SORTEDSET, context);
    if (keyRegion == null) {
      command.setResponse(Coder.getScanResponse(context.getByteBufAllocator(), new ArrayList<String>()));
      return;
    }
    byte[] cAr = commandElems.get(2);
    //String cursorString = ResponseToByteEncoder.bytesToString(cAr);

    int cursor = 0;
    Pattern matchPattern = null;
    String globMatchPattern = null;
    int count = DEFUALT_COUNT;
    try {
      cursor = Coder.bytesToInt(cAr);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_CURSOR));
      return;
    }
    if (cursor < 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_CURSOR));
      return;
    }

    if (commandElems.size() > 4) {
      try {
        byte[] bytes = commandElems.get(3);
        if (Coder.bytesToString(bytes).equalsIgnoreCase(""MATCH"")) {
          bytes = commandElems.get(4);
          globMatchPattern = Coder.bytesToString(bytes);
        } else if (Coder.bytesToString(bytes).equalsIgnoreCase(""COUNT"")) {
          bytes = commandElems.get(4);
          count = Coder.bytesToInt(bytes);
        }
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
        return;
      }
    }

    if (commandElems.size() > 6) {
      try {
        byte[] bytes = commandElems.get(5);
        if (Coder.bytesToString(bytes).equalsIgnoreCase(""COUNT"")) {
          bytes = commandElems.get(6);
          count = Coder.bytesToInt(bytes);
        }
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
        return;
      }
    }

    if (count < 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_COUNT));
      return;
    }

    try {
      matchPattern = convertGlobToRegex(globMatchPattern);
    } catch (PatternSyntaxException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), RedisConstants.ERROR_ILLEGAL_GLOB));
      return;
    }

    List<ByteArrayWrapper> returnList = (List<ByteArrayWrapper>) getIteration(new HashSet(keyRegion.entrySet()), matchPattern, count, cursor);

    command.setResponse(Coder.getScanResponse(context.getByteBufAllocator(), returnList));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();;

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.APPEND));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper string = r.get(key);

    byte[] stringByteArray = commandElems.get(VALUE_INDEX);
    if (string == null) {
      r.put(key, new ByteArrayWrapper(stringByteArray));
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), stringByteArray.length));
    } else {
      byte[] newValue = concatArrays(string.toBytes(), stringByteArray);
      string.setBytes(newValue);
      r.put(key, string);
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), newValue.length));
    }

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();;

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.APPEND));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper string = r.get(key);

    byte[] stringByteArray = commandElems.get(VALUE_INDEX);
    if (string == null) {
      r.put(key, new ByteArrayWrapper(stringByteArray));
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), stringByteArray.length));
    } else {
      byte[] newValue = concatArrays(string.toBytes(), stringByteArray);
      string.setBytes(newValue);
      r.put(key, string);
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), newValue.length));
    }

  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() != 2 && commandElems.size() != 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.BITCOUNT));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper wrapper = r.get(key);
    if (wrapper == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      return;
    }
    byte[] value = wrapper.toBytes();

    long startL = 0;
    long endL = value.length - 1;

    if (commandElems.size() == 4) {
      try {
        startL = Coder.bytesToLong(commandElems.get(2));
        endL = Coder.bytesToLong(commandElems.get(3));
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_INT));
        return;
      }
    }
    if (startL > Integer.MAX_VALUE || endL > Integer.MAX_VALUE) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), RedisConstants.ERROR_OUT_OF_RANGE));
      return;
    }

    int start = (int) startL;
    int end = (int) endL;
    if (start < 0)
      start += value.length;
    if (end < 0)
      end += value.length;

    if (start < 0)
      start = 0;
    if (end < 0)
      end = 0;

    if (end > value.length - 1)
      end = value.length - 1;

    if (end < start || start >= value.length) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      return;
    }

    long setBits = 0;
    for (int j = start; j <= end; j++)
      setBits += Integer.bitCount(0xFF & value[j]); // 0xFF keeps same bit sequence as the byte as opposed to keeping the same value

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), setBits));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() != 2 && commandElems.size() != 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.BITCOUNT));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper wrapper = r.get(key);
    if (wrapper == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      return;
    }
    byte[] value = wrapper.toBytes();

    long startL = 0;
    long endL = value.length - 1;

    if (commandElems.size() == 4) {
      try {
        startL = Coder.bytesToLong(commandElems.get(2));
        endL = Coder.bytesToLong(commandElems.get(3));
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_INT));
        return;
      }
    }
    if (startL > Integer.MAX_VALUE || endL > Integer.MAX_VALUE) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), RedisConstants.ERROR_OUT_OF_RANGE));
      return;
    }

    int start = (int) startL;
    int end = (int) endL;
    if (start < 0)
      start += value.length;
    if (end < 0)
      end += value.length;

    if (start < 0)
      start = 0;
    if (end < 0)
      end = 0;

    if (end > value.length - 1)
      end = value.length - 1;

    if (end < start || start >= value.length) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      return;
    }

    long setBits = 0;
    for (int j = start; j <= end; j++)
      setBits += Integer.bitCount(0xFF & value[j]); // 0xFF keeps same bit sequence as the byte as opposed to keeping the same value

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), setBits));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.BITOP));
      return;
    }

    String operation = command.getStringKey().toUpperCase();
    ByteArrayWrapper destKey = new ByteArrayWrapper(commandElems.get(2));
    checkDataType(destKey, context);

    byte[][] values = new byte[commandElems.size() - 3][];
    int maxLength = 0;
    for (int i = 3; i < commandElems.size(); i++) {
      ByteArrayWrapper key = new ByteArrayWrapper(commandElems.get(i));
      checkDataType(key, context);
      ByteArrayWrapper value = r.get(key);
      if (value == null) {
        values[i - 3] = null;
        continue;
      }

      byte[] val = value.toBytes();
      values[i - 3] = val;
      if (val.length > maxLength) {
        maxLength = val.length;
        byte[] tmp = values[0];
        values[0] = val;
        values[i - 3] = tmp;
      }
      if (i == 3 && operation.equalsIgnoreCase(""NOT""))
        break;
    }


    if (operation.equals(""AND""))
      and(context, r, destKey, values, maxLength);
    else if (operation.equals(""OR""))
      or(context, r, destKey, values, maxLength);
    else if (operation.equals(""XOR""))
      xor(context, r, destKey, values, maxLength);
    else if (operation.equals(""NOT""))
      not(context, r, destKey, values, maxLength);
    else {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NO_SUCH_OP));
      return;
    }

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), maxLength));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.BITOP));
      return;
    }

    String operation = command.getStringKey().toUpperCase();
    ByteArrayWrapper destKey = new ByteArrayWrapper(commandElems.get(2));
    checkDataType(destKey, context);

    byte[][] values = new byte[commandElems.size() - 3][];
    int maxLength = 0;
    for (int i = 3; i < commandElems.size(); i++) {
      ByteArrayWrapper key = new ByteArrayWrapper(commandElems.get(i));
      checkDataType(key, context);
      ByteArrayWrapper value = r.get(key);
      if (value == null) {
        values[i - 3] = null;
        continue;
      }

      byte[] val = value.toBytes();
      values[i - 3] = val;
      if (val.length > maxLength) {
        maxLength = val.length;
        byte[] tmp = values[0];
        values[0] = val;
        values[i - 3] = tmp;
      }
      if (i == 3 && operation.equalsIgnoreCase(""NOT""))
        break;
    }


    if (operation.equals(""AND""))
      and(context, r, destKey, values, maxLength);
    else if (operation.equals(""OR""))
      or(context, r, destKey, values, maxLength);
    else if (operation.equals(""XOR""))
      xor(context, r, destKey, values, maxLength);
    else if (operation.equals(""NOT""))
      not(context, r, destKey, values, maxLength);
    else {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NO_SUCH_OP));
      return;
    }

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), maxLength));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.BITPOS));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper string = r.get(key);

    int bit;
    int bitPosition = -1;
    boolean endSet = false;

    try {
      byte[] bitAr = commandElems.get(2);
      bit = Coder.bytesToInt(bitAr);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_INT));
      return;
    }

    if (bit != 0 && bit != 1) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_BIT));
      return;
    }

    if (string == null || string.length() == 0) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), -bit)); // Redis returns 0 when key does not exists for this command
      return;
    }
    byte[] bytes = string.toBytes();
    int start = 0;
    int end = bytes.length - 1;
    if (commandElems.size() > 3) {
      try {
        byte[] startAr = commandElems.get(3);
        start = Coder.bytesToInt(startAr);
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_INT));
        return;
      }
    }


    if (commandElems.size() > 4) {
      try {
        byte[] endAr = commandElems.get(4);
        end = Coder.bytesToInt(endAr);
        endSet = true;
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_INT));
        return;
      }
    }

    if (start < 0)
      start += bytes.length;
    if (end < 0)
      end += bytes.length;

    if (start < 0)
      start = 0;
    if (end < 0)
      end = 0;

    if (start > bytes.length)
      start = bytes.length - 1;
    if (end > bytes.length)
      end = bytes.length - 1;

    if (end < start) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), -1));
      return;
    }

    outerLoop:
      for (int i = start; i <= end; i++) {
        int cBit;
        byte cByte = bytes[i];
        for (int j = 0; j < 8; j++) {
          cBit = (cByte & (0x80 >> j)) >> (7 - j);
    if (cBit ==  bit) {
      bitPosition = 8 * i + j;
      break outerLoop;
    }
        }
      }

    if (bit == 0 && bitPosition == -1 && !endSet)
      bitPosition = bytes.length * 8;

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), bitPosition));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.BITPOS));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper string = r.get(key);

    int bit;
    int bitPosition = -1;
    boolean endSet = false;

    try {
      byte[] bitAr = commandElems.get(2);
      bit = Coder.bytesToInt(bitAr);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_INT));
      return;
    }

    if (bit != 0 && bit != 1) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_BIT));
      return;
    }

    if (string == null || string.length() == 0) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), -bit)); // Redis returns 0 when key does not exists for this command
      return;
    }
    byte[] bytes = string.toBytes();
    int start = 0;
    int end = bytes.length - 1;
    if (commandElems.size() > 3) {
      try {
        byte[] startAr = commandElems.get(3);
        start = Coder.bytesToInt(startAr);
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_INT));
        return;
      }
    }


    if (commandElems.size() > 4) {
      try {
        byte[] endAr = commandElems.get(4);
        end = Coder.bytesToInt(endAr);
        endSet = true;
      } catch (NumberFormatException e) {
        command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_INT));
        return;
      }
    }

    if (start < 0)
      start += bytes.length;
    if (end < 0)
      end += bytes.length;

    if (start < 0)
      start = 0;
    if (end < 0)
      end = 0;

    if (start > bytes.length)
      start = bytes.length - 1;
    if (end > bytes.length)
      end = bytes.length - 1;

    if (end < start) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), -1));
      return;
    }

    outerLoop:
      for (int i = start; i <= end; i++) {
        int cBit;
        byte cByte = bytes[i];
        for (int j = 0; j < 8; j++) {
          cBit = (cByte & (0x80 >> j)) >> (7 - j);
    if (cBit ==  bit) {
      bitPosition = 8 * i + j;
      break outerLoop;
    }
        }
      }

    if (bit == 0 && bitPosition == -1 && !endSet)
      bitPosition = bytes.length * 8;

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), bitPosition));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.DECRBY));
      return;
    }
    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper valueWrapper = r.get(key);

    /*
     * Try increment
     */

    byte[] decrArray = commandElems.get(DECREMENT_INDEX);
    String decrString = Coder.bytesToString(decrArray);
    Long decrement;

    try {
      decrement = Long.parseLong(decrString);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_DECREMENT_NOT_USABLE));
      return;
    }

    /*
     * Value does not exist
     */

    if (valueWrapper == null) {
      String negativeDecrString = decrString.charAt(0) == Coder.HYPHEN_ID ? decrString.substring(1) : ""-"" + decrString;
      r.put(key, new ByteArrayWrapper(Coder.stringToBytes(negativeDecrString)));
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), -decrement));
      return;
    }

    /*
     * Value exists
     */

    String stringValue = Coder.bytesToString(valueWrapper.toBytes());

    Long value;
    try {
      value = Long.parseLong(stringValue);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_VALUE_NOT_USABLE));
      return;
    }

    /*
     * Check for overflow
     * Negative decrement is used because the decrement is stored as a positive long
     */
    if (value <= 0 && -decrement < (Long.MIN_VALUE - value)) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_OVERFLOW));
      return;
    }

    value -= decrement;

    stringValue = """" + value;
    r.put(key, new ByteArrayWrapper(Coder.stringToBytes(stringValue)));

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), value));

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.DECRBY));
      return;
    }
    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper valueWrapper = r.get(key);

    /*
     * Try increment
     */

    byte[] decrArray = commandElems.get(DECREMENT_INDEX);
    String decrString = Coder.bytesToString(decrArray);
    Long decrement;

    try {
      decrement = Long.parseLong(decrString);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_DECREMENT_NOT_USABLE));
      return;
    }

    /*
     * Value does not exist
     */

    if (valueWrapper == null) {
      String negativeDecrString = decrString.charAt(0) == Coder.HYPHEN_ID ? decrString.substring(1) : ""-"" + decrString;
      r.put(key, new ByteArrayWrapper(Coder.stringToBytes(negativeDecrString)));
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), -decrement));
      return;
    }

    /*
     * Value exists
     */

    String stringValue = Coder.bytesToString(valueWrapper.toBytes());

    Long value;
    try {
      value = Long.parseLong(stringValue);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_VALUE_NOT_USABLE));
      return;
    }

    /*
     * Check for overflow
     * Negative decrement is used because the decrement is stored as a positive long
     */
    if (value <= 0 && -decrement < (Long.MIN_VALUE - value)) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_OVERFLOW));
      return;
    }

    value -= decrement;

    stringValue = """" + value;
    r.put(key, new ByteArrayWrapper(Coder.stringToBytes(stringValue)));

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), value));

  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    RegionCache rC = context.getRegionCache();
    Region<ByteArrayWrapper, ByteArrayWrapper> r = rC.getStringsRegion();;

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.DECR));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper valueWrapper = r.get(key);

    /*
     * Value does not exist
     */

    if (valueWrapper == null) {
      byte[] newValue = INIT_VALUE_BYTES;
      r.put(key, new ByteArrayWrapper(newValue));
      rC.metaPut(key, RedisDataType.REDIS_STRING);
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), INIT_VALUE_INT));
      return;
    }

    /*
     * Value exists
     */

    String stringValue = valueWrapper.toString();
    Long value;
    try {
      value = Long.parseLong(stringValue);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_VALUE_NOT_USABLE));
      return;
    }

    if (value == Long.MIN_VALUE) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_OVERFLOW));
      return;
    }

    value--;

    stringValue = """" + value;

    r.put(key, new ByteArrayWrapper(Coder.stringToBytes(stringValue)));
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), value));

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    RegionProvider rC = context.getRegionProvider();
    Region<ByteArrayWrapper, ByteArrayWrapper> r = rC.getStringsRegion();;

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.DECR));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper valueWrapper = r.get(key);

    /*
     * Value does not exist
     */

    if (valueWrapper == null) {
      byte[] newValue = INIT_VALUE_BYTES;
      r.put(key, new ByteArrayWrapper(newValue));
      rC.metaPut(key, RedisDataType.REDIS_STRING);
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), INIT_VALUE_INT));
      return;
    }

    /*
     * Value exists
     */

    String stringValue = valueWrapper.toString();
    Long value;
    try {
      value = Long.parseLong(stringValue);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_VALUE_NOT_USABLE));
      return;
    }

    if (value == Long.MIN_VALUE) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_OVERFLOW));
      return;
    }

    value--;

    stringValue = """" + value;

    r.put(key, new ByteArrayWrapper(Coder.stringToBytes(stringValue)));
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), value));

  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.GETBIT));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper wrapper = r.get(key);
    if (wrapper == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      return;
    }

    int bit = 0;
    byte[] bytes = wrapper.toBytes();
    int offset;
    try {
      byte[] offAr = commandElems.get(2);
      offset = Coder.bytesToInt(offAr);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_INT));
      return;
    }
    if (offset < 0)
      offset += bytes.length * 8;

    if (offset < 0 || offset > bytes.length * 8) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      return;
    }

    int byteIndex = offset / 8;
    offset %= 8;
    
    if (byteIndex >= bytes.length) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      return;
    }
    
    bit = (bytes[byteIndex] & (0x80 >> offset)) >> (7 - offset);
    
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), bit));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.GETBIT));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper wrapper = r.get(key);
    if (wrapper == null) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      return;
    }

    int bit = 0;
    byte[] bytes = wrapper.toBytes();
    int offset;
    try {
      byte[] offAr = commandElems.get(2);
      offset = Coder.bytesToInt(offAr);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_INT));
      return;
    }
    if (offset < 0)
      offset += bytes.length * 8;

    if (offset < 0 || offset > bytes.length * 8) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      return;
    }

    int byteIndex = offset / 8;
    offset %= 8;
    
    if (byteIndex >= bytes.length) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
      return;
    }
    
    bit = (bytes[byteIndex] & (0x80 >> offset)) >> (7 - offset);
    
    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), bit));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    Region<ByteArrayWrapper, ByteArrayWrapper> r= context.getRegionCache().getStringsRegion();

    if (command.getProcessedCommand().size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.GETEXECUTOR));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, RedisDataType.REDIS_STRING, context);
    ByteArrayWrapper wrapper = r.get(key);

    if (wrapper == null) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    } else {
      command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), wrapper.toBytes()));
    }

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    Region<ByteArrayWrapper, ByteArrayWrapper> r= context.getRegionProvider().getStringsRegion();

    if (command.getProcessedCommand().size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.GETEXECUTOR));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, RedisDataType.REDIS_STRING, context);
    ByteArrayWrapper wrapper = r.get(key);

    if (wrapper == null) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    } else {
      command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), wrapper.toBytes()));
    }

  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.GETRANGE));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, RedisDataType.REDIS_STRING, context);
    ByteArrayWrapper valueWrapper = r.get(key);

    if (valueWrapper == null) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }

    byte[] value = valueWrapper.toBytes();
    int length = value.length;

    long start;
    long end;


    try {
      byte[] startI = commandElems.get(startIndex);
      byte[] stopI = commandElems.get(stopIndex);
      start = Coder.bytesToLong(startI);
      end = Coder.bytesToLong(stopI);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_INT));
      return;
    }
    start = getBoundedStartIndex(start, length);
    end = getBoundedEndIndex(end, length);
    
    /*
     * If the properly formatted indexes are illegal, send nil
     */
    if (start > end || start == length) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }
    /*
     *  1 is added to end because the end in copyOfRange is exclusive
     *  but in Redis it is inclusive
     */
    if (end != length) end++;
    byte[] returnRange = Arrays.copyOfRange(value, (int) start, (int) end);
    if (returnRange == null || returnRange.length == 0) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }

    command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), returnRange));

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.GETRANGE));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, RedisDataType.REDIS_STRING, context);
    ByteArrayWrapper valueWrapper = r.get(key);

    if (valueWrapper == null) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }

    byte[] value = valueWrapper.toBytes();
    int length = value.length;

    long start;
    long end;


    try {
      byte[] startI = commandElems.get(startIndex);
      byte[] stopI = commandElems.get(stopIndex);
      start = Coder.bytesToLong(startI);
      end = Coder.bytesToLong(stopI);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_INT));
      return;
    }
    start = getBoundedStartIndex(start, length);
    end = getBoundedEndIndex(end, length);
    
    /*
     * If the properly formatted indexes are illegal, send nil
     */
    if (start > end || start == length) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }
    /*
     *  1 is added to end because the end in copyOfRange is exclusive
     *  but in Redis it is inclusive
     */
    if (end != length) end++;
    byte[] returnRange = Arrays.copyOfRange(value, (int) start, (int) end);
    if (returnRange == null || returnRange.length == 0) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
      return;
    }

    command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), returnRange));

  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.GETSET));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);

    byte[] newCharValue = commandElems.get(VALUE_INDEX);
    ByteArrayWrapper newValueWrapper = new ByteArrayWrapper(newCharValue);

    ByteArrayWrapper oldValueWrapper = r.get(key);
    r.put(key, newValueWrapper);

    if (oldValueWrapper == null) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
    } else {
      command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), oldValueWrapper.toBytes()));
    }

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.GETSET));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);

    byte[] newCharValue = commandElems.get(VALUE_INDEX);
    ByteArrayWrapper newValueWrapper = new ByteArrayWrapper(newCharValue);

    ByteArrayWrapper oldValueWrapper = r.get(key);
    r.put(key, newValueWrapper);

    if (oldValueWrapper == null) {
      command.setResponse(Coder.getNilResponse(context.getByteBufAllocator()));
    } else {
      command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), oldValueWrapper.toBytes()));
    }

  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.INCRBY));
      return;
    }
    
    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper valueWrapper = r.get(key);

    /*
     * Try increment
     */

    byte[] incrArray = commandElems.get(INCREMENT_INDEX);
    Long increment;

    try {
      increment = Coder.bytesToLong(incrArray);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_INCREMENT_NOT_USABLE));
      return;
    }

    /*
     * Value does not exist
     */

    if (valueWrapper == null) {
      r.put(key, new ByteArrayWrapper(incrArray));
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), increment));
      return;
    }

    /*
     * Value exists
     */

    String stringValue = Coder.bytesToString(valueWrapper.toBytes());
    Long value;
    try {
      value = Long.parseLong(stringValue);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_VALUE_NOT_USABLE));
      return;
    }

    /*
     * Check for overflow
     */
    if (value >= 0 && increment > (Long.MAX_VALUE - value)) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_OVERFLOW));
      return;
    }

    value += increment;

    stringValue = """" + value;
    r.put(key, new ByteArrayWrapper(Coder.stringToBytes(stringValue)));

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), value));

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.INCRBY));
      return;
    }
    
    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper valueWrapper = r.get(key);

    /*
     * Try increment
     */

    byte[] incrArray = commandElems.get(INCREMENT_INDEX);
    Long increment;

    try {
      increment = Coder.bytesToLong(incrArray);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_INCREMENT_NOT_USABLE));
      return;
    }

    /*
     * Value does not exist
     */

    if (valueWrapper == null) {
      r.put(key, new ByteArrayWrapper(incrArray));
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), increment));
      return;
    }

    /*
     * Value exists
     */

    String stringValue = Coder.bytesToString(valueWrapper.toBytes());
    Long value;
    try {
      value = Long.parseLong(stringValue);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_VALUE_NOT_USABLE));
      return;
    }

    /*
     * Check for overflow
     */
    if (value >= 0 && increment > (Long.MAX_VALUE - value)) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_OVERFLOW));
      return;
    }

    value += increment;

    stringValue = """" + value;
    r.put(key, new ByteArrayWrapper(Coder.stringToBytes(stringValue)));

    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), value));

  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();
    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.INCRBYFLOAT));
      return;
    }
    
    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper valueWrapper = r.get(key);

    /*
     * Try increment
     */

    byte[] incrArray = commandElems.get(INCREMENT_INDEX);
    String doub = Coder.bytesToString(incrArray).toLowerCase();
    if (doub.contains(""inf"") || doub.contains(""nan"")) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ""Increment would produce NaN or infinity""));
      return;
    } else if (valueWrapper != null && valueWrapper.toString().contains("" "")) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_VALUE_NOT_USABLE));
      return;
    }
    
    
    Double increment;

    try {
      increment = Coder.stringToDouble(doub);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_INCREMENT_NOT_USABLE));
      return;
    }

    /*
     * Value does not exist
     */

    if (valueWrapper == null) {
      r.put(key, new ByteArrayWrapper(incrArray));
      command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), increment));
      return;
    }

    /*
     * Value exists
     */

    String stringValue = Coder.bytesToString(valueWrapper.toBytes());

    Double value;
    try {
      value = Coder.stringToDouble(stringValue);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_VALUE_NOT_USABLE));
      return;
    }

    /*
     * Check for overflow
     */
    if (value >= 0 && increment > (Double.MAX_VALUE - value)) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_OVERFLOW));
      return;
    }

    double result = value + increment;
    if (Double.isNaN(result) || Double.isInfinite(result)) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), RedisConstants.ERROR_NAN_INF_INCR));
      return;
    }
    value += increment;

    stringValue = """" + value;
    r.put(key, new ByteArrayWrapper(Coder.stringToBytes(stringValue)));

    command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), value));
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();
    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.INCRBYFLOAT));
      return;
    }
    
    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper valueWrapper = r.get(key);

    /*
     * Try increment
     */

    byte[] incrArray = commandElems.get(INCREMENT_INDEX);
    String doub = Coder.bytesToString(incrArray).toLowerCase();
    if (doub.contains(""inf"") || doub.contains(""nan"")) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ""Increment would produce NaN or infinity""));
      return;
    } else if (valueWrapper != null && valueWrapper.toString().contains("" "")) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_VALUE_NOT_USABLE));
      return;
    }
    
    
    Double increment;

    try {
      increment = Coder.stringToDouble(doub);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_INCREMENT_NOT_USABLE));
      return;
    }

    /*
     * Value does not exist
     */

    if (valueWrapper == null) {
      r.put(key, new ByteArrayWrapper(incrArray));
      command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), increment));
      return;
    }

    /*
     * Value exists
     */

    String stringValue = Coder.bytesToString(valueWrapper.toBytes());

    Double value;
    try {
      value = Coder.stringToDouble(stringValue);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_VALUE_NOT_USABLE));
      return;
    }

    /*
     * Check for overflow
     */
    if (value >= 0 && increment > (Double.MAX_VALUE - value)) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_OVERFLOW));
      return;
    }

    double result = value + increment;
    if (Double.isNaN(result) || Double.isInfinite(result)) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), RedisConstants.ERROR_NAN_INF_INCR));
      return;
    }
    value += increment;

    stringValue = """" + value;
    r.put(key, new ByteArrayWrapper(Coder.stringToBytes(stringValue)));

    command.setResponse(Coder.getBulkStringResponse(context.getByteBufAllocator(), value));
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.INCR));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper valueWrapper = r.get(key);

    /*
     * Value does not exist
     */

    if (valueWrapper == null) {
      byte[] newValue = {Coder.NUMBER_1_BYTE};
      r.put(key, new ByteArrayWrapper(newValue));
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), INIT_VALUE_INT));
      return;
    }

    /*
     * Value exists
     */

    String stringValue = valueWrapper.toString();

    Long value;
    try {
      value = Long.parseLong(stringValue);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_VALUE_NOT_USABLE));
      return;
    }

    if (value == Long.MAX_VALUE) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_OVERFLOW));
      return;
    }

    value++;

    stringValue = """" + value;
    r.put(key, new ByteArrayWrapper(Coder.stringToBytes(stringValue)));


    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), value));

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.INCR));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper valueWrapper = r.get(key);

    /*
     * Value does not exist
     */

    if (valueWrapper == null) {
      byte[] newValue = {Coder.NUMBER_1_BYTE};
      r.put(key, new ByteArrayWrapper(newValue));
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), INIT_VALUE_INT));
      return;
    }

    /*
     * Value exists
     */

    String stringValue = valueWrapper.toString();

    Long value;
    try {
      value = Long.parseLong(stringValue);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_VALUE_NOT_USABLE));
      return;
    }

    if (value == Long.MAX_VALUE) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_OVERFLOW));
      return;
    }

    value++;

    stringValue = """" + value;
    r.put(key, new ByteArrayWrapper(Coder.stringToBytes(stringValue)));


    command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), value));

  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.MGET));
      return;
    }

    Collection<ByteArrayWrapper> keys = new ArrayList<ByteArrayWrapper>();
    for (int i = 1; i < commandElems.size(); i++) {
      byte[] keyArray = commandElems.get(i);
      ByteArrayWrapper key = new ByteArrayWrapper(keyArray);
      /*
      try {
        checkDataType(key, RedisDataType.REDIS_STRING, context);
      } catch (RedisDataTypeMismatchException e) {
        keys.ad
        continue;
      }
      */
      keys.add(key);
    }

    Map<ByteArrayWrapper, ByteArrayWrapper> results = r.getAll(keys);

    Collection<ByteArrayWrapper> values = new ArrayList<ByteArrayWrapper>();

    /*
     * This is done to preserve order in the output
     */
    for (ByteArrayWrapper key : keys)
      values.add(results.get(key));

    command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), values));

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.MGET));
      return;
    }

    Collection<ByteArrayWrapper> keys = new ArrayList<ByteArrayWrapper>();
    for (int i = 1; i < commandElems.size(); i++) {
      byte[] keyArray = commandElems.get(i);
      ByteArrayWrapper key = new ByteArrayWrapper(keyArray);
      /*
      try {
        checkDataType(key, RedisDataType.REDIS_STRING, context);
      } catch (RedisDataTypeMismatchException e) {
        keys.ad
        continue;
      }
      */
      keys.add(key);
    }

    Map<ByteArrayWrapper, ByteArrayWrapper> results = r.getAll(keys);

    Collection<ByteArrayWrapper> values = new ArrayList<ByteArrayWrapper>();

    /*
     * This is done to preserve order in the output
     */
    for (ByteArrayWrapper key : keys)
      values.add(results.get(key));

    command.setResponse(Coder.getBulkStringArrayResponse(context.getByteBufAllocator(), values));

  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() < 3 || commandElems.size() % 2 == 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.MSET));
      return;
    }

    Map<ByteArrayWrapper, ByteArrayWrapper> map = new HashMap<ByteArrayWrapper, ByteArrayWrapper>();
    for (int i = 1; i < commandElems.size(); i += 2) {
      byte[] keyArray = commandElems.get(i);
      ByteArrayWrapper key = new ByteArrayWrapper(keyArray);
      try {
        checkAndSetDataType(key, context);
      } catch (RedisDataTypeMismatchException e) {
        continue;
      }
      byte[] value = commandElems.get(i + 1);
      map.put(key, new ByteArrayWrapper(value));
    }
    r.putAll(map);

    command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), SUCCESS));

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() < 3 || commandElems.size() % 2 == 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.MSET));
      return;
    }

    Map<ByteArrayWrapper, ByteArrayWrapper> map = new HashMap<ByteArrayWrapper, ByteArrayWrapper>();
    for (int i = 1; i < commandElems.size(); i += 2) {
      byte[] keyArray = commandElems.get(i);
      ByteArrayWrapper key = new ByteArrayWrapper(keyArray);
      try {
        checkAndSetDataType(key, context);
      } catch (RedisDataTypeMismatchException e) {
        continue;
      }
      byte[] value = commandElems.get(i + 1);
      map.put(key, new ByteArrayWrapper(value));
    }
    r.putAll(map);

    command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), SUCCESS));

  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() < 3 || commandElems.size() % 2 == 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.MSETNX));
      return;
    }

    boolean hasEntry = false;

    Map<ByteArrayWrapper, ByteArrayWrapper> map = new HashMap<ByteArrayWrapper, ByteArrayWrapper>();
    for (int i = 1; i < commandElems.size(); i += 2) {
      byte[] keyArray = commandElems.get(i);
      ByteArrayWrapper key = new ByteArrayWrapper(keyArray);
      try {
        checkDataType(key, context);
      } catch (RedisDataTypeMismatchException e) {
        hasEntry = true;
        break;
      }
      byte[] value = commandElems.get(i + 1);
      map.put(key, new ByteArrayWrapper(value));
      if (r.containsKey(key)) {
        hasEntry = true;
        break;
      }
    }
    boolean successful = false;
    if (!hasEntry) {
      successful = true;
      for (ByteArrayWrapper k : map.keySet()) {
        try {
          checkAndSetDataType(k, context);
        } catch (RedisDataTypeMismatchException e) {
          successful = false;
          break;
        }
      }
      r.putAll(map);
    }
    if (successful) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), SET));
    } else {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_SET));
    }

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() < 3 || commandElems.size() % 2 == 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.MSETNX));
      return;
    }

    boolean hasEntry = false;

    Map<ByteArrayWrapper, ByteArrayWrapper> map = new HashMap<ByteArrayWrapper, ByteArrayWrapper>();
    for (int i = 1; i < commandElems.size(); i += 2) {
      byte[] keyArray = commandElems.get(i);
      ByteArrayWrapper key = new ByteArrayWrapper(keyArray);
      try {
        checkDataType(key, context);
      } catch (RedisDataTypeMismatchException e) {
        hasEntry = true;
        break;
      }
      byte[] value = commandElems.get(i + 1);
      map.put(key, new ByteArrayWrapper(value));
      if (r.containsKey(key)) {
        hasEntry = true;
        break;
      }
    }
    boolean successful = false;
    if (!hasEntry) {
      successful = true;
      for (ByteArrayWrapper k : map.keySet()) {
        try {
          checkAndSetDataType(k, context);
        } catch (RedisDataTypeMismatchException e) {
          successful = false;
          break;
        }
      }
      r.putAll(map);
    }
    if (successful) {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), SET));
    } else {
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_SET));
    }

  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SETBIT));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper wrapper = r.get(key);

    long offset;
    int value;
    int returnBit = 0;
    try {
      byte[] offAr = commandElems.get(2);
      byte[] valAr = commandElems.get(3);
      offset = Coder.bytesToLong(offAr);
      value = Coder.bytesToInt(valAr);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_INT));
      return;
    }

    if (value != 0 && value != 1) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_VALUE));
      return;
    }

    if (offset < 0 || offset > 4294967295L) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_ILLEGAL_OFFSET));
      return;
    }

    int byteIndex = (int) (offset / 8);
    offset %= 8;

    if (wrapper == null) {
      byte[] bytes = new byte[byteIndex + 1];
      if (value == 1)
        bytes[byteIndex] = (byte) (0x80 >> offset);
      r.put(key, new ByteArrayWrapper(bytes));
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
    } else {

      byte[] bytes = wrapper.toBytes();
      if (byteIndex < bytes.length)
        returnBit = (bytes[byteIndex] & (0x80 >> offset)) >> (7 - offset);
        else 
          returnBit = 0;

      if (byteIndex < bytes.length) {
        bytes[byteIndex] = value == 1 ? (byte) (bytes[byteIndex] | (0x80 >> offset)) : (byte) (bytes[byteIndex] & ~(0x80 >> offset));
        r.put(key, new ByteArrayWrapper(bytes));
      } else {
        byte[] newBytes = new byte[byteIndex + 1];
        System.arraycopy(bytes, 0, newBytes, 0, bytes.length);
        newBytes[byteIndex] = value == 1 ? (byte) (newBytes[byteIndex] | (0x80 >> offset)) : (byte) (newBytes[byteIndex] & ~(0x80 >> offset));
        r.put(key, new ByteArrayWrapper(newBytes));
      }

      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), returnBit));
    }

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SETBIT));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper wrapper = r.get(key);

    long offset;
    int value;
    int returnBit = 0;
    try {
      byte[] offAr = commandElems.get(2);
      byte[] valAr = commandElems.get(3);
      offset = Coder.bytesToLong(offAr);
      value = Coder.bytesToInt(valAr);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_INT));
      return;
    }

    if (value != 0 && value != 1) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_VALUE));
      return;
    }

    if (offset < 0 || offset > 4294967295L) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_ILLEGAL_OFFSET));
      return;
    }

    int byteIndex = (int) (offset / 8);
    offset %= 8;

    if (wrapper == null) {
      byte[] bytes = new byte[byteIndex + 1];
      if (value == 1)
        bytes[byteIndex] = (byte) (0x80 >> offset);
      r.put(key, new ByteArrayWrapper(bytes));
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), 0));
    } else {

      byte[] bytes = wrapper.toBytes();
      if (byteIndex < bytes.length)
        returnBit = (bytes[byteIndex] & (0x80 >> offset)) >> (7 - offset);
        else 
          returnBit = 0;

      if (byteIndex < bytes.length) {
        bytes[byteIndex] = value == 1 ? (byte) (bytes[byteIndex] | (0x80 >> offset)) : (byte) (bytes[byteIndex] & ~(0x80 >> offset));
        r.put(key, new ByteArrayWrapper(bytes));
      } else {
        byte[] newBytes = new byte[byteIndex + 1];
        System.arraycopy(bytes, 0, newBytes, 0, bytes.length);
        newBytes[byteIndex] = value == 1 ? (byte) (newBytes[byteIndex] | (0x80 >> offset)) : (byte) (newBytes[byteIndex] & ~(0x80 >> offset));
        r.put(key, new ByteArrayWrapper(newBytes));
      }

      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), returnBit));
    }

  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), getArgsError()));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    byte[] value = commandElems.get(VALUE_INDEX);

    byte[] expirationArray = commandElems.get(2);
    long expiration;
    try {
      expiration = Coder.bytesToLong(expirationArray);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_SECONDS_NOT_A_NUMBER));
      return;
    }

    if (expiration <= 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_SECONDS_NOT_LEGAL));
      return;
    }

    if (!timeUnitMillis())
      expiration *= millisInSecond;

    checkAndSetDataType(key, context);
    r.put(key, new ByteArrayWrapper(value));

    context.getRegionCache().setExpiration(key, expiration);

    command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), SUCCESS));

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), getArgsError()));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    byte[] value = commandElems.get(VALUE_INDEX);

    byte[] expirationArray = commandElems.get(2);
    long expiration;
    try {
      expiration = Coder.bytesToLong(expirationArray);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_SECONDS_NOT_A_NUMBER));
      return;
    }

    if (expiration <= 0) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_SECONDS_NOT_LEGAL));
      return;
    }

    if (!timeUnitMillis())
      expiration *= millisInSecond;

    checkAndSetDataType(key, context);
    r.put(key, new ByteArrayWrapper(value));

    context.getRegionProvider().setExpiration(key, expiration);

    command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), SUCCESS));

  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SET));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, context);
    byte[] value = commandElems.get(VALUE_INDEX);
    ByteArrayWrapper valueWrapper = new ByteArrayWrapper(value);

    boolean NX = false; // Set only if not exists
    boolean XX = false; // Set only if exists
    long expiration = 0L;

    if (commandElems.size() >= 6) {
      String elem4;
      String elem5;
      String elem6;

      elem4 = Coder.bytesToString(commandElems.get(3));
      elem5 = Coder.bytesToString(commandElems.get(4));
      elem6 = Coder.bytesToString(commandElems.get(5));

      if (elem4.equalsIgnoreCase(""XX"") || elem6.equalsIgnoreCase(""XX""))
        XX = true;
      else if (elem4.equalsIgnoreCase(""NX"") || elem6.equalsIgnoreCase(""NX""))
        NX = true;

      if (elem4.equalsIgnoreCase(""PX""))
        expiration = getExpirationMillis(elem4, elem5);
      else if (elem5.equalsIgnoreCase(""PX""))
        expiration = getExpirationMillis(elem5, elem6);
      else if (elem4.equalsIgnoreCase(""EX""))
        expiration = getExpirationMillis(elem4, elem5);
      else if (elem5.equalsIgnoreCase(""EX""))
        expiration = getExpirationMillis(elem5, elem6);

    } else if (commandElems.size() >= 5) {
      String elem4;
      String expiry;

      elem4 = Coder.bytesToString(commandElems.get(3));
      expiry = Coder.bytesToString(commandElems.get(4));

      expiration = getExpirationMillis(elem4, expiry);
    } else if (commandElems.size() >= 4) {
      byte[] elem4 = commandElems.get(3);
      if (elem4.length == 2 && Character.toUpperCase(elem4[1]) == 'X') {
        if (Character.toUpperCase(elem4[0]) == 'N')
          NX = true;
        else if (Character.toUpperCase(elem4[0]) == 'X')
          XX = true;
      }
    }

    boolean keyWasSet = false;

    if (NX)
      keyWasSet = setNX(r, command, key, valueWrapper, context);
    else if (XX)
      keyWasSet = setXX(r, command, key, valueWrapper, context);
    else {
      checkAndSetDataType(key, context);
      r.put(key, valueWrapper);
      command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), SUCCESS));
      keyWasSet = true;
    }

    if (keyWasSet && expiration > 0L) {
      context.getRegionCache().setExpiration(key, expiration);
    }

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SET));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, context);
    byte[] value = commandElems.get(VALUE_INDEX);
    ByteArrayWrapper valueWrapper = new ByteArrayWrapper(value);

    boolean NX = false; // Set only if not exists
    boolean XX = false; // Set only if exists
    long expiration = 0L;

    if (commandElems.size() >= 6) {
      String elem4;
      String elem5;
      String elem6;

      elem4 = Coder.bytesToString(commandElems.get(3));
      elem5 = Coder.bytesToString(commandElems.get(4));
      elem6 = Coder.bytesToString(commandElems.get(5));

      if (elem4.equalsIgnoreCase(""XX"") || elem6.equalsIgnoreCase(""XX""))
        XX = true;
      else if (elem4.equalsIgnoreCase(""NX"") || elem6.equalsIgnoreCase(""NX""))
        NX = true;

      if (elem4.equalsIgnoreCase(""PX""))
        expiration = getExpirationMillis(elem4, elem5);
      else if (elem5.equalsIgnoreCase(""PX""))
        expiration = getExpirationMillis(elem5, elem6);
      else if (elem4.equalsIgnoreCase(""EX""))
        expiration = getExpirationMillis(elem4, elem5);
      else if (elem5.equalsIgnoreCase(""EX""))
        expiration = getExpirationMillis(elem5, elem6);

    } else if (commandElems.size() >= 5) {
      String elem4;
      String expiry;

      elem4 = Coder.bytesToString(commandElems.get(3));
      expiry = Coder.bytesToString(commandElems.get(4));

      expiration = getExpirationMillis(elem4, expiry);
    } else if (commandElems.size() >= 4) {
      byte[] elem4 = commandElems.get(3);
      if (elem4.length == 2 && Character.toUpperCase(elem4[1]) == 'X') {
        if (Character.toUpperCase(elem4[0]) == 'N')
          NX = true;
        else if (Character.toUpperCase(elem4[0]) == 'X')
          XX = true;
      }
    }

    boolean keyWasSet = false;

    if (NX)
      keyWasSet = setNX(r, command, key, valueWrapper, context);
    else if (XX)
      keyWasSet = setXX(r, command, key, valueWrapper, context);
    else {
      checkAndSetDataType(key, context);
      r.put(key, valueWrapper);
      command.setResponse(Coder.getSimpleStringResponse(context.getByteBufAllocator(), SUCCESS));
      keyWasSet = true;
    }

    if (keyWasSet && expiration > 0L) {
      context.getRegionProvider().setExpiration(key, expiration);
    }

  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SETNX));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    byte[] value = commandElems.get(VALUE_INDEX);

    Object oldValue = r.putIfAbsent(key, new ByteArrayWrapper(value));

    if (oldValue != null)
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_SET));
    else
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), SET));

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() < 3) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SETNX));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    byte[] value = commandElems.get(VALUE_INDEX);

    Object oldValue = r.putIfAbsent(key, new ByteArrayWrapper(value));

    if (oldValue != null)
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), NOT_SET));
    else
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), SET));

  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SETRANGE));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper wrapper = r.get(key);

    int offset;
    byte[] value = commandElems.get(3);
    try {
      byte[] offAr = commandElems.get(2);
      offset = Coder.bytesToInt(offAr);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_INT));
      return;
    }

    int totalLength = offset + value.length;
    if (offset < 0 || totalLength > 536870911) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_ILLEGAL_OFFSET));
      return;
    } else if (value.length == 0) {
      int length = wrapper == null ? 0 : wrapper.toBytes().length;
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), length));
      if (wrapper == null)
        context.getRegionCache().removeKey(key);
      return;
    }

    if (wrapper == null) {
      byte[] bytes = new byte[totalLength];
      System.arraycopy(value, 0, bytes, offset, value.length);
      r.put(key, new ByteArrayWrapper(bytes));
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), bytes.length));
    } else {

      byte[] bytes = wrapper.toBytes();
      int returnLength;
      if (totalLength < bytes.length) {
        System.arraycopy(value, 0, bytes, offset, value.length);
        r.put(key, new ByteArrayWrapper(bytes));
        returnLength = bytes.length;
      } else {
        byte[] newBytes = new byte[totalLength];
        System.arraycopy(bytes, 0, newBytes, 0, bytes.length);
        System.arraycopy(value, 0, newBytes, offset, value.length);
        returnLength = newBytes.length;
        r.put(key, new ByteArrayWrapper(newBytes));
      }

      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), returnLength));
    }
  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() < 4) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.SETRANGE));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkAndSetDataType(key, context);
    ByteArrayWrapper wrapper = r.get(key);

    int offset;
    byte[] value = commandElems.get(3);
    try {
      byte[] offAr = commandElems.get(2);
      offset = Coder.bytesToInt(offAr);
    } catch (NumberFormatException e) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_NOT_INT));
      return;
    }

    int totalLength = offset + value.length;
    if (offset < 0 || totalLength > 536870911) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ERROR_ILLEGAL_OFFSET));
      return;
    } else if (value.length == 0) {
      int length = wrapper == null ? 0 : wrapper.toBytes().length;
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), length));
      if (wrapper == null)
        context.getRegionProvider().removeKey(key);
      return;
    }

    if (wrapper == null) {
      byte[] bytes = new byte[totalLength];
      System.arraycopy(value, 0, bytes, offset, value.length);
      r.put(key, new ByteArrayWrapper(bytes));
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), bytes.length));
    } else {

      byte[] bytes = wrapper.toBytes();
      int returnLength;
      if (totalLength < bytes.length) {
        System.arraycopy(value, 0, bytes, offset, value.length);
        r.put(key, new ByteArrayWrapper(bytes));
        returnLength = bytes.length;
      } else {
        byte[] newBytes = new byte[totalLength];
        System.arraycopy(bytes, 0, newBytes, 0, bytes.length);
        System.arraycopy(value, 0, newBytes, offset, value.length);
        returnLength = newBytes.length;
        r.put(key, new ByteArrayWrapper(newBytes));
      }

      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), returnLength));
    }
  }",False
"  protected void checkDataType(ByteArrayWrapper key, ExecutionHandlerContext context) {
    RedisDataType currentType = context.getRegionCache().getRedisDataType(key);
    if (currentType == null)
      return;
    if (currentType == RedisDataType.REDIS_PROTECTED)
      throw new RedisDataTypeMismatchException(""The key name \"""" + key + ""\"" is protected"");
    if (currentType != RedisDataType.REDIS_STRING)
      throw new RedisDataTypeMismatchException(""The key name \"""" + key + ""\"" is already used by a "" + currentType.toString());
  }",True
"  protected void checkDataType(ByteArrayWrapper key, ExecutionHandlerContext context) {
    RedisDataType currentType = context.getRegionProvider().getRedisDataType(key);
    if (currentType == null)
      return;
    if (currentType == RedisDataType.REDIS_PROTECTED)
      throw new RedisDataTypeMismatchException(""The key name \"""" + key + ""\"" is protected"");
    if (currentType != RedisDataType.REDIS_STRING)
      throw new RedisDataTypeMismatchException(""The key name \"""" + key + ""\"" is already used by a "" + currentType.toString());
  }",False
"  protected final void checkAndSetDataType(ByteArrayWrapper key, ExecutionHandlerContext context) {
    Object oldVal = context.getRegionCache().metaPutIfAbsent(key, RedisDataType.REDIS_STRING);
    if (oldVal == RedisDataType.REDIS_PROTECTED)
      throw new RedisDataTypeMismatchException(""The key name \"""" + key + ""\"" is protected"");
    if (oldVal != null && oldVal != RedisDataType.REDIS_STRING)
      throw new RedisDataTypeMismatchException(""The key name \"""" + key + ""\"" is already used by a "" + oldVal.toString());
  }",True
"  protected final void checkAndSetDataType(ByteArrayWrapper key, ExecutionHandlerContext context) {
    Object oldVal = context.getRegionProvider().metaPutIfAbsent(key, RedisDataType.REDIS_STRING);
    if (oldVal == RedisDataType.REDIS_PROTECTED)
      throw new RedisDataTypeMismatchException(""The key name \"""" + key + ""\"" is protected"");
    if (oldVal != null && oldVal != RedisDataType.REDIS_STRING)
      throw new RedisDataTypeMismatchException(""The key name \"""" + key + ""\"" is already used by a "" + oldVal.toString());
  }",False
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionCache().getStringsRegion();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.STRLEN));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, RedisDataType.REDIS_STRING, context);
    ByteArrayWrapper valueWrapper = r.get(key);


    if (valueWrapper == null)
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), KEY_DOES_NOT_EXIST));
    else
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), valueWrapper.toBytes().length));

  }",True
"  public void executeCommand(Command command, ExecutionHandlerContext context) {
    List<byte[]> commandElems = command.getProcessedCommand();

    Region<ByteArrayWrapper, ByteArrayWrapper> r = context.getRegionProvider().getStringsRegion();

    if (commandElems.size() < 2) {
      command.setResponse(Coder.getErrorResponse(context.getByteBufAllocator(), ArityDef.STRLEN));
      return;
    }

    ByteArrayWrapper key = command.getKey();
    checkDataType(key, RedisDataType.REDIS_STRING, context);
    ByteArrayWrapper valueWrapper = r.get(key);


    if (valueWrapper == null)
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), KEY_DOES_NOT_EXIST));
    else
      command.setResponse(Coder.getIntegerResponse(context.getByteBufAllocator(), valueWrapper.toBytes().length));

  }",False
"  public GemFireRedisServer(int port) {
    this(null, port, null);
  }",True
"  public GemFireRedisServer(String bindAddress, int port, String logLevel) {
    if (port <= 0)
      this.serverPort = DEFAULT_REDIS_SERVER_PORT;
    else
      this.serverPort = port;
    this.bindAddress = bindAddress;
    this.logLevel = logLevel;
    this.numWorkerThreads = setNumWorkerThreads();
    if (this.numWorkerThreads == 0)
      this.singleThreadPerConnection = true;
    this.numSelectorThreads = 1;
    this.metaListener = new MetaCacheListener();
    this.expirationFutures = new ConcurrentHashMap<ByteArrayWrapper, ScheduledFuture<?>>();
    this.expirationExecutor = Executors.newScheduledThreadPool(numExpirationThreads, new ThreadFactory() {
      private final AtomicInteger counter = new AtomicInteger();
      @Override
      public Thread newThread(Runnable r) {
        Thread t = new Thread(r);
        t.setName(""GemFireRedis-ScheduledExecutor-"" + counter.incrementAndGet());
        t.setDaemon(true);
        return t;
      }

    });
    this.DEFAULT_REGION_TYPE = setRegionType();
    this.shutdown = false;
    this.started = false;
  }",False
"  public void shutdown() {
    if (logger.infoEnabled())
      logger.info(""GemFireRedisServer shutting down"");
    ChannelFuture closeFuture = this.serverChannel.closeFuture();
    this.serverChannel.close();
    Future<?> c = workerGroup.shutdownGracefully();
    Future<?> c2 = bossGroup.shutdownGracefully();
    c.syncUninterruptibly();
    c2.syncUninterruptibly();
    this.regionCache.close();
    if (mainThread != null)
      mainThread.interrupt();
    for (ScheduledFuture<?> f : this.expirationFutures.values())
      f.cancel(true);
    this.expirationFutures.clear();
    this.expirationExecutor.shutdownNow();
    closeFuture.syncUninterruptibly();
  }",True
"  public synchronized void shutdown() {
    if (!shutdown) {
      if (logger.infoEnabled())
        logger.info(""GemFireRedisServer shutting down"");
      ChannelFuture closeFuture = this.serverChannel.closeFuture();
      Future<?> c = workerGroup.shutdownGracefully();
      Future<?> c2 = bossGroup.shutdownGracefully();
      this.serverChannel.close();
      c.syncUninterruptibly();
      c2.syncUninterruptibly();
      this.regionCache.close();
      if (mainThread != null)
        mainThread.interrupt();
      for (ScheduledFuture<?> f : this.expirationFutures.values())
        f.cancel(true);
      this.expirationFutures.clear();
      this.expirationExecutor.shutdownNow();
      closeFuture.syncUninterruptibly();
      shutdown = true;
    }
  }",False
"  private static RegionShortcut setRegionType() {
    String regionType = System.getProperty(DEFAULT_REGION_SYS_PROP_NAME, ""PARTITION"");
    RegionShortcut type;
    try {
      type = RegionShortcut.valueOf(regionType);
    } catch (Exception e) {
      type = RegionShortcut.PARTITION;
    }
    return type;
  }",False
"  private static RegionShortcut setRegion(String regionType) {
    RegionShortcut type;
    try {
      type = RegionShortcut.valueOf(regionType);
    } catch (Exception e) {
      type = RegionShortcut.PARTITION;
    }
    return type;
  }",True
"      type = RegionShortcut.PARTITION;
    }
    return type;
  }

  /**
   * Helper method to set the number of worker threads
   * 
   * @return If the System property {@value #NUM_THREADS_SYS_PROP_NAME} is set then that number",False
"  public void start() {
    try {
      startGemFire();
      initializeRedis();
      startRedisServer();
    } catch (IOException e) {
      throw new RuntimeException(""Could not start Server"", e);
    } catch (InterruptedException e) {
      throw new RuntimeException(""Could not start Server"", e);
    }
  }",True
"  public synchronized void start() {
    if (!started) {
      try {
        startGemFire();
        initializeRedis();
        startRedisServer();
      } catch (IOException e) {
        throw new RuntimeException(""Could not start Server"", e);
      } catch (InterruptedException e) {
        throw new RuntimeException(""Could not start Server"", e);
      }
      started = true;
    }
  }",False
"  private void afterKeyDestroy(EntryEvent<String, RedisDataType> event) {
    if (event.isOriginRemote()) {
      final String key = (String) event.getKey();
      final RedisDataType value = event.getOldValue();
      if (value != null && value != RedisDataType.REDIS_STRING && value != RedisDataType.REDIS_HLL && value != RedisDataType.REDIS_PROTECTED) {
        Region<?, ?> r = this.regionCache.getRegion(Coder.stringToByteArrayWrapper(key));
        if (r != null) { 
          ByteArrayWrapper kW = Coder.stringToByteArrayWrapper(key);
          this.regionCache.removeRegionReferenceLocally(kW, value);
        }
      }
    }
  }",True
"  private void afterKeyDestroy(EntryEvent<String, RedisDataType> event) {
    if (event.isOriginRemote()) {
      final String key = (String) event.getKey();
      final RedisDataType value = event.getOldValue();
      if (value != null && value != RedisDataType.REDIS_STRING && value != RedisDataType.REDIS_HLL && value != RedisDataType.REDIS_PROTECTED) {
        ByteArrayWrapper kW = Coder.stringToByteArrayWrapper(key);
        Region<?, ?> r = this.regionCache.getRegion(kW);
        if (r != null) { 
          this.regionCache.removeRegionReferenceLocally(kW, value);
        }
      }
    }
  }",False
"  private void initializeRedis() {
    synchronized (this.cache) {
      RegionFactory<String, RedisDataType> rfMeta = cache.createRegionFactory(RegionShortcut.REPLICATE);
      rfMeta.addCacheListener(this.metaListener);
      RegionFactory<String, Integer> rfList = cache.createRegionFactory(RegionShortcut.REPLICATE);
      RegionFactory<ByteArrayWrapper, ByteArrayWrapper> rfString = cache.createRegionFactory(DEFAULT_REGION_TYPE);
      RegionFactory<ByteArrayWrapper, HyperLogLogPlus> rfHLL = cache.createRegionFactory(DEFAULT_REGION_TYPE);
      Region<ByteArrayWrapper, ByteArrayWrapper> stringsRegion;
      if ((stringsRegion = this.cache.getRegion(STRING_REGION)) == null)
        stringsRegion = rfString.create(GemFireRedisServer.STRING_REGION);
      Region<ByteArrayWrapper, HyperLogLogPlus> hLLRegion;
      if ((hLLRegion = this.cache.getRegion(HLL_REGION)) == null)
        hLLRegion = rfHLL.create(HLL_REGION);
      Region<String, RedisDataType> redisMetaData;
      if ((redisMetaData = this.cache.getRegion(REDIS_META_DATA_REGION)) == null)
        redisMetaData = rfMeta.create(REDIS_META_DATA_REGION);
      Region<String, Integer> listsMetaData;
      if ((listsMetaData = this.cache.getRegion(LISTS_META_DATA_REGION)) == null)
        listsMetaData = rfList.create(LISTS_META_DATA_REGION);
      this.regionCache = new RegionCache(stringsRegion, hLLRegion, redisMetaData, listsMetaData, expirationFutures, expirationExecutor);
      redisMetaData.put(REDIS_META_DATA_REGION, RedisDataType.REDIS_PROTECTED);
      redisMetaData.put(HLL_REGION, RedisDataType.REDIS_PROTECTED);
      redisMetaData.put(STRING_REGION, RedisDataType.REDIS_PROTECTED);
      redisMetaData.put(LISTS_META_DATA_REGION, RedisDataType.REDIS_PROTECTED);
    }
    checkForRegions();
  }",True
"  private void initializeRedis() {
    synchronized (this.cache) {
      RegionFactory<String, RedisDataType> rfMeta = cache.createRegionFactory(RegionShortcut.REPLICATE);
      rfMeta.addCacheListener(this.metaListener);
      RegionFactory<ByteArrayWrapper, ByteArrayWrapper> rfString = cache.createRegionFactory(DEFAULT_REGION_TYPE);
      RegionFactory<ByteArrayWrapper, HyperLogLogPlus> rfHLL = cache.createRegionFactory(DEFAULT_REGION_TYPE);
      Region<ByteArrayWrapper, ByteArrayWrapper> stringsRegion;
      if ((stringsRegion = this.cache.getRegion(STRING_REGION)) == null)
        stringsRegion = rfString.create(GemFireRedisServer.STRING_REGION);
      Region<ByteArrayWrapper, HyperLogLogPlus> hLLRegion;
      if ((hLLRegion = this.cache.getRegion(HLL_REGION)) == null)
        hLLRegion = rfHLL.create(HLL_REGION);
      Region<String, RedisDataType> redisMetaData;
      if ((redisMetaData = this.cache.getRegion(REDIS_META_DATA_REGION)) == null)
        redisMetaData = rfMeta.create(REDIS_META_DATA_REGION);
      this.regionCache = new RegionProvider(stringsRegion, hLLRegion, redisMetaData, expirationFutures, expirationExecutor, this.DEFAULT_REGION_TYPE);
      redisMetaData.put(REDIS_META_DATA_REGION, RedisDataType.REDIS_PROTECTED);
      redisMetaData.put(HLL_REGION, RedisDataType.REDIS_PROTECTED);
      redisMetaData.put(STRING_REGION, RedisDataType.REDIS_PROTECTED);
    }
    checkForRegions();
  }",False
"  private void startGemFire() {
    Cache c = GemFireCacheImpl.getInstance();
    if (c == null) {
      CacheFactory cacheFactory = new CacheFactory();
      if (logLevel != null)
        cacheFactory.set(""log-level"", logLevel);
      this.cache = cacheFactory.create();
    } else
      this.cache = c;
    this.logger = this.cache.getLogger();
  }",True
"  private void startGemFire() {
    Cache c = GemFireCacheImpl.getInstance();
    if (c == null) {
      synchronized (GemFireRedisServer.class) {
        c = GemFireCacheImpl.getInstance();
        if (c == null) {
          CacheFactory cacheFactory = new CacheFactory();
          if (logLevel != null)
            cacheFactory.set(""log-level"", logLevel);
          c = cacheFactory.create();
        }
      }
    }
    this.cache = c;
    this.logger = c.getLogger();
  }",False
"  public void testCachefulStart() throws InterruptedException {
    CacheFactory cf = new CacheFactory();
    cf.set(""mcast-port"", ""0"");
    cf.set(""locators"", """");
    Cache c = cf.create();
    runNServers(numServers);
    c.close();
  }",False
"  private void runNServers(int n) throws InterruptedException {
    final int[] ports = AvailablePortHelper.getRandomAvailableTCPPorts(numServers);
    final Thread[] threads = new Thread[n];
    for (int i = 0; i < n; i++) {
      final int j = i;
      Runnable r = new Runnable() {

        @Override
        public void run() {
          GemFireRedisServer s = new GemFireRedisServer(ports[j]);
          s.start();
          s.shutdown();
        }
      };
      
      Thread t = new Thread(r);
      t.setDaemon(true);
      t.start();
      threads[i] = t;
    }
    for (Thread t : threads)
      t.join();
    Cache c = GemFireCacheImpl.getInstance();
    assertFalse(c.isClosed());
  }",False
"  public void testCachelessStart() throws InterruptedException {
    runNServers(numServers);
    GemFireCacheImpl.getInstance().close();
  }",False
"  public void testHMSetHSetHLen() {
    int num = 10;
    String key = randString();
    Map<String, String> hash = new HashMap<String, String>();
    for (int i = 0; i < num; i++) {
      hash.put(randString(), randString());
    }
    String response = jedis.hmset(key, hash);
    assertTrue(response.equals(""OK""));
    assertEquals(new Long(hash.size()), jedis.hlen(key));

    key = randString();
    hash = new HashMap<String, String>();
    for (int i = 0; i < num; i++) {
      hash.put(randString(), randString());
    }
    Set<String> keys = hash.keySet();
    Long count = 1L;
    for (String field: keys) {
      Long res = jedis.hset(key, field, hash.get(field));
      assertTrue(res == 1L);
      assertEquals(count++, jedis.hlen(key));
    }
  }",False
"  public static void setUp() throws IOException {
    rand = new Random();
    CacheFactory cf = new CacheFactory();
    //cf.set(""log-file"", ""redis.log"");
    cf.set(""log-level"", ""error"");
    cf.set(""mcast-port"", ""0"");
    cf.set(""locators"", """");
    cache = cf.create();
    port = AvailablePortHelper.getRandomAvailableTCPPort();
    server = new GemFireRedisServer(""localhost"", port);

    server.start();
    jedis = new Jedis(""localhost"", port, 10000000);
  }",False
"  public void testHMGetHDelHGetAllHVals() {
    String key = randString();
    Map<String, String> hash = new HashMap<String, String>();
    for (int i = 0; i < 10; i++) {
      String m = randString();
      String f = randString();
      hash.put(m, f);
    }
    jedis.hmset(key, hash);
    Set<String> keys = hash.keySet();
    String[] keyArray = keys.toArray(new String[keys.size()]);
    List<String> retList = jedis.hmget(key, keyArray);

    for (int i = 0; i < keys.size(); i++) {
      assertEquals(retList.get(i), hash.get(keyArray[i]));
    }

    Map<String, String> retMap = jedis.hgetAll(key);

    assertEquals(retMap, hash);

    List<String> retVals = jedis.hvals(key);
    Set<String> retSet = new HashSet<String>(retVals);

    assertTrue(retSet.containsAll(hash.values()));

    jedis.hdel(key, keyArray);
    assertTrue(jedis.hlen(key) == 0);
  }",False
"  private String randString() {
    int length = rand.nextInt(8) + 5;
    StringBuilder rString = new StringBuilder();
    for (int i = 0; i < length; i++)
      rString.append((char) (rand.nextInt(57) + 65));
    return rString.toString();
    //return Long.toHexString(Double.doubleToLongBits(Math.random()));
  }",False
"  public static void tearDown() {
    jedis.close();
    cache.close();
    server.shutdown();
  }",False
"  public void testHIncrBy() {
    String key = randString();
    String field = randString();

    Long incr = (long) rand.nextInt(50);
    if (incr == 0)
      incr++;

    long response1 = jedis.hincrBy(key, field, incr);
    assertTrue(response1 == incr);

    long response2 = jedis.hincrBy(randString(), randString(), incr);
    assertTrue(response2 == incr);

    long response3 = jedis.hincrBy(key, field, incr);
    assertTrue(response3 == 2*incr);


    String field1 = randString();
    Exception ex = null;
    try {
      jedis.hincrBy(key, field1, Long.MAX_VALUE);
      jedis.hincrBy(key, field1, incr);
    } catch (Exception e) {
      ex = e;
    }

    assertNotNull(ex);
  }",False
"  public void testHkeys() {
    String key = randString();
    Map<String, String> hash = new HashMap<String, String>();
    for (int i = 0; i < 10; i++) {
      hash.put(randString(), randString());
    }
    String response = jedis.hmset(key, hash);

    Set<String> keys = hash.keySet();
    Set<String> retSet = jedis.hkeys(key);

    assertTrue(retSet.containsAll(keys));
  }",False
"  public void flushAll() {
    jedis.flushAll();
  }",False
"  public void testLRange() {
    int elements = 10;
    ArrayList<String> strings = new ArrayList<String>();
    String key = randString();
    for (int i = 0; i < elements; i++) {
      String elem = randString();
      strings.add(elem);
    }
    String[] stringArray = strings.toArray(new String[strings.size()]);
    jedis.rpush(key, stringArray);

    for (int i = 0; i < elements; i++) {
      List<String> range = jedis.lrange(key, 0, i);
      assertEquals(range, strings.subList(0, i+1));
    }

    for (int i = 0; i < elements; i++) {
      List<String> range = jedis.lrange(key, i, -1);
      assertEquals(range, strings.subList(i, strings.size()));
    }
  }",False
"  public void testLPopRPush() {
    int elements = 50;
    ArrayList<String> strings = new ArrayList<String>();
    String key = randString();
    for (int i = 0; i < elements; i++) {
      String elem = randString();
      strings.add(elem);
    }
    String[] stringArray = strings.toArray(new String[strings.size()]);
    jedis.rpush(key, stringArray);

    for (int i = 0; i < elements; i++) {
      String gemString = jedis.lpop(key);
      String s = strings.get(i);
      assertEquals(s, gemString);
    }
  }",False
"  private String randString() {
    int length = rand.nextInt(8) + 5;
    StringBuilder rString = new StringBuilder();
    for (int i = 0; i < length; i++)
      rString.append((char) (rand.nextInt(57) + 65));
    //return rString.toString();
    return Long.toHexString(Double.doubleToLongBits(Math.random()));
  }",False
"  public void testLRPushX() {
    String key = randString();
    String otherKey = ""Other key"";
    jedis.lpush(key, randString());
    assertTrue(jedis.lpushx(key, randString()) > 0);
    assertTrue(jedis.rpushx(key, randString()) > 0);

    assertTrue(jedis.lpushx(otherKey, randString()) == 0);
    assertTrue(jedis.rpushx(otherKey, randString()) == 0);

    jedis.del(key);

    assertTrue(jedis.lpushx(key, randString()) == 0);
    assertTrue(jedis.rpushx(key, randString()) == 0);
  }",False
"  public void testLTrim() {
    int elements = 5;
    ArrayList<String> strings = new ArrayList<String>();
    String key = randString();
    for (int i = 0; i < elements; i++) {
      String elem = randString();
      strings.add(elem);
    }
    String[] stringArray = strings.toArray(new String[strings.size()]);
    jedis.rpush(key, stringArray);
    // Take off last element one at a time
    for (int i = elements - 1; i >= 0; i--) {
      jedis.ltrim(key, 0, i);
      List<String> range = jedis.lrange(key, 0, -1);
      assertEquals(range, strings.subList(0, i+1));
    }
    jedis.rpop(key);
    jedis.rpush(key, stringArray);
    // Take off first element one at a time
    for (int i = 1; i < elements; i++) {
      jedis.ltrim(key, 1, -1);
      List<String> range = jedis.lrange(key, 0, -1);
      List<String> expected = strings.subList(i, strings.size());
      assertEquals(range, expected);
    }
  }",False
"  public void testLSet() {
    int elements = 10;
    ArrayList<String> strings = new ArrayList<String>();
    String key = randString();
    for (int i = 0; i < elements; i++) {
      String elem = randString();
      strings.add(elem);
    }
    String[] stringArray = strings.toArray(new String[strings.size()]);
    jedis.rpush(key, stringArray);

    for (int i = 0; i < elements; i++) {
      String s = randString();
      strings.set(i, s);
      jedis.lset(key, i, s);
      List<String> range = jedis.lrange(key, 0, -1);
      assertEquals(range, strings);
    }
  }",False
"  public void testRPopLPush() {
    int elements = 500;
    ArrayList<String> strings = new ArrayList<String>();
    String key = randString();
    for (int i = 0; i < elements; i++) {
      String elem = randString();
      strings.add(elem);
    }
    String[] stringArray = strings.toArray(new String[strings.size()]);
    jedis.lpush(key, stringArray);

    for (int i = 0; i < elements; i++) {
      String gemString = jedis.rpop(key);
      String s = strings.get(i);
      assertEquals(gemString, s);
    }

  }",False
"  public void testLRem() {
    int elements = 5;
    ArrayList<String> strings = new ArrayList<String>();
    String key = randString();
    for (int i = 0; i < elements; i++) {
      String elem = randString();
      strings.add(elem);
    }
    String[] stringArray = strings.toArray(new String[strings.size()]);
    jedis.rpush(key, stringArray);

    for (int i = 0; i < elements; i++) {
      String remove = strings.remove(0);
      jedis.lrem(key, 0, remove);
      List<String> range = jedis.lrange(key, 0, -1);
      assertEquals(strings, range);
    }
  }",False
"  public void testLindex() {
    int elements = 50;
    ArrayList<String> strings = new ArrayList<String>();
    String key = randString();
    for (int i = 0; i < elements; i++) {
      String elem = randString();
      strings.add(elem);
    }
    String[] stringArray = strings.toArray(new String[strings.size()]);
    jedis.rpush(key, stringArray);
    

    for (int i = 0; i < elements; i++) {
      String gemString = jedis.lindex(key, i);
      String s = strings.get(i);
      assertEquals(gemString, s);
    }
  }",False
"  private String randString() {
    return Long.toHexString(Double.doubleToLongBits(Math.random()));
  }",False
"  public void setUp() throws Exception {
    super.setUp();
    disconnectAllFromDS();
    host = Host.getHost(0);
    server1 = host.getVM(0);
    server2 = host.getVM(1);
    client1 = host.getVM(2);
    client2 = host.getVM(3);  
    final SerializableCallable<Object> startRedisAdapter = new SerializableCallable<Object>() {

      private static final long serialVersionUID = 1978017907725504294L;

      @Override
      public Object call() throws Exception {
        int port = AvailablePortHelper.getRandomAvailableTCPPort();
        CacheFactory cF = new CacheFactory();
        cF.set(""log-level"", ""info"");
        cF.set(""redis-bind-address"", ""localhost"");
        cF.set(""redis-port"", """"+port);
        cF.set(""mcast-port"", ""40404"");
        cF.create();
        return Integer.valueOf(port);
      }
    };
    AsyncInvocation i = server1.invokeAsync(startRedisAdapter);
    server2Port = (Integer) server2.invoke(startRedisAdapter);
    try {
      server1Port = (Integer) i.getResult();
    } catch (Throwable e) {
      throw new Exception(e);
    }
  }",False
"    protected ClientTestBase (int port) {
      this.port = port;
    }",False
"  public void testConcOps() throws Throwable {

    final int ops = 100;
    final String hKey = TEST_KEY+""hash"";
    final String lKey = TEST_KEY+""list"";
    final String zKey = TEST_KEY+""zset"";
    final String sKey = TEST_KEY+""set"";

    class ConcOps extends ClientTestBase {

      protected ConcOps(int port) {
        super(port);
      }

      @Override
      public Object call() throws Exception {
        Jedis jedis = new Jedis(""localhost"", port, 10000);
        Random r = new Random();
        for (int i = 0; i < ops; i++) {
          int n = r.nextInt(4);
          if (n == 0) {
            jedis.hset(hKey, randString(), randString());
            jedis.hgetAll(hKey);
            jedis.hvals(hKey);
          } else if (n == 1) {
            jedis.lpush(lKey, randString());
            jedis.rpush(lKey, randString());
            jedis.ltrim(lKey, 0, 100);
            jedis.lrange(lKey, 0, -1);
          } else if (n == 2) {
            jedis.zadd(zKey, r.nextDouble(), randString());
            jedis.zrangeByLex(zKey, ""(a"", ""[z"");
            jedis.zrangeByScoreWithScores(zKey, 0, 1, 0, 100);
            jedis.zremrangeByScore(zKey, r.nextDouble(), r.nextDouble());
          } else {
            jedis.sadd(sKey, randString());
            jedis.smembers(sKey);
            jedis.sdiff(sKey, ""afd"");
            jedis.sunionstore(""dst"", sKey, ""afds"");
          }
        }
        return null;
      }
    }

    // Expect to run with no exception
    AsyncInvocation i = client1.invokeAsync(new ConcOps(server1Port));
    client2.invoke(new ConcOps(server2Port));
    i.getResult();
  }",False
"  public void testConcCreateDestroy() throws Throwable {
    final int ops = 40;
    final String hKey = TEST_KEY+""hash"";
    final String lKey = TEST_KEY+""list"";
    final String zKey = TEST_KEY+""zset"";
    final String sKey = TEST_KEY+""set"";

    class ConcCreateDestroy extends ClientTestBase{
      protected ConcCreateDestroy(int port) {
        super(port);
      }

      @Override
      public Object call() throws Exception {
        Jedis jedis = new Jedis(""localhost"", port, 10000);
        Random r = new Random();
        for (int i = 0; i < ops; i++) {
          int n = r.nextInt(4);
          if (n == 0) {
            if (r.nextBoolean()) {
              jedis.hset(hKey, randString(), randString());
            } else {
              jedis.del(hKey);
            }
          } else if (n == 1) {
            if (r.nextBoolean()) {
              jedis.lpush(lKey, randString());
            } else {
              jedis.del(lKey);
            }
          } else if (n == 2) {
            if (r.nextBoolean()) {
              jedis.zadd(zKey, r.nextDouble(), randString());
            } else {
              jedis.del(zKey);
            }
          } else {
            if (r.nextBoolean()) {
              jedis.sadd(sKey, randString());
            } else {
              jedis.del(sKey);
            }
          }
        }
        return null;
      }
    }

    // Expect to run with no exception
    AsyncInvocation i = client1.invokeAsync(new ConcCreateDestroy(server1Port));
    client2.invoke(new ConcCreateDestroy(server2Port));
    i.getResult();
  }",False
"  public RedisDistDUnitTest() throws Throwable {
    super(""RedisDistTest"");  
  }",False
"  public void tearDown2() throws Exception {
    super.tearDown2();
    disconnectAllFromDS();
  }",False
"  public void testConcListOps() throws Throwable {
    final Jedis jedis1 = new Jedis(""localhost"", server1Port, 10000);
    final Jedis jedis2 = new Jedis(""localhost"", server2Port, 10000);
    final int pushes = 20;
    class ConcListOps extends ClientTestBase {
      protected ConcListOps(int port) {
        super(port);
      }

      @Override
      public Object call() throws Exception {
        Jedis jedis = new Jedis(""localhost"", port, 10000);
        Random r = new Random();
        for (int i = 0; i < pushes; i++) {
          if (r.nextBoolean()) {
            jedis.lpush(TEST_KEY, randString());
          } else {
            jedis.rpush(TEST_KEY, randString());
          }
        }
        return null;
      }
    };

    AsyncInvocation i = client1.invokeAsync(new ConcListOps(server1Port));
    client2.invoke(new ConcListOps(server2Port));
    i.getResult();
    long expected = 2 * pushes;
    long result1 = jedis1.llen(TEST_KEY);
    long result2 = jedis2.llen(TEST_KEY);
    assertEquals(expected, result1);
    assertEquals(result1, result2);
  }",False
"  public void testSMove() {
    String source = randString();
    String dest = randString();
    String test = randString();
    int elements = 10;
    Set<String> strings = new HashSet<String>();
    for (int i = 0; i < elements; i++) {
      String elem = randString();
      strings.add(elem);
    }
    String[] stringArray = strings.toArray(new String[strings.size()]);
    jedis.sadd(source, stringArray);

    long i = 1;
    for (String entry: strings) {
      assertTrue(jedis.smove(source, dest, entry) == 1);
      assertTrue(jedis.sismember(dest, entry));
      assertTrue(jedis.scard(source) == strings.size() - i);
      assertTrue(jedis.scard(dest) == i);
      i++;
    }

    assertTrue(jedis.smove(test, dest, randString()) == 0);
  }",False
"  public void testSAddScard() {
    int elements = 10;
    Set<String> strings = new HashSet<String>();
    String key = randString();
    for (int i = 0; i < elements; i++) {
      String elem = randString();
      strings.add(elem);
    }
    String[] stringArray = strings.toArray(new String[strings.size()]);
    Long response = jedis.sadd(key, stringArray);
    assertEquals(response, new Long(strings.size()));

    assertEquals(jedis.scard(key), new Long(strings.size()));
  }",False
"  public void testSUnionAndStore() {
    int numSets = 3;
    int elements = 10;
    String[] keys = new String[numSets];
    ArrayList<Set<String>> sets = new ArrayList<Set<String>>();
    for (int j = 0; j < numSets; j++) {
      keys[j] = randString();
      Set<String> newSet = new HashSet<String>();
      for (int i = 0; i < elements; i++)
        newSet.add(randString());
      sets.add(newSet);
    }
    
    for (int i = 0; i < numSets; i++) {
      Set<String> s = sets.get(i);
      String[] stringArray = s.toArray(new String[s.size()]);
      jedis.sadd(keys[i], stringArray);
    }
    
    Set<String> result = sets.get(0);
    for (int i = 1; i < numSets; i++)
      result.addAll(sets.get(i));
    
    assertEquals(result, jedis.sunion(keys));
    
    String destination = randString();
    
    jedis.sunionstore(destination, keys);
    
    Set<String> destResult = jedis.smembers(destination);
    
    assertEquals(result, destResult);
    
  }",False
"  public void testSInterAndStore() {
    int numSets = 3;
    int elements = 10;
    String[] keys = new String[numSets];
    ArrayList<Set<String>> sets = new ArrayList<Set<String>>();
    for (int j = 0; j < numSets; j++) {
      keys[j] = randString();
      Set<String> newSet = new HashSet<String>();
      for (int i = 0; i < elements; i++)
        newSet.add(randString());
      sets.add(newSet);
    }
    
    for (int i = 0; i < numSets; i++) {
      Set<String> s = sets.get(i);
      String[] stringArray = s.toArray(new String[s.size()]);
      jedis.sadd(keys[i], stringArray);
    }
    
    Set<String> result = sets.get(0);
    for (int i = 1; i < numSets; i++)
      result.retainAll(sets.get(i));
    
    assertEquals(result, jedis.sinter(keys));
    
    String destination = randString();
    
    jedis.sinterstore(destination, keys);
    
    Set<String> destResult = jedis.smembers(destination);
    
    assertEquals(result, destResult);
    
  }",False
"  public void testSDiffAndStore() {
    int numSets = 3;
    int elements = 10;
    String[] keys = new String[numSets];
    ArrayList<Set<String>> sets = new ArrayList<Set<String>>();
    for (int j = 0; j < numSets; j++) {
      keys[j] = randString();
      Set<String> newSet = new HashSet<String>();
      for (int i = 0; i < elements; i++)
        newSet.add(randString());
      sets.add(newSet);
    }
    
    for (int i = 0; i < numSets; i++) {
      Set<String> s = sets.get(i);
      String[] stringArray = s.toArray(new String[s.size()]);
      jedis.sadd(keys[i], stringArray);
    }
    
    Set<String> result = sets.get(0);
    for (int i = 1; i < numSets; i++)
      result.removeAll(sets.get(i));
    
    assertEquals(result, jedis.sdiff(keys));
    
    String destination = randString();
    
    jedis.sdiffstore(destination, keys);
    
    Set<String> destResult = jedis.smembers(destination);
    
    assertEquals(result, destResult);
    
  }",False
"  public void testSMembersIsMember() {
    int elements = 10;
    Set<String> strings = new HashSet<String>();
    String key = randString();
    for (int i = 0; i < elements; i++) {
      String elem = randString();
      strings.add(elem);
    }
    String[] stringArray = strings.toArray(new String[strings.size()]);
    jedis.sadd(key, stringArray);

    Set<String> returnedSet = jedis.smembers(key);

    assertEquals(returnedSet, new HashSet<String>(strings));

    for (String entry: strings) {
      boolean exists = jedis.sismember(key, entry);
      assertTrue(exists);
    }
  }",False
"    public int compare(Entry<String, Double> o1, Entry<String, Double> o2) {
      Double diff = o2.getValue() - o1.getValue();
      if (diff == 0) 
        return o1.getKey().compareTo(o2.getKey());
      else
        return diff > 0 ? 1 : -1;
    }",False
"  public void testZCount() {
    int num = 10;
    int runs = 2;
    for (int i = 0; i < runs; i++) {
      Double min;
      Double max;
      do {
        min = rand.nextDouble();
        max = rand.nextDouble();
      } while (min > max);


      int count = 0;

      String key = randString();
      Map<String, Double> scoreMembers = new HashMap<String, Double>();

      for (int j = 0; j < num; j++) {
        Double nextDouble = rand.nextDouble();
        if (nextDouble >= min && nextDouble <= max)
          count++;
        scoreMembers.put(randString(), nextDouble);
      }

      jedis.zadd(key, scoreMembers);
      Long countResult = jedis.zcount(key, min, max);
      assertTrue(count == countResult);
    }

  }",False
"  public void testZIncrBy() {
    String key = randString();
    String member = randString();
    Double score = 0.0;
    for (int i = 0; i < 20; i++) {
      Double incr = rand.nextDouble();
      Double result = jedis.zincrby(key, incr, member);
      score += incr;
      assertEquals(score, result, 1.0/100000000.0);
    }


    jedis.zincrby(key, Double.MAX_VALUE, member);
    Double infResult = jedis.zincrby(key, Double.MAX_VALUE, member);


    assertEquals(infResult, Double.valueOf(Double.POSITIVE_INFINITY));
  }",False
"  public void testZRangeByScore() {
    Double min;
    Double max;
    for (int j = 0; j < 2; j++) {
      do {
        min = rand.nextDouble();
        max = rand.nextDouble();
      } while (min > max);
      int numMembers = 500;
      String key = randString();
      Map<String, Double> scoreMembers = new HashMap<String, Double>();
      List<Entry<String, Double>> expected = new ArrayList<Entry<String, Double>>();
      for (int i = 0; i < numMembers; i++) {
        String s = randString();
        Double d = rand.nextDouble();
        scoreMembers.put(s, d);
        if (d > min && d < max)
          expected.add(new AbstractMap.SimpleEntry<String, Double>(s, d));
      }
      jedis.zadd(key, scoreMembers);
      Set<Tuple> results = jedis.zrangeByScoreWithScores(key, min, max);
      List<Entry<String, Double>> resultList = new ArrayList<Entry<String, Double>>();
      for (Tuple t: results)
        resultList.add(new AbstractMap.SimpleEntry<String, Double>(t.getElement(), t.getScore()));
      Collections.sort(expected, new EntryCmp());

      assertEquals(expected, resultList);
      jedis.del(key);
    }
  }",False
"    public int compare(Entry<String, Double> o1, Entry<String, Double> o2) {
      Double diff = o1.getValue() - o2.getValue();
      if (diff == 0) 
        return o2.getKey().compareTo(o1.getKey());
      else
        return diff > 0 ? 1 : -1;
    }",False
"  public void testZRevRange() {
    int numMembers = 10;
    String key = randString();

    Map<String, Double> scoreMembers = new HashMap<String, Double>();

    for (int i = 0; i < numMembers; i++)
      scoreMembers.put(randString(), rand.nextDouble());

    jedis.zadd(key, scoreMembers);

    Set<Tuple> results;

    for (int i = 0; i < 10; i++) {
      int start;
      int stop;
      do {
        start = rand.nextInt(numMembers);
        stop = rand.nextInt(numMembers);
      } while (start > stop);
      results = jedis.zrevrangeWithScores(key, start, stop);
      List<Entry<String, Double>> resultList = new ArrayList<Entry<String, Double>>();
      for (Tuple t: results)
        resultList.add(new AbstractMap.SimpleEntry<String, Double>(t.getElement(), t.getScore()));
      List<Entry<String, Double>> list = new ArrayList<Entry<String, Double>>(scoreMembers.entrySet());
      Collections.sort(list, new EntryRevCmp());
      list = list.subList(start, stop + 1);
      assertEquals(list, resultList);
    }
  }",False
"  public void testZRevRank() {
    for (int j = 0; j < 2; j++) {
      int numMembers = 10;
      String key = randString();
      Map<String, Double> scoreMembers = new HashMap<String, Double>();
      List<Entry<String, Double>> expected = new ArrayList<Entry<String, Double>>();
      for (int i = 0; i < numMembers; i++) {
        String s = randString();
        Double d = rand.nextDouble();
        scoreMembers.put(s, d);
        expected.add(new AbstractMap.SimpleEntry<String, Double>(s, d));
      }
      Collections.sort(expected, new EntryRevCmp());
      jedis.zadd(key, scoreMembers);
      for (int i = 0; i < expected.size(); i++) {
        Entry<String, Double> en = expected.get(i);
        String field = en.getKey();
        Long rank = jedis.zrevrank(key, field);
        assertEquals(new Long(i), rank);
      }
      String field = randString();
      if (!expected.contains(field))
        assertNull(jedis.zrank(key, field));
      jedis.del(key);
    }
  }",False
"  public void testZAddZRange() {
    int numMembers = 10;
    String key = randString();
    Map<String, Double> scoreMembers = new HashMap<String, Double>();

    for (int i = 0; i < numMembers; i++)
      scoreMembers.put(randString(), rand.nextDouble());

    jedis.zadd(key, scoreMembers);
    int k = 0;
    for (String entry: scoreMembers.keySet())
      assertNotNull(jedis.zscore(key, entry));

    Set<Tuple> results = jedis.zrangeWithScores(key, 0, -1);
    Map<String, Double> resultMap = new HashMap<String, Double>();
    for (Tuple t: results) {
      resultMap.put(t.getElement(), t.getScore());
    }

    assertEquals(scoreMembers, resultMap);

    for (int i = 0; i < 10; i++) {
      int start;
      int stop;
      do {
        start = rand.nextInt(numMembers);
        stop = rand.nextInt(numMembers);
      } while (start > stop);
      results = jedis.zrangeWithScores(key, start, stop);
      List<Entry<String, Double>> resultList = new ArrayList<Entry<String, Double>>();
      for (Tuple t: results)
        resultList.add(new AbstractMap.SimpleEntry<String, Double>(t.getElement(), t.getScore()));
      List<Entry<String, Double>> list = new ArrayList<Entry<String, Double>>(scoreMembers.entrySet());
      Collections.sort(list, new EntryCmp());
      list = list.subList(start, stop + 1);
      assertEquals(list, resultList);
    }
  }",False
"  public void testZRank() {
    for (int j = 0; j < 2; j++) {
      int numMembers = 10;
      String key = randString();
      Map<String, Double> scoreMembers = new HashMap<String, Double>();
      List<Entry<String, Double>> expected = new ArrayList<Entry<String, Double>>();
      for (int i = 0; i < numMembers; i++) {
        String s = randString();
        Double d = rand.nextDouble();
        scoreMembers.put(s, d);
        expected.add(new AbstractMap.SimpleEntry<String, Double>(s, d));
      }
      Collections.sort(expected, new EntryCmp());
      jedis.zadd(key, scoreMembers);
      for (int i = 0; i < expected.size(); i++) {
        Entry<String, Double> en = expected.get(i);
        String field = en.getKey();
        Long rank = jedis.zrank(key, field);
        assertEquals(new Long(i), rank);
      }
      String field = randString();
      if (!expected.contains(field))
        assertNull(jedis.zrank(key, field));
      jedis.del(key);
    }
  }",False
"  public void testZRemRangeByScore() {
    Double min;
    Double max;
    for (int j = 0; j < 3; j++) {
      do {
        min = rand.nextDouble();
        max = rand.nextDouble();
      } while (min > max);
      int numMembers = 10;
      String key = randString();
      Map<String, Double> scoreMembers = new HashMap<String, Double>();
      List<Entry<String, Double>> fullList = new ArrayList<Entry<String, Double>>();
      List<Entry<String, Double>> toRemoveList = new ArrayList<Entry<String, Double>>();
      for (int i = 0; i < numMembers; i++) {
        String s = randString();
        Double d = rand.nextDouble();
        scoreMembers.put(s, d);
        fullList.add(new AbstractMap.SimpleEntry<String, Double>(s, d));
        if (d > min && d < max)
          toRemoveList.add(new AbstractMap.SimpleEntry<String, Double>(s, d));
      }
      jedis.zadd(key, scoreMembers);
      Long numRemoved = jedis.zremrangeByScore(key, min, max);
      List<Entry<String, Double>> expectedList = new ArrayList<Entry<String, Double>>(fullList);
      expectedList.removeAll(toRemoveList);
      Collections.sort(expectedList, new EntryCmp());
      Set<Tuple> result = jedis.zrangeWithScores(key, 0, -1);
      List<Entry<String, Double>> resultList = new ArrayList<Entry<String, Double>>();
      for (Tuple t: result)
        resultList.add(new AbstractMap.SimpleEntry<String, Double>(t.getElement(), t.getScore()));
      assertEquals(expectedList, resultList);
      jedis.del(key);
    }
  }",False
"  public void testZRemZScore() {
    Double min;
    Double max;
    for (int j = 0; j < 2; j++) {
      do {
        min = rand.nextDouble();
        max = rand.nextDouble();
      } while (min > max);
      int numMembers = 5000;
      String key = randString();
      Map<String, Double> scoreMembers = new HashMap<String, Double>();
      List<Entry<String, Double>> expected = new ArrayList<Entry<String, Double>>();
      for (int i = 0; i < numMembers; i++) {
        String s = randString();
        Double d = rand.nextDouble();
        scoreMembers.put(s, d);
        if (d > min && d < max)
          expected.add(new AbstractMap.SimpleEntry<String, Double>(s, d));
      }
      jedis.zadd(key, scoreMembers);
      Collections.sort(expected, new EntryCmp());
      for (int i = expected.size(); i <= 0; i--) {
        Entry<String, Double> remEntry = expected.remove(i);
        String rem = remEntry.getKey();
        Double val = remEntry.getValue();
        assertEquals(val, jedis.zscore(key, rem));

        assertTrue(jedis.zrem(key, rem) == 1);
      }
      String s = randString();
      if (!expected.contains(s))
        assertTrue(jedis.zrem(key, s) == 0);
      jedis.del(key);
    }
  }",False
"  public void testZRevRangeByScore() {
    Double min;
    Double max;
    for (int j = 0; j < 2; j++) {
      do {
        min = rand.nextDouble();
        max = rand.nextDouble();
      } while (min > max);
      int numMembers = 500;
      String key = randString();
      Map<String, Double> scoreMembers = new HashMap<String, Double>();
      List<Entry<String, Double>> expected = new ArrayList<Entry<String, Double>>();
      for (int i = 0; i < numMembers; i++) {
        String s = randString();
        Double d = rand.nextDouble();
        scoreMembers.put(s, d);
        if (d > min && d < max)
          expected.add(new AbstractMap.SimpleEntry<String, Double>(s, d));
      }
      jedis.zadd(key, scoreMembers);
      Set<Tuple> results = jedis.zrevrangeByScoreWithScores(key, max, min);
      List<Entry<String, Double>> resultList = new ArrayList<Entry<String, Double>>();
      for (Tuple t: results)
        resultList.add(new AbstractMap.SimpleEntry<String, Double>(t.getElement(), t.getScore()));
      Collections.sort(expected, new EntryRevCmp());

      assertEquals(expected, resultList);
      jedis.del(key);
    }
  }",False
"  public void testMSetAndGet() {
    int r = 5;
    String[] keyvals = new String[(r*2)];
    String[] keys = new String[r];
    String[] vals = new String[r];
    for(int i = 0; i < r; i++) {
      String key = randString();
      String val = randString();
      keyvals[2*i] = key;
      keyvals[2*i+1] = val;
      keys[i] = key;
      vals[i] = val;
    }

    jedis.mset(keyvals);

    List<String> ret = jedis.mget(keys);
    Object[] retArray =  ret.toArray();

    assertTrue(Arrays.equals(vals, retArray));
  }",False
"  public void testIncr() {
    String key1 = randString();
    String key2 = randString();
    String key3 = randString();
    int num1 = 100;
    int num2 = -100;
    jedis.set(key1, """"+num1);
    //jedis.set(key3, ""-100"");
    jedis.set(key2, """"+num2);

    jedis.incr(key1);
    jedis.incr(key3);
    jedis.incr(key2);

    assertTrue(jedis.get(key1).equals("""" + (num1 + 1)));
    assertTrue(jedis.get(key2).equals("""" + (num2 + 1)));
    assertTrue(jedis.get(key3).equals("""" + (+1)));
  }",False
"  public void testPAndSetex() {
    Random r = new Random();
    int setex = r.nextInt(5);
    if (setex == 0)
      setex = 1;
    String key = randString();
    jedis.setex(key, setex, randString());
    try {
      Thread.sleep((setex  + 5) * 1000);
    } catch (InterruptedException e) {
      return;
    }
    String result = jedis.get(key);
    //System.out.println(result);
    assertNull(result);

    int psetex = r.nextInt(5000);
    if (psetex == 0)
      psetex = 1;
    key = randString();
    jedis.psetex(key, psetex, randString());
    long start = System.currentTimeMillis();
    try {
      Thread.sleep(psetex + 5000);
    } catch (InterruptedException e) {
      return;
    }
    long stop = System.currentTimeMillis();
    result = jedis.get(key);
    assertTrue(stop - start >= psetex);
    assertNull(result);
  }",False
"  public void testGetSet() {
    String key = randString();
    String contents = randString();
    jedis.set(key, contents);
    String newContents = randString();
    String oldContents = jedis.getSet(key, newContents);
    assertTrue(oldContents.equals(contents));
    contents = newContents;
  }",False
"  public void testDecrBy() {
    String key1 = randString();
    String key2 = randString();
    String key3 = randString();
    int decr1 = rand.nextInt(100);
    int decr2 = rand.nextInt(100);
    Long decr3 = Long.MAX_VALUE/2;
    int num1 = 100;
    int num2 = -100;
    jedis.set(key1, """"+num1);
    jedis.set(key2, """"+num2);
    jedis.set(key3, """"+Long.MIN_VALUE);

    jedis.decrBy(key1, decr1);
    jedis.decrBy(key2, decr2);

    assertTrue(jedis.get(key1).equals("""" + (num1 - decr1*1)));
    assertTrue(jedis.get(key2).equals("""" + (num2 - decr2*1)));

    Exception ex= null;
    try {
      jedis.decrBy(key3, decr3);
    } catch(Exception e) {
      ex = e;
    }
    assertNotNull(ex);

  }  ",False
"  public void testIncrBy() {
    String key1 = randString();
    String key2 = randString();
    String key3 = randString();
    int incr1 = rand.nextInt(100);
    int incr2 = rand.nextInt(100);
    Long incr3 = Long.MAX_VALUE/2;
    int num1 = 100;
    int num2 = -100;
    jedis.set(key1, """"+num1);
    jedis.set(key2, """"+num2);
    jedis.set(key3, """"+Long.MAX_VALUE);

    jedis.incrBy(key1, incr1);
    jedis.incrBy(key2, incr2);
    assertTrue(jedis.get(key1).equals("""" + (num1 + incr1*1)));
    assertTrue(jedis.get(key2).equals("""" + (num2 + incr2*1)));

    Exception ex= null;
    try {
      jedis.incrBy(key3, incr3);
    } catch(Exception e) {
      ex = e;
    }
    assertNotNull(ex);
  }",False
"  public void testGetRange() {
    String sent = randString();
    String contents = randString();
    jedis.set(sent, contents);
    for (int i = 0; i < sent.length(); i++) {
      String range = jedis.getrange(sent, i, -1);
      assertTrue(contents.substring(i).equals(range));
    }
    assertNull(jedis.getrange(sent, 2,0));
  }",False
"  public void testDecr() {
    String key1 = randString();
    String key2 = randString();
    String key3 = randString();
    int num1 = 100;
    int num2 = -100;
    jedis.set(key1, """"+num1);
    //jedis.set(key3, ""-100"");
    jedis.set(key2, """"+num2);

    jedis.decr(key1);
    jedis.decr(key3);
    jedis.decr(key2);
    assertTrue(jedis.get(key1).equals("""" + (num1 - 1)));
    assertTrue(jedis.get(key2).equals("""" + (num2 - 1)));
    assertTrue(jedis.get(key3).equals("""" + (-1)));
  }",False
"  public void testAppendAndStrlen() {
    String key = randString();
    int len = key.length();
    String full = key;
    jedis.set(key, key);
    for (int i = 0; i < 15; i++) {
      String rand = randString();
      jedis.append(key, rand);
      len += rand.length();
      full += rand;
    }
    String ret = jedis.get(key);
    assertTrue(ret.length() == len);
    assertTrue(full.equals(ret));
    assertTrue(full.length() == jedis.strlen(key));
  }",False
"  public void testSetNX() {
    String key1 = randString();
    String key2;
    do {
      key2 = randString();
    } while (key2.equals(key1));

    long response1 = jedis.setnx(key1, key1);
    long response2 = jedis.setnx(key2, key2);
    long response3 = jedis.setnx(key1, key2);

    assertTrue(response1 == 1);
    assertTrue(response2 == 1);
    assertTrue(response3 == 0);
  }",False
"  public void testMSetNX() {
    Set<String> strings = new HashSet<String>();
    for(int i = 0; i < 2 * 5; i++)
      strings.add(randString());
    String[] array = strings.toArray(new String[0]);
    long response = jedis.msetnx(array);

    assertTrue(response == 1);

    long response2 = jedis.msetnx(array[0], randString());

    assertTrue(response2 == 0);
    assertEquals(array[1], jedis.get(array[0]));
  }",False
"  public final int entryCount() {
    return entryCount(null);
  }",True
"  public final int entryCount() {
    return getDataView().entryCount(this);
  }",False
"  public void testSize() {
  }",True
"  public void testSizeForTXHostedOnRemoteNode() {
  }",False
"  public void testSizeOnAccessor() {
  }",False
"  public void testSizeOnAccessor() {
    doSizeTest(true);
  }",False
"  public void testSizeForTXHostedOnRemoteNode() {
    doSizeTest(false);
  }",False
"  public void testSize() {
    Host host = Host.getHost(0);
    VM accessor = host.getVM(0);
    VM datastore1 = host.getVM(1);
    VM datastore2 = host.getVM(2);
    initAccessorAndDataStore(accessor, datastore1, datastore2, 0);

    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region custRegion = getCache().getRegion(CUSTOMER);
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        mgr.begin();
        assertEquals(5, custRegion.size());
        assertNotNull(mgr.getTXState());
        return null;
      }
    });
    datastore1.invoke(verifyNoTxState);
    datastore2.invoke(verifyNoTxState);
    
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region custRegion = getCache().getRegion(CUSTOMER);
        Region orderRegion = getCache().getRegion(ORDER);
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        assertNotNull(mgr.getTXState());
        CustId custId = new CustId(5);
        OrderId orderId = new OrderId(5, custId);
        custRegion.put(custId, new Customer(""customer5"", ""address5""));
        orderRegion.put(orderId, new Order(""order5""));
        assertEquals(6, custRegion.size());
        return mgr.getTransactionId();
      }
    });
    final Integer txOnDatastore1 = (Integer)datastore1.invoke(getNumberOfTXInProgress);
    final Integer txOnDatastore2 = (Integer)datastore2.invoke(getNumberOfTXInProgress);
    assertEquals(1, txOnDatastore1+txOnDatastore2);

    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        CacheTransactionManager mgr = getGemfireCache().getTxManager();
        mgr.commit();
        return null;
      }
    });
    
    datastore1.invoke(verifyNoTxState);
    datastore2.invoke(verifyNoTxState);
    
    
    final Integer txOnDatastore1_1 = (Integer)datastore1.invoke(getNumberOfTXInProgress);
    final Integer txOnDatastore2_2 = (Integer)datastore2.invoke(getNumberOfTXInProgress);
    assertEquals(0, txOnDatastore1_1.intValue());
    assertEquals(0, txOnDatastore2_2.intValue());
  }",True
"  public void testSizeForTXHostedOnRemoteNode() {
    doSizeTest(false);
  }

  public void testSizeOnAccessor() {
    doSizeTest(true);
  }

  private void doSizeTest(final boolean isAccessor) {
    Host host = Host.getHost(0);
    VM accessor = host.getVM(0);
    VM datastore1 = host.getVM(1);
    VM datastore2 = host.getVM(2);
    initAccessorAndDataStore(accessor, datastore1, datastore2, 0);

    VM taskVM = isAccessor ? accessor : datastore1;

    taskVM.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region custRegion = getCache().getRegion(CUSTOMER);
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        mgr.begin();
        assertEquals(5, custRegion.size());
        assertNotNull(mgr.getTXState());
        return null;
      }
    });
    datastore1.invoke(verifyNoTxState);
    datastore2.invoke(verifyNoTxState);
    
    taskVM.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region custRegion = getCache().getRegion(CUSTOMER);
        Region orderRegion = getCache().getRegion(ORDER);
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        TransactionId txId = mgr.suspend();
        PartitionedRegion custPR = (PartitionedRegion)custRegion;
        int remoteKey = -1;
        for (int i=100; i<200; i++) {
          DistributedMember myId = custPR.getMyId();
          if (!myId.equals(custPR.getOwnerForKey(custPR.getKeyInfo(new CustId(i))))) {
            remoteKey = i;
            break;
          }
        }
        if (remoteKey == -1) {
          throw new IllegalStateException(""expected non-negative key"");
        }
        mgr.resume(txId);
        assertNotNull(mgr.getTXState());
        CustId custId = new CustId(remoteKey);
        OrderId orderId = new OrderId(remoteKey, custId);
        custRegion.put(custId, new Customer(""customer""+remoteKey, ""address""+remoteKey));
        getCache().getLogger().info(""Putting ""+custId+"", keyInfo:""+custPR.getKeyInfo(new CustId(remoteKey)));
        orderRegion.put(orderId, new Order(""order""+remoteKey));",False
"  private void doSizeTest(final boolean isAccessor) {
    Host host = Host.getHost(0);
    VM accessor = host.getVM(0);
    VM datastore1 = host.getVM(1);
    VM datastore2 = host.getVM(2);
    initAccessorAndDataStore(accessor, datastore1, datastore2, 0);

    VM taskVM = isAccessor ? accessor : datastore1;

    taskVM.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region custRegion = getCache().getRegion(CUSTOMER);
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        mgr.begin();
        assertEquals(5, custRegion.size());
        assertNotNull(mgr.getTXState());
        return null;
      }
    });
    datastore1.invoke(verifyNoTxState);
    datastore2.invoke(verifyNoTxState);
    
    taskVM.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region custRegion = getCache().getRegion(CUSTOMER);
        Region orderRegion = getCache().getRegion(ORDER);
        TXManagerImpl mgr = getGemfireCache().getTxManager();
        TransactionId txId = mgr.suspend();
        PartitionedRegion custPR = (PartitionedRegion)custRegion;
        int remoteKey = -1;
        for (int i=100; i<200; i++) {
          DistributedMember myId = custPR.getMyId();
          if (!myId.equals(custPR.getOwnerForKey(custPR.getKeyInfo(new CustId(i))))) {
            remoteKey = i;
            break;
          }
        }
        if (remoteKey == -1) {
          throw new IllegalStateException(""expected non-negative key"");
        }
        mgr.resume(txId);
        assertNotNull(mgr.getTXState());
        CustId custId = new CustId(remoteKey);
        OrderId orderId = new OrderId(remoteKey, custId);
        custRegion.put(custId, new Customer(""customer""+remoteKey, ""address""+remoteKey));
        getCache().getLogger().info(""Putting ""+custId+"", keyInfo:""+custPR.getKeyInfo(new CustId(remoteKey)));
        orderRegion.put(orderId, new Order(""order""+remoteKey));
        assertEquals(6, custRegion.size());
        return mgr.getTransactionId();
      }
    });
    final Integer txOnDatastore1 = (Integer)datastore1.invoke(getNumberOfTXInProgress);
    final Integer txOnDatastore2 = (Integer)datastore2.invoke(getNumberOfTXInProgress);
    assertEquals(1, txOnDatastore1+txOnDatastore2);

    taskVM.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        CacheTransactionManager mgr = getGemfireCache().getTxManager();
        mgr.commit();
        return null;
      }
    });
    
    datastore1.invoke(verifyNoTxState);
    datastore2.invoke(verifyNoTxState);
    
    
    final Integer txOnDatastore1_1 = (Integer)datastore1.invoke(getNumberOfTXInProgress);
    final Integer txOnDatastore2_2 = (Integer)datastore2.invoke(getNumberOfTXInProgress);
    assertEquals(0, txOnDatastore1_1.intValue());
    assertEquals(0, txOnDatastore2_2.intValue());
  }",False
"  private boolean samePdxSerializer(PdxSerializer s1, PdxSerializer s2) {
    Object o1 = s1;
    Object o2 = s2;
    if (s1 instanceof ReflectionBasedAutoSerializer && s2 instanceof ReflectionBasedAutoSerializer) {
      // Fix for bug 44907.
      o1 = AutoSerializableManager.getInstance((ReflectionBasedAutoSerializer) s1);
      o2 = AutoSerializableManager.getInstance((ReflectionBasedAutoSerializer) s2);
    }
    return equals(o1, o2);
  }",True
"  private boolean samePdxSerializer(PdxSerializer s1, PdxSerializer s2) {
    Object o1 = s1;
    Object o2 = s2;
    if (s1 instanceof ReflectionBasedAutoSerializer && s2 instanceof ReflectionBasedAutoSerializer) {
      // Fix for bug 44907.
      o1 = ((ReflectionBasedAutoSerializer) s1).getManager();
      o2 = ((ReflectionBasedAutoSerializer) s2).getManager();
    }
    return equals(o1, o2);
  }",False
"  private void basicSetPdxSerializer(PdxSerializer v) {
    TypeRegistry.setPdxSerializer(v);
    if (v instanceof ReflectionBasedAutoSerializer) {
      AutoSerializableManager asm = AutoSerializableManager.getInstance((ReflectionBasedAutoSerializer) v);
      if (asm != null) {
        asm.setRegionService(this);
      }
    }
  }",True
"  private void basicSetPdxSerializer(PdxSerializer v) {
    TypeRegistry.setPdxSerializer(v);
    if (v instanceof ReflectionBasedAutoSerializer) {
      AutoSerializableManager asm = (AutoSerializableManager) ((ReflectionBasedAutoSerializer) v).getManager();
      if (asm != null) {
        asm.setRegionService(this);
      }
    }
  }",False
"  public final Object getManager() {
    // The result is not AutoSerializableManager because
    // that class is not part of our public APIs.
    return this.manager;
  }",False
"  public static AutoSerializableManager getInstance(ReflectionBasedAutoSerializer owner) {
    return instances.get(owner);
  }",True
"
  private boolean checkPortability;
  public void setCheckPortability(boolean b) {",False
"  public static AutoSerializableManager create(ReflectionBasedAutoSerializer owner, boolean checkPortability, String... patterns) {
    AutoSerializableManager result = new AutoSerializableManager(owner);
    result.reconfigure(checkPortability, patterns);
    instances.put(owner, result);
    return result;
  }",True
"    result.reconfigure(checkPortability, patterns);
    return result;
  }
  private AutoSerializableManager(ReflectionBasedAutoSerializer owner) {
    this.owner = owner;
  }",False
"  public static void setPdxSerializer(PdxSerializer v) {
    if (v == null) {
      PdxSerializer oldValue = pdxSerializer.getAndSet(null);
      if (oldValue instanceof ReflectionBasedAutoSerializer) {
        asm.compareAndSet(AutoSerializableManager.getInstance((ReflectionBasedAutoSerializer) oldValue), null);
      }
    } else {
      pdxSerializerWasSet = true;
      pdxSerializer.set(v);
      if (v instanceof ReflectionBasedAutoSerializer) {
        asm.set(AutoSerializableManager.getInstance((ReflectionBasedAutoSerializer) v));
      }
    }
  }",True
"  public static void setPdxSerializer(PdxSerializer v) {
    if (v == null) {
      PdxSerializer oldValue = pdxSerializer.getAndSet(null);
      if (oldValue instanceof ReflectionBasedAutoSerializer) {
        asm.compareAndSet((AutoSerializableManager) ((ReflectionBasedAutoSerializer) oldValue).getManager(), null);
      }
    } else {
      pdxSerializerWasSet = true;
      pdxSerializer.set(v);
      if (v instanceof ReflectionBasedAutoSerializer) {
        asm.set((AutoSerializableManager) ((ReflectionBasedAutoSerializer) v).getManager());
      }
    }
  }",False
"  private void setupSerializer(String... classPatterns) {
    setupSerializer(new ReflectionBasedAutoSerializer(classPatterns), true);
  }",True
"  private void setupSerializer(ReflectionBasedAutoSerializer s, boolean readSerialized) {
    this.serializer = s;
    this.manager = (AutoSerializableManager) s.getManager();
    this.c = (GemFireCacheImpl) new CacheFactory().
    set(""mcast-port"", ""0"").
    setPdxReadSerialized(readSerialized).
    setPdxSerializer(s).
    create();
  }",False
"    public void testEntryTtlDestroyEvent()
    throws InterruptedException {
      
      if(getRegionAttributes().getPartitionAttributes() != null)
        return;
      
      final String name = this.getUniqueName();
      final int timeout = 40; // ms
      final Object key = ""KEY"";
      final Object value = ""VALUE"";

      Host host = Host.getHost(0);
      VM vm0 = host.getVM(0);
      VM vm1 = host.getVM(1);

      class DestroyListener extends TestCacheListener {
        boolean eventIsExpiration = false;

        public void afterDestroyBeforeAddEvent(EntryEvent event) {
          eventIsExpiration = event.isExpiration();
        }
        public void afterDestroy2(EntryEvent event) {
          if (event.isOriginRemote()) {
            assertTrue(!event.getDistributedMember().equals(getSystem().getDistributedMember()));
          } else {
            assertEquals(getSystem().getDistributedMember(), event.getDistributedMember());
          }
          assertEquals(Operation.EXPIRE_DESTROY, event.getOperation());
          assertEquals(value, event.getOldValue());
          eventIsExpiration = event.getOperation().isExpiration();
        }

        public void afterCreate2(EntryEvent event) {
          // ignore
        }

        public void afterUpdate2(EntryEvent event) {
          // ignore
        }
      }


      SerializableRunnable create = new CacheSerializableRunnable(""Populate"") {
        public void run2() throws CacheException {
          AttributesFactory fac = new AttributesFactory(getRegionAttributes());
          fac.addCacheListener(destroyListener = new DestroyListener());
          Region region = null;
          System.setProperty(LocalRegion.EXPIRY_MS_PROPERTY, ""true"");
          try {
            region = createRegion(name, fac.create());
          } 
          finally {
            System.getProperties().remove(LocalRegion.EXPIRY_MS_PROPERTY);
          }
        }
      };

      vm1.invoke(create);

      vm0.invoke(new CacheSerializableRunnable(""Create with TTL"") {
          public void run2() throws CacheException {
            AttributesFactory factory = new AttributesFactory(getRegionAttributes());
            final boolean partitioned = getRegionAttributes().getPartitionAttributes() != null ||
            getRegionAttributes().getDataPolicy().withPartitioning();
            factory.setStatisticsEnabled(true);
            ExpirationAttributes expire =
              new ExpirationAttributes(timeout,
                                       ExpirationAction.DESTROY);
            factory.setEntryTimeToLive(expire);
            if (!getRegionAttributes().getDataPolicy().withReplication()&& ! partitioned) {
              factory.setDataPolicy(DataPolicy.NORMAL);
              factory.setSubscriptionAttributes(new SubscriptionAttributes(InterestPolicy.ALL));
            }
            System.setProperty(LocalRegion.EXPIRY_MS_PROPERTY, ""true"");
            try {
              createRegion(name, factory.create());
            } 
            finally {
              System.getProperties().remove(LocalRegion.EXPIRY_MS_PROPERTY);
            }
          }
        });

      // let create finish before setting up other cache
      //pause(10);

      vm1.invoke(new SerializableCallable() {
        public Object call() throws Exception {
          Region region = getRootRegion().getSubregion(name);
          region.put(key, value);
          // reset listener after create event
          assertTrue(((DestroyListener)region.getAttributes().
            getCacheListeners()[0]).wasInvoked());
          return null;
        }
      });

      vm0.invoke(new CacheSerializableRunnable(""Check local destroy"") {
          public void run2() throws CacheException {
            Region region =
              getRootRegion().getSubregion(name);
            int retries = 10;
            while (region.getEntry(key) != null && retries-- > 0) {
              pause(timeout);
            }
            assertNull(region.getEntry(key));
          }
        });

      vm1.invoke(new CacheSerializableRunnable(""Verify destroyed and event"") {
          public void run2() throws CacheException {
            Region region = getRootRegion().getSubregion(name);
            int retries = 10;
            while (region.getEntry(key) != null && retries-- > 0) {
              pause(timeout);
            }
            assertNull(region.getEntry(key));
            assertTrue(destroyListener.waitForInvocation(555));
            assertTrue(((DestroyListener)destroyListener).eventIsExpiration);
          }
        });
    }",True
"    public void testEntryTtlDestroyEvent()
    throws InterruptedException {
      
      if(getRegionAttributes().getPartitionAttributes() != null)
        return;
      
      final String name = this.getUniqueName();
      final int timeout = 22; // ms
      final Object key = ""KEY"";
      final Object value = ""VALUE"";

      Host host = Host.getHost(0);
      VM vm0 = host.getVM(0);
      VM vm1 = host.getVM(1);

      class DestroyListener extends TestCacheListener {
        boolean eventIsExpiration = false;

        public void afterDestroyBeforeAddEvent(EntryEvent event) {
          eventIsExpiration = event.isExpiration();
        }
        public void afterDestroy2(EntryEvent event) {
          if (event.isOriginRemote()) {
            assertTrue(!event.getDistributedMember().equals(getSystem().getDistributedMember()));
          } else {
            assertEquals(getSystem().getDistributedMember(), event.getDistributedMember());
          }
          assertEquals(Operation.EXPIRE_DESTROY, event.getOperation());
          assertEquals(value, event.getOldValue());
          eventIsExpiration = event.getOperation().isExpiration();
        }

        public void afterCreate2(EntryEvent event) {
          // ignore
        }

        public void afterUpdate2(EntryEvent event) {
          // ignore
        }
      }


      SerializableRunnable createRegion = new CacheSerializableRunnable(""Create with Listener"") {
        public void run2() throws CacheException {
          AttributesFactory fac = new AttributesFactory(getRegionAttributes());
          fac.addCacheListener(destroyListener = new DestroyListener());
          createRegion(name, fac.create());
        }
      };

      vm1.invoke(createRegion);

      vm0.invoke(new CacheSerializableRunnable(""Create with TTL"") {
          public void run2() throws CacheException {
            AttributesFactory factory = new AttributesFactory(getRegionAttributes());
            factory.setStatisticsEnabled(true);
            ExpirationAttributes expire =
              new ExpirationAttributes(timeout,
                                       ExpirationAction.DESTROY);
            factory.setEntryTimeToLive(expire);
            if (!getRegionAttributes().getDataPolicy().withReplication()) {
              factory.setDataPolicy(DataPolicy.NORMAL);
              factory.setSubscriptionAttributes(new SubscriptionAttributes(InterestPolicy.ALL));
            }
            System.setProperty(LocalRegion.EXPIRY_MS_PROPERTY, ""true"");
            try {
              createRegion(name, factory.create());
              ExpiryTask.suspendExpiration();
              // suspend to make sure we can see that the put is distributed to this member
            } 
            finally {
              System.getProperties().remove(LocalRegion.EXPIRY_MS_PROPERTY);
            }
          }
        });
      
      try {

      // let region create finish before doing put
      //pause(10);

      vm1.invoke(new SerializableCallable() {
        public Object call() throws Exception {
          Region region = getRootRegion().getSubregion(name);
          DestroyListener dl = (DestroyListener)region.getAttributes().getCacheListeners()[0];
          dl.enableEventHistory();
          region.put(key, value);
          // reset listener after create event
          assertTrue(dl.wasInvoked());
          List<CacheEvent> history = dl.getEventHistory();
          CacheEvent ce = history.get(0);
          dl.disableEventHistory();
          assertEquals(Operation.CREATE, ce.getOperation());
          return null;
        }
      });
      vm0.invoke(new CacheSerializableRunnable(""Check create received from vm1"") {
        public void run2() throws CacheException {
          final Region region = getRootRegion().getSubregion(name);
          WaitCriterion waitForCreate = new WaitCriterion() {
            public boolean done() {
              return region.getEntry(key) != null;
            }
            public String description() {
              return ""never saw create of "" + key;
            }
          };
          DistributedTestCase.waitForCriterion(waitForCreate, 3000, 10, true);
        }
      });
      
      } finally {
        vm0.invoke(new CacheSerializableRunnable(""resume expiration"") {
          public void run2() throws CacheException {
            ExpiryTask.permitExpiration();
          }
        });
      }
      
      // now wait for it to expire
      vm0.invoke(new CacheSerializableRunnable(""Check local destroy"") {
          public void run2() throws CacheException {
            final Region region = getRootRegion().getSubregion(name);
            WaitCriterion waitForExpire = new WaitCriterion() {
              public boolean done() {
                return region.getEntry(key) == null;
              }
              public String description() {
                return ""never saw expire of "" + key + "" entry="" + region.getEntry(key);
              }
            };
            DistributedTestCase.waitForCriterion(waitForExpire, 4000, 10, true);
          }
        });

      vm1.invoke(new CacheSerializableRunnable(""Verify destroyed and event"") {
          public void run2() throws CacheException {
            final Region region = getRootRegion().getSubregion(name);
            WaitCriterion waitForExpire = new WaitCriterion() {
              public boolean done() {
                return region.getEntry(key) == null;
              }
              public String description() {
                return ""never saw expire of "" + key + "" entry="" + region.getEntry(key);
              }
            };
            DistributedTestCase.waitForCriterion(waitForExpire, 4000, 10, true);
            assertTrue(destroyListener.waitForInvocation(555));
            assertTrue(((DestroyListener)destroyListener).eventIsExpiration);
          }
        });
    }",False
"  public boolean isMcastDiscovery() {
    return this.isMcastEnabled() && (this.getLocators().length() == 0);
  }",True
"  public boolean isMcastEnabled() {
    return this.getMcastPort() > 0 ;
  }",False
"  protected List parseLocators() {

    // assumes host[port] format, delimited by "",""
    List locatorIds = new ArrayList();
    if (isMcastEnabled()) {
      String mcastId = new StringBuffer(
          this.getMcastAddress()).append(""["").append(
          this.getMcastPort()).append(""]"").toString();
      locatorIds.add(new DistributionLocatorId(mcastId));
    }
    if (!isMcastDiscovery()) {
      StringTokenizer st = new StringTokenizer(this.getLocators(), "","");
      while (st.hasMoreTokens()) {
        locatorIds.add(new DistributionLocatorId(st.nextToken()));
      }
    }

    if (logger.isDebugEnabled()) {
      StringBuffer sb = new StringBuffer(""Locator set is: "");
      for (Iterator iter = locatorIds.iterator(); iter.hasNext(); ) {
        sb.append(iter.next());
        sb.append("" "");
      }
      logger.debug(sb);
    }

    return locatorIds;
  }",True
"  protected List parseLocators() {

    // assumes host[port] format, delimited by "",""
    List locatorIds = new ArrayList();
    if (isMcastEnabled()) {
      String mcastId = new StringBuffer(
          this.getMcastAddress()).append(""["").append(
          this.getMcastPort()).append(""]"").toString();
      locatorIds.add(new DistributionLocatorId(mcastId));
    }
    StringTokenizer st = new StringTokenizer(this.getLocators(), "","");
    while (st.hasMoreTokens()) {
      locatorIds.add(new DistributionLocatorId(st.nextToken()));
    }

    if (logger.isDebugEnabled()) {
      StringBuffer sb = new StringBuffer(""Locator set is: "");
      for (Iterator iter = locatorIds.iterator(); iter.hasNext(); ) {
        sb.append(iter.next());
        sb.append("" "");
      }
      logger.debug(sb);
    }

    return locatorIds;
  }",False
"  private GfManagerAgentConfig buildAgentConfig(InternalLogWriter logWriter) {
    RemoteTransportConfig conf = new RemoteTransportConfig(
        isMcastEnabled(), isMcastDiscovery(), getDisableTcp(),
        getDisableAutoReconnect(),
        getBindAddress(), buildSSLConfig(), parseLocators(), 
        getMembershipPortRange(), getTcpPort());
    return new GfManagerAgentConfig(
        getSystemName(), conf, logWriter, this.alertLevel.getSeverity(), this, this);
  }",True
"  private GfManagerAgentConfig buildAgentConfig(InternalLogWriter logWriter) {
    RemoteTransportConfig conf = new RemoteTransportConfig(
        isMcastEnabled(), getDisableTcp(),
        getDisableAutoReconnect(),
        getBindAddress(), buildSSLConfig(), parseLocators(), 
        getMembershipPortRange(), getTcpPort());
    return new GfManagerAgentConfig(
        getSystemName(), conf, logWriter, this.alertLevel.getSeverity(), this, this);
  }",False
"  private void generateDiscovery() throws SAXException {
    if (!this.system.isMcastDiscovery()) {
      handler.startElement("""", LOCATORS, LOCATORS, EMPTY);

      generateLocators();
    }
    
    handler.endElement("""", LOCATORS, LOCATORS);
  }",True
"  private void generateDiscovery() throws SAXException {
    handler.startElement("""", LOCATORS, LOCATORS, EMPTY);

    generateLocators();
    
    handler.endElement("""", LOCATORS, LOCATORS);
  }",False
"  private void generateMulticast() throws SAXException {
    int port = this.system.getMcastPort();
    String address = this.system.getMcastAddress();

    AttributesImpl atts = new AttributesImpl();
    atts.addAttribute("""", """", PORT, """", String.valueOf(port));
    atts.addAttribute("""", """", ADDRESS, """", address);

    handler.startElement("""", MULTICAST, MULTICAST, atts);
    handler.endElement("""", MULTICAST, MULTICAST);
  }",True
"      this.system.getDistributionLocators();
    for (int i = 0; i < locators.length; i++) {
      generateLocator(locators[i].getConfig());
    }
  }

  /**
   * Generates XML for a locator
   */
  private void generateLocator(DistributionLocatorConfig config) 
    throws SAXException {",False
"  private void computeMcastPortDefault() {
    ConfigSource cs = getAttSourceMap().get(MCAST_PORT_NAME);
    if (cs == null) {
      String locators = getLocators();
      if (locators != null && !locators.isEmpty()) {
        this.mcastPort = 0; // fixes 46308
      }
    }
    
  }",True
"  private void computeMcastPortDefault() {
    // a no-op since multicast discovery has been removed
    // and the default mcast port is now zero
    
//    ConfigSource cs = getAttSourceMap().get(MCAST_PORT_NAME);
//    if (cs == null) {
//      String locators = getLocators();
//      if (locators != null && !locators.isEmpty()) {
//        this.mcastPort = 0; // fixes 46308
//      }
//    }
  }",False
"  public HighPriorityAckedMessage() {
    super();
    InternalDistributedSystem ds = InternalDistributedSystem.getAnyInstance();
    this.originDm = (DistributionManager)ds.getDistributionManager();
    this.id = this.originDm.getDistributionManagerId();
  }",True
"  public HighPriorityAckedMessage() {
    super();
    InternalDistributedSystem ds = InternalDistributedSystem.getAnyInstance();
    if (ds != null) {
      this.originDm = (DistributionManager)ds.getDistributionManager();
    }
    this.id = this.originDm.getDistributionManagerId();
  }",False
"  private static String canonicalizeLocators(String locators) {
    SortedSet sorted = new TreeSet();
    StringTokenizer st = new StringTokenizer(locators, "","");
    while (st.hasMoreTokens()) {
      String l = st.nextToken();
      StringBuffer canonical = new StringBuffer();
      DistributionLocatorId locId = new DistributionLocatorId(l);
      if (!locId.isMcastId()) {
        String addr = locId.getBindAddress();
        if (addr != null && addr.trim().length() > 0) {
          canonical.append(addr);
        }
        else {
          canonical.append(locId.getHost().getHostAddress());
        }
        canonical.append(""["");
        canonical.append(String.valueOf(locId.getPort()));
        canonical.append(""]"");
        sorted.add(canonical.toString());
      }
    }

    StringBuffer sb = new StringBuffer();
    for (Iterator iter = sorted.iterator(); iter.hasNext(); ) {
      sb.append((String) iter.next());
      if (iter.hasNext()) {
        sb.append("","");
      }
    }
    return sb.toString();
  }",True
"  private static String canonicalizeLocators(String locators) {
    SortedSet sorted = new TreeSet();
    StringTokenizer st = new StringTokenizer(locators, "","");
    while (st.hasMoreTokens()) {
      String l = st.nextToken();
      StringBuffer canonical = new StringBuffer();
      DistributionLocatorId locId = new DistributionLocatorId(l);
      String addr = locId.getBindAddress();
      if (addr != null && addr.trim().length() > 0) {
        canonical.append(addr);
      }
      else {
        canonical.append(locId.getHost().getHostAddress());
      }
      canonical.append(""["");
      canonical.append(String.valueOf(locId.getPort()));
      canonical.append(""]"");
      sorted.add(canonical.toString());
    }

    StringBuffer sb = new StringBuffer();
    for (Iterator iter = sorted.iterator(); iter.hasNext(); ) {
      sb.append((String) iter.next());
      if (iter.hasNext()) {
        sb.append("","");
      }
    }
    return sb.toString();
  }",False
"  public boolean sameSystemAs(Properties props) {
    DistributionConfig other = DistributionConfigImpl.produce(props);
    DistributionConfig me = this.getConfig();

    if (!me.getBindAddress().equals(other.getBindAddress())) {
      return false;
    }

    // @todo Do we need to compare SSL properties?

    if (me.getMcastPort() != 0) {
      // mcast
      return me.getMcastPort() == other.getMcastPort() &&
        me.getMcastAddress().equals(other.getMcastAddress());

    } else {
      // locators
      String myLocators = me.getLocators();
      String otherLocators = other.getLocators();

      // quick check
      if (myLocators.equals(otherLocators)) {
        return true;

      } else {
        myLocators = canonicalizeLocators(myLocators);
        otherLocators = canonicalizeLocators(otherLocators);

        return myLocators.equals(otherLocators);
      }
    }
  }",True
"  public boolean sameSystemAs(Properties props) {
    DistributionConfig other = DistributionConfigImpl.produce(props);
    DistributionConfig me = this.getConfig();

    if (!me.getBindAddress().equals(other.getBindAddress())) {
      return false;
    }

    // @todo Do we need to compare SSL properties?

    // locators
    String myLocators = me.getLocators();
    String otherLocators = other.getLocators();

    // quick check
    if (myLocators.equals(otherLocators)) {
      return true;

    } else {
      myLocators = canonicalizeLocators(myLocators);
      otherLocators = canonicalizeLocators(otherLocators);

      return myLocators.equals(otherLocators);
    }
  }",False
"  private void initialize() {
    if (this.originalConfig.getMcastPort() == 0 && this.originalConfig.getLocators().equals("""")) {
      // no distribution
      this.isLoner = true;
//       throw new IllegalArgumentException(""The ""
//                                          + DistributionConfig.LOCATORS_NAME
//                                          + "" attribute can not be empty when the ""
//                                          + DistributionConfig.MCAST_PORT_NAME
//                                          + "" attribute is zero."");
    }

    if (this.isLoner) {
      this.config = new RuntimeDistributionConfigImpl(this);
    } else {
      this.config = new RuntimeDistributionConfigImpl(this);
      this.attemptingToReconnect = (reconnectAttemptCounter > 0);
    }
    try {
    SocketCreator.getDefaultInstance(this.config);

    // LOG: create LogWriterAppender(s) if log-file or security-log-file is specified
    final boolean hasLogFile = this.config.getLogFile() != null && !this.config.getLogFile().equals(new File(""""));
    final boolean hasSecurityLogFile = this.config.getSecurityLogFile() != null && !this.config.getSecurityLogFile().equals(new File(""""));
    LogService.configureLoggers(hasLogFile, hasSecurityLogFile);
    if (hasLogFile || hasSecurityLogFile) {
      
      // main log file
      if (hasLogFile) {
        // if log-file then create logWriterAppender
        this.logWriterAppender = LogWriterAppenders.getOrCreateAppender(LogWriterAppenders.Identifier.MAIN, this.isLoner, this.config, true);
      }
      
      // security log file
      if (hasSecurityLogFile) {
        // if security-log-file then create securityLogWriterAppender
        this.securityLogWriterAppender = LogWriterAppenders.getOrCreateAppender(LogWriterAppenders.Identifier.SECURITY, this.isLoner, this.config, false);
      } else {
        // let security route to regular log-file or stdout
      }
    }
    
    // LOG: create LogWriterLogger(s) for backwards compatibility of getLogWriter and getSecurityLogWriter
    if (this.logWriter == null) {
      this.logWriter = LogWriterFactory.createLogWriterLogger(this.isLoner, false, this.config, true);
      this.logWriter.fine(""LogWriter is created."");
    }
    
//    logWriter.info(""Created log writer for IDS@""+System.identityHashCode(this));
    
    if (this.securityLogWriter == null) {
      // LOG: whole new LogWriterLogger instance for security
      this.securityLogWriter = LogWriterFactory.createLogWriterLogger(this.isLoner, true, this.config, false);
      this.securityLogWriter.fine(""SecurityLogWriter is created."");
    }
    
    Services.setSecurityLogWriter(this.securityLogWriter);

    this.clock = new DSClock(this.isLoner);
    
    if (this.attemptingToReconnect && logger.isDebugEnabled()) {
      logger.debug(""This thread is initializing a new DistributedSystem in order to reconnect to other members"");
    }
    // Note we need loners to load the license in case they are a
    // bridge server and will need to enforce the member limit
    if (Boolean.getBoolean(InternalLocator.FORCE_LOCATOR_DM_TYPE)) {
      this.locatorDMTypeForced = true;
    }

    // Initialize the Diffie-Hellman and public/private keys
    try {
      HandShake.initCertsMap(this.config.getSecurityProps());
      HandShake.initPrivateKey(this.config.getSecurityProps());
      HandShake.initDHKeys(this.config);
    }
    catch (Exception ex) {
      throw new GemFireSecurityException(
        LocalizedStrings.InternalDistributedSystem_PROBLEM_IN_INITIALIZING_KEYS_FOR_CLIENT_AUTHENTICATION.toLocalizedString(), ex);
    }

    final long offHeapMemorySize = OffHeapStorage.parseOffHeapMemorySize(getConfig().getOffHeapMemorySize());

    this.offHeapStore = OffHeapStorage.createOffHeapStorage(getLogWriter(), this, offHeapMemorySize, this);
    
    // Note: this can only happen on a linux system
    if (getConfig().getLockMemory()) {
      // This calculation is not exact, but seems fairly close.  So far we have
      // not loaded much into the heap and the current RSS usage is already 
      // included the available memory calculation.
      long avail = LinuxProcFsStatistics.getAvailableMemory(logger);
      long size = offHeapMemorySize + Runtime.getRuntime().totalMemory();
      if (avail < size) {
        if (GemFireCacheImpl.ALLOW_MEMORY_LOCK_WHEN_OVERCOMMITTED) {
          logger.warn(LocalizedMessage.create(LocalizedStrings.InternalDistributedSystem_MEMORY_OVERCOMMIT_WARN, size - avail));
        } else {
          throw new IllegalStateException(LocalizedStrings.InternalDistributedSystem_MEMORY_OVERCOMMIT.toLocalizedString(avail, size));
        }
      }
      
      logger.info(""Locking memory. This may take a while..."");
      GemFireCacheImpl.lockMemory();
      logger.info(""Finished locking memory."");
    }

    try {
      startInitLocator();
    } catch (InterruptedException e) {
      throw new SystemConnectException(""Startup has been interrupted"", e);
    }

    synchronized (this.isConnectedMutex) {
      this.isConnected = true;
    }
    
    if (!this.isLoner) {
      try {
        if (this.quorumChecker != null) {
          this.quorumChecker.suspend();
        }
        this.dm = DistributionManager.create(this);
        // fix bug #46324
        if (InternalLocator.hasLocator()) {
          InternalLocator locator = InternalLocator.getLocator();
          getDistributionManager().addHostedLocators(getDistributedMember(), InternalLocator.getLocatorStrings(), locator.isSharedConfigurationEnabled());
        }
      }
      finally {
        if (this.dm == null && this.quorumChecker != null) {
          this.quorumChecker.resume();
        }
        setDisconnected();
      }
    }
    else {
      this.dm = new LonerDistributionManager(this, this.logWriter);
    }
    
    Assert.assertTrue(this.dm != null);
    Assert.assertTrue(this.dm.getSystem() == this);

    try {
      this.id = this.dm.getChannelId();
    } catch (DistributedSystemDisconnectedException e) {
      // bug #48144 - The dm's channel threw an NPE.  It now throws this exception
      // but during startup we should instead throw a SystemConnectException
      throw new SystemConnectException(
          LocalizedStrings.InternalDistributedSystem_DISTRIBUTED_SYSTEM_HAS_DISCONNECTED
            .toLocalizedString(), e);
    }

    synchronized (this.isConnectedMutex) {
      this.isConnected = true;
    }
    if (attemptingToReconnect  &&  (this.startedLocator == null)) {
      try {
        startInitLocator();
      } catch (InterruptedException e) {
        throw new SystemConnectException(""Startup has been interrupted"", e);
      }
    }
    try {
      endInitLocator();
    }
    catch (IOException e) {
      throw new GemFireIOException(""Problem finishing a locator service start"", e);
    }

      if (!statsDisabled) {
        // to fix bug 42527 we need a sampler
        // even if sampling is not enabled.
      this.sampler = new GemFireStatSampler(this);
      this.sampler.start();
    }

    if (this.logWriterAppender != null) {
      LogWriterAppenders.startupComplete(LogWriterAppenders.Identifier.MAIN);
    }
    if (this.securityLogWriterAppender != null) {
      LogWriterAppenders.startupComplete(LogWriterAppenders.Identifier.SECURITY);
    }
    
    //this.logger.info(""ds created"", new RuntimeException(""DEBUG: STACK""));

    //Log any instantiators that were registered before the log writer
    //was created
    InternalInstantiator.logInstantiators();
    }
    catch (RuntimeException ex) {
      this.config.close();
      throw ex;
    }
    
    resourceListeners = new CopyOnWriteArrayList<ResourceEventsListener>();
    this.reconnected = this.attemptingToReconnect;
    this.attemptingToReconnect = false;
  }",True
"  private void initialize() {
    if (this.originalConfig.getLocators().equals("""")) {
      if (this.originalConfig.getMcastPort() != 0) {
        throw new GemFireConfigException(""The ""
                                          + DistributionConfig.LOCATORS_NAME
                                          + "" attribute can not be empty when the ""
                                          + DistributionConfig.MCAST_PORT_NAME
                                          + "" attribute is non-zero."");
      } else {
        // no distribution
        this.isLoner = true;
      }
    }

    if (this.isLoner) {
      this.config = new RuntimeDistributionConfigImpl(this);
    } else {
      this.config = new RuntimeDistributionConfigImpl(this);
      this.attemptingToReconnect = (reconnectAttemptCounter > 0);
    }
    try {
    SocketCreator.getDefaultInstance(this.config);

    // LOG: create LogWriterAppender(s) if log-file or security-log-file is specified
    final boolean hasLogFile = this.config.getLogFile() != null && !this.config.getLogFile().equals(new File(""""));
    final boolean hasSecurityLogFile = this.config.getSecurityLogFile() != null && !this.config.getSecurityLogFile().equals(new File(""""));
    LogService.configureLoggers(hasLogFile, hasSecurityLogFile);
    if (hasLogFile || hasSecurityLogFile) {
      
      // main log file
      if (hasLogFile) {
        // if log-file then create logWriterAppender
        this.logWriterAppender = LogWriterAppenders.getOrCreateAppender(LogWriterAppenders.Identifier.MAIN, this.isLoner, this.config, true);
      }
      
      // security log file
      if (hasSecurityLogFile) {
        // if security-log-file then create securityLogWriterAppender
        this.securityLogWriterAppender = LogWriterAppenders.getOrCreateAppender(LogWriterAppenders.Identifier.SECURITY, this.isLoner, this.config, false);
      } else {
        // let security route to regular log-file or stdout
      }
    }
    
    // LOG: create LogWriterLogger(s) for backwards compatibility of getLogWriter and getSecurityLogWriter
    if (this.logWriter == null) {
      this.logWriter = LogWriterFactory.createLogWriterLogger(this.isLoner, false, this.config, true);
      this.logWriter.fine(""LogWriter is created."");
    }
    
//    logWriter.info(""Created log writer for IDS@""+System.identityHashCode(this));
    
    if (this.securityLogWriter == null) {
      // LOG: whole new LogWriterLogger instance for security
      this.securityLogWriter = LogWriterFactory.createLogWriterLogger(this.isLoner, true, this.config, false);
      this.securityLogWriter.fine(""SecurityLogWriter is created."");
    }
    
    Services.setSecurityLogWriter(this.securityLogWriter);

    this.clock = new DSClock(this.isLoner);
    
    if (this.attemptingToReconnect && logger.isDebugEnabled()) {
      logger.debug(""This thread is initializing a new DistributedSystem in order to reconnect to other members"");
    }
    // Note we need loners to load the license in case they are a
    // bridge server and will need to enforce the member limit
    if (Boolean.getBoolean(InternalLocator.FORCE_LOCATOR_DM_TYPE)) {
      this.locatorDMTypeForced = true;
    }

    // Initialize the Diffie-Hellman and public/private keys
    try {
      HandShake.initCertsMap(this.config.getSecurityProps());
      HandShake.initPrivateKey(this.config.getSecurityProps());
      HandShake.initDHKeys(this.config);
    }
    catch (Exception ex) {
      throw new GemFireSecurityException(
        LocalizedStrings.InternalDistributedSystem_PROBLEM_IN_INITIALIZING_KEYS_FOR_CLIENT_AUTHENTICATION.toLocalizedString(), ex);
    }

    final long offHeapMemorySize = OffHeapStorage.parseOffHeapMemorySize(getConfig().getOffHeapMemorySize());

    this.offHeapStore = OffHeapStorage.createOffHeapStorage(getLogWriter(), this, offHeapMemorySize, this);
    
    // Note: this can only happen on a linux system
    if (getConfig().getLockMemory()) {
      // This calculation is not exact, but seems fairly close.  So far we have
      // not loaded much into the heap and the current RSS usage is already 
      // included the available memory calculation.
      long avail = LinuxProcFsStatistics.getAvailableMemory(logger);
      long size = offHeapMemorySize + Runtime.getRuntime().totalMemory();
      if (avail < size) {
        if (GemFireCacheImpl.ALLOW_MEMORY_LOCK_WHEN_OVERCOMMITTED) {
          logger.warn(LocalizedMessage.create(LocalizedStrings.InternalDistributedSystem_MEMORY_OVERCOMMIT_WARN, size - avail));
        } else {
          throw new IllegalStateException(LocalizedStrings.InternalDistributedSystem_MEMORY_OVERCOMMIT.toLocalizedString(avail, size));
        }
      }
      
      logger.info(""Locking memory. This may take a while..."");
      GemFireCacheImpl.lockMemory();
      logger.info(""Finished locking memory."");
    }

    try {
      startInitLocator();
    } catch (InterruptedException e) {
      throw new SystemConnectException(""Startup has been interrupted"", e);
    }

    synchronized (this.isConnectedMutex) {
      this.isConnected = true;
    }
    
    if (!this.isLoner) {
      try {
        if (this.quorumChecker != null) {
          this.quorumChecker.suspend();
        }
        this.dm = DistributionManager.create(this);
        // fix bug #46324
        if (InternalLocator.hasLocator()) {
          InternalLocator locator = InternalLocator.getLocator();
          getDistributionManager().addHostedLocators(getDistributedMember(), InternalLocator.getLocatorStrings(), locator.isSharedConfigurationEnabled());
        }
      }
      finally {
        if (this.dm == null && this.quorumChecker != null) {
          this.quorumChecker.resume();
        }
        setDisconnected();
      }
    }
    else {
      this.dm = new LonerDistributionManager(this, this.logWriter);
    }
    
    Assert.assertTrue(this.dm != null);
    Assert.assertTrue(this.dm.getSystem() == this);

    try {
      this.id = this.dm.getChannelId();
    } catch (DistributedSystemDisconnectedException e) {
      // bug #48144 - The dm's channel threw an NPE.  It now throws this exception
      // but during startup we should instead throw a SystemConnectException
      throw new SystemConnectException(
          LocalizedStrings.InternalDistributedSystem_DISTRIBUTED_SYSTEM_HAS_DISCONNECTED
            .toLocalizedString(), e);
    }

    synchronized (this.isConnectedMutex) {
      this.isConnected = true;
    }
    if (attemptingToReconnect  &&  (this.startedLocator == null)) {
      try {
        startInitLocator();
      } catch (InterruptedException e) {
        throw new SystemConnectException(""Startup has been interrupted"", e);
      }
    }
    try {
      endInitLocator();
    }
    catch (IOException e) {
      throw new GemFireIOException(""Problem finishing a locator service start"", e);
    }

      if (!statsDisabled) {
        // to fix bug 42527 we need a sampler
        // even if sampling is not enabled.
      this.sampler = new GemFireStatSampler(this);
      this.sampler.start();
    }

    if (this.logWriterAppender != null) {
      LogWriterAppenders.startupComplete(LogWriterAppenders.Identifier.MAIN);
    }
    if (this.securityLogWriterAppender != null) {
      LogWriterAppenders.startupComplete(LogWriterAppenders.Identifier.SECURITY);
    }
    
    //this.logger.info(""ds created"", new RuntimeException(""DEBUG: STACK""));

    //Log any instantiators that were registered before the log writer
    //was created
    InternalInstantiator.logInstantiators();
    }
    catch (RuntimeException ex) {
      this.config.close();
      throw ex;
    }
    
    resourceListeners = new CopyOnWriteArrayList<ResourceEventsListener>();
    this.reconnected = this.attemptingToReconnect;
    this.attemptingToReconnect = false;
  }",False
"  private void reconnect(boolean forcedDisconnect, String reason) {

    // Collect all the state for cache
    // Collect all the state for Regions
    //Close the cache,
    // loop trying to connect, waiting before each attempt
    //
    // If reconnecting for lost-roles the reconnected system's cache will decide
    // whether the reconnected system should stay up.  After max-tries we will
    // give up.
    //
    // If reconnecting for forced-disconnect we ignore max-tries and keep attempting
    // to join the distributed system until successful
    
    this.attemptingToReconnect = true;
    InternalDistributedSystem ids = InternalDistributedSystem.getAnyInstance();
    if (ids == null) {
      ids = this;
    }
    
    // first save the current cache description.  This is created by
    // the membership manager when forced-disconnect starts.  If we're
    // reconnecting for lost roles then this will be null
    String cacheXML = null;
    List<BridgeServerCreation> cacheServerCreation = null;
    
    GemFireCacheImpl cache = GemFireCacheImpl.getInstance();
    boolean inhibitCacheForSQLFire = false;
    if (cache != null) {
      if (cache.isSqlfSystem()) {
        inhibitCacheForSQLFire = true;
      } else {
        cacheXML = cache.getCacheConfig().getCacheXMLDescription();
        cacheServerCreation = cache.getCacheConfig().getCacheServerCreation();
      }
    }
    
    DistributionConfig oldConfig = ids.getConfig();
    Properties configProps = getProperties();
    int timeOut = oldConfig.getMaxWaitTimeForReconnect();
    int maxTries = oldConfig.getMaxNumReconnectTries();

    final boolean isDebugEnabled = logger.isDebugEnabled();
    
//    logger.info(""reconnecting IDS@""+System.identityHashCode(this));

    boolean mcastDiscovery = oldConfig.getLocators().isEmpty()
        && oldConfig.getStartLocator().isEmpty()
        && oldConfig.getMcastPort() != 0;
    boolean mcastQuorumContacted = false;
    

    if (Thread.currentThread().getName().equals(""CloserThread"")) {
      if (isDebugEnabled) {
        logger.debug(""changing thread name to ReconnectThread""); // wha?! really?
      }
      Thread.currentThread().setName(""ReconnectThread"");
    }
    
    // get the membership manager for quorum checks
    MembershipManager mbrMgr = this.dm.getMembershipManager();
    this.quorumChecker = mbrMgr.getQuorumChecker();
    if (logger.isDebugEnabled()) {
      if (quorumChecker == null) {
        logger.debug(""No quorum checks will be performed during reconnect attempts"");
      } else {
        logger.debug(""Initialized quorum checking service: {}"", quorumChecker);
      }
    }
    
    // LOG:CLEANUP: deal with reconnect and INHIBIT_DM_BANNER -- this should be ok now
    String appendToLogFile = System.getProperty(APPEND_TO_LOG_FILE);
    if (appendToLogFile == null) {
      System.setProperty(APPEND_TO_LOG_FILE, ""true"");
    }
    String inhibitBanner = System.getProperty(InternalLocator.INHIBIT_DM_BANNER);
    if (inhibitBanner == null) {
      System.setProperty(InternalLocator.INHIBIT_DM_BANNER, ""true"");
    }
    if (forcedDisconnect) {
      systemAttemptingReconnect = this;
    }
    try {
      while (this.reconnectDS == null || !this.reconnectDS.isConnected()) {
        synchronized(this.reconnectCancelledLock) {
          if (this.reconnectCancelled) {
            break;
          }
        }
        if (!forcedDisconnect) {
          if (isDebugEnabled) {
            logger.debug(""Max number of tries : {} and max time out : {}"", maxTries, timeOut);
          }
          if(reconnectAttemptCounter >= maxTries){
            if (isDebugEnabled) {
              logger.debug(""Stopping the checkrequiredrole thread becuase reconnect : {} reached the max number of reconnect tries : {}"", reconnectAttemptCounter, maxTries);
            }
            throw new CacheClosedException(LocalizedStrings.InternalDistributedSystem_SOME_REQUIRED_ROLES_MISSING.toLocalizedString());
          }
        }
        
        if (reconnectAttemptCounter == 0) {
          reconnectAttemptTime = System.currentTimeMillis();
        }
        reconnectAttemptCounter++;
        
        synchronized(this.reconnectCancelledLock) { 
          if (this.reconnectCancelled) {
            if (isDebugEnabled) {
              logger.debug(""reconnect can no longer be done because of an explicit disconnect"");
            }
            return;
          }
        }
    
        logger.info(""Disconnecting old DistributedSystem to prepare for a reconnect attempt"");
//        logger.info(""IDS@""+System.identityHashCode(this));
        
        try {
          disconnect(true, reason, false);
        }
        catch(Exception ee){
          logger.warn(""Exception disconnecting for reconnect"", ee);
        }
        
        try {
  //        log.fine(""waiting "" + timeOut + "" before reconnecting to the distributed system"");
          reconnectLock.wait(timeOut);
        }
        catch (InterruptedException e) {
          logger.warn(LocalizedMessage.create(LocalizedStrings.InternalDistributedSystem_WAITING_THREAD_FOR_RECONNECT_GOT_INTERRUPTED));
          Thread.currentThread().interrupt();
          return;
        }
        synchronized(this.reconnectCancelledLock) { 
          if (this.reconnectCancelled) {
            if (isDebugEnabled) {
              logger.debug(""reconnect can no longer be done because of an explicit disconnect"");
            }
            return;
          }
        }
        
    
        logger.info(LocalizedMessage.create(LocalizedStrings.DISTRIBUTED_SYSTEM_RECONNECTING, new Object[]{reconnectAttemptCounter}));
        
        int savNumOfTries = reconnectAttemptCounter;
        try {
          // notify listeners of each attempt and then again after successful
          notifyReconnectListeners(this, this.reconnectDS, true);
          if (this.locatorDMTypeForced) {
            System.setProperty(InternalLocator.FORCE_LOCATOR_DM_TYPE, ""true"");
          }
  //        log.fine(""DistributedSystem@""+System.identityHashCode(this)+"" reconnecting distributed system.  attempt #""+reconnectAttemptCounter);
          if (mcastDiscovery  &&  (quorumChecker != null) && !mcastQuorumContacted) {
            mcastQuorumContacted = quorumChecker.checkForQuorum(3*this.config.getMemberTimeout());
            if (!mcastQuorumContacted) {
              if (logger.isDebugEnabled()) {
                logger.debug(""quorum check failed - skipping reconnect attempt"");
              }
              continue;
            }
            if (logger.isDebugEnabled()) {
              logger.debug(LocalizedMessage.create(LocalizedStrings.InternalDistributedSystem_QUORUM_OF_MEMBERS_CONTACTED));
            }
            mcastQuorumContacted = true;
            // bug #51527: become more aggressive about reconnecting since there are other 
            // members around now
            if (timeOut > 5000) {
              timeOut = 5000;
            }
          }
          configProps.put(DistributionConfig.DS_RECONNECTING_NAME, Boolean.TRUE);
          if (quorumChecker != null) {
            configProps.put(DistributionConfig.DS_QUORUM_CHECKER_NAME, quorumChecker);
          }
          InternalDistributedSystem newDS = null;
          synchronized(this.reconnectCancelledLock) { 
            if (this.reconnectCancelled) {
              if (isDebugEnabled) {
                logger.debug(""reconnect can no longer be done because of an explicit disconnect"");
              }
              return;
            }
          }
          try {
            newDS = (InternalDistributedSystem)connect(configProps);
          } catch (DistributedSystemDisconnectedException e) {
            synchronized(this.reconnectCancelledLock) {
          	  if (this.reconnectCancelled) {
          	    return;
          	  } else {
          	    throw e;
          	  }
            }
          } finally {
            if (newDS == null  &&  quorumChecker != null) {
              // make sure the quorum checker is listening for messages from former members
              quorumChecker.resume();
            }
          }
          if (newDS != null) { // newDS will not be null here but findbugs requires this check
            boolean cancelled;
            synchronized(this.reconnectCancelledLock) { 
              cancelled = this.reconnectCancelled;
            }
            if (cancelled) {
              newDS.disconnect();
            } else {
              this.reconnectDS = newDS;
              newDS.isReconnectingDS = false;
              notifyReconnectListeners(this, this.reconnectDS, false);
            }
          }
        }
        catch (SystemConnectException e) {
          // retry;
          if (isDebugEnabled) {
            logger.debug(""Attempt to reconnect failed with SystemConnectException"");
          }
          if (e.getMessage().contains(""Rejecting the attempt of a member using an older version"")
              || e.getMessage().contains(""15806"")) { // 15806 is in the message if it's been localized to another language
            logger.warn(LocalizedMessage.create(LocalizedStrings.InternalDistributedSystem_EXCEPTION_OCCURED_WHILE_TRYING_TO_CONNECT_THE_SYSTEM_DURING_RECONNECT), e);
            attemptingToReconnect = false;
            return;
          }
        }
        catch (GemFireConfigException e) {
          if (isDebugEnabled) {
            logger.debug(""Attempt to reconnect failed with GemFireConfigException"");
          }
        }
        catch (Exception ee) {
          logger.warn(LocalizedMessage.create(LocalizedStrings.InternalDistributedSystem_EXCEPTION_OCCURED_WHILE_TRYING_TO_CONNECT_THE_SYSTEM_DURING_RECONNECT), ee);
          attemptingToReconnect = false;
          return;
        }
        finally {
          if (this.locatorDMTypeForced) {
            System.getProperties().remove(InternalLocator.FORCE_LOCATOR_DM_TYPE);
          }
          reconnectAttemptCounter = savNumOfTries;
        }
      } // while()
    } finally {
      systemAttemptingReconnect = null;
      if (appendToLogFile == null) {
        System.getProperties().remove(APPEND_TO_LOG_FILE);
      } else {
        System.setProperty(APPEND_TO_LOG_FILE,  appendToLogFile);
      }
      if (inhibitBanner == null) {
        System.getProperties().remove(InternalLocator.INHIBIT_DM_BANNER);
      } else {
        System.setProperty(InternalLocator.INHIBIT_DM_BANNER, inhibitBanner);
      }
      if (quorumChecker != null) {
        mbrMgr.releaseQuorumChecker(quorumChecker);
      }
    }
    
    boolean cancelled;
    synchronized(this.reconnectCancelledLock) { 
      cancelled = this.reconnectCancelled;
    }
    if (cancelled) {
      if (isDebugEnabled) {
        logger.debug(""reconnect can no longer be done because of an explicit disconnect"");
      }
      if (reconnectDS != null) {
        reconnectDS.disconnect();
      }
      attemptingToReconnect = false;
      return;
    }

    try {
      DM newDM = this.reconnectDS.getDistributionManager();
      if ( !inhibitCacheForSQLFire && (newDM instanceof DistributionManager) ) {
        // sqlfire will have already replayed DDL and recovered.
        // Admin systems don't carry a cache, but for others we can now create
        // a cache
        if (((DistributionManager)newDM).getDMType() != DistributionManager.ADMIN_ONLY_DM_TYPE) {
          try {
            CacheConfig config = new CacheConfig();
            if (cacheXML != null) {
              config.setCacheXMLDescription(cacheXML);
            }
            cache = GemFireCacheImpl.create(this.reconnectDS, config);
            if (cacheServerCreation != null) {
              for (BridgeServerCreation bridge: cacheServerCreation) {
                BridgeServerImpl impl = (BridgeServerImpl)cache.addCacheServer();
                impl.configureFrom(bridge);
                try {
                  if (!impl.isRunning()) {
                    impl.start();
                  }
                } catch (IOException ex) {
                  throw new GemFireIOException(
                      LocalizedStrings.CacheCreation_WHILE_STARTING_BRIDGE_SERVER_0
                          .toLocalizedString(impl), ex);
                }
              }
            }
            if (cache.getCachePerfStats().getReliableRegionsMissing() == 0){
              reconnectAttemptCounter = 0;
              if (isDebugEnabled) {
                logger.debug(""Reconnected properly"");
              }  
            }
            else {
              // this try failed. The new cache will call reconnect again
            }
          }
          catch (CancelException ignor) {
              //getLogWriter().warning(""Exception occured while trying to create the cache during reconnect : ""+ignor.toString());
              throw ignor;
              // this.reconnectDS.reconnect();
          }
          catch (Exception e) {
            logger.warn(LocalizedMessage.create(LocalizedStrings.InternalDistributedSystem_EXCEPTION_OCCURED_WHILE_TRYING_TO_CREATE_THE_CACHE_DURING_RECONNECT), e);
          }
        }
      }
    } finally {
      attemptingToReconnect = false;
    }
  }",True
"    //
    // If reconnecting for lost-roles the reconnected system's cache will decide
    // whether the reconnected system should stay up.  After max-tries we will
    // give up.
    //
    // If reconnecting for forced-disconnect we ignore max-tries and keep attempting
    // to join the distributed system until successful
    
    this.attemptingToReconnect = true;
    InternalDistributedSystem ids = InternalDistributedSystem.getAnyInstance();
    if (ids == null) {
      ids = this;
    }
    
    // first save the current cache description.  This is created by
    // the membership manager when forced-disconnect starts.  If we're
    // reconnecting for lost roles then this will be null
    String cacheXML = null;
    List<BridgeServerCreation> cacheServerCreation = null;
    
    GemFireCacheImpl cache = GemFireCacheImpl.getInstance();
    boolean inhibitCacheForSQLFire = false;
    if (cache != null) {
      if (cache.isSqlfSystem()) {
        inhibitCacheForSQLFire = true;
      } else {
        cacheXML = cache.getCacheConfig().getCacheXMLDescription();
        cacheServerCreation = cache.getCacheConfig().getCacheServerCreation();
      }
    }
    
    DistributionConfig oldConfig = ids.getConfig();
    Properties configProps = getProperties();
    int timeOut = oldConfig.getMaxWaitTimeForReconnect();
    int maxTries = oldConfig.getMaxNumReconnectTries();

    final boolean isDebugEnabled = logger.isDebugEnabled();
    
//    logger.info(""reconnecting IDS@""+System.identityHashCode(this));

    if (Thread.currentThread().getName().equals(""CloserThread"")) {
      if (isDebugEnabled) {
        logger.debug(""changing thread name to ReconnectThread""); // wha?! really?
      }
      Thread.currentThread().setName(""ReconnectThread"");
    }
    
    // get the membership manager for quorum checks
    MembershipManager mbrMgr = this.dm.getMembershipManager();
    this.quorumChecker = mbrMgr.getQuorumChecker();
    if (logger.isDebugEnabled()) {
      if (quorumChecker == null) {
        logger.debug(""No quorum checks will be performed during reconnect attempts"");
      } else {
        logger.debug(""Initialized quorum checking service: {}"", quorumChecker);
      }
    }
    
    // LOG:CLEANUP: deal with reconnect and INHIBIT_DM_BANNER -- this should be ok now
    String appendToLogFile = System.getProperty(APPEND_TO_LOG_FILE);
    if (appendToLogFile == null) {
      System.setProperty(APPEND_TO_LOG_FILE, ""true"");
    }
    String inhibitBanner = System.getProperty(InternalLocator.INHIBIT_DM_BANNER);
    if (inhibitBanner == null) {
      System.setProperty(InternalLocator.INHIBIT_DM_BANNER, ""true"");
    }
    if (forcedDisconnect) {
      systemAttemptingReconnect = this;
    }
    try {
      while (this.reconnectDS == null || !this.reconnectDS.isConnected()) {
        synchronized(this.reconnectCancelledLock) {
          if (this.reconnectCancelled) {
            break;
          }
        }
        if (!forcedDisconnect) {
          if (isDebugEnabled) {
            logger.debug(""Max number of tries : {} and max time out : {}"", maxTries, timeOut);
          }
          if(reconnectAttemptCounter >= maxTries){
            if (isDebugEnabled) {
              logger.debug(""Stopping the checkrequiredrole thread becuase reconnect : {} reached the max number of reconnect tries : {}"", reconnectAttemptCounter, maxTries);
            }
            throw new CacheClosedException(LocalizedStrings.InternalDistributedSystem_SOME_REQUIRED_ROLES_MISSING.toLocalizedString());
          }
        }
        
        if (reconnectAttemptCounter == 0) {
          reconnectAttemptTime = System.currentTimeMillis();
        }
        reconnectAttemptCounter++;
        
        synchronized(this.reconnectCancelledLock) { 
          if (this.reconnectCancelled) {
            if (isDebugEnabled) {
              logger.debug(""reconnect can no longer be done because of an explicit disconnect"");
            }
            return;
          }
        }
    
        logger.info(""Disconnecting old DistributedSystem to prepare for a reconnect attempt"");
//        logger.info(""IDS@""+System.identityHashCode(this));
        
        try {
          disconnect(true, reason, false);
        }
        catch(Exception ee){
          logger.warn(""Exception disconnecting for reconnect"", ee);
        }
        
        try {
  //        log.fine(""waiting "" + timeOut + "" before reconnecting to the distributed system"");
          reconnectLock.wait(timeOut);
        }
        catch (InterruptedException e) {
          logger.warn(LocalizedMessage.create(LocalizedStrings.InternalDistributedSystem_WAITING_THREAD_FOR_RECONNECT_GOT_INTERRUPTED));
          Thread.currentThread().interrupt();
          return;
        }
        synchronized(this.reconnectCancelledLock) { 
          if (this.reconnectCancelled) {
            if (isDebugEnabled) {
              logger.debug(""reconnect can no longer be done because of an explicit disconnect"");
            }
            return;
          }
        }
        
    
        logger.info(LocalizedMessage.create(LocalizedStrings.DISTRIBUTED_SYSTEM_RECONNECTING, new Object[]{reconnectAttemptCounter}));
        
        int savNumOfTries = reconnectAttemptCounter;
        try {
          // notify listeners of each attempt and then again after successful
          notifyReconnectListeners(this, this.reconnectDS, true);
          if (this.locatorDMTypeForced) {
            System.setProperty(InternalLocator.FORCE_LOCATOR_DM_TYPE, ""true"");
          }
  //        log.fine(""DistributedSystem@""+System.identityHashCode(this)+"" reconnecting distributed system.  attempt #""+reconnectAttemptCounter);
          configProps.put(DistributionConfig.DS_RECONNECTING_NAME, Boolean.TRUE);
          if (quorumChecker != null) {
            configProps.put(DistributionConfig.DS_QUORUM_CHECKER_NAME, quorumChecker);
          }
          InternalDistributedSystem newDS = null;
          synchronized(this.reconnectCancelledLock) { 
            if (this.reconnectCancelled) {
              if (isDebugEnabled) {
                logger.debug(""reconnect can no longer be done because of an explicit disconnect"");
              }
              return;
            }
          }
          try {
            newDS = (InternalDistributedSystem)connect(configProps);
          } catch (DistributedSystemDisconnectedException e) {
            synchronized(this.reconnectCancelledLock) {
          	  if (this.reconnectCancelled) {
          	    return;
          	  } else {
          	    throw e;
          	  }
            }
          } finally {
            if (newDS == null  &&  quorumChecker != null) {
              // make sure the quorum checker is listening for messages from former members
              quorumChecker.resume();
            }
          }
          if (newDS != null) { // newDS will not be null here but findbugs requires this check
            boolean cancelled;
            synchronized(this.reconnectCancelledLock) { 
              cancelled = this.reconnectCancelled;
            }
            if (cancelled) {
              newDS.disconnect();
            } else {
              this.reconnectDS = newDS;
              newDS.isReconnectingDS = false;
              notifyReconnectListeners(this, this.reconnectDS, false);
            }
          }
        }
        catch (SystemConnectException e) {
          // retry;
          if (isDebugEnabled) {
            logger.debug(""Attempt to reconnect failed with SystemConnectException"");
          }
          if (e.getMessage().contains(""Rejecting the attempt of a member using an older version"")
              || e.getMessage().contains(""15806"")) { // 15806 is in the message if it's been localized to another language
            logger.warn(LocalizedMessage.create(LocalizedStrings.InternalDistributedSystem_EXCEPTION_OCCURED_WHILE_TRYING_TO_CONNECT_THE_SYSTEM_DURING_RECONNECT), e);
            attemptingToReconnect = false;
            return;
          }
        }
        catch (GemFireConfigException e) {
          if (isDebugEnabled) {
            logger.debug(""Attempt to reconnect failed with GemFireConfigException"");
          }
        }
        catch (Exception ee) {
          logger.warn(LocalizedMessage.create(LocalizedStrings.InternalDistributedSystem_EXCEPTION_OCCURED_WHILE_TRYING_TO_CONNECT_THE_SYSTEM_DURING_RECONNECT), ee);
          attemptingToReconnect = false;
          return;
        }
        finally {
          if (this.locatorDMTypeForced) {
            System.getProperties().remove(InternalLocator.FORCE_LOCATOR_DM_TYPE);
          }
          reconnectAttemptCounter = savNumOfTries;
        }
      } // while()
    } finally {
      systemAttemptingReconnect = null;
      if (appendToLogFile == null) {
        System.getProperties().remove(APPEND_TO_LOG_FILE);
      } else {
        System.setProperty(APPEND_TO_LOG_FILE,  appendToLogFile);
      }
      if (inhibitBanner == null) {
        System.getProperties().remove(InternalLocator.INHIBIT_DM_BANNER);
      } else {
        System.setProperty(InternalLocator.INHIBIT_DM_BANNER, inhibitBanner);
      }
      if (quorumChecker != null) {
        mbrMgr.releaseQuorumChecker(quorumChecker);
      }
    }
    
    boolean cancelled;
    synchronized(this.reconnectCancelledLock) { 
      cancelled = this.reconnectCancelled;
    }
    if (cancelled) {
      if (isDebugEnabled) {
        logger.debug(""reconnect can no longer be done because of an explicit disconnect"");
      }
      if (reconnectDS != null) {
        reconnectDS.disconnect();
      }
      attemptingToReconnect = false;
      return;
    }

    try {
      DM newDM = this.reconnectDS.getDistributionManager();
      if ( !inhibitCacheForSQLFire && (newDM instanceof DistributionManager) ) {
        // sqlfire will have already replayed DDL and recovered.
        // Admin systems don't carry a cache, but for others we can now create
        // a cache
        if (((DistributionManager)newDM).getDMType() != DistributionManager.ADMIN_ONLY_DM_TYPE) {
          try {
            CacheConfig config = new CacheConfig();
            if (cacheXML != null) {
              config.setCacheXMLDescription(cacheXML);
            }
            cache = GemFireCacheImpl.create(this.reconnectDS, config);
            if (cacheServerCreation != null) {
              for (BridgeServerCreation bridge: cacheServerCreation) {
                BridgeServerImpl impl = (BridgeServerImpl)cache.addCacheServer();
                impl.configureFrom(bridge);
                try {
                  if (!impl.isRunning()) {
                    impl.start();
                  }
                } catch (IOException ex) {
                  throw new GemFireIOException(
                      LocalizedStrings.CacheCreation_WHILE_STARTING_BRIDGE_SERVER_0
                          .toLocalizedString(impl), ex);
                }
              }
            }
            if (cache.getCachePerfStats().getReliableRegionsMissing() == 0){
              reconnectAttemptCounter = 0;
              if (isDebugEnabled) {
                logger.debug(""Reconnected properly"");
              }  
            }
            else {
              // this try failed. The new cache will call reconnect again
            }
          }
          catch (CancelException ignor) {
              //getLogWriter().warning(""Exception occured while trying to create the cache during reconnect : ""+ignor.toString());
              throw ignor;
              // this.reconnectDS.reconnect();
          }
          catch (Exception e) {
            logger.warn(LocalizedMessage.create(LocalizedStrings.InternalDistributedSystem_EXCEPTION_OCCURED_WHILE_TRYING_TO_CREATE_THE_CACHE_DURING_RECONNECT), e);
          }
        }
      }
    } finally {
      attemptingToReconnect = false;
    }
  }

  /**
   * Validates that the configuration provided is the same as the configuration for this
   * InternalDistributedSystem
   * @param propsToCheck the Properties instance to compare with the existing Properties
   * @throws java.lang.IllegalStateException when the configuration is not the same other returns
   */
  public void validateSameProperties(Properties propsToCheck, boolean isConnected)
  {
    if (!this.sameAs(propsToCheck, isConnected)) {
      StringBuffer sb = new StringBuffer();

      DistributionConfig wanted = DistributionConfigImpl.produce(propsToCheck);

      String[] validAttributeNames = this.originalConfig.getAttributeNames();
      for (int i = 0; i < validAttributeNames.length; i++) {
        String attName = validAttributeNames[i];
        Object expectedAtt = wanted.getAttributeObject(attName);
        String expectedAttStr = expectedAtt.toString();
        Object actualAtt = this.originalConfig.getAttributeObject(attName);
        String actualAttStr = actualAtt.toString();
        sb.append(""  "");
        sb.append(attName);
        sb.append(""=\"""");
        if (actualAtt.getClass().isArray()) {
          actualAttStr = arrayToString(actualAtt);
          expectedAttStr = arrayToString(expectedAtt);
        }

        sb.append(actualAttStr);",False
"  public void waitToStop() throws InterruptedException {
    boolean restarted;
    do {
      restarted = false;
      this.server.join();
      if (this.stoppedForReconnect) {
        restarted = this.myDs.waitUntilReconnected(-1, TimeUnit.SECONDS);
      }
    } while (restarted);
  }",True
"  public void waitToStop() throws InterruptedException {
    boolean restarted;
    do {
      restarted = false;
      this.server.join();
      if (this.stoppedForReconnect) {
        logger.info(""waiting for distributed system to disconnect..."");
        while (this.myDs.isConnected()) {
          Thread.sleep(5000);
        }
        logger.info(""waiting for distributed system to reconnect..."");
        restarted = this.myDs.waitUntilReconnected(-1, TimeUnit.SECONDS);
        if (restarted) {
          logger.info(""system restarted"");
        } else {
          logger.info(""system was not restarted"");
        }
        Thread rs = this.restartThread;
        if (rs != null) {
          logger.info(""waiting for services to restart..."");
          rs.join();
          this.restartThread = null;
        }
      }
    } while (restarted);
  }",False
"  public boolean attemptReconnect() throws InterruptedException, IOException {
    boolean restarted = false;
    if (this.stoppedForReconnect) {
      logger.info(""attempting to restart locator"");
      boolean tcpServerStarted = false;
      InternalDistributedSystem ds = this.myDs;
      long waitTime = ds.getConfig().getMaxWaitTimeForReconnect()/2;
      QuorumChecker checker = null;
      while (ds.getReconnectedSystem() == null &&
          !ds.isReconnectCancelled()) {
        if (checker == null) {
          checker = this.myDs.getQuorumChecker();
          if (checker != null) {
            logger.info(""The distributed system returned this quorum checker: {}"", checker);
          }
        }
        if (checker != null && !tcpServerStarted) {
          boolean start = checker.checkForQuorum(3*this.myDs.getConfig().getMemberTimeout());
          if (start) {
            // start up peer location.  server location is started after the DS finishes
            // reconnecting
            logger.info(""starting peer location"");
            if(this.locatorListener != null){
              this.locatorListener.clearLocatorInfo();
            }
            this.stoppedForReconnect = false;
            this.myDs = null;
            this.myCache = null;
            restartWithoutDS();
            tcpServerStarted = true;
            setLocator(this);
          }
        }
        ds.waitUntilReconnected(waitTime, TimeUnit.MILLISECONDS);
      }
      InternalDistributedSystem newSystem = (InternalDistributedSystem)ds.getReconnectedSystem();
//      LogWriter log = new ManagerLogWriter(LogWriterImpl.FINE_LEVEL, System.out);
      if (newSystem != null) {
//        log.fine(""reconnecting locator: starting location services"");
        if (!tcpServerStarted) {
          if(this.locatorListener != null){
            this.locatorListener.clearLocatorInfo();
          }
          this.stoppedForReconnect = false;
        }
        restartWithDS(newSystem, GemFireCacheImpl.getInstance());
        setLocator(this);
        restarted = true;
      }
    }
    return restarted;
  }",True
"  public boolean attemptReconnect() throws InterruptedException, IOException {
    boolean restarted = false;
    if (this.stoppedForReconnect) {
      logger.info(""attempting to restart locator"");
      boolean tcpServerStarted = false;
      InternalDistributedSystem ds = this.myDs;
      long waitTime = ds.getConfig().getMaxWaitTimeForReconnect()/2;
      QuorumChecker checker = null;
      while (ds.getReconnectedSystem() == null &&
          !ds.isReconnectCancelled()) {
        if (checker == null) {
          checker = this.myDs.getQuorumChecker();
          if (checker != null) {
            logger.info(""The distributed system returned this quorum checker: {}"", checker);
          }
        }
        if (checker != null && !tcpServerStarted) {
          boolean start = checker.checkForQuorum(3*this.myDs.getConfig().getMemberTimeout());
          if (start) {
            // start up peer location.  server location is started after the DS finishes
            // reconnecting
            logger.info(""starting peer location"");
            if(this.locatorListener != null){
              this.locatorListener.clearLocatorInfo();
            }
            this.stoppedForReconnect = false;
            this.myDs = null;
            this.myCache = null;
            restartWithoutDS();
            tcpServerStarted = true;
            setLocator(this);
          }
        }
        ds.waitUntilReconnected(waitTime, TimeUnit.MILLISECONDS);
      }
      InternalDistributedSystem newSystem = (InternalDistributedSystem)ds.getReconnectedSystem();
//      LogWriter log = new ManagerLogWriter(LogWriterImpl.FINE_LEVEL, System.out);
      if (newSystem != null) {
//        log.fine(""reconnecting locator: starting location services"");
        if (!tcpServerStarted) {
          if(this.locatorListener != null){
            this.locatorListener.clearLocatorInfo();
          }
          this.stoppedForReconnect = false;
        }
        restartWithDS(newSystem, GemFireCacheImpl.getInstance());
        setLocator(this);
        restarted = true;
      }
    }
    logger.info(""restart thread exiting.  Service was ""+(restarted? """" : ""not "") + ""restarted"");
    return restarted;
  }",False
"  public void toData(DataOutput out) throws IOException {
    super.toData(out);
    out.writeBoolean(this.directChannel != null);
    if (this.directChannel != null) {
      InternalDataSerializer.invokeToData(this.directChannel, out);
    }

    boolean pre9_0_0_0 = InternalDataSerializer.
        getVersionForDataStream(out).compareTo(Version.GFE_90) < 0;
    if (pre9_0_0_0) {
      DataSerializer.writeObject(new Properties(), out);
    }

    DataSerializer.writeString(this.version, out);
    out.writeInt(this.replyProcessorId);
    out.writeBoolean(this.isMcastEnabled);
    out.writeBoolean(this.isMcastDiscovery);
    out.writeBoolean(this.isTcpDisabled);

    // Send a description of all of the DataSerializers and
    // Instantiators that have been registered
    SerializerAttributesHolder[] sahs = InternalDataSerializer.getSerializersForDistribution();
    out.writeInt(sahs.length);
    for (int i = 0; i < sahs.length; i++) {
      DataSerializer.writeNonPrimitiveClassName(sahs[i].getClassName(), out);
      out.writeInt(sahs[i].getId());
    }

    Object[] insts = InternalInstantiator.getInstantiatorsForSerialization();
    out.writeInt(insts.length);
    for (int i = 0; i < insts.length; i++) {
      String instantiatorClassName, instantiatedClassName;
      int id;
      if (insts[i] instanceof Instantiator) {
        instantiatorClassName = ((Instantiator)insts[i]).getClass().getName();
        instantiatedClassName = ((Instantiator)insts[i]).getInstantiatedClass().getName();
        id = ((Instantiator)insts[i]).getId();
      } else {
        instantiatorClassName = ((InstantiatorAttributesHolder)insts[i]).getInstantiatorClassName();
        instantiatedClassName = ((InstantiatorAttributesHolder)insts[i]).getInstantiatedClassName();
        id = ((InstantiatorAttributesHolder)insts[i]).getId();
      }
      DataSerializer.writeNonPrimitiveClassName(instantiatorClassName, out);
      DataSerializer.writeNonPrimitiveClassName(instantiatedClassName, out);
      out.writeInt(id);
    }
    DataSerializer.writeObject(interfaces, out);
    out.writeInt(distributedSystemId);
    DataSerializer.writeString(redundancyZone, out);
    out.writeBoolean(enforceUniqueZone);

    StartupMessageData data = new StartupMessageData();
    data.writeHostedLocators(this.hostedLocatorsAll);
    data.writeIsSharedConfigurationEnabled(this.isSharedConfigurationEnabled);
    data.writeMcastPort(this.mcastPort);
    data.writeMcastHostAddress(this.mcastHostAddress);
    data.writeTo(out);
  }",True
"    if (pre9_0_0_0) {
      DataSerializer.writeObject(new Properties(), out);
    }

    DataSerializer.writeString(this.version, out);
    out.writeInt(this.replyProcessorId);
    out.writeBoolean(this.isMcastEnabled);
    out.writeBoolean(this.isTcpDisabled);

    // Send a description of all of the DataSerializers and
    // Instantiators that have been registered
    SerializerAttributesHolder[] sahs = InternalDataSerializer.getSerializersForDistribution();
    out.writeInt(sahs.length);
    for (int i = 0; i < sahs.length; i++) {
      DataSerializer.writeNonPrimitiveClassName(sahs[i].getClassName(), out);
      out.writeInt(sahs[i].getId());
    }

    Object[] insts = InternalInstantiator.getInstantiatorsForSerialization();
    out.writeInt(insts.length);
    for (int i = 0; i < insts.length; i++) {
      String instantiatorClassName, instantiatedClassName;
      int id;
      if (insts[i] instanceof Instantiator) {
        instantiatorClassName = ((Instantiator)insts[i]).getClass().getName();
        instantiatedClassName = ((Instantiator)insts[i]).getInstantiatedClass().getName();
        id = ((Instantiator)insts[i]).getId();
      } else {
        instantiatorClassName = ((InstantiatorAttributesHolder)insts[i]).getInstantiatorClassName();
        instantiatedClassName = ((InstantiatorAttributesHolder)insts[i]).getInstantiatedClassName();
        id = ((InstantiatorAttributesHolder)insts[i]).getId();
      }
      DataSerializer.writeNonPrimitiveClassName(instantiatorClassName, out);
      DataSerializer.writeNonPrimitiveClassName(instantiatedClassName, out);
      out.writeInt(id);
    }
    DataSerializer.writeObject(interfaces, out);
    out.writeInt(distributedSystemId);
    DataSerializer.writeString(redundancyZone, out);
    out.writeBoolean(enforceUniqueZone);

    StartupMessageData data = new StartupMessageData();
    data.writeHostedLocators(this.hostedLocatorsAll);
    data.writeIsSharedConfigurationEnabled(this.isSharedConfigurationEnabled);
    data.writeMcastPort(this.mcastPort);
    data.writeMcastHostAddress(this.mcastHostAddress);
    data.writeTo(out);
  }

  /**
   * Notes a problem that occurs while invoking {@link #fromData}.
   */
  private void fromDataProblem(String s) {
    if (this.fromDataProblems == null) {
      this.fromDataProblems = new StringBuffer();
    }

    this.fromDataProblems.append(s);",False
"  void setMcastDiscovery(boolean flag) {
    isMcastDiscovery = flag;
  }",True
"    isTcpDisabled = flag;
  }
",False
"  public void fromData(DataInput in)
    throws IOException, ClassNotFoundException {
    super.fromData(in);
    boolean hasDirectChannel = in.readBoolean();
    if (hasDirectChannel) {
      this.directChannel = Stub.createFromData(in);
    } else {
      this.directChannel = null;
    }

    boolean pre9_0_0_0 = InternalDataSerializer.
        getVersionForDataStream(in).compareTo(Version.GFE_90) < 0;
    if (pre9_0_0_0) {
      DataSerializer.readObject(in);
    }
    
    this.version = DataSerializer.readString(in);
    this.replyProcessorId = in.readInt();
    this.isMcastEnabled = in.readBoolean();
    this.isMcastDiscovery = in.readBoolean();
    this.isTcpDisabled = in.readBoolean();

    int serializerCount = in.readInt();
    for (int i = 0; i < serializerCount; i++) {
      String cName = DataSerializer.readNonPrimitiveClassName(in);

      int id = in.readInt(); // id
      try {
        if (cName != null) {
          // @todo verify that the id is correct
          InternalDataSerializer.register(cName, false, null, null, id);
        }
      } catch (IllegalArgumentException ex) {
        fromDataProblem(
            LocalizedStrings.StartupMessage_ILLEGALARGUMENTEXCEPTION_WHILE_REGISTERING_A_DATASERIALIZER_0
            .toLocalizedString(ex));
      }
    }

    int instantiatorCount = in.readInt();
    for (int i = 0; i < instantiatorCount; i++) {
      String instantiatorClassName = DataSerializer.readNonPrimitiveClassName(in);
      String instantiatedClassName = DataSerializer.readNonPrimitiveClassName(in);
      int id = in.readInt();

      try {
        if (instantiatorClassName != null && instantiatedClassName != null) {
          InternalInstantiator.register(instantiatorClassName, instantiatedClassName, id, false);
        }
      } catch (IllegalArgumentException ex) {
        fromDataProblem(
          LocalizedStrings.StartupMessage_ILLEGALARGUMENTEXCEPTION_WHILE_REGISTERING_AN_INSTANTIATOR_0
          .toLocalizedString(ex));
      }
    } // for

    this.interfaces = (Set)DataSerializer.readObject(in);
    this.distributedSystemId = in.readInt();
    this.redundancyZone = DataSerializer.readString(in);
    this.enforceUniqueZone = in.readBoolean();

    StartupMessageData data = new StartupMessageData();
    data.readFrom(in);
    this.hostedLocatorsAll = data.readHostedLocators();
    this.isSharedConfigurationEnabled = data.readIsSharedConfigurationEnabled();
    this.mcastPort = data.readMcastPort();
    this.mcastHostAddress = data.readMcastHostAddress();
  }",True
"    boolean pre9_0_0_0 = InternalDataSerializer.
        getVersionForDataStream(in).compareTo(Version.GFE_90) < 0;
    if (pre9_0_0_0) {
      DataSerializer.readObject(in);
    }
    
    this.version = DataSerializer.readString(in);
    this.replyProcessorId = in.readInt();
    this.isMcastEnabled = in.readBoolean();
    this.isTcpDisabled = in.readBoolean();

    int serializerCount = in.readInt();
    for (int i = 0; i < serializerCount; i++) {
      String cName = DataSerializer.readNonPrimitiveClassName(in);

      int id = in.readInt(); // id
      try {
        if (cName != null) {
          // @todo verify that the id is correct
          InternalDataSerializer.register(cName, false, null, null, id);
        }
      } catch (IllegalArgumentException ex) {
        fromDataProblem(
            LocalizedStrings.StartupMessage_ILLEGALARGUMENTEXCEPTION_WHILE_REGISTERING_A_DATASERIALIZER_0
            .toLocalizedString(ex));
      }
    }

    int instantiatorCount = in.readInt();
    for (int i = 0; i < instantiatorCount; i++) {
      String instantiatorClassName = DataSerializer.readNonPrimitiveClassName(in);
      String instantiatedClassName = DataSerializer.readNonPrimitiveClassName(in);
      int id = in.readInt();

      try {
        if (instantiatorClassName != null && instantiatedClassName != null) {
          InternalInstantiator.register(instantiatorClassName, instantiatedClassName, id, false);
        }
      } catch (IllegalArgumentException ex) {
        fromDataProblem(
          LocalizedStrings.StartupMessage_ILLEGALARGUMENTEXCEPTION_WHILE_REGISTERING_AN_INSTANTIATOR_0
          .toLocalizedString(ex));
      }
    } // for

    this.interfaces = (Set)DataSerializer.readObject(in);
    this.distributedSystemId = in.readInt();
    this.redundancyZone = DataSerializer.readString(in);
    this.enforceUniqueZone = in.readBoolean();

    StartupMessageData data = new StartupMessageData();
    data.readFrom(in);
    this.hostedLocatorsAll = data.readHostedLocators();
    this.isSharedConfigurationEnabled = data.readIsSharedConfigurationEnabled();
    this.mcastPort = data.readMcastPort();
    this.mcastHostAddress = data.readMcastHostAddress();
  }

  @Override
  public String toString() {
    return 
      LocalizedStrings.StartupMessage_STARTUPMESSAGE_DM_0_HAS_STARTED_PROCESSOR_1_WITH_DISTRIBUTED_SYSTEM_ID_2
      .toLocalizedString(new Object[]{getSender(), Integer.valueOf(replyProcessorId), this.distributedSystemId});
  }
}
",False
"  boolean sendStartupMessage(Set recipients, long timeout, Set interfaces, 
      String redundancyZone, boolean enforceUniqueZone)
            throws InterruptedException, ReplyException,
              java.net.UnknownHostException, IOException
  {
    if (Thread.interrupted()) throw new InterruptedException();
    StartupMessageReplyProcessor proc = new StartupMessageReplyProcessor(dm, recipients);
    boolean isSharedConfigurationEnabled = false;
    if (InternalLocator.hasLocator()) {
      isSharedConfigurationEnabled = InternalLocator.getLocator().isSharedConfigurationEnabled();
    }
    StartupMessage msg = new StartupMessage(InternalLocator.getLocatorStrings(), isSharedConfigurationEnabled);
    
    msg.setInterfaces(interfaces);
    msg.setDistributedSystemId(dm.getConfig().getDistributedSystemId());
    msg.setRedundancyZone(redundancyZone);
    msg.setEnforceUniqueZone(enforceUniqueZone);
    msg.setDirectChannel(dm.getDirectChannel());
    msg.setMcastEnabled(transport.isMcastEnabled());
    msg.setMcastDiscovery(transport.isMcastDiscovery());
    msg.setMcastPort(dm.getSystem().getOriginalConfig().getMcastPort());
    msg.setMcastHostAddress(dm.getSystem().getOriginalConfig().getMcastAddress());
    msg.setTcpDisabled(transport.isTcpDisabled());
    msg.setRecipients(recipients);
    msg.setReplyProcessorId(proc.getProcessorId());

    this.newlyDeparted = dm.sendOutgoing(msg);  // set of departed jgroups ids
    if (this.newlyDeparted != null && !this.newlyDeparted.isEmpty()) {
      // tell the reply processor not to wait for the recipients that didn't
      // get the message
//      Vector viewMembers = dm.getViewMembers();
      for (Iterator it=this.newlyDeparted.iterator(); it.hasNext(); ) {
        InternalDistributedMember id = (InternalDistributedMember)it.next();
        this.dm.handleManagerDeparture(id, false, LocalizedStrings.StartupOperation_LEFT_THE_MEMBERSHIP_VIEW.toLocalizedString());
        proc.memberDeparted(id, true);
      }
    }
    
    if (proc.stillWaiting() && logger.isDebugEnabled()) {
      logger.debug(""Waiting {} milliseconds to receive startup responses"", timeout);
    }
    boolean timedOut = true;
    Set unresponsive = null;
    try {
      timedOut = !proc.waitForReplies(timeout);
    }
    finally {
      if (timedOut) {
        unresponsive = new HashSet();
        proc.collectUnresponsiveMembers(unresponsive);
        if (!unresponsive.isEmpty()) {
          for (Iterator it=unresponsive.iterator(); it.hasNext(); ) {
            InternalDistributedMember um = (InternalDistributedMember)it.next();
            if (!dm.getViewMembers().contains(um)) {
              // Member slipped away and we didn't notice.
              it.remove();
              dm.handleManagerDeparture(um, true, LocalizedStrings.StartupOperation_DISAPPEARED_DURING_STARTUP_HANDSHAKE.toLocalizedString());
            }
            else
            if (dm.isCurrentMember(um)) {
              // he must have connected back to us and now we just
              // need to get his startup response
              logger.warn(LocalizedMessage.create(
                  LocalizedStrings.StartupOperation_MEMBERSHIP_RECEIVED_CONNECTION_FROM_0_BUT_RECEIVED_NO_STARTUP_RESPONSE_AFTER_1_MS,
                  new Object[] {um, Long.valueOf(timeout)}));
            } 
          } // for

          // Tell the dm who we expect to be waiting for...
          this.dm.setUnfinishedStartups(unresponsive);
          
          // Re-examine list now that we have elided the startup problems....
          if (!unresponsive.isEmpty()) {
            logger.warn(LocalizedMessage.create(
                LocalizedStrings.StartupOperation_MEMBERSHIP_STARTUP_TIMED_OUT_AFTER_WAITING_0_MILLISECONDS_FOR_RESPONSES_FROM_1,
                new Object[] {Long.valueOf(timeout), unresponsive}));
          }
        } // !isEmpty
      } // timedOut
    } // finally
    
    boolean problems;
    problems = this.newlyDeparted != null && this.newlyDeparted.size() > 0;
//    problems = problems || 
//        (unresponsive != null && unresponsive.size() > 0);
    return !problems;
  }",True
"  boolean sendStartupMessage(Set recipients, long timeout, Set interfaces, 
      String redundancyZone, boolean enforceUniqueZone)
            throws InterruptedException, ReplyException,
              java.net.UnknownHostException, IOException
  {
    if (Thread.interrupted()) throw new InterruptedException();
    StartupMessageReplyProcessor proc = new StartupMessageReplyProcessor(dm, recipients);
    boolean isSharedConfigurationEnabled = false;
    if (InternalLocator.hasLocator()) {
      isSharedConfigurationEnabled = InternalLocator.getLocator().isSharedConfigurationEnabled();
    }
    StartupMessage msg = new StartupMessage(InternalLocator.getLocatorStrings(), isSharedConfigurationEnabled);
    
    msg.setInterfaces(interfaces);
    msg.setDistributedSystemId(dm.getConfig().getDistributedSystemId());
    msg.setRedundancyZone(redundancyZone);
    msg.setEnforceUniqueZone(enforceUniqueZone);
    msg.setDirectChannel(dm.getDirectChannel());
    msg.setMcastEnabled(transport.isMcastEnabled());
    msg.setMcastPort(dm.getSystem().getOriginalConfig().getMcastPort());
    msg.setMcastHostAddress(dm.getSystem().getOriginalConfig().getMcastAddress());
    msg.setTcpDisabled(transport.isTcpDisabled());
    msg.setRecipients(recipients);
    msg.setReplyProcessorId(proc.getProcessorId());

    this.newlyDeparted = dm.sendOutgoing(msg);  // set of departed jgroups ids
    if (this.newlyDeparted != null && !this.newlyDeparted.isEmpty()) {
      // tell the reply processor not to wait for the recipients that didn't
      // get the message
//      Vector viewMembers = dm.getViewMembers();
      for (Iterator it=this.newlyDeparted.iterator(); it.hasNext(); ) {
        InternalDistributedMember id = (InternalDistributedMember)it.next();
        this.dm.handleManagerDeparture(id, false, LocalizedStrings.StartupOperation_LEFT_THE_MEMBERSHIP_VIEW.toLocalizedString());
        proc.memberDeparted(id, true);
      }
    }
    
    if (proc.stillWaiting() && logger.isDebugEnabled()) {
      logger.debug(""Waiting {} milliseconds to receive startup responses"", timeout);
    }
    boolean timedOut = true;
    Set unresponsive = null;
    try {
      timedOut = !proc.waitForReplies(timeout);
    }
    finally {
      if (timedOut) {
        unresponsive = new HashSet();
        proc.collectUnresponsiveMembers(unresponsive);
        if (!unresponsive.isEmpty()) {
          for (Iterator it=unresponsive.iterator(); it.hasNext(); ) {
            InternalDistributedMember um = (InternalDistributedMember)it.next();
            if (!dm.getViewMembers().contains(um)) {
              // Member slipped away and we didn't notice.
              it.remove();
              dm.handleManagerDeparture(um, true, LocalizedStrings.StartupOperation_DISAPPEARED_DURING_STARTUP_HANDSHAKE.toLocalizedString());
            }
            else
            if (dm.isCurrentMember(um)) {
              // he must have connected back to us and now we just
              // need to get his startup response
              logger.warn(LocalizedMessage.create(
                  LocalizedStrings.StartupOperation_MEMBERSHIP_RECEIVED_CONNECTION_FROM_0_BUT_RECEIVED_NO_STARTUP_RESPONSE_AFTER_1_MS,
                  new Object[] {um, Long.valueOf(timeout)}));
            } 
          } // for

          // Tell the dm who we expect to be waiting for...
          this.dm.setUnfinishedStartups(unresponsive);
          
          // Re-examine list now that we have elided the startup problems....
          if (!unresponsive.isEmpty()) {
            logger.warn(LocalizedMessage.create(
                LocalizedStrings.StartupOperation_MEMBERSHIP_STARTUP_TIMED_OUT_AFTER_WAITING_0_MILLISECONDS_FOR_RESPONSES_FROM_1,
                new Object[] {Long.valueOf(timeout), unresponsive}));
          }
        } // !isEmpty
      } // timedOut
    } // finally
    
    boolean problems;
    problems = this.newlyDeparted != null && this.newlyDeparted.size() > 0;
//    problems = problems || 
//        (unresponsive != null && unresponsive.size() > 0);
    return !problems;
  }
}",False
"  public void fromDataPre_GFE_9_0_0_0(DataInput in)
  throws IOException, ClassNotFoundException {
    InetAddress inetAddr = DataSerializer.readInetAddress(in);
    int port = in.readInt();

    this.hostName = DataSerializer.readString(in);
    this.hostName = SocketCreator.resolve_dns? SocketCreator.getCanonicalHostName(inetAddr, hostName) : inetAddr.getHostAddress();

    int flags = in.readUnsignedByte();
    boolean sbEnabled = (flags & SB_ENABLED_MASK) != 0;
    boolean elCoord = (flags & COORD_ENABLED_MASK) != 0;
    this.isPartial = (flags & PARTIAL_ID_MASK) != 0;

    this.dcPort = in.readInt();
    this.vmPid = in.readInt();
    this.vmKind = in.readUnsignedByte();
    this.groups = DataSerializer.readStringArray(in);

    this.name = DataSerializer.readString(in);
    if (this.vmKind == DistributionManager.LONER_DM_TYPE) {
      this.uniqueTag = DataSerializer.readString(in);
    } else {
      String str = DataSerializer.readString(in);
      if (str != null) { // backward compatibility from earlier than 6.5
        this.vmViewId = Integer.parseInt(str);
      }
    }

    String durableId = DataSerializer.readString(in);
    int durableTimeout = DataSerializer.readInteger(in).intValue();
    this.durableClientAttributes = new DurableClientAttributes(durableId, durableTimeout);

    readVersion(flags, in);

    MemberAttributes attr = new MemberAttributes(this.dcPort, this.vmPid,
        this.vmKind, this.vmViewId, this.name, this.groups, this.durableClientAttributes);
    netMbr = MemberFactory.newNetMember(inetAddr, port, sbEnabled, elCoord, version, attr);

    synchPayload();

    Assert.assertTrue(this.vmKind > 0);
//    Assert.assertTrue(getPort() > 0);
  }",False
"  public void fromDataPre_9_0_0_0(DataInput in)
  throws IOException, ClassNotFoundException {
    InetAddress inetAddr = DataSerializer.readInetAddress(in);
    int port = in.readInt();

    this.hostName = DataSerializer.readString(in);
    this.hostName = SocketCreator.resolve_dns? SocketCreator.getCanonicalHostName(inetAddr, hostName) : inetAddr.getHostAddress();

    int flags = in.readUnsignedByte();
    boolean sbEnabled = (flags & SB_ENABLED_MASK) != 0;
    boolean elCoord = (flags & COORD_ENABLED_MASK) != 0;
    this.isPartial = (flags & PARTIAL_ID_MASK) != 0;

    this.dcPort = in.readInt();
    this.vmPid = in.readInt();
    this.vmKind = in.readUnsignedByte();
    this.groups = DataSerializer.readStringArray(in);

    this.name = DataSerializer.readString(in);
    if (this.vmKind == DistributionManager.LONER_DM_TYPE) {
      this.uniqueTag = DataSerializer.readString(in);
    } else {
      String str = DataSerializer.readString(in);
      if (str != null) { // backward compatibility from earlier than 6.5
        this.vmViewId = Integer.parseInt(str);
      }
    }

    String durableId = DataSerializer.readString(in);
    int durableTimeout = DataSerializer.readInteger(in).intValue();
    this.durableClientAttributes = new DurableClientAttributes(durableId, durableTimeout);

    readVersion(flags, in);

    MemberAttributes attr = new MemberAttributes(this.dcPort, this.vmPid,
        this.vmKind, this.vmViewId, this.name, this.groups, this.durableClientAttributes);
    netMbr = MemberFactory.newNetMember(inetAddr, port, sbEnabled, elCoord, version, attr);

    synchPayload();

    Assert.assertTrue(this.vmKind > 0);
//    Assert.assertTrue(getPort() > 0);
  }",True
"  public void fromData(DataInput in)
  throws IOException, ClassNotFoundException {
    fromDataPre_9_0_0_0(in);
    netMbr.readAdditionalData(in);
  }",True
"  public void fromData(DataInput in)
  throws IOException, ClassNotFoundException {
    fromDataPre_GFE_9_0_0_0(in);
    netMbr.readAdditionalData(in);
  }",False
"  public static void setDefaultVmPid(int uniqueID) {
    // note: JGroupMembershipManager establishes DEFAULT before attempting to
    // create a JGroups channel, so we know it isn't INVALID here
    setDefaults(DEFAULT.dcPort, uniqueID, DEFAULT.vmKind, DEFAULT.vmViewId, DEFAULT.name,
        DEFAULT.groups, DEFAULT.durableClientAttributes);
  }",True
"  public static List<InetSocketAddress> parseLocators(String locatorsString, String bindAddress) {
    InetAddress addr = null;
    
    try {
      if (bindAddress == null || bindAddress.trim().length() == 0) {
        addr = SocketCreator.getLocalHost();
        logger.info(""Peer-to-peer bind address was null - checking for locator communications using "" + addr);
      } else {
        addr = InetAddress.getByName(bindAddress);
      }
    } catch (UnknownHostException e) {
      // ignore
    }
    return parseLocators(locatorsString, addr);
  }",True
"  public static List<InetSocketAddress> parseLocators(String locatorsString, String bindAddress) {
    InetAddress addr = null;
    
    try {
      if (bindAddress == null || bindAddress.trim().length() == 0) {
        addr = SocketCreator.getLocalHost();
      } else {
        addr = InetAddress.getByName(bindAddress);
      }
    } catch (UnknownHostException e) {
      // ignore
    }
    return parseLocators(locatorsString, addr);
  }
  ",False
"  protected void start() {
    boolean started = false;
    try {
      logger.info(""Membership: starting Authenticator"");
      this.auth.start();
      logger.info(""Membership: starting Messenger"");
      this.messenger.start();
      logger.info(""Membership: starting JoinLeave"");
      this.joinLeave.start();
      logger.info(""Membership: starting HealthMonitor"");
      this.healthMon.start();
      logger.info(""Membership: starting Manager"");
      this.manager.start();
      started = true;
    } catch (RuntimeException e) {
      logger.fatal(""Unexpected exception while booting membership services"", e);
      throw e;
    } finally {
      if (!started) {
        this.manager.stop();
        this.healthMon.stop();
        this.joinLeave.stop();
        this.messenger.stop();
        this.auth.stop();
      }
    }
    this.auth.started();
    this.messenger.started();
    this.joinLeave.started();
    this.healthMon.started();
    this.manager.started();
    
    this.manager.joinDistributedSystem();
  }",True
"  protected void start() {
    boolean started = false;
    try {
      logger.info(""Membership: starting Authenticator"");
      this.auth.start();
      logger.info(""Membership: starting Messenger"");
      this.messenger.start();
      logger.info(""Membership: starting JoinLeave"");
      this.joinLeave.start();
      logger.info(""Membership: starting HealthMonitor"");
      this.healthMon.start();
      logger.info(""Membership: starting Manager"");
      this.manager.start();
      started = true;
    } catch (RuntimeException e) {
      logger.fatal(""Unexpected exception while booting membership services"", e);
      throw e;
    } finally {
      if (!started) {
        this.manager.stop();
        this.healthMon.stop();
        this.joinLeave.stop();
        this.messenger.stop();
        this.auth.stop();
      }
    }
    this.auth.started();
    this.messenger.started();
    this.joinLeave.started();
    this.healthMon.started();
    this.manager.started();
    logger.info(""Membership: all services have been started"");
    this.manager.joinDistributedSystem();
  }",False
"  public void fromData(DataInput in) throws IOException, ClassNotFoundException {
    coordinator = DataSerializer.readObject(in);
    networkPartitionDetectionEnabled = in.readBoolean();
    usePreferredCoordinators = in.readBoolean();
  }",True
"  public void fromData(DataInput in) throws IOException, ClassNotFoundException {
    coordinator = DataSerializer.readObject(in);
    fromView = in.readBoolean();
    networkPartitionDetectionEnabled = in.readBoolean();
    usePreferredCoordinators = in.readBoolean();
  }",False
"  public boolean isFromView() {
    return fromView;
  }",False
"  public void toData(DataOutput out) throws IOException {
    DataSerializer.writeObject(coordinator, out);
    out.writeBoolean(networkPartitionDetectionEnabled);
    out.writeBoolean(usePreferredCoordinators);
  }",True
"  public void toData(DataOutput out) throws IOException {
    DataSerializer.writeObject(coordinator, out);
    out.writeBoolean(fromView);
    out.writeBoolean(networkPartitionDetectionEnabled);
    out.writeBoolean(usePreferredCoordinators);
  }",False
"  public FindCoordinatorResponse(InternalDistributedMember coordinator,
      boolean networkPartitionDectionEnabled, boolean usePreferredCoordinators) {
    this.coordinator = coordinator;
    this.networkPartitionDetectionEnabled = networkPartitionDectionEnabled;
    this.usePreferredCoordinators = usePreferredCoordinators;
  }",True
"  public FindCoordinatorResponse(InternalDistributedMember coordinator,
      boolean fromView,
      boolean networkPartitionDectionEnabled, boolean usePreferredCoordinators) {
    this.coordinator = coordinator;
    this.networkPartitionDetectionEnabled = networkPartitionDectionEnabled;
    this.usePreferredCoordinators = usePreferredCoordinators;
  }",False
"  public Object processRequest(Object request) throws IOException {
    Object response = null;
    
    if (logger.isDebugEnabled()) {
      logger.debug(""Peer locator processing "" + request);
    }
    
    if (request instanceof GetViewRequest) {
      if (view != null) {
        response = new GetViewResponse(view);
      }
    } else if (request instanceof FindCoordinatorRequest) {
      FindCoordinatorRequest findRequest = (FindCoordinatorRequest)request;
      
      if (findRequest.getMemberID() != null) {
        InternalDistributedMember coord = null;

        // at this level we want to return the coordinator known to membership services,
        // which may be more up-to-date than the one known by the membership manager
        if (view == null) {
          findServices();
        }
        if (view != null) {
          coord = view.getCoordinator();
        }
        
        if (coord != null) {
          // no need to keep track of registrants after we're in the distributed system
          synchronized(registrants) {
            registrants.clear();
          }
          
        } else {
          // find the ""oldest"" registrant
          synchronized(registrants) {
            registrants.add(findRequest.getMemberID());
            if (services != null) {
              coord = services.getJoinLeave().getMemberID();
            }
            for (InternalDistributedMember mbr: registrants) {
              if (mbr != coord  &&  (coord==null  ||  mbr.compareTo(coord) < 0)) {
                if (mbr.getNetMember().preferredForCoordinator() || !mbr.getNetMember().splitBrainEnabled()) {
                  coord = mbr;
                }
              }
            }
          }
        }
        response = new FindCoordinatorResponse(coord,
            this.networkPartitionDetectionEnabled, this.usePreferredCoordinators);
      }
    }
    if (logger.isDebugEnabled()) {
      logger.debug(""Peer locator returning "" + response);
    }
    return response;
  }",True
"  public Object processRequest(Object request) throws IOException {
    Object response = null;
    
    if (logger.isDebugEnabled()) {
      logger.debug(""Peer locator processing "" + request);
    }
    
    if (request instanceof GetViewRequest) {
      if (view != null) {
        response = new GetViewResponse(view);
      }
    } else if (request instanceof FindCoordinatorRequest) {
      FindCoordinatorRequest findRequest = (FindCoordinatorRequest)request;
      
      if (findRequest.getMemberID() != null) {
        InternalDistributedMember coord = null;

        // at this level we want to return the coordinator known to membership services,
        // which may be more up-to-date than the one known by the membership manager
        if (view == null) {
          findServices();
        }
        
        boolean fromView = false;
        
        if (view != null) {
          coord = view.getCoordinator();
          fromView = true;
        }
        
        if (coord != null) {
          // no need to keep track of registrants after we're in the distributed system
          synchronized(registrants) {
            registrants.clear();
          }
          
        } else {
          // find the ""oldest"" registrant
          synchronized(registrants) {
            registrants.add(findRequest.getMemberID());
            if (services != null) {
              coord = services.getJoinLeave().getMemberID();
            }
            for (InternalDistributedMember mbr: registrants) {
              if (mbr != coord  &&  (coord==null  ||  mbr.compareTo(coord) < 0)) {
                if (mbr.getNetMember().preferredForCoordinator() || !mbr.getNetMember().splitBrainEnabled()) {
                  coord = mbr;
                }
              }
            }
          }
        }
        response = new FindCoordinatorResponse(coord, fromView,
            this.networkPartitionDetectionEnabled, this.usePreferredCoordinators);
      }
    }
    if (logger.isDebugEnabled()) {
      logger.debug(""Peer locator returning "" + response);
    }
    return response;
  }",False
"    boolean createAndSendView(List<DistributionMessage> requests) {
      List<InternalDistributedMember> joinReqs = new ArrayList<InternalDistributedMember>();
      List<InternalDistributedMember> leaveReqs = new ArrayList<InternalDistributedMember>();
      List<InternalDistributedMember> removalReqs = new ArrayList<InternalDistributedMember>();
      List<String> removalReasons = new ArrayList<String>();
      
      for (DistributionMessage msg: requests) {
        logger.debug(""processing request {}"", msg);
        if (msg instanceof JoinRequestMessage) {
          InternalDistributedMember mbr = ((JoinRequestMessage)msg).getMemberID();
          joinReqs.add(mbr);
        }
        else if (msg instanceof LeaveRequestMessage) {
          leaveReqs.add(((LeaveRequestMessage) msg).getMemberID());
        }
        else if (msg instanceof RemoveMemberMessage) {
          removalReqs.add(((RemoveMemberMessage) msg).getMemberID());
          removalReasons.add(((RemoveMemberMessage) msg).getReason());
        }
        else {
          // TODO: handle removals
          logger.warn(""Unknown membership request encountered: {}"", msg);
        }
      }
      
      NetView newView;
      synchronized(viewInstallationLock) {
        int viewNumber = 0;
        List<InternalDistributedMember> mbrs;
        if (currentView == null) {
          mbrs = new ArrayList<InternalDistributedMember>(joinReqs.size());
        } else {
          viewNumber = currentView.getViewId()+1;
          mbrs = new ArrayList<InternalDistributedMember>(currentView.getMembers());
        }
        mbrs.addAll(joinReqs);
        mbrs.removeAll(leaveReqs);
        mbrs.removeAll(removalReqs);
        newView = new NetView(localAddress, viewNumber, mbrs, leaveReqs,
            removalReqs);
      }
      
      for (InternalDistributedMember mbr: joinReqs) {
        mbr.setVmViewId(newView.getViewId());
      }
      // send removal messages before installing the view so we stop
      // getting messages from members that have been kicked out
      sendRemoveMessages(removalReqs, removalReasons, newView);
      
      // we want to always check for quorum loss but don't act on it
      // unless network-partition-detection is enabled
      if ( !(checkForPartition(newView) && quorumRequired) ) {
        sendJoinResponses(joinReqs, newView);
      }

      if (quorumRequired) {
        boolean prepared = false;
        do {
          if (this.shutdown || Thread.currentThread().isInterrupted()) {
            return false;
          }
          prepared = prepareView(newView);
          if (!prepared && quorumRequired) {
            Set<InternalDistributedMember> unresponsive = prepareResponses.getUnresponsiveMembers();
            try {
              removeHealthyMembers(unresponsive);
            } catch (InterruptedException e) {
              // abort the view if interrupted
              shutdown = true;
              return false;
            }
  
            List<InternalDistributedMember> failures = new ArrayList<InternalDistributedMember>(currentView.getCrashedMembers().size() + unresponsive.size());
            failures.addAll(unresponsive);
            
            NetView conflictingView = prepareResponses.getConflictingView();
            if (conflictingView != null
                && !conflictingView.getCreator().equals(localAddress)
                && conflictingView.getViewId() > newView.getViewId()
                && (lastConflictingView == null || conflictingView.getViewId() > lastConflictingView.getViewId())) {
              lastConflictingView = conflictingView;
              failures.addAll(conflictingView.getCrashedMembers());
            }
  
            failures.removeAll(removalReqs);
            if (failures.size() > 0) {
              // abort the current view and try again
              removalReqs.addAll(failures);
              newView = new NetView(localAddress, newView.getViewId()+1, newView.getMembers(), leaveReqs,
                  removalReqs);
            }
          }
        } while (!prepared);
      } // quorumRequired
      
      lastConflictingView = null;
      
      sendView(newView);
      return true;
    }",True
"    boolean createAndSendView(List<DistributionMessage> requests) {
      List<InternalDistributedMember> joinReqs = new ArrayList<InternalDistributedMember>();
      List<InternalDistributedMember> leaveReqs = new ArrayList<InternalDistributedMember>();
      List<InternalDistributedMember> removalReqs = new ArrayList<InternalDistributedMember>();
      List<String> removalReasons = new ArrayList<String>();
      
      for (DistributionMessage msg: requests) {
        logger.debug(""processing request {}"", msg);
        if (msg instanceof JoinRequestMessage) {
          InternalDistributedMember mbr = ((JoinRequestMessage)msg).getMemberID();
          joinReqs.add(mbr);
        }
        else if (msg instanceof LeaveRequestMessage) {
          leaveReqs.add(((LeaveRequestMessage) msg).getMemberID());
        }
        else if (msg instanceof RemoveMemberMessage) {
          removalReqs.add(((RemoveMemberMessage) msg).getMemberID());
          removalReasons.add(((RemoveMemberMessage) msg).getReason());
        }
        else {
          // TODO: handle removals
          logger.warn(""Unknown membership request encountered: {}"", msg);
        }
      }
      
      NetView newView;
      synchronized(viewInstallationLock) {
        int viewNumber = 0;
        List<InternalDistributedMember> mbrs;
        if (currentView == null) {
          mbrs = new ArrayList<InternalDistributedMember>(joinReqs.size());
        } else {
          viewNumber = currentView.getViewId()+1;
          mbrs = new ArrayList<InternalDistributedMember>(currentView.getMembers());
        }
        mbrs.addAll(joinReqs);
        mbrs.removeAll(leaveReqs);
        mbrs.removeAll(removalReqs);
        newView = new NetView(localAddress, viewNumber, mbrs, leaveReqs,
            removalReqs);
      }
      
      for (InternalDistributedMember mbr: joinReqs) {
        mbr.setVmViewId(newView.getViewId());
      }
      // send removal messages before installing the view so we stop
      // getting messages from members that have been kicked out
      sendRemoveMessages(removalReqs, removalReasons, newView);
      
      // we want to always check for quorum loss but don't act on it
      // unless network-partition-detection is enabled
      if ( !(checkForPartition(newView) && quorumRequired) ) {
        sendJoinResponses(joinReqs, newView);
      }

      if (quorumRequired) {
        boolean prepared = false;
        do {
          if (this.shutdown || Thread.currentThread().isInterrupted()) {
            return false;
          }
          prepared = prepareView(newView, joinReqs);
          if (!prepared && quorumRequired) {
            Set<InternalDistributedMember> unresponsive = prepareProcessor.getUnresponsiveMembers();
            try {
              removeHealthyMembers(unresponsive);
            } catch (InterruptedException e) {
              // abort the view if interrupted
              shutdown = true;
              return false;
            }
  
            if (!unresponsive.isEmpty()) {
              List<InternalDistributedMember> failures = new ArrayList<InternalDistributedMember>(currentView.getCrashedMembers().size() + unresponsive.size());
              failures.addAll(unresponsive);

              NetView conflictingView = prepareProcessor.getConflictingView();
              if (conflictingView != null
                  && !conflictingView.getCreator().equals(localAddress)
                  && conflictingView.getViewId() > newView.getViewId()
                  && (lastConflictingView == null || conflictingView.getViewId() > lastConflictingView.getViewId())) {
                lastConflictingView = conflictingView;
                failures.addAll(conflictingView.getCrashedMembers());
              }

              failures.removeAll(removalReqs);
              if (failures.size() > 0) {
                // abort the current view and try again
                removalReqs.addAll(failures);
                newView = new NetView(localAddress, newView.getViewId()+1, newView.getMembers(), leaveReqs,
                    removalReqs);
              }
            }
          }
        } while (!prepared);
      } // quorumRequired
      
      lastConflictingView = null;
      
      sendView(newView, joinReqs);
      return true;
    }",False
"    Set<InternalDistributedMember> waitForResponses() {
      Set<InternalDistributedMember> result = this.recipients;
      long endOfWait = System.currentTimeMillis() + viewAckTimeout;
      try {
        while (System.currentTimeMillis() < endOfWait
            &&  (services.getCancelCriterion().cancelInProgress() == null)) {
          try {
            synchronized(result) {
              result.wait(1000);
            }
          } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            return result;
          }
        }
      } finally {
        this.waiting = false;
      }
      return result;
    }",True
"    Set<InternalDistributedMember> waitForResponses() {
      Set<InternalDistributedMember> result = this.recipients;
      long endOfWait = System.currentTimeMillis() + viewAckTimeout;
      try {
        while (System.currentTimeMillis() < endOfWait
            &&  (services.getCancelCriterion().cancelInProgress() == null)) {
          try {
            synchronized(result) {
              result.wait(1000);
            }
          } catch (InterruptedException e) {
            logger.debug(""Interrupted while waiting for view resonses"");
            Thread.currentThread().interrupt();
            return result;
          }
        }
      } finally {
        this.waiting = false;
      }
      return result;
    }",False
"  public void installView(NetView newView) {
    synchronized(viewInstallationLock) {
      if (currentView != null && currentView.getViewId() >= newView.getViewId()) {
        // old view - ignore it
        return;
      }
      
      if (checkForPartition(newView)) {
        if (quorumRequired) {
          List<InternalDistributedMember> crashes = newView.getActualCrashedMembers(currentView);
          services.getManager().forceDisconnect(
              LocalizedStrings.Network_partition_detected.toLocalizedString(crashes.size(), crashes));
        }
        return;
      }
      
      currentView = newView;
      preparedView = null;
      lastConflictingView = null;
      services.installView(newView);
      
      if (!newView.getCreator().equals(this.localAddress)) {
        if (newView.shouldBeCoordinator(this.localAddress)) {
          becomeCoordinator();
        } else if (this.isCoordinator) {
          // stop being coordinator
          stateLock.writeLock().lock();
          try {
            stopCoordinatorServices();
            this.isCoordinator = false;
          } finally {
            stateLock.writeLock().unlock();
          }
        }
      }
      if (!this.isCoordinator) {
        // get rid of outdated requests
        synchronized(viewRequests) {
          for (Iterator<DistributionMessage> it = viewRequests.iterator(); it.hasNext(); ) {
            DistributionMessage m = it.next();
            if (m instanceof JoinRequestMessage) {
              it.remove();
            } else if (m instanceof LeaveRequestMessage) {
              if (!currentView.contains(((LeaveRequestMessage)m).getMemberID())) {
                it.remove();
              }
            } else if (m instanceof RemoveMemberMessage) {
              if (!currentView.contains(((RemoveMemberMessage)m).getMemberID())) {
                it.remove();
              }
            }
          }
        }
      }
    }
  }",True
"  public void installView(NetView newView) {
    synchronized(viewInstallationLock) {
      if (currentView != null && currentView.getViewId() >= newView.getViewId()) {
        // old view - ignore it
        return;
      }
      
      if (checkForPartition(newView)) {
        if (quorumRequired) {
          List<InternalDistributedMember> crashes = newView.getActualCrashedMembers(currentView);
          services.getManager().forceDisconnect(
              LocalizedStrings.Network_partition_detected.toLocalizedString(crashes.size(), crashes));
        }
        return;
      }
      
      currentView = newView;
      preparedView = null;
      lastConflictingView = null;
      services.installView(newView);
      
      if (!newView.getCreator().equals(this.localAddress)) {
        if (newView.shouldBeCoordinator(this.localAddress)) {
          becomeCoordinator();
        } else if (this.isCoordinator) {
          // stop being coordinator
          stateLock.writeLock().lock();
          try {
            stopCoordinatorServices();
            this.isCoordinator = false;
          } finally {
            stateLock.writeLock().unlock();
          }
        }
      }
      if (!this.isCoordinator) {
        // get rid of outdated requests.  It's possible some requests are
        // newer than the view just processed - the senders will have to
        // resend these
        synchronized(viewRequests) {
          for (Iterator<DistributionMessage> it = viewRequests.iterator(); it.hasNext(); ) {
            DistributionMessage m = it.next();
            if (m instanceof JoinRequestMessage) {
              it.remove();
            } else if (m instanceof LeaveRequestMessage) {
              if (!currentView.contains(((LeaveRequestMessage)m).getMemberID())) {
                it.remove();
              }
            } else if (m instanceof RemoveMemberMessage) {
              if (!currentView.contains(((RemoveMemberMessage)m).getMemberID())) {
                it.remove();
              }
            }
          }
        }
      }
    }
  }",False
"  private void ackView(InstallViewMessage m) {
    if (m.getView().contains(m.getView().getCreator())) {
      try {
        services.getMessenger().send(new ViewAckMessage(m.getSender(), m.getView().getViewId(), m.isPreparing()));
      } catch (IOException e) {
        logger.info(""unable to send view response to "" + m.getSender(), e);
      }
    }
  }",True
"  private void ackView(InstallViewMessage m) {
    if (m.getView().contains(m.getView().getCreator())) {
      services.getMessenger().send(new ViewAckMessage(m.getSender(), m.getView().getViewId(), m.isPreparing()));
    }
  }",False
"  void sendView(NetView view) {
    sendView(view, false, this.viewResponses);
  }",True
"  boolean sendView(NetView view, Collection<InternalDistributedMember> newMembers, boolean preparing, ViewReplyProcessor rp) {
    int id = view.getViewId();
    InstallViewMessage msg = new InstallViewMessage(view, services.getAuthenticator().getCredentials(), preparing);
    Set<InternalDistributedMember> recips = new HashSet<InternalDistributedMember>(view.getMembers());
    recips.removeAll(newMembers); // new members get the view in a JoinResponseMessage
    recips.remove(this.localAddress); // no need to send it to ourselves
    installView(view);
    recips.addAll(view.getCrashedMembers());
    if (recips.isEmpty()) {
      return true;
    }
    msg.setRecipients(recips);
    rp.initialize(id, recips);

    logger.info((preparing? ""preparing"" : ""sending"") + "" new view "" + view);
    services.getMessenger().send(msg);

    // only wait for responses during preparation
    if (preparing) {
      Set<InternalDistributedMember> failedToRespond = rp.waitForResponses();

      logger.info(""View Creator is finished waiting for responses to view preparation"");
      
      InternalDistributedMember conflictingViewSender = rp.getConflictingViewSender();
      NetView conflictingView = rp.getConflictingView();
      if (conflictingView != null) {
        logger.warn(""View Creator received a conflicting membership view from "" + conflictingViewSender
            + "" during preparation: "" + conflictingView);
        return false;
      }
      
      if (!failedToRespond.isEmpty()  &&  (services.getCancelCriterion().cancelInProgress() == null)) {
        logger.warn(""these members failed to respond to the view change: "" + failedToRespond);
        return false;
      }
    }
    
    return true;
  }",False
"  public void init(Services s) {
    this.services = s;
    services.getMessenger().addHandler(JoinRequestMessage.class, this);
    services.getMessenger().addHandler(JoinResponseMessage.class, this);
    services.getMessenger().addHandler(InstallViewMessage.class, this);
    services.getMessenger().addHandler(ViewAckMessage.class, this);
    services.getMessenger().addHandler(LeaveRequestMessage.class, this);
    services.getMessenger().addHandler(RemoveMemberMessage.class, this);

    DistributionConfig dc = services.getConfig().getDistributionConfig();
    int ackCollectionTimeout = dc.getMemberTimeout() * 2 * 12437 / 10000;
    if (ackCollectionTimeout < 1500) {
      ackCollectionTimeout = 1500;
    } else if (ackCollectionTimeout > 12437) {
      ackCollectionTimeout = 12437;
    }
    ackCollectionTimeout = Integer.getInteger(""gemfire.VIEW_ACK_TIMEOUT"", ackCollectionTimeout).intValue();
    this.viewAckTimeout = ackCollectionTimeout;
    
    this.quorumRequired = services.getConfig().getDistributionConfig().getEnableNetworkPartitionDetection();
    
  }",True
"  public void init(Services s) {
    this.services = s;
    services.getMessenger().addHandler(JoinRequestMessage.class, this);
    services.getMessenger().addHandler(JoinResponseMessage.class, this);
    services.getMessenger().addHandler(InstallViewMessage.class, this);
    services.getMessenger().addHandler(ViewAckMessage.class, this);
    services.getMessenger().addHandler(LeaveRequestMessage.class, this);
    services.getMessenger().addHandler(RemoveMemberMessage.class, this);
    services.getMessenger().addHandler(JoinRequestMessage.class, this);
    services.getMessenger().addHandler(JoinResponseMessage.class, this);

    DistributionConfig dc = services.getConfig().getDistributionConfig();
    int ackCollectionTimeout = dc.getMemberTimeout() * 2 * 12437 / 10000;
    if (ackCollectionTimeout < 1500) {
      ackCollectionTimeout = 1500;
    } else if (ackCollectionTimeout > 12437) {
      ackCollectionTimeout = 12437;
    }
    ackCollectionTimeout = Integer.getInteger(""gemfire.VIEW_ACK_TIMEOUT"", ackCollectionTimeout).intValue();
    this.viewAckTimeout = ackCollectionTimeout;
    
    this.quorumRequired = services.getConfig().getDistributionConfig().getEnableNetworkPartitionDetection();
    
    DistributionConfig dconfig = services.getConfig().getDistributionConfig();
    String bindAddr = dconfig.getBindAddress();
    locators = GMSUtil.parseLocators(dconfig.getLocators(), bindAddr);
  }",False
"  boolean prepareView(NetView view) {
    return sendView(view, true, this.prepareResponses);
  }",True
"  public boolean join() {
    for (int tries=0; tries<JOIN_ATTEMPTS; tries++) {
      InternalDistributedMember coord = findCoordinator();
      logger.debug(""found possible coordinator {}"", coord);
      if (coord != null) {
        if (coord.equals(this.localAddress)) {
          if (tries > (JOIN_ATTEMPTS/2)) {
            becomeCoordinator();
            return true;
          }
        } else {
          if (attemptToJoin(coord)) {
            return true;
          } 
        }
      }
      try {
        Thread.sleep(JOIN_RETRY_SLEEP);
      } catch (InterruptedException e) {
        return false;
      }
    } // for
    return this.isConnected;
  }",True
"  public boolean join() {

    if (this.localAddress.getVmKind() == LOCATOR_DM_TYPE
        && Boolean.getBoolean(""gemfire.first-member"")) {
      becomeCoordinator();
      return true;
    }

    for (int tries=0; tries<JOIN_ATTEMPTS; tries++) {
      InternalDistributedMember coord = findCoordinator();
      logger.debug(""found possible coordinator {}"", coord);
      if (coord != null) {
        if (coord.equals(this.localAddress)) {
          if (tries > (JOIN_ATTEMPTS/2)) {
            becomeCoordinator();
            return true;
          }
        } else {
          if (attemptToJoin(coord)) {
            return true;
          } 
        }
      }
      try {
        Thread.sleep(JOIN_RETRY_SLEEP);
      } catch (InterruptedException e) {
        return false;
      }
    } // for
    return this.isJoined;
  }",False
"  public void processMessage(DistributionMessage m) {
    if (isStopping) {
      return;
    }
    logger.debug(""JoinLeave processing {}"", m);
    if (m instanceof JoinRequestMessage) {
      processJoinRequest((JoinRequestMessage)m);
    } else if (m instanceof JoinResponseMessage) {
      processJoinResponse((JoinResponseMessage)m);
    } else if (m instanceof InstallViewMessage) {
      processViewMessage((InstallViewMessage)m);
    } else if (m instanceof ViewAckMessage) {
      processViewAckMessage((ViewAckMessage)m);
    } else if (m instanceof LeaveRequestMessage) {
      processLeaveRequest((LeaveRequestMessage)m);
    } else if (m instanceof RemoveMemberMessage) {
      processRemoveRequest((RemoveMemberMessage)m);
    } else {
      throw new IllegalArgumentException(""unknown message type: "" + m);
    }
  }",True
"  public void processMessage(DistributionMessage m) {
    if (isStopping) {
      return;
    }
    logger.debug(""JoinLeave processing {}"", m);
    switch (m.getDSFID()) {
    case JOIN_REQUEST:
      processJoinRequest((JoinRequestMessage)m);
      break;
    case JOIN_RESPONSE:
      processJoinResponse((JoinResponseMessage)m);
      break;
    case INSTALL_VIEW_MESSAGE:
      processViewMessage((InstallViewMessage)m);
      break;
    case VIEW_ACK_MESSAGE:
      processViewAckMessage((ViewAckMessage)m);
      break;
    case LEAVE_REQUEST_MESSAGE:
      processLeaveRequest((LeaveRequestMessage)m);
      break;
    case REMOVE_MEMBER_MESSAGE:
      processRemoveRequest((RemoveMemberMessage)m);
      break;
    default:
      throw new IllegalArgumentException(""unknown message type: "" + m);
    }
  }",False
"  public void remove(InternalDistributedMember m, String reason) {
    NetView v = this.currentView;
    if (v != null) {
      RemoveMemberMessage msg = new RemoveMemberMessage(v.getCoordinator(), m,
          reason);
      try {
        services.getMessenger().send(msg);
      } catch (IOException e) {
        logger.info(""JoinLeave was unable to remove member "" + m + "" due to an i/o exception"");
      }
    }
  }",True
"  public void remove(InternalDistributedMember m, String reason) {
    NetView v = this.currentView;
    if (v != null) {
      RemoveMemberMessage msg = new RemoveMemberMessage(v.getCoordinator(), m,
          reason);
      services.getMessenger().send(msg);
    }
  }",False
"  private InternalDistributedMember findCoordinator() {
    if (locators == null) {
      DistributionConfig dconfig = services.getConfig().getDistributionConfig();
      String bindAddr = dconfig.getBindAddress();
      locators = GMSUtil.parseLocators(dconfig.getLocators(), bindAddr);
    }

    assert this.localAddress != null;
    
    FindCoordinatorRequest request = new FindCoordinatorRequest(this.localAddress);
    Set<InternalDistributedMember> coordinators = new HashSet<InternalDistributedMember>();
    long giveUpTime = System.currentTimeMillis() + (services.getConfig().getLocatorWaitTime() * 1000L);
    boolean anyResponses = false;
    
    do {
      for (InetSocketAddress addr: locators) { 
        try {
          Object o = TcpClient.requestToServer(
              addr.getAddress(), addr.getPort(), request, services.getConfig().getJoinTimeout(), 
              true);
          FindCoordinatorResponse response = (o instanceof FindCoordinatorResponse) ? (FindCoordinatorResponse)o : null;
          if (response != null && response.getCoordinator() != null) {
            anyResponses = false;
            coordinators.add(response.getCoordinator());
            GMSMember mbr = (GMSMember)this.localAddress.getNetMember();
            services.getConfig().setNetworkPartitionDetectionEnabled(response.isNetworkPartitionDetectionEnabled());
            if (response.isUsePreferredCoordinators()
                && localAddress.getVmKind() != DistributionManager.LOCATOR_DM_TYPE) {
              mbr.setPreferredForCoordinator(false);
            }
          }
        } catch (IOException | ClassNotFoundException problem) {
        }
      }
      if (coordinators.isEmpty()) {
        return null;
      }
      if (!anyResponses) {
        try { Thread.sleep(2000); } catch (InterruptedException e) {
          Thread.currentThread().interrupt();
          return null;
        }
      }
    } while (!anyResponses && System.currentTimeMillis() < giveUpTime);
    
    Iterator<InternalDistributedMember> it = coordinators.iterator();
    if (coordinators.size() == 1) {
      return it.next();
    }
    InternalDistributedMember oldest = it.next();
    while (it.hasNext()) {
      InternalDistributedMember candidate = it.next();
      if (oldest.compareTo(candidate) > 0) {
        oldest = candidate;
      }
    }
    return oldest;
  }",True
"  private InternalDistributedMember findCoordinator() {
    assert this.localAddress != null;
    
    FindCoordinatorRequest request = new FindCoordinatorRequest(this.localAddress);
    Set<InternalDistributedMember> coordinators = new HashSet<InternalDistributedMember>();
    long giveUpTime = System.currentTimeMillis() + (services.getConfig().getLocatorWaitTime() * 1000L);
    boolean anyResponses = false;
    
    do {
      for (InetSocketAddress addr: locators) { 
        try {
          Object o = TcpClient.requestToServer(
              addr.getAddress(), addr.getPort(), request, services.getConfig().getJoinTimeout(), 
              true);
          FindCoordinatorResponse response = (o instanceof FindCoordinatorResponse) ? (FindCoordinatorResponse)o : null;
          if (response != null && response.getCoordinator() != null) {
            anyResponses = false;
            coordinators.add(response.getCoordinator());
            if (response.isFromView()) {
              GMSMember mbr = (GMSMember)this.localAddress.getNetMember();
              services.getConfig().setNetworkPartitionDetectionEnabled(response.isNetworkPartitionDetectionEnabled());
              if (response.isUsePreferredCoordinators()
                  && localAddress.getVmKind() != DistributionManager.LOCATOR_DM_TYPE) {
                mbr.setPreferredForCoordinator(false);
              }
            }
          }
        } catch (IOException | ClassNotFoundException problem) {
        }
      }
      if (coordinators.isEmpty()) {
        return null;
      }
      if (!anyResponses) {
        try { Thread.sleep(2000); } catch (InterruptedException e) {
          Thread.currentThread().interrupt();
          return null;
        }
      }
    } while (!anyResponses && System.currentTimeMillis() < giveUpTime);
    
    Iterator<InternalDistributedMember> it = coordinators.iterator();
    if (coordinators.size() == 1) {
      return it.next();
    }
    InternalDistributedMember oldest = it.next();
    while (it.hasNext()) {
      InternalDistributedMember candidate = it.next();
      if (oldest.compareTo(candidate) > 0) {
        oldest = candidate;
      }
    }
    return oldest;
  }",False
"  private void processViewMessage(InstallViewMessage m) {
    NetView view = m.getView();
    
    if (currentView != null  &&  view.getViewId() < currentView.getViewId()) {
      // ignore old views
      ackView(m);
      return;
    }
    
    
    if (m.isPreparing()) {
      if (this.preparedView != null && this.preparedView.getViewId() >= view.getViewId()) {
        try {
          services.getMessenger().send(new ViewAckMessage(m.getSender(), this.preparedView));
        } catch (IOException e) {
          logger.info(""unable to send view response to "" + m.getSender(), e);
        }
      }
      else {
        this.preparedView = view;
        ackView(m);
      }
    }
    else { // !preparing
      if (currentView != null  &&  !view.contains(this.localAddress)) {
        if (quorumRequired) {
          services.getManager().forceDisconnect(""This node is no longer in the membership view"");
        }
      }
      else {
        ackView(m);
        installView(view);
      }
    }
  }",True
"  private void processViewMessage(InstallViewMessage m) {
    NetView view = m.getView();
    
    if (currentView != null  &&  view.getViewId() < currentView.getViewId()) {
      // ignore old views
      ackView(m);
      return;
    }
    
    
    if (m.isPreparing()) {
      if (this.preparedView != null && this.preparedView.getViewId() >= view.getViewId()) {
        services.getMessenger().send(new ViewAckMessage(m.getSender(), this.preparedView));
      }
      else {
        this.preparedView = view;
        ackView(m);
      }
    }
    else { // !preparing
      if (currentView != null  &&  !view.contains(this.localAddress)) {
        if (quorumRequired) {
          services.getManager().forceDisconnect(""This node is no longer in the membership view"");
        }
      }
      else {
        ackView(m);
        installView(view);
      }
    }
  }",False
"    void initialize(int viewId, Set<InternalDistributedMember> recips) {
      this.waiting = true;
      this.viewId = viewId;
      this.recipients = recips;
    }",True
"    void initialize(int viewId, Set<InternalDistributedMember> recips) {
      this.waiting = true;
      this.viewId = viewId;
      this.recipients = recips;
      this.conflictingView = null;
    }",False
"  private void becomeCoordinator() {
    becomeCoordinator(null);
  }",True
"  private void becomeCoordinator(InternalDistributedMember oldCoordinator) {
    stateLock.writeLock().lock();
    try {
      if (isCoordinator) {
        return;
      }
      logger.info(""This member is becoming the membership coordinator with address {}"", localAddress);
      isCoordinator = true;
      if (currentView == null) {
        // create the initial membership view
        NetView newView = new NetView(this.localAddress);
        this.localAddress.setVmViewId(0);
        installView(newView);
        isJoined = true;
        startCoordinatorServices();
      } else {
        // create and send out a new view
        NetView newView;
        synchronized(viewInstallationLock) {
          int viewNumber = currentView.getViewId() + 5;
          List<InternalDistributedMember> mbrs = new ArrayList<InternalDistributedMember>(currentView.getMembers());
          mbrs.add(localAddress);
          List<InternalDistributedMember> leaving = new ArrayList<InternalDistributedMember>();
          if (oldCoordinator != null) {
            leaving.add(oldCoordinator);
          }
          newView = new NetView(this.localAddress, viewNumber, mbrs, leaving,
              Collections.<InternalDistributedMember>emptyList());
        }
        sendView(newView, Collections.<InternalDistributedMember>emptyList());
        startCoordinatorServices();
      }
    } finally {
      stateLock.writeLock().unlock();
    }
  }",False
"    void processViewResponse(int viewId, InternalDistributedMember sender, NetView conflictingView) {
      if (!this.waiting) {
        return;
      }
      
      if (viewId == this.viewId) {
        if (conflictingView != null) {
          this.conflictingViewSender = sender;
          this.conflictingView = conflictingView;
        }
        Set<InternalDistributedMember> waitingFor = this.recipients;
        waitingFor.remove(sender);
        if (waitingFor.isEmpty()) {
          synchronized(waitingFor) {
            waitingFor.notify();
          }
        }
      }
      
    }",True
"    void processViewResponse(int viewId, InternalDistributedMember sender, NetView conflictingView) {
      if (!this.waiting) {
        return;
      }
      
      if (viewId == this.viewId) {
        if (conflictingView != null) {
          this.conflictingViewSender = sender;
          this.conflictingView = conflictingView;
        }

        Set<InternalDistributedMember> waitingFor = this.recipients;
        synchronized(waitingFor) {
          waitingFor.remove(sender);
          if (waitingFor.isEmpty()) {
            logger.debug(""All view responses received - notifying waiting thread"");
            waitingFor.notify();
          }
        }

      }
    }",False
"  boolean prepareView(NetView view, Collection<InternalDistributedMember> newMembers) {
    return sendView(view, newMembers, true, this.prepareProcessor);
  }",False
"  public void leave() {
    synchronized(viewInstallationLock) {
      NetView view = currentView;
      isStopping = true;
      if (view != null) {
        if (view.size() > 1) {
          if (this.isCoordinator) {
            logger.debug(""JoinLeave stopping coordination services"");
            stopCoordinatorServices();
            NetView newView = new NetView(view, view.getViewId()+1);
            newView.remove(localAddress);
            InstallViewMessage m = new InstallViewMessage(newView, services.getAuthenticator().getCredentials());
            m.setRecipients(newView.getMembers());
            try {
              services.getMessenger().send(m);
              try { Thread.sleep(LEAVE_MESSAGE_SLEEP_TIME); }
              catch (InterruptedException e) { Thread.currentThread().interrupt(); }
            } catch (IOException e) {
              logger.info(""JoinLeave: unable to notify remaining members shutdown due to i/o exception"", e);
            }
          }
          else {
            logger.debug(""JoinLeave sending a leave request to {}"", view.getCoordinator());
            LeaveRequestMessage m = new LeaveRequestMessage(view.getCoordinator(), this.localAddress);
            try {
              services.getMessenger().send(m);
            } catch (IOException e) {
              logger.info(""JoinLeave: unable to notify membership coordinator of shutdown due to i/o exception"", e);
            }
          }
        } // view.size
      }// view != null
    }
      
  }",True
"  public void leave() {
    synchronized(viewInstallationLock) {
      NetView view = currentView;
      isStopping = true;
      if (view != null) {
        if (view.size() > 1) {
          if (this.isCoordinator) {
            logger.debug(""JoinLeave stopping coordination services"");
            stopCoordinatorServices();
            NetView newView = new NetView(view, view.getViewId()+1);
            newView.remove(localAddress);
            InstallViewMessage m = new InstallViewMessage(newView, services.getAuthenticator().getCredentials());
            m.setRecipients(newView.getMembers());
            services.getMessenger().send(m);
            try { Thread.sleep(LEAVE_MESSAGE_SLEEP_TIME); }
            catch (InterruptedException e) { Thread.currentThread().interrupt(); }
          }
          else {
            logger.debug(""JoinLeave sending a leave request to {}"", view.getCoordinator());
            LeaveRequestMessage m = new LeaveRequestMessage(view.getCoordinator(), this.localAddress);
            services.getMessenger().send(m);
          }
        } // view.size
      }// view != null
    }
      
  }",False
"  public void emergencyClose() {
    isStopping = true;
    isConnected = false;
    stopCoordinatorServices();
    isCoordinator = false;
    currentView = null;
  }",True
"  public void emergencyClose() {
    isStopping = true;
    isJoined = false;
    stopCoordinatorServices();
    isCoordinator = false;
    currentView = null;
  }",False
"  private void processViewAckMessage(ViewAckMessage m) {
    if (m.isPrepareAck()) {
      this.prepareResponses.processViewResponse(m.getViewId(), m.getSender(), m.getAlternateView());
    } else {
      this.viewResponses.processViewResponse(m.getViewId(), m.getSender(), m.getAlternateView());
    }
  }",True
"  private void processViewAckMessage(ViewAckMessage m) {
    if (m.isPrepareAck()) {
      this.prepareProcessor.processViewResponse(m.getViewId(), m.getSender(), m.getAlternateView());
    } else {
      this.viewProcessor.processViewResponse(m.getViewId(), m.getSender(), m.getAlternateView());
    }
  }",False
"  private boolean attemptToJoin(InternalDistributedMember coord) {
    // send a join request to the coordinator and wait for a response
    logger.info(""Attempting to join the distributed system through coordinator "" + coord + "" using address "" + this.localAddress);
    JoinRequestMessage req = new JoinRequestMessage(coord, this.localAddress, 
        services.getAuthenticator().getCredentials());
    try {
      services.getMessenger().send(req);
    } catch (IOException e) {
      throw new SystemConnectException(""Exception caught while trying to join"", e);
    }
    JoinResponseMessage response = null;
    synchronized(joinResponse) {
      if (joinResponse[0] == null) {
        try {
          joinResponse.wait(services.getConfig().getJoinTimeout()/JOIN_ATTEMPTS);
        } catch (InterruptedException e) {
          Thread.currentThread().interrupt();
          return false;
        }
      }
      response = joinResponse[0];
    }
    if (response != null) {
      joinResponse[0] = null;
      String failReason = response.getRejectionMessage();
      if (failReason != null) {
        if (failReason.contains(""Rejecting the attempt of a member using an older version"")
            || failReason.contains(""15806"")) {
          throw new SystemConnectException(failReason);
        }
        throw new AuthenticationFailedException(failReason);
      }
      if (response.getCurrentView() != null) {
        this.birthViewId = response.getMemberID().getVmViewId();
        this.localAddress.setVmViewId(this.birthViewId);
        GMSMember me = (GMSMember)this.localAddress.getNetMember();
        GMSMember o = (GMSMember)response.getMemberID().getNetMember();
        me.setSplitBrainEnabled(o.isSplitBrainEnabled());
        me.setPreferredForCoordinator(o.preferredForCoordinator());
        installView(response.getCurrentView());
        return true;
      }
    }
    return false;
  }",True
"  private boolean attemptToJoin(InternalDistributedMember coord) {
    // send a join request to the coordinator and wait for a response
    logger.info(""Attempting to join the distributed system through coordinator "" + coord + "" using address "" + this.localAddress);
    JoinRequestMessage req = new JoinRequestMessage(coord, this.localAddress, 
        services.getAuthenticator().getCredentials());

    services.getMessenger().send(req);
    
    JoinResponseMessage response = null;
    synchronized(joinResponse) {
      if (joinResponse[0] == null) {
        try {
          joinResponse.wait(services.getConfig().getJoinTimeout()/JOIN_ATTEMPTS);
        } catch (InterruptedException e) {
          Thread.currentThread().interrupt();
          return false;
        }
      }
      response = joinResponse[0];
    }
    if (response != null) {
      joinResponse[0] = null;
      String failReason = response.getRejectionMessage();
      if (failReason != null) {
        if (failReason.contains(""Rejecting the attempt of a member using an older version"")
            || failReason.contains(""15806"")) {
          throw new SystemConnectException(failReason);
        }
        throw new AuthenticationFailedException(failReason);
      }
      if (response.getCurrentView() != null) {
        this.birthViewId = response.getMemberID().getVmViewId();
        this.localAddress.setVmViewId(this.birthViewId);
        GMSMember me = (GMSMember)this.localAddress.getNetMember();
        GMSMember o = (GMSMember)response.getMemberID().getNetMember();
        me.setSplitBrainEnabled(o.isSplitBrainEnabled());
        me.setPreferredForCoordinator(o.preferredForCoordinator());
        installView(response.getCurrentView());
        return true;
      }
    }
    return false;
  }",False
"  private void sendJoinResponses(List<InternalDistributedMember> newMbrs, NetView newView) {
    for (InternalDistributedMember mbr: newMbrs) {
      JoinResponseMessage response = new JoinResponseMessage(mbr, newView);
      try {
        services.getMessenger().send(response);
      } catch (IOException e) {
        logger.info(""unable to send join response to {}"", mbr);
      }
    }
  }",True
"  private void sendJoinResponses(List<InternalDistributedMember> newMbrs, NetView newView) {
    for (InternalDistributedMember mbr: newMbrs) {
      JoinResponseMessage response = new JoinResponseMessage(mbr, newView);
      services.getMessenger().send(response);
    }
  }",False
"  void sendView(NetView view, Collection<InternalDistributedMember> newMembers) {
    sendView(view, newMembers, false, this.viewProcessor);
  }",False
"    private void removeHealthyMembers(Collection<InternalDistributedMember> mbrs) throws InterruptedException {
      List<Callable<InternalDistributedMember>> checkers = new ArrayList<Callable<InternalDistributedMember>>(mbrs.size()); 
      
      for (InternalDistributedMember mbr: mbrs) {
        final InternalDistributedMember fmbr = mbr;
        checkers.add(new Callable<InternalDistributedMember>() {
          @Override
          public InternalDistributedMember call() throws Exception {
            // return the member id if it fails health checks
            logger.info(""checking state of member "" + fmbr);
            if (services.getHealthMonitor().checkIfAvailable(fmbr, ""Member failed to acknowledge a membership view"", false)) {
              logger.info(""member "" + fmbr + "" passed availability check"");
              return null;
            }
            logger.info(""member "" + fmbr + "" failed availability check"");
            return fmbr;
          }
        });
      }
      
      ExecutorService svc = Executors.newFixedThreadPool(mbrs.size(), new ThreadFactory() {
        AtomicInteger i = new AtomicInteger();
        @Override
        public Thread newThread(Runnable r) {
          return new Thread(Services.getThreadGroup(), r,
              ""Member verification thread "" + i.incrementAndGet());
        }
      });

      try {
        List<Future<InternalDistributedMember>> futures;
        futures = svc.invokeAll(checkers);

        for (Future<InternalDistributedMember> future: futures) {
          try {
            InternalDistributedMember mbr = future.get(viewAckTimeout, TimeUnit.MILLISECONDS);
            if (mbr != null) {
              logger.debug(""disregarding lack of acknowledgement from {}"", mbr);
              mbrs.remove(mbr);
            }
          } catch (java.util.concurrent.TimeoutException e) {
            // TODO should the member be removed if we can't verify it in time?
          } catch (ExecutionException e) {
            logger.info(""unexpected exception caught during member verification"", e);
          }
        }
      } finally {
        svc.shutdownNow();
      }
    }",True
"    private void removeHealthyMembers(Collection<InternalDistributedMember> mbrs) throws InterruptedException {
      List<Callable<InternalDistributedMember>> checkers = new ArrayList<Callable<InternalDistributedMember>>(mbrs.size()); 
      
      for (InternalDistributedMember mbr: mbrs) {
        final InternalDistributedMember fmbr = mbr;
        checkers.add(new Callable<InternalDistributedMember>() {
          @Override
          public InternalDistributedMember call() throws Exception {
            // return the member id if it fails health checks
            logger.info(""checking state of member "" + fmbr);
            if (services.getHealthMonitor().checkIfAvailable(fmbr, ""Member failed to acknowledge a membership view"", false)) {
              logger.info(""member "" + fmbr + "" passed availability check"");
              return fmbr;
            }
            logger.info(""member "" + fmbr + "" failed availability check"");
            return null;
          }
        });
      }
      
      ExecutorService svc = Executors.newFixedThreadPool(mbrs.size(), new ThreadFactory() {
        AtomicInteger i = new AtomicInteger();
        @Override
        public Thread newThread(Runnable r) {
          return new Thread(Services.getThreadGroup(), r,
              ""Member verification thread "" + i.incrementAndGet());
        }
      });

      try {
        List<Future<InternalDistributedMember>> futures;
        futures = svc.invokeAll(checkers);

        for (Future<InternalDistributedMember> future: futures) {
          try {
            InternalDistributedMember mbr = future.get(viewAckTimeout, TimeUnit.MILLISECONDS);
            if (mbr != null) {
              logger.debug(""disregarding lack of acknowledgement from {}"", mbr);
              mbrs.remove(mbr);
            }
          } catch (java.util.concurrent.TimeoutException e) {
            // TODO should the member be removed if we can't verify it in time?
          } catch (ExecutionException e) {
            logger.info(""unexpected exception caught during member verification"", e);
          }
        }
      } finally {
        svc.shutdownNow();
      }
    }",False
"  private void processJoinRequest(JoinRequestMessage incomingRequest) {
    if (incomingRequest.getMemberID().getVersionObject().compareTo(Version.CURRENT) < 0) {
      logger.warn(""detected an attempt to start a peer using an older version of the product {}"",
          incomingRequest.getMemberID());
      JoinResponseMessage m = new JoinResponseMessage(""Rejecting the attempt of a member using an older version"");
      m.setRecipient(incomingRequest.getMemberID());
      try {
        services.getMessenger().send(m);
      } catch (IOException e) {
        //ignore - the attempt has been logged and the member can't join
      }
      return;
    }
    Object creds = incomingRequest.getCredentials();
    if (creds != null) {
      String rejection = null;
      try {
        rejection = services.getAuthenticator().authenticate(incomingRequest.getMemberID(), creds);
      } catch (Exception e) {
        rejection = e.getMessage();
      }
      if (rejection != null  &&  rejection.length() > 0) {
        JoinResponseMessage m = new JoinResponseMessage(rejection);
        m.setRecipient(incomingRequest.getMemberID());
        try {
          services.getMessenger().send(m);
        } catch (IOException e2) {
          logger.info(""unable to send join response "" + rejection + "" to "" + incomingRequest.getMemberID(), e2);
        }
      }
    }
    recordViewRequest(incomingRequest);
  }",True
"  private void processJoinRequest(JoinRequestMessage incomingRequest) {
    if (incomingRequest.getMemberID().getVersionObject().compareTo(Version.CURRENT) < 0) {
      logger.warn(""detected an attempt to start a peer using an older version of the product {}"",
          incomingRequest.getMemberID());
      JoinResponseMessage m = new JoinResponseMessage(""Rejecting the attempt of a member using an older version"");
      m.setRecipient(incomingRequest.getMemberID());
      services.getMessenger().send(m);
      return;
    }
    Object creds = incomingRequest.getCredentials();
    if (creds != null) {
      String rejection = null;
      try {
        rejection = services.getAuthenticator().authenticate(incomingRequest.getMemberID(), creds);
      } catch (Exception e) {
        rejection = e.getMessage();
      }
      if (rejection != null  &&  rejection.length() > 0) {
        JoinResponseMessage m = new JoinResponseMessage(rejection);
        m.setRecipient(incomingRequest.getMemberID());
        services.getMessenger().send(m);
      }
    }
    recordViewRequest(incomingRequest);
  }",False
"  private void sendRemoveMessages(List<InternalDistributedMember> newMbrs,
      List<String> reasons, NetView newView) {
    Iterator<String> reason = reasons.iterator();
    for (InternalDistributedMember mbr: newMbrs) {
      RemoveMemberMessage response = new RemoveMemberMessage(mbr, mbr, reason.next());
      try {
        services.getMessenger().send(response);
      } catch (IOException e) {
        logger.info(""unable to send remove message to {}"", mbr);
      }
    }
  }",True
"  private void sendRemoveMessages(List<InternalDistributedMember> newMbrs,
      List<String> reasons, NetView newView) {
    Iterator<String> reason = reasons.iterator();
    for (InternalDistributedMember mbr: newMbrs) {
      RemoveMemberMessage response = new RemoveMemberMessage(mbr, mbr, reason.next());
      services.getMessenger().send(response);
    }
  }",False
"    sendView(view, newMembers, false, this.viewProcessor);
  }
  
  
  boolean sendView(NetView view, Collection<InternalDistributedMember> newMembers, boolean preparing, ViewReplyProcessor rp) {
    int id = view.getViewId();
    InstallViewMessage msg = new InstallViewMessage(view, services.getAuthenticator().getCredentials(), preparing);
    Set<InternalDistributedMember> recips = new HashSet<InternalDistributedMember>(view.getMembers());
    recips.removeAll(newMembers); // new members get the view in a JoinResponseMessage
    recips.remove(this.localAddress); // no need to send it to ourselves
    installView(view);
    recips.addAll(view.getCrashedMembers());
    if (recips.isEmpty()) {
      return true;
    }
    msg.setRecipients(recips);
    rp.initialize(id, recips);

    logger.info((preparing? ""preparing"" : ""sending"") + "" new view "" + view);
    services.getMessenger().send(msg);

    // only wait for responses during preparation
    if (preparing) {
      Set<InternalDistributedMember> failedToRespond = rp.waitForResponses();

      logger.info(""View Creator is finished waiting for responses to view preparation"");
      
      InternalDistributedMember conflictingViewSender = rp.getConflictingViewSender();
      NetView conflictingView = rp.getConflictingView();
      if (conflictingView != null) {
        logger.warn(""View Creator received a conflicting membership view from "" + conflictingViewSender
            + "" during preparation: "" + conflictingView);
        return false;
      }
      
      if (!failedToRespond.isEmpty()  &&  (services.getCancelCriterion().cancelInProgress() == null)) {
        logger.warn(""these members failed to respond to the view change: "" + failedToRespond);
        return false;",False
"  public JoinRequestMessage(InternalDistributedMember coord, InternalDistributedMember id, Object credentials) {
    super();
    setRecipient(coord);
    this.memberID = id;
    this.credentials = credentials;
  }",True
"  public JoinRequestMessage(InternalDistributedMember coord,
      InternalDistributedMember id, Object credentials) {
    super();
    setRecipient(coord);
    this.memberID = id;
    this.credentials = credentials;
  }",False
"  public void fromData(DataInput in) throws IOException, ClassNotFoundException {
    memberID = DataSerializer.readObject(in);
    credentials = DataSerializer.readObject(in);
  }",True
"  public void fromData(DataInput in) throws IOException, ClassNotFoundException {
    memberID = DataSerializer.readObject(in);
    credentials = DataSerializer.readObject(in);
    setMulticast(in.readBoolean());
  }",False
"  public void toData(DataOutput out) throws IOException {
    DataSerializer.writeObject(memberID, out);
    DataSerializer.writeObject(credentials, out);
  }",True
"  public void toData(DataOutput out) throws IOException {
    DataSerializer.writeObject(memberID, out);
    DataSerializer.writeObject(credentials, out);
    // preserve the multicast setting so the receiver can tell
    // if this is a mcast join request
    out.writeBoolean(getMulticast());
  }",False
"  public Object getMessengerData() {
    return this.messengerData;
  }",False
"  public void toData(DataOutput out) throws IOException {
    DataSerializer.writeObject(currentView, out);
    DataSerializer.writeObject(memberID, out);
    DataSerializer.writeString(rejectionMessage, out);
  }",True
"  public void toData(DataOutput out) throws IOException {
    DataSerializer.writeObject(currentView, out);
    DataSerializer.writeObject(memberID, out);
    DataSerializer.writeString(rejectionMessage, out);
    DataSerializer.writeObject(messengerData, out);
  }",False
"  public void setMessengerData(Object data) {
    this.messengerData = data;
  }",False
"  public void fromData(DataInput in) throws IOException, ClassNotFoundException {
    currentView = DataSerializer.readObject(in);
    memberID = DataSerializer.readObject(in);
    rejectionMessage = DataSerializer.readString(in);
  }",True
"  public void fromData(DataInput in) throws IOException, ClassNotFoundException {
    currentView = DataSerializer.readObject(in);
    memberID = DataSerializer.readObject(in);
    rejectionMessage = DataSerializer.readString(in);
    messengerData = DataSerializer.readObject(in);
  }",False
"  private void filterIncomingMessage(DistributionMessage m) {
    switch (m.getDSFID()) {
    case JOIN_RESPONSE:
      JoinResponseMessage jrsp = (JoinResponseMessage)m;
      
      if (jrsp.getRejectionMessage() != null
          &&  services.getConfig().getTransport().isMcastEnabled()) {
        Digest digest = (Digest)jrsp.getMessengerData();
        if (digest != null) {
          this.myChannel.getProtocolStack()
              .getTopProtocol().down(new Event(Event.SET_DIGEST, digest));
        }
      }
      break;
    default:
      break;
    }
  }",False
"  private void filterOutgoingMessage(DistributionMessage m) {
    switch (m.getDSFID()) {
    case JOIN_RESPONSE:
      JoinResponseMessage jrsp = (JoinResponseMessage)m;
      
      if (jrsp.getRejectionMessage() != null
          &&  services.getConfig().getTransport().isMcastEnabled()) {
        // get the multicast message digest and pass it with the join response
        Digest digest = (Digest)this.myChannel.getProtocolStack()
            .getTopProtocol().down(Event.GET_DIGEST_EVT);
        jrsp.setMessengerData(digest);
      }
      break;
    default:
      break;
    }
  }",False
"  public Set<InternalDistributedMember> send(DistributionMessage msg) {
    
    // perform the same jgroups messaging as in 8.2's GMSMembershipManager.send() method

    // BUT: when marshalling messages we need to include the version of the product and
    // localAddress at the beginning of the message.  These should be used in the receiver
    // code to create a versioned input stream, read the sender address, then read the message
    // and set its sender address
    DMStats theStats = services.getStatistics();

    if (!myChannel.isConnected()) {
      throw new DistributedSystemDisconnectedException(""Distributed System is shutting down"");
    }
    
    filterMessage(msg);
    
    logger.debug(""Membership: sending message via JGroups: {} recipients: {}"", msg, msg.getRecipientsDescription());
    
    InternalDistributedMember[] destinations = msg.getRecipients();
    boolean allDestinations = msg.forAll();
    
    boolean useMcast = false;
    if (services.getConfig().getTransport().isMcastEnabled()) {
      useMcast = !services.getManager().isMulticastAllowed()
          && (msg.getMulticast() || allDestinations);
    }
    
    JGAddress local = this.jgAddress;
    
    if (useMcast) {
      if (logger.isTraceEnabled())
        logger.trace(""Membership: sending message via multicast"");

      Exception problem = null;
      try {
        long startSer = theStats.startMsgSerialization();
        Message jmsg = createJGMessage(msg, local, Version.CURRENT_ORDINAL);
        theStats.endMsgSerialization(startSer);
        theStats.incSentBytes(jmsg.getLength());
        myChannel.send(jmsg);
      }
      catch (IllegalArgumentException e) {
        problem = e;
      }
      catch (Exception e) {
        logger.info(""caught unexpected exception"", e);
        Throwable cause = e.getCause();
        if (cause instanceof ForcedDisconnectException) {
          problem = (Exception) cause;
        } else {
          problem = e;
        }
      }
      if (problem != null) {
        if (services.getManager().getShutdownCause() != null) {
          Throwable cause = services.getManager().getShutdownCause();
          // If ForcedDisconnectException occurred then report it as actual
          // problem.
          if (cause instanceof ForcedDisconnectException) {
            problem = (Exception) cause;
          } else {
            Throwable ne = problem;
            while (ne.getCause() != null) {
              ne = ne.getCause();
            }
            ne.initCause(services.getManager().getShutdownCause());
          }
        }
        final String channelClosed = LocalizedStrings.GroupMembershipService_CHANNEL_CLOSED.toLocalizedString();
        services.getManager().membershipFailure(channelClosed, problem);
        throw new DistributedSystemDisconnectedException(channelClosed, problem);
      }
    } // useMcast
    else { // ! useMcast
      int len = destinations.length;
        List<GMSMember> calculatedMembers; // explicit list of members
        int calculatedLen; // == calculatedMembers.len
        if (len == 1 && destinations[0] == DistributionMessage.ALL_RECIPIENTS) { // send to all
          // Grab a copy of the current membership
          NetView v = services.getJoinLeave().getView();
          
          // Construct the list
          calculatedLen = v.size();
          calculatedMembers = new LinkedList<GMSMember>();
          for (int i = 0; i < calculatedLen; i ++) {
            InternalDistributedMember m = (InternalDistributedMember)v.get(i);
            calculatedMembers.add((GMSMember)m.getNetMember());
          }
        } // send to all
        else { // send to explicit list
          calculatedLen = len;
          calculatedMembers = new LinkedList<GMSMember>();
          for (int i = 0; i < calculatedLen; i ++) {
            calculatedMembers.add((GMSMember)destinations[i].getNetMember());
          }
        } // send to explicit list
        Int2ObjectOpenHashMap messages = new Int2ObjectOpenHashMap();
        long startSer = theStats.startMsgSerialization();
        boolean firstMessage = true;
        for (Iterator it=calculatedMembers.iterator(); it.hasNext(); ) {
          GMSMember mbr = (GMSMember)it.next();
          short version = mbr.getVersionOrdinal();
          if ( !messages.containsKey(version) ) {
            Message jmsg = createJGMessage(msg, local, version);
            messages.put(version, jmsg);
            if (firstMessage) {
              theStats.incSentBytes(jmsg.getLength());
              firstMessage = false;
            }
          }
        }
        theStats.endMsgSerialization(startSer);
        Collections.shuffle(calculatedMembers);
        int i=0;
        for (Iterator<GMSMember> it=calculatedMembers.iterator();
          it.hasNext(); i++) { // send individually
          GMSMember mbr = it.next();
          JGAddress to = new JGAddress(mbr);
          short version = mbr.getVersionOrdinal();
          Message jmsg = (Message)messages.get(version);
          Exception problem = null;
          try {
            Message tmp = (i < (calculatedLen-1)) ? jmsg.copy(true) : jmsg;
            tmp.setDest(to);
            tmp.setSrc(this.jgAddress);
            if (logger.isDebugEnabled())
              logger.debug(""Membership: Sending {} to '{}' via udp unicast"", tmp, mbr);
            myChannel.send(tmp);
          }
          catch (Exception e) {
            problem = e;
          }
          if (problem != null) {
            if (services.getManager().getShutdownCause() != null) {
              Throwable cause = services.getManager().getShutdownCause();
              // If ForcedDisconnectException occurred then report it as actual
              // problem.
              if (cause instanceof ForcedDisconnectException) {
                problem = (Exception) cause;
              } else {
                Throwable ne = problem;
                while (ne.getCause() != null) {
                  ne = ne.getCause();
                }
                ne.initCause(services.getManager().getShutdownCause());
              }
            }
            services.getManager().membershipFailure(""Channel closed"", problem);
            throw new DistributedSystemDisconnectedException(""Channel closed"", problem);
          }
        } // send individually
    } // !useMcast

    // The contract is that every destination enumerated in the
    // message should have received the message.  If one left
    // (i.e., left the view), we signal it here.
    if (msg.forAll())
      return null;
    Set<InternalDistributedMember> result = new HashSet<InternalDistributedMember>();
    NetView newView = services.getJoinLeave().getView();
    if (newView != null) {
      for (int i = 0; i < destinations.length; i ++) {
        InternalDistributedMember d = destinations[i];
        if (!newView.contains(d)) {
          result.add(d);
        }
      }
    }
    if (result.size() == 0)
      return null;
    return result;
  }",True
"  public Set<InternalDistributedMember> send(DistributionMessage msg) {
    
    // perform the same jgroups messaging as in 8.2's GMSMembershipManager.send() method

    // BUT: when marshalling messages we need to include the version of the product and
    // localAddress at the beginning of the message.  These should be used in the receiver
    // code to create a versioned input stream, read the sender address, then read the message
    // and set its sender address
    DMStats theStats = services.getStatistics();

    if (!myChannel.isConnected()) {
      throw new DistributedSystemDisconnectedException(""Distributed System is shutting down"");
    }
    
    filterOutgoingMessage(msg);
    
    if (logger.isDebugEnabled()) {
      logger.debug(""JGroupsMessenger sending [{}] recipients: {}"", msg, msg.getRecipientsDescription());
    }
    
    InternalDistributedMember[] destinations = msg.getRecipients();
    boolean allDestinations = msg.forAll();
    
    boolean useMcast = false;
    if (services.getConfig().getTransport().isMcastEnabled()) {
      useMcast = !services.getManager().isMulticastAllowed()
          && (msg.getMulticast() || allDestinations);
    }
    
    JGAddress local = this.jgAddress;
    
    if (useMcast) {
      if (logger.isTraceEnabled())
        logger.trace(""This message is being multicast"");

      Exception problem = null;
      try {
        long startSer = theStats.startMsgSerialization();
        Message jmsg = createJGMessage(msg, local, Version.CURRENT_ORDINAL);
        theStats.endMsgSerialization(startSer);
        theStats.incSentBytes(jmsg.getLength());
        myChannel.send(jmsg);
      }
      catch (IllegalArgumentException e) {
        problem = e;
      }
      catch (Exception e) {
        logger.info(""caught unexpected exception"", e);
        Throwable cause = e.getCause();
        if (cause instanceof ForcedDisconnectException) {
          problem = (Exception) cause;
        } else {
          problem = e;
        }
      }
      if (problem != null) {
        if (services.getManager().getShutdownCause() != null) {
          Throwable cause = services.getManager().getShutdownCause();
          // If ForcedDisconnectException occurred then report it as actual
          // problem.
          if (cause instanceof ForcedDisconnectException) {
            problem = (Exception) cause;
          } else {
            Throwable ne = problem;
            while (ne.getCause() != null) {
              ne = ne.getCause();
            }
            ne.initCause(services.getManager().getShutdownCause());
          }
        }
        final String channelClosed = LocalizedStrings.GroupMembershipService_CHANNEL_CLOSED.toLocalizedString();
        services.getManager().membershipFailure(channelClosed, problem);
        throw new DistributedSystemDisconnectedException(channelClosed, problem);
      }
    } // useMcast
    else { // ! useMcast
      int len = destinations.length;
        List<GMSMember> calculatedMembers; // explicit list of members
        int calculatedLen; // == calculatedMembers.len
        if (len == 1 && destinations[0] == DistributionMessage.ALL_RECIPIENTS) { // send to all
          // Grab a copy of the current membership
          NetView v = services.getJoinLeave().getView();
          
          // Construct the list
          calculatedLen = v.size();
          calculatedMembers = new LinkedList<GMSMember>();
          for (int i = 0; i < calculatedLen; i ++) {
            InternalDistributedMember m = (InternalDistributedMember)v.get(i);
            calculatedMembers.add((GMSMember)m.getNetMember());
          }
        } // send to all
        else { // send to explicit list
          calculatedLen = len;
          calculatedMembers = new LinkedList<GMSMember>();
          for (int i = 0; i < calculatedLen; i ++) {
            calculatedMembers.add((GMSMember)destinations[i].getNetMember());
          }
        } // send to explicit list
        Int2ObjectOpenHashMap<Message> messages = new Int2ObjectOpenHashMap<>();
        long startSer = theStats.startMsgSerialization();
        boolean firstMessage = true;
        for (Iterator<GMSMember> it=calculatedMembers.iterator(); it.hasNext(); ) {
          GMSMember mbr = it.next();
          short version = mbr.getVersionOrdinal();
          if ( !messages.containsKey(version) ) {
            Message jmsg = createJGMessage(msg, local, version);
            messages.put(version, jmsg);
            if (firstMessage) {
              theStats.incSentBytes(jmsg.getLength());
              firstMessage = false;
            }
          }
        }
        theStats.endMsgSerialization(startSer);
        Collections.shuffle(calculatedMembers);
        int i=0;
        for (GMSMember mbr: calculatedMembers) {
          JGAddress to = new JGAddress(mbr);
          short version = mbr.getVersionOrdinal();
          Message jmsg = (Message)messages.get(version);
          Exception problem = null;
          try {
            Message tmp = (i < (calculatedLen-1)) ? jmsg.copy(true) : jmsg;
            tmp.setDest(to);
            tmp.setSrc(this.jgAddress);
            if (logger.isTraceEnabled())
              logger.trace(""Unicasting to {}"", to);
            myChannel.send(tmp);
          }
          catch (Exception e) {
            problem = e;
          }
          if (problem != null) {
            if (services.getManager().getShutdownCause() != null) {
              Throwable cause = services.getManager().getShutdownCause();
              // If ForcedDisconnectException occurred then report it as actual
              // problem.
              if (cause instanceof ForcedDisconnectException) {
                problem = (Exception) cause;
              } else {
                Throwable ne = problem;
                while (ne.getCause() != null) {
                  ne = ne.getCause();
                }
                ne.initCause(services.getManager().getShutdownCause());
              }
            }
            services.getManager().membershipFailure(""Channel closed"", problem);
            throw new DistributedSystemDisconnectedException(""Channel closed"", problem);
          }
        } // send individually
    } // !useMcast

    // The contract is that every destination enumerated in the
    // message should have received the message.  If one left
    // (i.e., left the view), we signal it here.
    if (msg.forAll())
      return null;
    Set<InternalDistributedMember> result = new HashSet<InternalDistributedMember>();
    NetView newView = services.getJoinLeave().getView();
    if (newView != null) {
      for (int i = 0; i < destinations.length; i ++) {
        InternalDistributedMember d = destinations[i];
        if (!newView.contains(d)) {
          result.add(d);
        }
      }
    }
    if (result.size() == 0)
      return null;
    return result;
  }",False
"  private void filterMessage(DistributionMessage m) {
    if (m instanceof JoinResponseMessage) {
      // TODO: for mcast does the new JGroups need to have the NAKACK digest transmitted
      // to new members at join-time?  The old JGroups needs this and it would require us to
      // install an uphandler for JChannel to handle GET_DIGEST_OK events.
      // I (bruce) am postponing looking into this until we move to the new version of jgroups.
    }
  }",True
"      logger.debug(""JGroupsReceiver deserialized {}"", result);

    }
    catch (ClassNotFoundException | IOException | RuntimeException e) {
      problem = e;
    }
    if (problem != null) {
      logger.error(LocalizedMessage.create(",False
"  public void start() {
    // create the configuration XML string for JGroups
    String properties = this.jgStackConfig;
    
    // start the jgroups channel and establish the membership ID
    try {
      InputStream is = new ByteArrayInputStream(properties.getBytes(""UTF-8""));
      myChannel = new JChannel(is);
      
    } catch (Exception e) {
      throw new SystemConnectException(""unable to create jgroups channel"", e);
    }

    try {
      
      myChannel.setReceiver(new JGroupsReceiver());
      myChannel.connect(""AG""); // apache g***** (whatever we end up calling it)
      
    } catch (Exception e) {
      throw new SystemConnectException(""unable to create jgroups channel"", e);
    }
    
    establishLocalAddress();
    
    try {
      logger.info(""Messenger established the local identity as {} localHost is {}"", localAddress, SocketCreator.getLocalHost());
    } catch (UnknownHostException e) {
      
    }
  }",True
"  public void start() {
    // create the configuration XML string for JGroups
    String properties = this.jgStackConfig;
    
    logger.debug(""JGroups configuration: {}"", properties);
    
    long start = System.currentTimeMillis();
    
    // start the jgroups channel and establish the membership ID
    try {
      InputStream is = new ByteArrayInputStream(properties.getBytes(""UTF-8""));
      myChannel = new JChannel(is);
      
    } catch (Exception e) {
      throw new GemFireConfigException(""unable to create jgroups channel"", e);
    }

    try {
      
      myChannel.setReceiver(new JGroupsReceiver());
      myChannel.connect(""AG""); // apache g***** (whatever we end up calling it)
      
    } catch (Exception e) {
      throw new SystemConnectException(""unable to create jgroups channel"", e);
    }
    
    establishLocalAddress();
    
    logger.info(""JGroups channel created (took {}ms)"", System.currentTimeMillis()-start);
    
  }",False
"    public void receive(Message jgmsg) {
      if (services.getManager().shutdownInProgress())
        return;

      logger.debug(""JGroupsReceiver received {} headers: {}"", jgmsg, jgmsg.getHeaders());
      
      Object o = readJGMessage(jgmsg);
      if (o == null) {
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_GEMFIRE_RECEIVED_NULL_MESSAGE_FROM__0, String.valueOf(jgmsg)));
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_MESSAGE_HEADERS__0, jgmsg.printObjectHeaders()));
        return;
      } else if ( !(o instanceof DistributionMessage) ) {
        logger.warn(""Received something other than a message from "" + jgmsg.getSrc() + "": "" + o);
        return;
      }

      DistributionMessage msg = (DistributionMessage)o;
      
      // admin-only VMs don't have caches, so we ignore cache operations
      // multicast to them, avoiding deserialization cost and classpath
      // problems
      if ( (MemberAttributes.DEFAULT.getVmKind() == DistributionManager.ADMIN_ONLY_DM_TYPE)
           && (msg instanceof DistributedCacheOperation.CacheOperationMessage)) {
        if (logger.isTraceEnabled())
          logger.trace(""Membership: admin VM discarding cache operation message {}"", jgmsg.getObject());
        return;
      }

      msg.resetTimestamp();
      msg.setBytesRead(jgmsg.getLength());
            
      if (msg.getSender() == null) {
        Exception e = new Exception(LocalizedStrings.GroupMembershipService_NULL_SENDER.toLocalizedString());
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_GEMFIRE_RECEIVED_A_MESSAGE_WITH_NO_SENDER_ADDRESS), e);
      }
      
      try {
        MessageHandler h = getMessageHandler(msg);
        logger.debug(""Handler for this message is {}"", h);
        h.processMessage(msg);
      }
      catch (MemberShunnedException e) {
        // message from non-member - ignore
      }
    }",True
"    public void receive(Message jgmsg) {
      if (services.getManager().shutdownInProgress())
        return;

      if (logger.isDebugEnabled()) {
        logger.debug(""JGroupsMessenger received {} headers: {}"", jgmsg, jgmsg.getHeaders());
      }
      
      Object o = readJGMessage(jgmsg);
      if (o == null) {
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_GEMFIRE_RECEIVED_NULL_MESSAGE_FROM__0, String.valueOf(jgmsg)));
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_MESSAGE_HEADERS__0, jgmsg.printObjectHeaders()));
        return;
      } else if ( !(o instanceof DistributionMessage) ) {
        logger.warn(""Received something other than a message from "" + jgmsg.getSrc() + "": "" + o);
        return;
      }

      DistributionMessage msg = (DistributionMessage)o;
      
      // admin-only VMs don't have caches, so we ignore cache operations
      // multicast to them, avoiding deserialization cost and classpath
      // problems
      if ( (MemberAttributes.DEFAULT.getVmKind() == DistributionManager.ADMIN_ONLY_DM_TYPE)
           && (msg instanceof DistributedCacheOperation.CacheOperationMessage)) {
        if (logger.isTraceEnabled())
          logger.trace(""Membership: admin VM discarding cache operation message {}"", jgmsg.getObject());
        return;
      }

      msg.resetTimestamp();
      msg.setBytesRead(jgmsg.getLength());
            
      if (msg.getSender() == null) {
        Exception e = new Exception(LocalizedStrings.GroupMembershipService_NULL_SENDER.toLocalizedString());
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_GEMFIRE_RECEIVED_A_MESSAGE_WITH_NO_SENDER_ADDRESS), e);
      }
      
      try {
        filterIncomingMessage(msg);
        MessageHandler h = getMessageHandler(msg);
        logger.trace(""Handler for this message is {}"", h);
        h.processMessage(msg);
      }
      catch (MemberShunnedException e) {
        // message from non-member - ignore
      }
    }",False
"  public void init(Services s) {
    this.services = s;

    RemoteTransportConfig transport = services.getConfig().getTransport();
    DistributionConfig dc = services.getConfig().getDistributionConfig();
    

    boolean b = dc.getEnableNetworkPartitionDetection();
    if (b) {
      if (!SocketCreator.FORCE_DNS_USE) {
        SocketCreator.resolve_dns = false;
      }
    }
    System.setProperty(""jgroups.resolve_dns"", String.valueOf(!b));

    InputStream is= null;

    if (JGROUPS_CONFIG != null) {
      File file = new File(JGROUPS_CONFIG);
      if (!file.exists()) {
        throw new GemFireConfigException(LocalizedStrings.GroupMembershipService_JGROUPS_CONFIGURATION_FILE_0_DOES_NOT_EXIST.toLocalizedString(JGROUPS_CONFIG));
      }
    }
    else {
      String r = null;
      if (transport.isMcastEnabled()) {
        r = DEFAULT_JGROUPS_MCAST_CONFIG;
      } else {
        r = DEFAULT_JGROUPS_TCP_CONFIG;
      }
      is = ClassPathLoader.getLatest().getResourceAsStream(getClass(), r);
      if (is == null) {
        throw new GemFireConfigException(LocalizedStrings.GroupMembershipService_CANNOT_FIND_0.toLocalizedString(r));
      }
    }

    String properties;
    try {
      //PlainConfigurator config = PlainConfigurator.getInstance(is);
      //properties = config.getProtocolStackString();
      StringBuffer sb = new StringBuffer(3000);
      BufferedReader br;
      if (JGROUPS_CONFIG != null) {
        br = new BufferedReader(new InputStreamReader(is));
      } else {
        br = new BufferedReader(new InputStreamReader(is, ""US-ASCII""));
      }
      String input;
      while ((input=br.readLine()) != null) {
        sb.append(input);
      }
      br.close();
      properties = sb.toString();
    }
    catch (Exception ex) {
      throw new GemFireConfigException(LocalizedStrings.GroupMembershipService_AN_EXCEPTION_WAS_THROWN_WHILE_READING_JGROUPS_CONFIG.toLocalizedString(), ex);
    }
    
    
    if (transport.isMcastEnabled()) {
      // TODO multicast-specific settings
    }

    if (transport.isMcastEnabled() || transport.isTcpDisabled() ||
        (dc.getUdpRecvBufferSize() != DistributionConfig.DEFAULT_UDP_RECV_BUFFER_SIZE) ) {
      properties = replaceStrings(properties, ""UDP_RECV_BUFFER_SIZE"", """"+dc.getUdpRecvBufferSize());
    }
    else {
      properties = replaceStrings(properties, ""UDP_RECV_BUFFER_SIZE"", """"+DistributionConfig.DEFAULT_UDP_RECV_BUFFER_SIZE_REDUCED);
    }
    properties = replaceStrings(properties, ""UDP_SEND_BUFFER_SIZE"", """"+dc.getUdpSendBufferSize());

    String str = transport.getBindAddress();
    // JGroups UDP protocol requires a bind address
    if (str == null || str.length() == 0) {
      try {
        str = SocketCreator.getLocalHost().getHostAddress();
      } catch (UnknownHostException e) {
        throw new GemFireConfigException(e.getMessage(), e);
      }
    }
    properties = replaceStrings(properties, ""BIND_ADDR_SETTING"", ""bind_addr=\""""+str+""\"""");

    int port = Integer.getInteger(""gemfire.jg-bind-port"", 0);
    if (port != 0) {
      properties = replaceStrings(properties, ""MEMBERSHIP_PORT_RANGE_START"", """"+port);
    } else {
      int[] ports = dc.getMembershipPortRange();
      properties = replaceStrings(properties, ""MEMBERSHIP_PORT_RANGE_START"", """"+ports[0]);
      properties = replaceStrings(properties, ""MEMBERSHIP_PORT_RANGE_END"", """"+(ports[1]-ports[0]));
    }
    
    properties = replaceStrings(properties, ""UDP_FRAGMENT_SIZE"", """"+dc.getUdpFragmentSize());

    this.jgStackConfig = properties;
    
  }",True
"  public void init(Services s) {
    this.services = s;

    RemoteTransportConfig transport = services.getConfig().getTransport();
    DistributionConfig dc = services.getConfig().getDistributionConfig();
    

    boolean b = dc.getEnableNetworkPartitionDetection();
    if (b) {
      if (!SocketCreator.FORCE_DNS_USE) {
        SocketCreator.resolve_dns = false;
      }
    }
    System.setProperty(""jgroups.resolve_dns"", String.valueOf(!b));

    InputStream is= null;

    if (JGROUPS_CONFIG != null) {
      File file = new File(JGROUPS_CONFIG);
      if (!file.exists()) {
        throw new GemFireConfigException(LocalizedStrings.GroupMembershipService_JGROUPS_CONFIGURATION_FILE_0_DOES_NOT_EXIST.toLocalizedString(JGROUPS_CONFIG));
      }
    }
    else {
      String r = null;
      if (transport.isMcastEnabled()) {
        r = DEFAULT_JGROUPS_MCAST_CONFIG;
      } else {
        r = DEFAULT_JGROUPS_TCP_CONFIG;
      }
      is = ClassPathLoader.getLatest().getResourceAsStream(getClass(), r);
      if (is == null) {
        throw new GemFireConfigException(LocalizedStrings.GroupMembershipService_CANNOT_FIND_0.toLocalizedString(r));
      }
    }

    String properties;
    try {
      //PlainConfigurator config = PlainConfigurator.getInstance(is);
      //properties = config.getProtocolStackString();
      StringBuffer sb = new StringBuffer(3000);
      BufferedReader br;
      if (JGROUPS_CONFIG != null) {
        br = new BufferedReader(new InputStreamReader(is));
      } else {
        br = new BufferedReader(new InputStreamReader(is, ""US-ASCII""));
      }
      String input;
      while ((input=br.readLine()) != null) {
        sb.append(input);
      }
      br.close();
      properties = sb.toString();
    }
    catch (Exception ex) {
      throw new GemFireConfigException(LocalizedStrings.GroupMembershipService_AN_EXCEPTION_WAS_THROWN_WHILE_READING_JGROUPS_CONFIG.toLocalizedString(), ex);
    }
    
    
    if (transport.isMcastEnabled()) {
      properties = replaceStrings(properties, ""MCAST_PORT"", String.valueOf(transport.getMcastId().getPort()));
      properties = replaceStrings(properties, ""MCAST_ADDRESS"", transport.getMcastId().getHost().getHostAddress());
      properties = replaceStrings(properties, ""MCAST_TTL"", String.valueOf(dc.getMcastTtl()));
      properties = replaceStrings(properties, ""MCAST_SEND_BUFFER_SIZE"", String.valueOf(dc.getMcastSendBufferSize()));
      properties = replaceStrings(properties, ""MCAST_RECV_BUFFER_SIZE"", String.valueOf(dc.getMcastRecvBufferSize()));
      properties = replaceStrings(properties, ""MCAST_RETRANSMIT_INTERVAL"", """"+Integer.getInteger(""gemfire.mcast-retransmit-interval"", 500));
      properties = replaceStrings(properties, ""RETRANSMIT_LIMIT"", String.valueOf(dc.getUdpFragmentSize()-256));
    }

    if (transport.isMcastEnabled() || transport.isTcpDisabled() ||
        (dc.getUdpRecvBufferSize() != DistributionConfig.DEFAULT_UDP_RECV_BUFFER_SIZE) ) {
      properties = replaceStrings(properties, ""UDP_RECV_BUFFER_SIZE"", """"+dc.getUdpRecvBufferSize());
    }
    else {
      properties = replaceStrings(properties, ""UDP_RECV_BUFFER_SIZE"", """"+DistributionConfig.DEFAULT_UDP_RECV_BUFFER_SIZE_REDUCED);
    }
    properties = replaceStrings(properties, ""UDP_SEND_BUFFER_SIZE"", """"+dc.getUdpSendBufferSize());

    String str = transport.getBindAddress();
    // JGroups UDP protocol requires a bind address
    if (str == null || str.length() == 0) {
      try {
        str = SocketCreator.getLocalHost().getHostAddress();
      } catch (UnknownHostException e) {
        throw new GemFireConfigException(e.getMessage(), e);
      }
    }
    properties = replaceStrings(properties, ""BIND_ADDR_SETTING"", ""bind_addr=\""""+str+""\"""");

    int port = Integer.getInteger(""gemfire.jg-bind-port"", 0);
    if (port != 0) {
      properties = replaceStrings(properties, ""MEMBERSHIP_PORT_RANGE_START"", """"+port);
    } else {
      int[] ports = dc.getMembershipPortRange();
      properties = replaceStrings(properties, ""MEMBERSHIP_PORT_RANGE_START"", """"+ports[0]);
      properties = replaceStrings(properties, ""MEMBERSHIP_PORT_RANGE_END"", """"+(ports[1]-ports[0]));
    }
    
    properties = replaceStrings(properties, ""UDP_FRAGMENT_SIZE"", """"+dc.getUdpFragmentSize());
    
    properties = replaceStrings(properties, ""FC_MAX_CREDITS"", """"+dc.getMcastFlowControl().getByteAllowance());
    properties = replaceStrings(properties, ""FC_THRESHOLD"", """"+dc.getMcastFlowControl().getRechargeThreshold());
    properties = replaceStrings(properties, ""FC_MAX_BLOCK"", """"+dc.getMcastFlowControl().getRechargeBlockMs());

    this.jgStackConfig = properties;
    
  }",False
"  private Message createJGMessage(DistributionMessage gfmsg, JGAddress src, short version) {
    if(gfmsg instanceof DirectReplyMessage) {
      ((DirectReplyMessage) gfmsg).registerProcessor();
    }
    Message msg = new Message();
    msg.setDest(null);
    msg.setSrc(src);
    //log.info(""Creating message with payload "" + gfmsg);
    if (gfmsg.getProcessorType() == DistributionManager.HIGH_PRIORITY_EXECUTOR
        || gfmsg instanceof HighPriorityDistributionMessage) {
      msg.setFlag(Flag.OOB);
      msg.setFlag(Flag.DONT_BUNDLE);
      msg.setFlag(Flag.NO_FC);
      msg.setFlag(Flag.SKIP_BARRIER);
    }
    try {
      HeapDataOutputStream out_stream =
        new HeapDataOutputStream(Version.fromOrdinalOrCurrent(version));
        Version.CURRENT.writeOrdinal(out_stream, true);
        DataSerializer.writeObject(this.localAddress.getNetMember(), out_stream);
        DataSerializer.writeObject(gfmsg, out_stream);
        msg.setBuffer(out_stream.toByteArray());
    }
    catch(IOException ex) {
        IllegalArgumentException ia = new
          IllegalArgumentException(""Error serializing message"");
        ia.initCause(ex);
        throw ia;
        //throw new IllegalArgumentException(ex.toString());
    }
    return msg;
  }",True
"  private Message createJGMessage(DistributionMessage gfmsg, JGAddress src, short version) {
    if(gfmsg instanceof DirectReplyMessage) {
      ((DirectReplyMessage) gfmsg).registerProcessor();
    }
    Message msg = new Message();
    msg.setDest(null);
    msg.setSrc(src);
    //log.info(""Creating message with payload "" + gfmsg);
    if (gfmsg.getProcessorType() == DistributionManager.HIGH_PRIORITY_EXECUTOR
        || gfmsg instanceof HighPriorityDistributionMessage) {
      msg.setFlag(Flag.OOB);
      msg.setFlag(Flag.DONT_BUNDLE);
      msg.setFlag(Flag.NO_FC);
      msg.setFlag(Flag.SKIP_BARRIER);
    }
    if (gfmsg instanceof DistributedCacheOperation.CacheOperationMessage) {
      // we don't want to see our own cache operation messages
      msg.setTransientFlag(Message.TransientFlag.DONT_LOOPBACK);
    }
    try {
      HeapDataOutputStream out_stream =
        new HeapDataOutputStream(Version.fromOrdinalOrCurrent(version));
        Version.CURRENT.writeOrdinal(out_stream, true);
        DataSerializer.writeObject(this.localAddress.getNetMember(), out_stream);
        DataSerializer.writeObject(gfmsg, out_stream);
        msg.setBuffer(out_stream.toByteArray());
    }
    catch(IOException ex) {
        IllegalArgumentException ia = new
          IllegalArgumentException(""Error serializing message"");
        ia.initCause(ex);
        throw ia;
        //throw new IllegalArgumentException(ex.toString());
    }
    return msg;
  }",False
"  Object readJGMessage(Message jgmsg) {
    Object result = null;
    
    int messageLength = jgmsg.getLength();
    
    if (logger.isDebugEnabled()) {
      logger.debug(""deserializing a message of length ""+messageLength);
    }
    
    if (messageLength == 0) {
      // jgroups messages with no payload are used for protocol interchange, such
      // as STABLE_GOSSIP
      logger.debug(""Message length is zero - ignoring"");
      return null;
    }

    InternalDistributedMember sender = null;

    Exception problem = null;
    try {
      byte[] buf = jgmsg.getRawBuffer();
      DataInputStream dis = new DataInputStream(new ByteArrayInputStream(buf, 
          jgmsg.getOffset(), jgmsg.getLength()));

      short ordinal = Version.readOrdinal(dis);
      
      if (ordinal < Version.CURRENT_ORDINAL) {
        dis = new VersionedDataInputStream(dis, Version.fromOrdinalNoThrow(
            ordinal, true));
      }
      
      GMSMember m = DataSerializer.readObject(dis);
      sender = getMemberFromView(m, ordinal);

      result = DataSerializer.readObject(dis);
      if (result instanceof DistributionMessage) {
        ((DistributionMessage)result).setSender(sender);
      }

      logger.debug(""JGroupsReceiver deserialized {}"", result);

    }
    catch (ClassNotFoundException | IOException | RuntimeException e) {
      problem = e;
    }
    if (problem != null) {
      logger.error(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_EXCEPTION_DESERIALIZING_MESSAGE_PAYLOAD_0, jgmsg), problem);
      return null;
    }

    return result;
  }",True
"  Object readJGMessage(Message jgmsg) {
    Object result = null;
    
    int messageLength = jgmsg.getLength();
    
    if (logger.isTraceEnabled()) {
      logger.trace(""deserializing a message of length ""+messageLength);
    }
    
    if (messageLength == 0) {
      // jgroups messages with no payload are used for protocol interchange, such
      // as STABLE_GOSSIP
      logger.trace(""message length is zero - ignoring"");
      return null;
    }

    InternalDistributedMember sender = null;

    Exception problem = null;
    try {
      byte[] buf = jgmsg.getRawBuffer();
      DataInputStream dis = new DataInputStream(new ByteArrayInputStream(buf, 
          jgmsg.getOffset(), jgmsg.getLength()));

      short ordinal = Version.readOrdinal(dis);
      
      if (ordinal < Version.CURRENT_ORDINAL) {
        dis = new VersionedDataInputStream(dis, Version.fromOrdinalNoThrow(
            ordinal, true));
      }
      
      GMSMember m = DataSerializer.readObject(dis);
      sender = getMemberFromView(m, ordinal);

      result = DataSerializer.readObject(dis);
      if (result instanceof DistributionMessage) {
        ((DistributionMessage)result).setSender(sender);
      }

      logger.debug(""JGroupsReceiver deserialized {}"", result);

    }
    catch (ClassNotFoundException | IOException | RuntimeException e) {
      problem = e;
    }
    if (problem != null) {
      logger.error(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_EXCEPTION_DESERIALIZING_MESSAGE_PAYLOAD_0, jgmsg), problem);
      return null;
    }

    return result;
  }",False
"  public Set send(InternalDistributedMember dest, DistributionMessage msg)
    throws NotSerializableException {
    
    InternalDistributedMember dests[] = new InternalDistributedMember[] { dest };
    return send (dests, msg, null);
  }",True
"  public Set send(InternalDistributedMember[] destinations,
      DistributionMessage msg,
      DMStats theStats)
      throws NotSerializableException
  {
    Set result = null;
    boolean allDestinations = msg.forAll();
    
    if (!this.hasConnected) {
      if (services.getCancelCriterion().cancelInProgress() != null) {
        throw services.getCancelCriterion().generateCancelledException(null);
      }
      // If we get here, we are starting up, so just report a failure.
      if (allDestinations)
        return null;
      else {
        result = new HashSet();
        for (int i = 0; i < destinations.length; i ++)
          result.add(destinations[i]);
        return result;
      }
    }

    // Handle trivial cases
    if (destinations == null) {
      if (logger.isTraceEnabled())
        logger.trace(""Membership: Message send: returning early because null set passed in: '{}'"", msg);
      return null; // trivially: all recipients received the message
    }
    if (destinations.length == 0) {
      if (logger.isTraceEnabled())
        logger.trace(""Membership: Message send: returning early because empty destination list passed in: '{}'"", msg);
      return null; // trivially: all recipients received the message
    }

    msg.setSender(address);
    
    msg.setBreadcrumbsInSender();
    Breadcrumbs.setProblem(null);

    boolean useMcast = false;
    if (mcastEnabled) {
      useMcast = (msg.getMulticast() || allDestinations);
    }
    
    if (useMcast || tcpDisabled) {
      result = services.getMessenger().send(msg);
    }
    else {
      result = directChannelSend(destinations, msg, theStats);
    }

    // If the message was a broadcast, don't enumerate failures.
    if (allDestinations)
      return null;
    else {
      return result;
    }
  }",False
"  public void setUniqueID(int uniqueID) {
    MemberAttributes.setDefaultVmPid(uniqueID);
  }",True
"      services.getMessenger().beHealthy();
    }
  }",False
"  public void start() {
    DistributionConfig config = services.getConfig().getDistributionConfig();
    RemoteTransportConfig transport = services.getConfig().getTransport();

    int dcPort = 0;
    if (!config.getDisableTcp()) {
      directChannel = new DirectChannel(this, dcReceiver, config, null);
      dcPort = directChannel.getPort();
    }

    
    services.getMessenger().getMemberID().setDirectChannelPort(dcPort);

    MemberAttributes.setDefaults(dcPort,
        MemberAttributes.DEFAULT.getVmPid(),
        MemberAttributes.DEFAULT.getVmKind(),
        MemberAttributes.DEFAULT.getVmViewId(),
        MemberAttributes.DEFAULT.getName(),
        MemberAttributes.DEFAULT.getGroups(), MemberAttributes.DEFAULT.getDurableClientAttributes());
  }",True
"  public void start() {
    DistributionConfig config = services.getConfig().getDistributionConfig();
    RemoteTransportConfig transport = services.getConfig().getTransport();

    int dcPort = 0;
    if (!tcpDisabled) {
      directChannel = new DirectChannel(this, dcReceiver, config, null);
      dcPort = directChannel.getPort();
    }

    
    services.getMessenger().getMemberID().setDirectChannelPort(dcPort);

    MemberAttributes.setDefaults(dcPort,
        MemberAttributes.DEFAULT.getVmPid(),
        MemberAttributes.DEFAULT.getVmKind(),
        MemberAttributes.DEFAULT.getVmViewId(),
        MemberAttributes.DEFAULT.getName(),
        MemberAttributes.DEFAULT.getGroups(), MemberAttributes.DEFAULT.getDurableClientAttributes());
  }",False
"  public void init(Services services) {
    this.services = services;

    Assert.assertTrue(services != null);
    
    this.stats = services.getStatistics();
    DistributionConfig config = services.getConfig().getDistributionConfig();
    RemoteTransportConfig transport = services.getConfig().getTransport();

    this.membershipCheckTimeout = config.getSecurityPeerMembershipTimeout();
    this.wasReconnectingSystem = transport.getIsReconnectingDS();
    this.oldDSUDPSocket = (DatagramSocket)transport.getOldDSMembershipInfo();
    
    if (!config.getDisableTcp()) {
      dcReceiver = new MyDCReceiver(listener);
    }
    
    surpriseMemberTimeout = Math.max(20 * DistributionConfig.DEFAULT_MEMBER_TIMEOUT,
        20 * config.getMemberTimeout());
    surpriseMemberTimeout = Integer.getInteger(""gemfire.surprise-member-timeout"", surpriseMemberTimeout).intValue();
  }",True
"  public void init(Services services) {
    this.services = services;

    Assert.assertTrue(services != null);
    
    this.stats = services.getStatistics();
    DistributionConfig config = services.getConfig().getDistributionConfig();
    RemoteTransportConfig transport = services.getConfig().getTransport();

    this.membershipCheckTimeout = config.getSecurityPeerMembershipTimeout();
    this.wasReconnectingSystem = transport.getIsReconnectingDS();
    this.oldDSUDPSocket = (DatagramSocket)transport.getOldDSMembershipInfo();
    
    // cache these settings for use in send()
    this.mcastEnabled = transport.isMcastEnabled();
    this.tcpDisabled  = transport.isTcpDisabled();

    if (!this.tcpDisabled) {
      dcReceiver = new MyDCReceiver(listener);
    }
    
    surpriseMemberTimeout = Math.max(20 * DistributionConfig.DEFAULT_MEMBER_TIMEOUT,
        20 * config.getMemberTimeout());
    surpriseMemberTimeout = Integer.getInteger(""gemfire.surprise-member-timeout"", surpriseMemberTimeout).intValue();
    
  }",False
"  public void joinDistributedSystem() {
    try {
      join();
    }
    catch (RuntimeException e) {
      if (directChannel != null) {
        directChannel.disconnect(e);
      }
      throw e;
    }
    
    this.address = services.getMessenger().getMemberID();

    int dcPort = 0;
    if (directChannel != null) {
      dcPort = directChannel.getPort();
    }
    
    MemberAttributes.setDefaults(dcPort,
        MemberAttributes.DEFAULT.getVmPid(),
        MemberAttributes.DEFAULT.getVmKind(),
        address.getVmViewId(),
        MemberAttributes.DEFAULT.getName(),
        MemberAttributes.DEFAULT.getGroups(), MemberAttributes.DEFAULT.getDurableClientAttributes());
    
    if (directChannel != null) {
      directChannel.setLocalAddr(address);
      Stub stub = directChannel.getLocalStub();
      memberToStubMap.put(address, stub);
      stubToMemberMap.put(stub, address);
    }

    this.hasConnected = true;

    // in order to debug startup issues we need to announce the membership
    // ID as soon as we know it
    logger.info(LocalizedMessage.create(LocalizedStrings.GroupMembershipService_entered_into_membership_in_group_0_with_id_1,
        new Object[]{address}));

  }",True
"  public void joinDistributedSystem() {
    long startTime = System.currentTimeMillis();
    
    try {
      join();
    }
    catch (RuntimeException e) {
      if (directChannel != null) {
        directChannel.disconnect(e);
      }
      throw e;
    }
    
    this.address = services.getMessenger().getMemberID();

    int dcPort = 0;
    if (directChannel != null) {
      dcPort = directChannel.getPort();
    }
    
    MemberAttributes.setDefaults(dcPort,
        MemberAttributes.DEFAULT.getVmPid(),
        MemberAttributes.DEFAULT.getVmKind(),
        address.getVmViewId(),
        MemberAttributes.DEFAULT.getName(),
        MemberAttributes.DEFAULT.getGroups(), MemberAttributes.DEFAULT.getDurableClientAttributes());
    
    if (directChannel != null) {
      directChannel.setLocalAddr(address);
      Stub stub = directChannel.getLocalStub();
      memberToStubMap.put(address, stub);
      stubToMemberMap.put(stub, address);
    }

    this.hasConnected = true;

    // in order to debug startup issues we need to announce the membership
    // ID as soon as we know it
    logger.info(LocalizedMessage.create(LocalizedStrings.GroupMembershipService_entered_into_membership_in_group_0_with_id_1,
        new Object[]{""""+(System.currentTimeMillis()-startTime)}));

  }",False
"  public static boolean isPortAvailable(final int port, int protocol) {
    return isPortAvailable(port, protocol, getAddress(protocol));
  }",True
"  public static boolean isPortAvailable(final int port, int protocol, InetAddress addr) {
    if (protocol == SOCKET) {
      // Try to create a ServerSocket
      if(addr == null) {
        return testAllInterfaces(port);
      } else {
        return testOneInterface(addr, port);
      }
    }
    
    else if (protocol == JGROUPS) {
      DatagramSocket socket = null;
      try {
        // TODO - need to find out if anyone is listening on this port
        return true;

//        socket = new MulticastSocket();
//        socket.setSoTimeout(Integer.getInteger(""AvailablePort.timeout"", 2000).intValue());
//        byte[] buffer = new byte[4];
//        buffer[0] = (byte)'p';
//        buffer[1] = (byte)'i';
//        buffer[2] = (byte)'n';
//        buffer[3] = (byte)'g';
//        SocketAddress mcaddr = new InetSocketAddress(
//          addr==null? DistributionConfig.DEFAULT_MCAST_ADDRESS : addr, port);
//        DatagramPacket packet = new DatagramPacket(buffer, 0, buffer.length, mcaddr);
//        socket.send(packet);
//        try {
//          socket.receive(packet);
//          packet.getData();  // make sure there's data, but no need to process it
//          return false;
//        }
//        catch (SocketTimeoutException ste) {
//          //System.out.println(""socket read timed out"");
//          return true;
//        }
//        catch (Exception e) {
//          e.printStackTrace();
//          return false;
//        }
//      }
//      catch (java.io.IOException ioe) {
//        if (ioe.getMessage().equals(""Network is unreachable"")) {
//          throw new RuntimeException(LocalizedStrings.AvailablePort_NETWORK_IS_UNREACHABLE.toLocalizedString(), ioe);
//        }
//        ioe.printStackTrace();
//        return false;
//      }
//      catch (Exception e) {
//        e.printStackTrace();
//        return false;
      }
      finally {
        if (socket != null) {
          try {
            socket.close();
          }
          catch (Exception e) {
            e.printStackTrace();
          }
        }
      }  
    }

    else {
      throw new IllegalArgumentException(LocalizedStrings.AvailablePort_UNKNOWN_PROTOCOL_0.toLocalizedString(Integer.valueOf(protocol)));
    }
  }",False
"  private void join() {
    if (transport.isMcastDiscovery()) {
      connectToDS();
    } else {
      daemon = new DSConnectionDaemon();
      daemon.start();
      // give the daemon some time to get us connected
      // we don't want to wait forever since there may be no one to connect to
      try {
        long endTime = System.currentTimeMillis() + 2000; // wait 2 seconds
        while (!connected && daemon.isAlive() && System.currentTimeMillis() < endTime) {
          daemon.join(200);
        }
      } 
      catch (InterruptedException ignore) {
        Thread.currentThread().interrupt();
        // Peremptory cancellation check, but keep going
        this.system.getCancelCriterion().checkCancelInProgress(ignore);
      }
    }
  }",True
"  private void join() {
    daemon = new DSConnectionDaemon();
    daemon.start();
    // give the daemon some time to get us connected
    // we don't want to wait forever since there may be no one to connect to
    try {
      long endTime = System.currentTimeMillis() + 2000; // wait 2 seconds
      while (!connected && daemon.isAlive() && System.currentTimeMillis() < endTime) {
        daemon.join(200);
      }
    } 
    catch (InterruptedException ignore) {
      Thread.currentThread().interrupt();
      // Peremptory cancellation check, but keep going
      this.system.getCancelCriterion().checkCancelInProgress(ignore);
    }
  }",False
"  public boolean disconnect() {
    boolean disconnectedTrue = false;
    synchronized(this) {
      if (disconnected) {
        return false;
      }
      disconnected = true;
      disconnectedTrue = true;
    }
    try {
      listening = false;
      //joinProcessor.interrupt();
      joinProcessor.shutDown();
      boolean removeListener = this.alertLevel != Alert.OFF;
      if (this.isConnected() ||(this.membersMap.size()>0)) { //Hot fix from 6.6.3
        RemoteApplicationVM[] apps = (RemoteApplicationVM[])listApplications(disconnectedTrue);
        for (int i=0; i < apps.length; i++) {
          try {
            apps[i].disconnect(removeListener); // hit NPE here in ConsoleDistributionManagerTest so fixed listApplications to exclude nulls returned from future
          } catch (RuntimeException ignore) {
            // if we can't notify a member that we are disconnecting don't throw
            // an exception. We need to finish disconnecting other resources.
          }
        }
        try {
          DM dm = system.getDistributionManager();
          synchronized (this.myMembershipListenerLock) {
            if (this.myMembershipListener != null) {
              dm.removeMembershipListener(this.myMembershipListener);
            }
          }

          if (dm instanceof DistributionManager) {
            ((DistributionManager) dm).setAgent(null);
          }

        } catch (IllegalArgumentException ignore) {
          // this can happen when connectToDS has not yet done the add

        } catch (DistributedSystemDisconnectedException de) {
          // ignore a forced disconnect and finish clean-up
        }

        if (system != null && DistributionManager.isDedicatedAdminVM &&
            system.isConnected()) {
          system.disconnect();
        }

        this.system = null;
        this.connected = false;
      }
      if (!transport.isMcastDiscovery()) {
        daemon.shutDown();
      }
      if (snapshotDispatcher != null) {
        snapshotDispatcher.shutDown();
      }
    }
    finally {
      removeAgent(this);
    }
    return true;
  }",True
"  public boolean disconnect() {
    boolean disconnectedTrue = false;
    synchronized(this) {
      if (disconnected) {
        return false;
      }
      disconnected = true;
      disconnectedTrue = true;
    }
    try {
      listening = false;
      //joinProcessor.interrupt();
      joinProcessor.shutDown();
      boolean removeListener = this.alertLevel != Alert.OFF;
      if (this.isConnected() ||(this.membersMap.size()>0)) { //Hot fix from 6.6.3
        RemoteApplicationVM[] apps = (RemoteApplicationVM[])listApplications(disconnectedTrue);
        for (int i=0; i < apps.length; i++) {
          try {
            apps[i].disconnect(removeListener); // hit NPE here in ConsoleDistributionManagerTest so fixed listApplications to exclude nulls returned from future
          } catch (RuntimeException ignore) {
            // if we can't notify a member that we are disconnecting don't throw
            // an exception. We need to finish disconnecting other resources.
          }
        }
        try {
          DM dm = system.getDistributionManager();
          synchronized (this.myMembershipListenerLock) {
            if (this.myMembershipListener != null) {
              dm.removeMembershipListener(this.myMembershipListener);
            }
          }

          if (dm instanceof DistributionManager) {
            ((DistributionManager) dm).setAgent(null);
          }

        } catch (IllegalArgumentException ignore) {
          // this can happen when connectToDS has not yet done the add

        } catch (DistributedSystemDisconnectedException de) {
          // ignore a forced disconnect and finish clean-up
        }

        if (system != null && DistributionManager.isDedicatedAdminVM &&
            system.isConnected()) {
          system.disconnect();
        }

        this.system = null;
        this.connected = false;
      }

      daemon.shutDown();
      
      if (snapshotDispatcher != null) {
        snapshotDispatcher.shutDown();
      }
    }
    finally {
      removeAgent(this);
    }
    return true;
  }",False
"  public RemoteTransportConfig(int port) {
    this(port, null);
  }",True
"  public RemoteTransportConfig(DistributionConfig config) {
    if (config.getBindAddress() == null) {
      this.bindAddress = DistributionConfig.DEFAULT_BIND_ADDRESS;
    } else {
      this.bindAddress = config.getBindAddress();
    }
    this.tcpPort = config.getTcpPort();
    this.membershipPortRange = 
            getMembershipPortRangeString(config.getMembershipPortRange());
    this.sslConfig = new SSLConfig();
    
    String initialHosts = config.getLocators();
    if (initialHosts == null)
      initialHosts = """";
    initialHosts = initialHosts.trim();
    
    if (config.getMcastPort() > 0) {
      this.mcastId = new DistributionLocatorId(config.getMcastAddress(), 
                                               config.getMcastPort(), 
                                               config.getBindAddress(),
                                               this.sslConfig);
      this.mcastEnabled = true;
    }
    else {
      this.mcastEnabled = false;
      this.mcastId = null;
    }
    
    this.tcpDisabled = config.getDisableTcp();
    this.disableAutoReconnect = config.getDisableAutoReconnect();

    // See what type of discovery is being used
    if (initialHosts.length() == 0) {
      // loner system
      this.ids = Collections.EMPTY_SET;
      return;
    }
    else {
      HashSet locators = new HashSet();
      int startIdx = 0;
      int endIdx = -1;
      do {
        String locator;
        endIdx = initialHosts.indexOf(',', startIdx);
        if (endIdx == -1) {
          locator = initialHosts.substring(startIdx);
        } else {
          locator = initialHosts.substring(startIdx, endIdx);
          startIdx = endIdx+1;
        }
        locators.add(new DistributionLocatorId(locator));

      } while (endIdx != -1);
    
      if (this.mcastEnabled) {
        locators.add(this.mcastId);
      }
      this.ids = Collections.unmodifiableSet(locators);
      if (this.mcastEnabled) {
        Assert.assertTrue(this.mcastId != null);
      }
    }
  }",False
"  Properties toDSProperties() {
    Properties props = new Properties();
    props.setProperty(DistributionConfig.BIND_ADDRESS_NAME,
                      bindAddress);
//    System.out.println(""entering ds port range property of "" + this.membershipPortRange);
    if (this.membershipPortRange != null) {
      props.setProperty(DistributionConfig.MEMBERSHIP_PORT_RANGE_NAME, this.membershipPortRange);
    }
    if (this.tcpPort != 0) {
      props.setProperty(DistributionConfig.TCP_PORT_NAME, String.valueOf(this.tcpPort));
    }
//System.out.println(""RemoteTransportConfig.mcastEnabled="" + this.mcastEnabled);
//System.out.println(""RemoteTransportConfig.mcastDiscovery="" + this.mcastDiscovery);
//Thread.currentThread().dumpStack();
    if (this.mcastEnabled) {
       // Fix bug 32849
       props.setProperty(DistributionConfig.MCAST_ADDRESS_NAME,
                         String.valueOf(this.mcastId.getHost().getHostAddress()));
       props.setProperty(DistributionConfig.MCAST_PORT_NAME,
                        String.valueOf(this.mcastId.getPort()));

    }
    else {
      props.setProperty(DistributionConfig.MCAST_PORT_NAME, 
                        String.valueOf(0));
    }
    if (!this.mcastDiscovery) {
      // Create locator string
      StringBuffer locators = new StringBuffer();
      for (Iterator iter = this.ids.iterator(); iter.hasNext(); ) {
        DistributionLocatorId locator =
          (DistributionLocatorId) iter.next();
        if (!locator.isMcastId()) {
          String baddr = locator.getBindAddress();
          if (baddr != null && baddr.trim().length() > 0) {
            locators.append(baddr);
          }
          else {
            locators.append(locator.getHost().getCanonicalHostName());
          }
          locators.append(""["");
          locators.append(locator.getPort());
          locators.append(""]"");

          if (iter.hasNext()) {
            locators.append("","");
          }
        }
      }

      props.setProperty(DistributionConfig.LOCATORS_NAME,
                        locators.toString());
    }
    this.sslConfig.toDSProperties(props);
    
    props.setProperty(DistributionConfig.DISABLE_TCP_NAME,
      this.tcpDisabled? ""true"" : ""false"");
    
    props.setProperty(DistributionConfig.DISABLE_AUTO_RECONNECT_NAME, this.disableAutoReconnect? ""true"" : ""false"");

    return props;
  }",True
"  Properties toDSProperties() {
    Properties props = new Properties();
    props.setProperty(DistributionConfig.BIND_ADDRESS_NAME,
                      bindAddress);
//    System.out.println(""entering ds port range property of "" + this.membershipPortRange);
    if (this.membershipPortRange != null) {
      props.setProperty(DistributionConfig.MEMBERSHIP_PORT_RANGE_NAME, this.membershipPortRange);
    }
    if (this.tcpPort != 0) {
      props.setProperty(DistributionConfig.TCP_PORT_NAME, String.valueOf(this.tcpPort));
    }
    if (this.mcastEnabled) {
       // Fix bug 32849
       props.setProperty(DistributionConfig.MCAST_ADDRESS_NAME,
                         String.valueOf(this.mcastId.getHost().getHostAddress()));
       props.setProperty(DistributionConfig.MCAST_PORT_NAME,
                        String.valueOf(this.mcastId.getPort()));

    }
    else {
      props.setProperty(DistributionConfig.MCAST_PORT_NAME, 
                        String.valueOf(0));
    }
    // Create locator string
    StringBuffer locators = new StringBuffer();
    for (Iterator iter = this.ids.iterator(); iter.hasNext(); ) {
      DistributionLocatorId locator =
          (DistributionLocatorId) iter.next();
      if (!locator.isMcastId()) {
        String baddr = locator.getBindAddress();
        if (baddr != null && baddr.trim().length() > 0) {
          locators.append(baddr);
        }
        else {
          locators.append(locator.getHost().getCanonicalHostName());
        }
        locators.append(""["");
        locators.append(locator.getPort());
        locators.append(""]"");

        if (iter.hasNext()) {
          locators.append("","");
        }
      }
    }

    props.setProperty(DistributionConfig.LOCATORS_NAME,
        locators.toString());

    this.sslConfig.toDSProperties(props);
    
    props.setProperty(DistributionConfig.DISABLE_TCP_NAME,
      this.tcpDisabled? ""true"" : ""false"");
    
    props.setProperty(DistributionConfig.DISABLE_AUTO_RECONNECT_NAME, this.disableAutoReconnect? ""true"" : ""false"");

    return props;
  }",False
"    }
    this.ids = Collections.unmodifiableSet(new HashSet(ids));
    this.mcastId = mid;
    if (this.mcastEnabled) {
      Assert.assertTrue(this.mcastId != null);
    }
    this.membershipPortRange = membershipPortRange;
    this.tcpPort = tcpPort;
 }
  
  
  private static String getMembershipPortRangeString(int[] membershipPortRange) {
    String membershipPortRangeString = """";
    if (membershipPortRange != null && 
        membershipPortRange.length == 2) {
      membershipPortRangeString = membershipPortRange[0] + ""-"" + 
                                  membershipPortRange[1];
    }
    
    return membershipPortRangeString;
  }

  // -------------------------------------------------------------------------
  //   Attribute(s)
  // -------------------------------------------------------------------------
  
  /**
   * Returns the set of DistributionLocatorId instances that define this
   * transport. The set is unmodifiable.
   */
  public Set getIds() {
    return this.ids;
  }
  
  /**
   * Returns true iff multicast is enabled in this transport.
   * Multicast must be enabled in order to use multicast discovery.
   */
  public boolean isMcastEnabled() {
    return this.mcastEnabled;
  }
  
  public DistributionLocatorId getMcastId() {
    return this.mcastId;
  }
  
  public boolean isTcpDisabled() {
    return this.tcpDisabled;",False
"  public int hashCode() {
    return this.ids.hashCode() + (isMcastDiscovery() ? 1 : 0);
  }",True
"  public int hashCode() {
    return this.ids.hashCode();
  }",False
"  /**
   * Creates a new <code>RemoteTransportConfig</code> from the
   * configuration information in a <code>DistributionConfig</code>.",False
"  public boolean equals(Object o) {
    if (o != null && o instanceof RemoteTransportConfig) {
      RemoteTransportConfig other = (RemoteTransportConfig)o;
      return (this.mcastEnabled == other.mcastEnabled)
        && (this.mcastDiscovery == other.mcastDiscovery)
        && this.ids.equals(other.ids);
    }
    return false;
  }",True
"    if (config.getBindAddress() == null) {
      this.bindAddress = DistributionConfig.DEFAULT_BIND_ADDRESS;
    } else {
      this.bindAddress = config.getBindAddress();
    }
    this.tcpPort = config.getTcpPort();
    this.membershipPortRange = 
            getMembershipPortRangeString(config.getMembershipPortRange());
    this.sslConfig = new SSLConfig();
    
    String initialHosts = config.getLocators();
    if (initialHosts == null)
      initialHosts = """";
    initialHosts = initialHosts.trim();
    
    if (config.getMcastPort() > 0) {",False
"  public boolean isMcastDiscovery() {
    return this.mcastDiscovery;
  }",True
"  }

  public void setOldDSMembershipInfo(Object oldDSMembershipInfo) {",False
"  public void distribute() {
    DistributedRegion region = getRegion();
    DM mgr = region.getDistributionManager();
    boolean reliableOp = isOperationReliable()
        && region.requiresReliabilityCheck();
    
    if (SLOW_DISTRIBUTION_MS > 0) { // test hook
      try { Thread.sleep(SLOW_DISTRIBUTION_MS); }
      catch (InterruptedException e) { Thread.currentThread().interrupt(); }
      SLOW_DISTRIBUTION_MS = 0;
    }
    
    boolean isPutAll = (this instanceof DistributedPutAllOperation);
    boolean isRemoveAll = (this instanceof DistributedRemoveAllOperation);

    long viewVersion = -1;
    if (this.containsRegionContentChange()) {
      viewVersion = region.getDistributionAdvisor().startOperation();
    }
    if (logger.isTraceEnabled(LogMarker.STATE_FLUSH_OP)) {
      logger.trace(LogMarker.STATE_FLUSH_OP, ""dispatching operation in view version {}"", viewVersion);
    }

    try {
      // Recipients with CacheOp
      Set<InternalDistributedMember> recipients = getRecipients();
      Map<InternalDistributedMember, PersistentMemberID> persistentIds = null;
      if(region.getDataPolicy().withPersistence()) {
        persistentIds = region.getDistributionAdvisor().adviseInitializedPersistentMembers();
      }

      // some members requiring old value are also in the cache op recipients set
      Set needsOldValueInCacheOp = Collections.EMPTY_SET;

      // set client routing information into the event
      boolean routingComputed = false;
      FilterRoutingInfo filterRouting = null;
      // recipients that will get a cacheop msg and also a PR message
      Set twoMessages = Collections.EMPTY_SET;
      if (region.isUsedForPartitionedRegionBucket()) {
        twoMessages = ((BucketRegion)region).getBucketAdvisor().adviseRequiresTwoMessages();
        routingComputed = true;
        filterRouting = getRecipientFilterRouting(recipients);
        if (filterRouting != null) {
          if (logger.isDebugEnabled()) {
            logger.debug(""Computed this filter routing: {}"", filterRouting);
          }
        }
      }

      // some members need PR notification of the change for client/wan
      // notification
      Set adjunctRecipients = Collections.EMPTY_SET;

      // Partitioned region listener notification messages piggyback on this
      // operation's replyprocessor and need to be sent at the same time as
      // the operation's message
      if (this.supportsAdjunctMessaging()
          && region.isUsedForPartitionedRegionBucket()) {
        BucketRegion br = (BucketRegion)region;
        adjunctRecipients = getAdjunctReceivers(br, recipients,
            twoMessages, filterRouting);
      }
      
      EntryEventImpl entryEvent = event.getOperation().isEntry()? getEvent() : null;

      if (entryEvent != null && entryEvent.hasOldValue()) {
        if (testSendingOldValues) {
          needsOldValueInCacheOp = new HashSet(recipients);
        }
        else {
          needsOldValueInCacheOp = region.getCacheDistributionAdvisor().adviseRequiresOldValueInCacheOp();
        }
        recipients.removeAll(needsOldValueInCacheOp);
      }

      Set cachelessNodes = Collections.EMPTY_SET;
      Set adviseCacheServers = Collections.EMPTY_SET;
      Set<InternalDistributedMember> cachelessNodesWithNoCacheServer = new HashSet<InternalDistributedMember>();
      if (region.getDistributionConfig().getDeltaPropagation()
          && this.supportsDeltaPropagation()) {
        cachelessNodes = region.getCacheDistributionAdvisor().adviseEmptys();
        if (!cachelessNodes.isEmpty()) {
          List list = new ArrayList(cachelessNodes);
          for (Object member : cachelessNodes) {
            if (!recipients.contains(member)) {
              // Don't include those originally excluded.
              list.remove(member);
            } else if (adjunctRecipients.contains(member)) {
              list.remove(member);
            }
          }
          cachelessNodes.clear();
          recipients.removeAll(list);
          cachelessNodes.addAll(list);
        }

        cachelessNodesWithNoCacheServer.addAll(cachelessNodes);
        adviseCacheServers = region.getCacheDistributionAdvisor()
            .adviseCacheServers();
        cachelessNodesWithNoCacheServer.removeAll(adviseCacheServers);
      }

      if (recipients.isEmpty() && adjunctRecipients.isEmpty()
          && needsOldValueInCacheOp.isEmpty() && cachelessNodes.isEmpty()) {
        if (mgr.getNormalDistributionManagerIds().size() > 1) {
          if (region.isInternalRegion()) {
            // suppress this msg if we are the only member.
            if (logger.isTraceEnabled()) {
              logger.trace(""<No Recipients> {}"", this);
            }
          } else {
            // suppress this msg if we are the only member.
            if (logger.isDebugEnabled()) {
              logger.debug(""<No Recipients> {}"", this);
            }
          }
        }
        if (!reliableOp || region.isNoDistributionOk()) {
          // nothing needs be done in this case
        } else {
          // create the message so it can be passed to
          // handleReliableDistribution
          // for queuing
          CacheOperationMessage msg = createMessage();
          initMessage(msg, null);
          msg.setRecipients(recipients); // it is going to no one
          region.handleReliableDistribution(msg, Collections.EMPTY_SET);
        }

        /** compute local client routing before waiting for an ack only for a bucket*/
        if (region.isUsedForPartitionedRegionBucket()) {
          FilterInfo filterInfo = getLocalFilterRouting(filterRouting);
          this.event.setLocalFilterInfo(filterInfo);
        }

      } else {
        boolean directAck = false;
        boolean useMulticast = region.getMulticastEnabled()
            && region.getSystem().getConfig().getMcastPort() != 0
            && this.supportsMulticast();
        ;
        boolean shouldAck = shouldAck();

        if (shouldAck) {
          if (this.supportsDirectAck() && adjunctRecipients.isEmpty()) {
            if (region.getSystem().threadOwnsResources()) {
              directAck = true;
            }
          }
        }
        // don't send to the sender of a remote-operation-message.  Those messages send
        // their own response.  fixes bug #45973
        if (entryEvent != null) {
          RemoteOperationMessage rmsg = entryEvent.getRemoteOperationMessage();
          if (rmsg != null) {
            recipients.remove(rmsg.getSender());
          }
          useMulticast = false; // bug #45106: can't mcast or the sender of the one-hop op will get it
        }
        
        if (logger.isDebugEnabled()) {
          logger.debug(""recipients for {}: {} with adjunct messages to: {}"", this, recipients, adjunctRecipients);
        }
        
        if (shouldAck) {
          // adjunct messages are sent using the same reply processor, so
          // add them to the processor's membership set
          Collection waitForMembers = null;
          if (recipients.size() > 0 && adjunctRecipients.size() == 0
                     && cachelessNodes.isEmpty()) { // the common case
            waitForMembers = recipients;
          } else if (!cachelessNodes.isEmpty()){
            waitForMembers = new HashSet(recipients);
            waitForMembers.addAll(cachelessNodes);
          } else {
            // note that we use a Vector instead of a Set for the responders
            // collection
            // because partitioned regions sometimes send both a regular cache
            // operation and a partitioned-region notification message to the
            // same recipient
            waitForMembers = new Vector(recipients);
            waitForMembers.addAll(adjunctRecipients);
            waitForMembers.addAll(needsOldValueInCacheOp);
            waitForMembers.addAll(cachelessNodes);
          }
          if (DistributedCacheOperation.LOSS_SIMULATION_RATIO != 0.0) {
            if (LOSS_SIMULATION_GENERATOR == null) {
              LOSS_SIMULATION_GENERATOR = new Random(this.hashCode());
            }
            if ( (LOSS_SIMULATION_GENERATOR.nextInt(100) * 1.0 / 100.0) < LOSS_SIMULATION_RATIO ) {
              if (logger.isDebugEnabled()) {
                logger.debug(""loss simulation is inhibiting message transmission to {}"", recipients);
              }
              waitForMembers.removeAll(recipients);
              recipients = Collections.EMPTY_SET;
            }
          }
          if (reliableOp) {
            this.departedMembers = new HashSet();
            this.processor = new ReliableCacheReplyProcessor(
                region.getSystem(), waitForMembers, this.departedMembers);
          } else {
            this.processor = new CacheOperationReplyProcessor(region
                .getSystem(), waitForMembers);
          }
        }

        Set failures = null;
        CacheOperationMessage msg = createMessage();
        initMessage(msg, this.processor);

        if (DistributedCacheOperation.internalBeforePutOutgoing != null) {
          DistributedCacheOperation.internalBeforePutOutgoing.run();
        }

        if (processor != null && msg.isSevereAlertCompatible()) {
          this.processor.enableSevereAlertProcessing();
          // if this message is distributing for a partitioned region message,
          // we can't wait as long as the full ack-severe-alert-threshold or
          // the sender might kick us out of the system before we can get an ack
          // back
          DistributedRegion r = getRegion();
          if (r.isUsedForPartitionedRegionBucket()
              && event.getOperation().isEntry()) {
            PartitionMessage pm = ((EntryEventImpl)event).getPartitionMessage();
            if (pm != null
                && pm.getSender() != null
                && !pm.getSender().equals(
                    r.getDistributionManager().getDistributionManagerId())) {
              // PR message sent by another member
              ReplyProcessor21.setShortSevereAlertProcessing(true);
            }
          }
        }

        msg.setMulticast(useMulticast);
        msg.directAck = directAck;
        if (region.isUsedForPartitionedRegionBucket()) {
          if (!isPutAll && !isRemoveAll && filterRouting != null && filterRouting.hasMemberWithFilterInfo()) {
            if (logger.isDebugEnabled()) {
              logger.debug(""Setting filter information for message to {}"",filterRouting);
            }
            msg.filterRouting = filterRouting;
          }
        } else if (!routingComputed) {
          msg.needsRouting = true;
        }

        initProcessor(processor, msg);

        if (region.cache.isClosed() && !canBeSentDuringShutdown()) {
          throw region.cache
              .getCacheClosedException(
                  LocalizedStrings.DistributedCacheOperation_THE_CACHE_HAS_BEEN_CLOSED
                      .toLocalizedString(), null);
        }

        msg.setRecipients(recipients);
        failures = mgr.putOutgoing(msg);

        // distribute to members needing the old value now
        if (needsOldValueInCacheOp.size() > 0) {
          msg.appendOldValueToMessage((EntryEventImpl)this.event); // TODO OFFHEAP optimize
          msg.resetRecipients();
          msg.setRecipients(needsOldValueInCacheOp);
          Set newFailures = mgr.putOutgoing(msg);
          if (newFailures != null) {
            if (logger.isDebugEnabled()) {
              logger.debug(""Failed sending ({}) to {}"", msg, newFailures);
            }
            if (failures != null && failures.size() > 0) {
              failures.addAll(newFailures);
            }
            else {
              failures = newFailures;
            }
          }
        }

        if (cachelessNodes.size() > 0) {
          cachelessNodes.removeAll(cachelessNodesWithNoCacheServer);
          if (cachelessNodes.size() > 0) {
            msg.resetRecipients();
            msg.setRecipients(cachelessNodes);
            msg.setSendDelta(false);
            Set newFailures = mgr.putOutgoing(msg);
            if (newFailures != null) {
              if (failures != null && failures.size() > 0) {
                failures.addAll(newFailures);
              } else {
                failures = newFailures;
              }
            }
          }

          if (cachelessNodesWithNoCacheServer.size() > 0) {
            msg.resetRecipients();
            msg.setRecipients(cachelessNodesWithNoCacheServer);
            msg.setSendDelta(false);
            ((UpdateMessage)msg).setSendDeltaWithFullValue(false);
            Set newFailures = mgr.putOutgoing(msg);
            if (newFailures != null) {
              if (failures != null && failures.size() > 0) {
                failures.addAll(newFailures);
              } else {
                failures = newFailures;
              }
            }
          }
          // Add it back for size calculation ahead
          cachelessNodes.addAll(cachelessNodesWithNoCacheServer);
        }

        if (failures != null && !failures.isEmpty() && logger.isDebugEnabled()) {
          logger.debug(""Failed sending ({}) to {} while processing event:{}"", msg,  failures, event);
        }

        Set<InternalDistributedMember> adjunctRecipientsWithNoCacheServer = new HashSet<InternalDistributedMember>();
        // send partitioned region listener notification messages now
        if (!adjunctRecipients.isEmpty()) {
          if (cachelessNodes.size() > 0) {
            // add non-delta recipients back into the set for adjunct
            // calculations
            if (recipients.isEmpty()) {
              recipients = cachelessNodes;
            } else {
              recipients.addAll(cachelessNodes);
            }
          }
          
          adjunctRecipientsWithNoCacheServer.addAll(adjunctRecipients);
          adviseCacheServers = ((BucketRegion)region).getPartitionedRegion()
              .getCacheDistributionAdvisor().adviseCacheServers();
          adjunctRecipientsWithNoCacheServer.removeAll(adviseCacheServers);

          if (isPutAll) {
            ((BucketRegion)region).performPutAllAdjunctMessaging(
                (DistributedPutAllOperation)this, recipients,
                adjunctRecipients, filterRouting, this.processor);
          } else if (isRemoveAll) {
            ((BucketRegion)region).performRemoveAllAdjunctMessaging(
                (DistributedRemoveAllOperation)this, recipients,
                adjunctRecipients, filterRouting, this.processor);
          } else {
            boolean calculateDelta = adjunctRecipientsWithNoCacheServer.size() < adjunctRecipients
                .size();
            adjunctRecipients.removeAll(adjunctRecipientsWithNoCacheServer);
            if (!adjunctRecipients.isEmpty()) {
              ((BucketRegion)region).performAdjunctMessaging(getEvent(),
                  recipients, adjunctRecipients, filterRouting, this.processor,
                  calculateDelta, true);
            }
            if (!adjunctRecipientsWithNoCacheServer.isEmpty()) {
              ((BucketRegion)region).performAdjunctMessaging(getEvent(),
                  recipients, adjunctRecipientsWithNoCacheServer,
                  filterRouting, this.processor, calculateDelta, false);
            }
          }
        }

        if (viewVersion > 0) {
          region.getDistributionAdvisor().endOperation(viewVersion);
          viewVersion = -1;
        }

        /** compute local client routing before waiting for an ack only for a bucket*/
        if (region.isUsedForPartitionedRegionBucket()) {
          FilterInfo filterInfo = getLocalFilterRouting(filterRouting);
          event.setLocalFilterInfo(filterInfo);
        }

        waitForAckIfNeeded(msg, persistentIds);

        if (/* msg != null && */reliableOp) {
          Set successfulRecips = new HashSet(recipients);
          successfulRecips.addAll(cachelessNodes);
          successfulRecips.addAll(needsOldValueInCacheOp);
          if (failures != null && !failures.isEmpty()) {
            successfulRecips.removeAll(failures);
          }
          if (departedMembers != null) {
            successfulRecips.removeAll(departedMembers);
          }
          region.handleReliableDistribution(msg, successfulRecips);
        }
      }

    } catch (CancelException e) {
      if (logger.isDebugEnabled()) {
        logger.debug(""distribution of message aborted by shutdown: {}"", this);
      }
      throw e;
    } catch (RuntimeException e) {
      logger.info(LocalizedMessage.create(LocalizedStrings.DistributedCacheOperation_EXCEPTION_OCCURRED_WHILE_PROCESSING__0, this), e);
      throw e;
    } finally {
      ReplyProcessor21.setShortSevereAlertProcessing(false);
      if (viewVersion != -1) {
        if (logger.isDebugEnabled()) {
          logger.trace(LogMarker.STATE_FLUSH_OP, ""done dispatching operation in view version {}"", viewVersion);
        }
        region.getDistributionAdvisor().endOperation(viewVersion);
      }
    }
  }",True
"  public void distribute() {
    DistributedRegion region = getRegion();
    DM mgr = region.getDistributionManager();
    boolean reliableOp = isOperationReliable()
        && region.requiresReliabilityCheck();
    
    if (SLOW_DISTRIBUTION_MS > 0) { // test hook
      try { Thread.sleep(SLOW_DISTRIBUTION_MS); }
      catch (InterruptedException e) { Thread.currentThread().interrupt(); }
      SLOW_DISTRIBUTION_MS = 0;
    }
    
    boolean isPutAll = (this instanceof DistributedPutAllOperation);
    boolean isRemoveAll = (this instanceof DistributedRemoveAllOperation);

    long viewVersion = -1;
    if (this.containsRegionContentChange()) {
      viewVersion = region.getDistributionAdvisor().startOperation();
    }
    if (logger.isTraceEnabled(LogMarker.STATE_FLUSH_OP)) {
      logger.trace(LogMarker.STATE_FLUSH_OP, ""dispatching operation in view version {}"", viewVersion);
    }

    try {
      // Recipients with CacheOp
      Set<InternalDistributedMember> recipients = getRecipients();
      Map<InternalDistributedMember, PersistentMemberID> persistentIds = null;
      if(region.getDataPolicy().withPersistence()) {
        persistentIds = region.getDistributionAdvisor().adviseInitializedPersistentMembers();
      }

      // some members requiring old value are also in the cache op recipients set
      Set needsOldValueInCacheOp = Collections.EMPTY_SET;

      // set client routing information into the event
      boolean routingComputed = false;
      FilterRoutingInfo filterRouting = null;
      // recipients that will get a cacheop msg and also a PR message
      Set twoMessages = Collections.EMPTY_SET;
      if (region.isUsedForPartitionedRegionBucket()) {
        twoMessages = ((BucketRegion)region).getBucketAdvisor().adviseRequiresTwoMessages();
        routingComputed = true;
        filterRouting = getRecipientFilterRouting(recipients);
        if (filterRouting != null) {
          if (logger.isDebugEnabled()) {
            logger.debug(""Computed this filter routing: {}"", filterRouting);
          }
        }
      }

      // some members need PR notification of the change for client/wan
      // notification
      Set adjunctRecipients = Collections.EMPTY_SET;

      // Partitioned region listener notification messages piggyback on this
      // operation's replyprocessor and need to be sent at the same time as
      // the operation's message
      if (this.supportsAdjunctMessaging()
          && region.isUsedForPartitionedRegionBucket()) {
        BucketRegion br = (BucketRegion)region;
        adjunctRecipients = getAdjunctReceivers(br, recipients,
            twoMessages, filterRouting);
      }
      
      EntryEventImpl entryEvent = event.getOperation().isEntry()? getEvent() : null;

      if (entryEvent != null && entryEvent.hasOldValue()) {
        if (testSendingOldValues) {
          needsOldValueInCacheOp = new HashSet(recipients);
        }
        else {
          needsOldValueInCacheOp = region.getCacheDistributionAdvisor().adviseRequiresOldValueInCacheOp();
        }
        recipients.removeAll(needsOldValueInCacheOp);
      }

      Set cachelessNodes = Collections.EMPTY_SET;
      Set adviseCacheServers = Collections.EMPTY_SET;
      Set<InternalDistributedMember> cachelessNodesWithNoCacheServer = new HashSet<InternalDistributedMember>();
      if (region.getDistributionConfig().getDeltaPropagation()
          && this.supportsDeltaPropagation()) {
        cachelessNodes = region.getCacheDistributionAdvisor().adviseEmptys();
        if (!cachelessNodes.isEmpty()) {
          List list = new ArrayList(cachelessNodes);
          for (Object member : cachelessNodes) {
            if (!recipients.contains(member)) {
              // Don't include those originally excluded.
              list.remove(member);
            } else if (adjunctRecipients.contains(member)) {
              list.remove(member);
            }
          }
          cachelessNodes.clear();
          recipients.removeAll(list);
          cachelessNodes.addAll(list);
        }

        cachelessNodesWithNoCacheServer.addAll(cachelessNodes);
        adviseCacheServers = region.getCacheDistributionAdvisor()
            .adviseCacheServers();
        cachelessNodesWithNoCacheServer.removeAll(adviseCacheServers);
      }

      if (recipients.isEmpty() && adjunctRecipients.isEmpty()
          && needsOldValueInCacheOp.isEmpty() && cachelessNodes.isEmpty()) {
        if (mgr.getNormalDistributionManagerIds().size() > 1) {
          if (region.isInternalRegion()) {
            // suppress this msg if we are the only member.
            if (logger.isTraceEnabled()) {
              logger.trace(""<No Recipients> {}"", this);
            }
          } else {
            // suppress this msg if we are the only member.
            if (logger.isDebugEnabled()) {
              logger.debug(""<No Recipients> {}"", this);
            }
          }
        }
        if (!reliableOp || region.isNoDistributionOk()) {
          // nothing needs be done in this case
        } else {
          // create the message so it can be passed to
          // handleReliableDistribution
          // for queuing
          CacheOperationMessage msg = createMessage();
          initMessage(msg, null);
          msg.setRecipients(recipients); // it is going to no one
          region.handleReliableDistribution(msg, Collections.EMPTY_SET);
        }

        /** compute local client routing before waiting for an ack only for a bucket*/
        if (region.isUsedForPartitionedRegionBucket()) {
          FilterInfo filterInfo = getLocalFilterRouting(filterRouting);
          this.event.setLocalFilterInfo(filterInfo);
        }

      } else {
        boolean directAck = false;
        boolean useMulticast = region.getMulticastEnabled()
            && region.getSystem().getConfig().getMcastPort() != 0
            && this.supportsMulticast();
        ;
        boolean shouldAck = shouldAck();

        if (shouldAck) {
          if (this.supportsDirectAck() && adjunctRecipients.isEmpty()) {
            if (region.getSystem().threadOwnsResources()) {
              directAck = true;
            }
          }
        }
        // don't send to the sender of a remote-operation-message.  Those messages send
        // their own response.  fixes bug #45973
        if (entryEvent != null) {
          RemoteOperationMessage rmsg = entryEvent.getRemoteOperationMessage();
          if (rmsg != null) {
            recipients.remove(rmsg.getSender());
            useMulticast = false; // bug #45106: can't mcast or the sender of the one-hop op will get it
          }
        }
        
        if (logger.isDebugEnabled()) {
          logger.debug(""recipients for {}: {} with adjunct messages to: {}"", this, recipients, adjunctRecipients);
        }
        
        if (shouldAck) {
          // adjunct messages are sent using the same reply processor, so
          // add them to the processor's membership set
          Collection waitForMembers = null;
          if (recipients.size() > 0 && adjunctRecipients.size() == 0
                     && cachelessNodes.isEmpty()) { // the common case
            waitForMembers = recipients;
          } else if (!cachelessNodes.isEmpty()){
            waitForMembers = new HashSet(recipients);
            waitForMembers.addAll(cachelessNodes);
          } else {
            // note that we use a Vector instead of a Set for the responders
            // collection
            // because partitioned regions sometimes send both a regular cache
            // operation and a partitioned-region notification message to the
            // same recipient
            waitForMembers = new Vector(recipients);
            waitForMembers.addAll(adjunctRecipients);
            waitForMembers.addAll(needsOldValueInCacheOp);
            waitForMembers.addAll(cachelessNodes);
          }
          if (DistributedCacheOperation.LOSS_SIMULATION_RATIO != 0.0) {
            if (LOSS_SIMULATION_GENERATOR == null) {
              LOSS_SIMULATION_GENERATOR = new Random(this.hashCode());
            }
            if ( (LOSS_SIMULATION_GENERATOR.nextInt(100) * 1.0 / 100.0) < LOSS_SIMULATION_RATIO ) {
              if (logger.isDebugEnabled()) {
                logger.debug(""loss simulation is inhibiting message transmission to {}"", recipients);
              }
              waitForMembers.removeAll(recipients);
              recipients = Collections.EMPTY_SET;
            }
          }
          if (reliableOp) {
            this.departedMembers = new HashSet();
            this.processor = new ReliableCacheReplyProcessor(
                region.getSystem(), waitForMembers, this.departedMembers);
          } else {
            this.processor = new CacheOperationReplyProcessor(region
                .getSystem(), waitForMembers);
          }
        }

        Set failures = null;
        CacheOperationMessage msg = createMessage();
        initMessage(msg, this.processor);

        if (DistributedCacheOperation.internalBeforePutOutgoing != null) {
          DistributedCacheOperation.internalBeforePutOutgoing.run();
        }

        if (processor != null && msg.isSevereAlertCompatible()) {
          this.processor.enableSevereAlertProcessing();
          // if this message is distributing for a partitioned region message,
          // we can't wait as long as the full ack-severe-alert-threshold or
          // the sender might kick us out of the system before we can get an ack
          // back
          DistributedRegion r = getRegion();
          if (r.isUsedForPartitionedRegionBucket()
              && event.getOperation().isEntry()) {
            PartitionMessage pm = ((EntryEventImpl)event).getPartitionMessage();
            if (pm != null
                && pm.getSender() != null
                && !pm.getSender().equals(
                    r.getDistributionManager().getDistributionManagerId())) {
              // PR message sent by another member
              ReplyProcessor21.setShortSevereAlertProcessing(true);
            }
          }
        }

        msg.setMulticast(useMulticast);
        msg.directAck = directAck;
        if (region.isUsedForPartitionedRegionBucket()) {
          if (!isPutAll && !isRemoveAll && filterRouting != null && filterRouting.hasMemberWithFilterInfo()) {
            if (logger.isDebugEnabled()) {
              logger.debug(""Setting filter information for message to {}"",filterRouting);
            }
            msg.filterRouting = filterRouting;
          }
        } else if (!routingComputed) {
          msg.needsRouting = true;
        }

        initProcessor(processor, msg);

        if (region.cache.isClosed() && !canBeSentDuringShutdown()) {
          throw region.cache
              .getCacheClosedException(
                  LocalizedStrings.DistributedCacheOperation_THE_CACHE_HAS_BEEN_CLOSED
                      .toLocalizedString(), null);
        }

        msg.setRecipients(recipients);
        failures = mgr.putOutgoing(msg);

        // distribute to members needing the old value now
        if (needsOldValueInCacheOp.size() > 0) {
          msg.appendOldValueToMessage((EntryEventImpl)this.event); // TODO OFFHEAP optimize
          msg.resetRecipients();
          msg.setRecipients(needsOldValueInCacheOp);
          Set newFailures = mgr.putOutgoing(msg);
          if (newFailures != null) {
            if (logger.isDebugEnabled()) {
              logger.debug(""Failed sending ({}) to {}"", msg, newFailures);
            }
            if (failures != null && failures.size() > 0) {
              failures.addAll(newFailures);
            }
            else {
              failures = newFailures;
            }
          }
        }

        if (cachelessNodes.size() > 0) {
          cachelessNodes.removeAll(cachelessNodesWithNoCacheServer);
          if (cachelessNodes.size() > 0) {
            msg.resetRecipients();
            msg.setRecipients(cachelessNodes);
            msg.setSendDelta(false);
            Set newFailures = mgr.putOutgoing(msg);
            if (newFailures != null) {
              if (failures != null && failures.size() > 0) {
                failures.addAll(newFailures);
              } else {
                failures = newFailures;
              }
            }
          }

          if (cachelessNodesWithNoCacheServer.size() > 0) {
            msg.resetRecipients();
            msg.setRecipients(cachelessNodesWithNoCacheServer);
            msg.setSendDelta(false);
            ((UpdateMessage)msg).setSendDeltaWithFullValue(false);
            Set newFailures = mgr.putOutgoing(msg);
            if (newFailures != null) {
              if (failures != null && failures.size() > 0) {
                failures.addAll(newFailures);
              } else {
                failures = newFailures;
              }
            }
          }
          // Add it back for size calculation ahead
          cachelessNodes.addAll(cachelessNodesWithNoCacheServer);
        }

        if (failures != null && !failures.isEmpty() && logger.isDebugEnabled()) {
          logger.debug(""Failed sending ({}) to {} while processing event:{}"", msg,  failures, event);
        }

        Set<InternalDistributedMember> adjunctRecipientsWithNoCacheServer = new HashSet<InternalDistributedMember>();
        // send partitioned region listener notification messages now
        if (!adjunctRecipients.isEmpty()) {
          if (cachelessNodes.size() > 0) {
            // add non-delta recipients back into the set for adjunct
            // calculations
            if (recipients.isEmpty()) {
              recipients = cachelessNodes;
            } else {
              recipients.addAll(cachelessNodes);
            }
          }
          
          adjunctRecipientsWithNoCacheServer.addAll(adjunctRecipients);
          adviseCacheServers = ((BucketRegion)region).getPartitionedRegion()
              .getCacheDistributionAdvisor().adviseCacheServers();
          adjunctRecipientsWithNoCacheServer.removeAll(adviseCacheServers);

          if (isPutAll) {
            ((BucketRegion)region).performPutAllAdjunctMessaging(
                (DistributedPutAllOperation)this, recipients,
                adjunctRecipients, filterRouting, this.processor);
          } else if (isRemoveAll) {
            ((BucketRegion)region).performRemoveAllAdjunctMessaging(
                (DistributedRemoveAllOperation)this, recipients,
                adjunctRecipients, filterRouting, this.processor);
          } else {
            boolean calculateDelta = adjunctRecipientsWithNoCacheServer.size() < adjunctRecipients
                .size();
            adjunctRecipients.removeAll(adjunctRecipientsWithNoCacheServer);
            if (!adjunctRecipients.isEmpty()) {
              ((BucketRegion)region).performAdjunctMessaging(getEvent(),
                  recipients, adjunctRecipients, filterRouting, this.processor,
                  calculateDelta, true);
            }
            if (!adjunctRecipientsWithNoCacheServer.isEmpty()) {
              ((BucketRegion)region).performAdjunctMessaging(getEvent(),
                  recipients, adjunctRecipientsWithNoCacheServer,
                  filterRouting, this.processor, calculateDelta, false);
            }
          }
        }

        if (viewVersion > 0) {
          region.getDistributionAdvisor().endOperation(viewVersion);
          viewVersion = -1;
        }

        /** compute local client routing before waiting for an ack only for a bucket*/
        if (region.isUsedForPartitionedRegionBucket()) {
          FilterInfo filterInfo = getLocalFilterRouting(filterRouting);
          event.setLocalFilterInfo(filterInfo);
        }

        waitForAckIfNeeded(msg, persistentIds);

        if (/* msg != null && */reliableOp) {
          Set successfulRecips = new HashSet(recipients);
          successfulRecips.addAll(cachelessNodes);
          successfulRecips.addAll(needsOldValueInCacheOp);
          if (failures != null && !failures.isEmpty()) {
            successfulRecips.removeAll(failures);
          }
          if (departedMembers != null) {
            successfulRecips.removeAll(departedMembers);
          }
          region.handleReliableDistribution(msg, successfulRecips);
        }
      }

    } catch (CancelException e) {
      if (logger.isDebugEnabled()) {
        logger.debug(""distribution of message aborted by shutdown: {}"", this);
      }
      throw e;
    } catch (RuntimeException e) {
      logger.info(LocalizedMessage.create(LocalizedStrings.DistributedCacheOperation_EXCEPTION_OCCURRED_WHILE_PROCESSING__0, this), e);
      throw e;
    } finally {
      ReplyProcessor21.setShortSevereAlertProcessing(false);
      if (viewVersion != -1) {
        if (logger.isDebugEnabled()) {
          logger.trace(LogMarker.STATE_FLUSH_OP, ""done dispatching operation in view version {}"", viewVersion);
        }
        region.getDistributionAdvisor().endOperation(viewVersion);
      }
    }
  }",False
"  private Region<?, ?> createRegionGlobally(String key) {
    Region<?, ?> r = null;
    Result result = cliCmds.createRegion(key, GemFireRedisServer.DEFAULT_REGION_TYPE, null, null, true, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null);
    r = cache.getRegion(key);
    if (result.getStatus() == Status.ERROR && r == null) {
      String err = """";
      while(result.hasNextLine())
        err += result.nextLine();
      throw new RegionCreationException(err);
    }
    if (r == null)
      throw new RegionCreationException();
    return r;
  }",False
"  public Result createRegion(
      @CliOption (key = CliStrings.CREATE_REGION__REGION,
                  mandatory = true,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__REGION__HELP)
      String regionPath,
      @CliOption (key = CliStrings.CREATE_REGION__REGIONSHORTCUT,
                  mandatory = false,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__REGIONSHORTCUT__HELP)
      RegionShortcut regionShortcut,
      @CliOption (key = CliStrings.CREATE_REGION__USEATTRIBUTESFROM,
                  optionContext = ConverterHint.REGIONPATH,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__USEATTRIBUTESFROM__HELP)
      String useAttributesFrom, 
      @CliOption (key = CliStrings.CREATE_REGION__GROUP,
                  optionContext = ConverterHint.MEMBERGROUP,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__GROUP__HELP)
      @CliMetaData (valueSeparator = "","")
      String[] groups,
      @CliOption (key = CliStrings.CREATE_REGION__SKIPIFEXISTS,
                  unspecifiedDefaultValue = ""true"",
                  specifiedDefaultValue = ""true"",
                  help = CliStrings.CREATE_REGION__SKIPIFEXISTS__HELP)
      boolean skipIfExists,
      
      // the following should all be in alphabetical order
      @CliOption (key = CliStrings.CREATE_REGION__ASYNCEVENTQUEUEID,
                  help = CliStrings.CREATE_REGION__ASYNCEVENTQUEUEID__HELP)
      @CliMetaData (valueSeparator = "","") 
      String[] asyncEventQueueIds,
      @CliOption (key = CliStrings.CREATE_REGION__CACHELISTENER,
                  help = CliStrings.CREATE_REGION__CACHELISTENER__HELP)
      @CliMetaData (valueSeparator = "","") 
      String[] cacheListener,
      @CliOption (key = CliStrings.CREATE_REGION__CACHELOADER,
                  help = CliStrings.CREATE_REGION__CACHELOADER__HELP)
      String cacheLoader,
      @CliOption (key = CliStrings.CREATE_REGION__CACHEWRITER,
                  help = CliStrings.CREATE_REGION__CACHEWRITER__HELP)
      String cacheWriter,
      @CliOption (key = CliStrings.CREATE_REGION__COLOCATEDWITH,
                  optionContext = ConverterHint.REGIONPATH,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__COLOCATEDWITH__HELP)
      String prColocatedWith,
      @CliOption (key = CliStrings.CREATE_REGION__COMPRESSOR,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__COMPRESSOR__HELP)
      String compressor,
      @CliOption (key = CliStrings.CREATE_REGION__CONCURRENCYLEVEL,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__CONCURRENCYLEVEL__HELP)
      Integer concurrencyLevel,
      @CliOption (key = CliStrings.CREATE_REGION__DISKSTORE,
                  help = CliStrings.CREATE_REGION__DISKSTORE__HELP)
      String diskStore,
      @CliOption (key = CliStrings.CREATE_REGION__ENABLEASYNCCONFLATION,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__ENABLEASYNCCONFLATION__HELP)
      Boolean enableAsyncConflation,
      @CliOption (key = CliStrings.CREATE_REGION__CLONINGENABLED,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__CLONINGENABLED__HELP)
      Boolean cloningEnabled,
      @CliOption (key = CliStrings.CREATE_REGION__CONCURRENCYCHECKSENABLED,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__CONCURRENCYCHECKSENABLED__HELP)
      Boolean concurrencyChecksEnabled,
      @CliOption (key = CliStrings.CREATE_REGION__STATISTICSENABLED,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__STATISTICSENABLED__HELP)
      Boolean statisticsEnabled,
      @CliOption (key = CliStrings.CREATE_REGION__ENABLESUBSCRIPTIONCONFLATION,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__ENABLESUBSCRIPTIONCONFLATION__HELP)
      Boolean enableSubscriptionConflation,
      @CliOption (key = CliStrings.CREATE_REGION__DISKSYNCHRONOUS,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__DISKSYNCHRONOUS__HELP)
      Boolean diskSynchronous,
      @CliOption (key = CliStrings.CREATE_REGION__ENTRYEXPIRATIONIDLETIME,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__ENTRYEXPIRATIONIDLETIME__HELP)
      Integer entryExpirationIdleTime,
      @CliOption (key = CliStrings.CREATE_REGION__ENTRYEXPIRATIONIDLETIMEACTION,
                  help = CliStrings.CREATE_REGION__ENTRYEXPIRATIONIDLETIMEACTION__HELP)
      String entryExpirationIdleTimeAction,
      @CliOption (key = CliStrings.CREATE_REGION__ENTRYEXPIRATIONTIMETOLIVE,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__ENTRYEXPIRATIONTIMETOLIVE__HELP)
      Integer entryExpirationTTL,
      @CliOption (key = CliStrings.CREATE_REGION__ENTRYEXPIRATIONTTLACTION,
                  help = CliStrings.CREATE_REGION__ENTRYEXPIRATIONTTLACTION__HELP)
      String entryExpirationTTLAction,
      @CliOption (key = CliStrings.CREATE_REGION__GATEWAYSENDERID,
                  help = CliStrings.CREATE_REGION__GATEWAYSENDERID__HELP)
      @CliMetaData (valueSeparator = "","") 
      String[] gatewaySenderIds,
      @CliOption (key = CliStrings.CREATE_REGION__HDFSSTORE_NAME,
                  help = CliStrings.CREATE_REGION__HDFSSTORE_NAME__HELP ,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE)
      String hdfsStoreName,
      @CliOption (key = CliStrings.CREATE_REGION__HDFSSTORE_WRITEONLY,      
                  help = CliStrings.CREATE_REGION__HDFSSTORE_WRITEONLY__HELP,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE)
      Boolean hdfsWriteOnly,      
      @CliOption (key = CliStrings.CREATE_REGION__KEYCONSTRAINT,
                  help = CliStrings.CREATE_REGION__KEYCONSTRAINT__HELP)
      String keyConstraint,
      @CliOption (key = CliStrings.CREATE_REGION__LOCALMAXMEMORY,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__LOCALMAXMEMORY__HELP)
      Integer prLocalMaxMemory, 
      @CliOption (key = CliStrings.CREATE_REGION__OFF_HEAP,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = ""true"",
                  help = CliStrings.CREATE_REGION__OFF_HEAP__HELP)
      Boolean offHeap,
      @CliOption (key = CliStrings.CREATE_REGION__REGIONEXPIRATIONIDLETIME,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__REGIONEXPIRATIONIDLETIME__HELP)
      Integer regionExpirationIdleTime,
      @CliOption (key = CliStrings.CREATE_REGION__REGIONEXPIRATIONIDLETIMEACTION,
                  help = CliStrings.CREATE_REGION__REGIONEXPIRATIONIDLETIMEACTION__HELP)
      String regionExpirationIdleTimeAction,
      @CliOption (key = CliStrings.CREATE_REGION__REGIONEXPIRATIONTTL,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__REGIONEXPIRATIONTTL__HELP)
      Integer regionExpirationTTL,
      @CliOption (key = CliStrings.CREATE_REGION__REGIONEXPIRATIONTTLACTION,
                  help = CliStrings.CREATE_REGION__REGIONEXPIRATIONTTLACTION__HELP)
      String regionExpirationTTLAction,      
      @CliOption (key = CliStrings.CREATE_REGION__RECOVERYDELAY,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__RECOVERYDELAY__HELP)
      Long prRecoveryDelay,
      @CliOption (key = CliStrings.CREATE_REGION__REDUNDANTCOPIES,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__REDUNDANTCOPIES__HELP)
      Integer prRedundantCopies, 
      @CliOption (key = CliStrings.CREATE_REGION__STARTUPRECOVERYDDELAY,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__STARTUPRECOVERYDDELAY__HELP)
      Long prStartupRecoveryDelay,
      @CliOption (key = CliStrings.CREATE_REGION__TOTALMAXMEMORY,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__TOTALMAXMEMORY__HELP)
      Long prTotalMaxMemory, 
      @CliOption (key = CliStrings.CREATE_REGION__TOTALNUMBUCKETS,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__TOTALNUMBUCKETS__HELP)
      Integer prTotalNumBuckets,      
      @CliOption (key = CliStrings.CREATE_REGION__VALUECONSTRAINT,
                  help = CliStrings.CREATE_REGION__VALUECONSTRAINT__HELP)
      String valueConstraint
      // NOTICE: keep the region attributes params in alphabetical order
) {
    Result result = null;
    XmlEntity xmlEntity = null;

    try {
      Cache cache = CacheFactory.getAnyInstance();

      if (regionShortcut != null && useAttributesFrom != null) {
        throw new IllegalArgumentException(CliStrings.CREATE_REGION__MSG__ONLY_ONE_OF_REGIONSHORTCUT_AND_USEATTRIBUESFROM_CAN_BE_SPECIFIED);
      } else if (regionShortcut == null && useAttributesFrom == null) {
        throw new IllegalArgumentException(CliStrings.CREATE_REGION__MSG__ONE_OF_REGIONSHORTCUT_AND_USEATTRIBUESFROM_IS_REQUIRED);
      }
      
      validateRegionPathAndParent(cache, regionPath);
      validateGroups(cache, groups);

      RegionFunctionArgs.ExpirationAttrs entryIdle = null;
      if (entryExpirationIdleTime != null) {
        entryIdle = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.ENTRY_IDLE, entryExpirationIdleTime, entryExpirationIdleTimeAction);
      }
      RegionFunctionArgs.ExpirationAttrs entryTTL = null;
      if (entryExpirationTTL != null) {
        entryTTL = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.ENTRY_TTL, entryExpirationTTL, entryExpirationTTLAction);
      }
      RegionFunctionArgs.ExpirationAttrs regionIdle = null;
      if (regionExpirationIdleTime != null) {
        regionIdle = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.REGION_IDLE, regionExpirationIdleTime, regionExpirationIdleTimeAction);
      }
      RegionFunctionArgs.ExpirationAttrs regionTTL = null;
      if (regionExpirationTTL != null) {
        regionTTL = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.REGION_TTL, regionExpirationTTL, regionExpirationTTLAction);
      }
      
      RegionFunctionArgs regionFunctionArgs = null;
      if (useAttributesFrom != null) {
        if (!regionExists(cache, useAttributesFrom)) {
          throw new IllegalArgumentException(CliStrings.format(CliStrings.CREATE_REGION__MSG__SPECIFY_VALID_REGION_PATH_FOR_0_REGIONPATH_1_NOT_FOUND, new Object[] {CliStrings.CREATE_REGION__USEATTRIBUTESFROM, useAttributesFrom}));
        }
        
        
        FetchRegionAttributesFunctionResult<Object, Object> regionAttributesResult = getRegionAttributes(cache, useAttributesFrom);
        RegionAttributes<?, ?> regionAttributes = regionAttributesResult.getRegionAttributes();
           
        
        // give preference to user specified plugins than the ones retrieved from other region
        String[] cacheListenerClasses = cacheListener != null && cacheListener.length != 0 ? cacheListener : regionAttributesResult.getCacheListenerClasses();
        String cacheLoaderClass = cacheLoader != null ? cacheLoader : regionAttributesResult.getCacheLoaderClass();
        String cacheWriterClass = cacheWriter != null ? cacheWriter : regionAttributesResult.getCacheWriterClass();;

        regionFunctionArgs = new RegionFunctionArgs(regionPath,
            useAttributesFrom, skipIfExists, keyConstraint, valueConstraint,
            statisticsEnabled, entryIdle, entryTTL, regionIdle,
            regionTTL, diskStore, diskSynchronous, enableAsyncConflation,
            enableSubscriptionConflation, cacheListenerClasses, cacheLoaderClass,
            cacheWriterClass, asyncEventQueueIds, gatewaySenderIds,
            concurrencyChecksEnabled, cloningEnabled, concurrencyLevel, 
            prColocatedWith, prLocalMaxMemory, prRecoveryDelay,
            prRedundantCopies, prStartupRecoveryDelay,
            prTotalMaxMemory, prTotalNumBuckets,
            offHeap, hdfsStoreName , hdfsWriteOnly,  regionAttributes);
        

        if (regionAttributes.getPartitionAttributes() == null && regionFunctionArgs.hasPartitionAttributes()) {
          throw new IllegalArgumentException(
              CliStrings.format(CliStrings.CREATE_REGION__MSG__OPTION_0_CAN_BE_USED_ONLY_FOR_PARTITIONEDREGION, 
                                regionFunctionArgs.getPartitionArgs().getUserSpecifiedPartitionAttributes()) + "" "" +
              CliStrings.format(CliStrings.CREATE_REGION__MSG__0_IS_NOT_A_PARITIONEDREGION, 
                                    useAttributesFrom));
        }
      } else {
        regionFunctionArgs = new RegionFunctionArgs(
          regionPath, regionShortcut, useAttributesFrom, skipIfExists,
          keyConstraint, valueConstraint, statisticsEnabled, entryIdle, entryTTL,
          regionIdle, regionTTL, diskStore, diskSynchronous,
          enableAsyncConflation, enableSubscriptionConflation, cacheListener,
          cacheLoader, cacheWriter, asyncEventQueueIds, gatewaySenderIds,
          concurrencyChecksEnabled, cloningEnabled, concurrencyLevel, 
          prColocatedWith, prLocalMaxMemory, prRecoveryDelay,
          prRedundantCopies, prStartupRecoveryDelay,
          prTotalMaxMemory, prTotalNumBuckets, null,compressor, offHeap , hdfsStoreName , hdfsWriteOnly);
        
        if (!regionShortcut.name().startsWith(""PARTITION"") && regionFunctionArgs.hasPartitionAttributes()) {
          throw new IllegalArgumentException(
              CliStrings.format(CliStrings.CREATE_REGION__MSG__OPTION_0_CAN_BE_USED_ONLY_FOR_PARTITIONEDREGION, 
                                regionFunctionArgs.getPartitionArgs().getUserSpecifiedPartitionAttributes()) + "" "" +
              CliStrings.format(CliStrings.CREATE_REGION__MSG__0_IS_NOT_A_PARITIONEDREGION, 
                                    useAttributesFrom));
        }
      }

      validateRegionFunctionArgs(cache, regionFunctionArgs);

      Set<DistributedMember> membersToCreateRegionOn = null;
      if (groups != null && groups.length != 0) {
        membersToCreateRegionOn = CliUtil.getDistributedMembersByGroup(cache, groups);
        // have only normal members from the group
        for (Iterator<DistributedMember> it = membersToCreateRegionOn.iterator(); it.hasNext();) {
          DistributedMember distributedMember = it.next();
          if ( ((InternalDistributedMember)distributedMember).getVmKind() == DistributionManager.LOCATOR_DM_TYPE ) {
            it.remove();
          }
        }
      } else {
        membersToCreateRegionOn = CliUtil.getAllNormalMembers(cache);
      }

      if (membersToCreateRegionOn.isEmpty()) {
        return ResultBuilder.createUserErrorResult(CliStrings.NO_CACHING_MEMBERS_FOUND_MESSAGE);
      }

      ResultCollector<?, ?> resultCollector = CliUtil.executeFunction(RegionCreateFunction.INSTANCE, regionFunctionArgs, membersToCreateRegionOn);
      @SuppressWarnings(""unchecked"")
      List<CliFunctionResult> regionCreateResults = (List<CliFunctionResult>) resultCollector.getResult();

      TabularResultData tabularResultData = ResultBuilder.createTabularResultData();
      final String errorPrefix = ""ERROR: "";
      for (CliFunctionResult regionCreateResult : regionCreateResults) {
        boolean success  = regionCreateResult.isSuccessful();
        tabularResultData.accumulate(""Member"", regionCreateResult.getMemberIdOrName());
        tabularResultData.accumulate(""Status"", (success ? """" : errorPrefix) + regionCreateResult.getMessage());
        
        if (success) {
          xmlEntity = regionCreateResult.getXmlEntity();
        }
      }
      
      result = ResultBuilder.buildResult(tabularResultData);
      verifyDistributedRegionMbean(cache, regionPath); 
      
    } catch (IllegalArgumentException e) {
      LogWrapper.getInstance().info(e.getMessage());
      result = ResultBuilder.createUserErrorResult(e.getMessage());
    } catch (IllegalStateException e) {
      LogWrapper.getInstance().info(e.getMessage());
      result = ResultBuilder.createUserErrorResult(e.getMessage());
    } catch (RuntimeException e) {
      LogWrapper.getInstance().info(e.getMessage(), e);
      result = ResultBuilder.createGemFireErrorResult(e.getMessage());
      
    }
    if (xmlEntity != null) {
      result.setCommandPersisted((new SharedConfigurationWriter()).addXmlEntity(xmlEntity, groups));
    }
    return result;
  }",True
"  public Result createRegion(
      @CliOption (key = CliStrings.CREATE_REGION__REGION,
                  mandatory = true,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__REGION__HELP)
      String regionPath,
      @CliOption (key = CliStrings.CREATE_REGION__REGIONSHORTCUT,
                  mandatory = false,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__REGIONSHORTCUT__HELP)
      RegionShortcut regionShortcut,
      @CliOption (key = CliStrings.CREATE_REGION__USEATTRIBUTESFROM,
                  optionContext = ConverterHint.REGIONPATH,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__USEATTRIBUTESFROM__HELP)
      String useAttributesFrom, 
      @CliOption (key = CliStrings.CREATE_REGION__GROUP,
                  optionContext = ConverterHint.MEMBERGROUP,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__GROUP__HELP)
      @CliMetaData (valueSeparator = "","")
      String[] groups,
      @CliOption (key = CliStrings.CREATE_REGION__SKIPIFEXISTS,
                  unspecifiedDefaultValue = ""true"",
                  specifiedDefaultValue = ""true"",
                  help = CliStrings.CREATE_REGION__SKIPIFEXISTS__HELP)
      boolean skipIfExists,
      
      // the following should all be in alphabetical order according to
      // their key string
      @CliOption (key = CliStrings.CREATE_REGION__ASYNCEVENTQUEUEID,
                  help = CliStrings.CREATE_REGION__ASYNCEVENTQUEUEID__HELP)
      @CliMetaData (valueSeparator = "","") 
      String[] asyncEventQueueIds,
      @CliOption (key = CliStrings.CREATE_REGION__CACHELISTENER,
                  help = CliStrings.CREATE_REGION__CACHELISTENER__HELP)
      @CliMetaData (valueSeparator = "","") 
      String[] cacheListener,
      @CliOption (key = CliStrings.CREATE_REGION__CACHELOADER,
                  help = CliStrings.CREATE_REGION__CACHELOADER__HELP)
      String cacheLoader,
      @CliOption (key = CliStrings.CREATE_REGION__CACHEWRITER,
                  help = CliStrings.CREATE_REGION__CACHEWRITER__HELP)
      String cacheWriter,
      @CliOption (key = CliStrings.CREATE_REGION__COLOCATEDWITH,
                  optionContext = ConverterHint.REGIONPATH,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__COLOCATEDWITH__HELP)
      String prColocatedWith,
      @CliOption (key = CliStrings.CREATE_REGION__COMPRESSOR,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__COMPRESSOR__HELP)
      String compressor,
      @CliOption (key = CliStrings.CREATE_REGION__CONCURRENCYLEVEL,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__CONCURRENCYLEVEL__HELP)
      Integer concurrencyLevel,
      @CliOption (key = CliStrings.CREATE_REGION__DISKSTORE,
                  help = CliStrings.CREATE_REGION__DISKSTORE__HELP)
      String diskStore,
      @CliOption (key = CliStrings.CREATE_REGION__ENABLEASYNCCONFLATION,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__ENABLEASYNCCONFLATION__HELP)
      Boolean enableAsyncConflation,
      @CliOption (key = CliStrings.CREATE_REGION__CLONINGENABLED,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__CLONINGENABLED__HELP)
      Boolean cloningEnabled,
      @CliOption (key = CliStrings.CREATE_REGION__CONCURRENCYCHECKSENABLED,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__CONCURRENCYCHECKSENABLED__HELP)
      Boolean concurrencyChecksEnabled,
      @CliOption (key = CliStrings.CREATE_REGION__MULTICASTENABLED,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__MULTICASTENABLED__HELP)
      Boolean mcastEnabled,
      @CliOption (key = CliStrings.CREATE_REGION__STATISTICSENABLED,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__STATISTICSENABLED__HELP)
      Boolean statisticsEnabled,
      @CliOption (key = CliStrings.CREATE_REGION__ENABLESUBSCRIPTIONCONFLATION,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__ENABLESUBSCRIPTIONCONFLATION__HELP)
      Boolean enableSubscriptionConflation,
      @CliOption (key = CliStrings.CREATE_REGION__DISKSYNCHRONOUS,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__DISKSYNCHRONOUS__HELP)
      Boolean diskSynchronous,
      @CliOption (key = CliStrings.CREATE_REGION__ENTRYEXPIRATIONIDLETIME,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__ENTRYEXPIRATIONIDLETIME__HELP)
      Integer entryExpirationIdleTime,
      @CliOption (key = CliStrings.CREATE_REGION__ENTRYEXPIRATIONIDLETIMEACTION,
                  help = CliStrings.CREATE_REGION__ENTRYEXPIRATIONIDLETIMEACTION__HELP)
      String entryExpirationIdleTimeAction,
      @CliOption (key = CliStrings.CREATE_REGION__ENTRYEXPIRATIONTIMETOLIVE,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__ENTRYEXPIRATIONTIMETOLIVE__HELP)
      Integer entryExpirationTTL,
      @CliOption (key = CliStrings.CREATE_REGION__ENTRYEXPIRATIONTTLACTION,
                  help = CliStrings.CREATE_REGION__ENTRYEXPIRATIONTTLACTION__HELP)
      String entryExpirationTTLAction,
      @CliOption (key = CliStrings.CREATE_REGION__GATEWAYSENDERID,
                  help = CliStrings.CREATE_REGION__GATEWAYSENDERID__HELP)
      @CliMetaData (valueSeparator = "","") 
      String[] gatewaySenderIds,
      @CliOption (key = CliStrings.CREATE_REGION__HDFSSTORE_NAME,
                  help = CliStrings.CREATE_REGION__HDFSSTORE_NAME__HELP ,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE)
      String hdfsStoreName,
      @CliOption (key = CliStrings.CREATE_REGION__HDFSSTORE_WRITEONLY,      
                  help = CliStrings.CREATE_REGION__HDFSSTORE_WRITEONLY__HELP,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE)
      Boolean hdfsWriteOnly,      
      @CliOption (key = CliStrings.CREATE_REGION__KEYCONSTRAINT,
                  help = CliStrings.CREATE_REGION__KEYCONSTRAINT__HELP)
      String keyConstraint,
      @CliOption (key = CliStrings.CREATE_REGION__LOCALMAXMEMORY,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__LOCALMAXMEMORY__HELP)
      Integer prLocalMaxMemory, 
      @CliOption (key = CliStrings.CREATE_REGION__OFF_HEAP,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = ""true"",
                  help = CliStrings.CREATE_REGION__OFF_HEAP__HELP)
      Boolean offHeap,
      @CliOption (key = CliStrings.CREATE_REGION__REGIONEXPIRATIONIDLETIME,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__REGIONEXPIRATIONIDLETIME__HELP)
      Integer regionExpirationIdleTime,
      @CliOption (key = CliStrings.CREATE_REGION__REGIONEXPIRATIONIDLETIMEACTION,
                  help = CliStrings.CREATE_REGION__REGIONEXPIRATIONIDLETIMEACTION__HELP)
      String regionExpirationIdleTimeAction,
      @CliOption (key = CliStrings.CREATE_REGION__REGIONEXPIRATIONTTL,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__REGIONEXPIRATIONTTL__HELP)
      Integer regionExpirationTTL,
      @CliOption (key = CliStrings.CREATE_REGION__REGIONEXPIRATIONTTLACTION,
                  help = CliStrings.CREATE_REGION__REGIONEXPIRATIONTTLACTION__HELP)
      String regionExpirationTTLAction,      
      @CliOption (key = CliStrings.CREATE_REGION__RECOVERYDELAY,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__RECOVERYDELAY__HELP)
      Long prRecoveryDelay,
      @CliOption (key = CliStrings.CREATE_REGION__REDUNDANTCOPIES,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__REDUNDANTCOPIES__HELP)
      Integer prRedundantCopies, 
      @CliOption (key = CliStrings.CREATE_REGION__STARTUPRECOVERYDDELAY,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__STARTUPRECOVERYDDELAY__HELP)
      Long prStartupRecoveryDelay,
      @CliOption (key = CliStrings.CREATE_REGION__TOTALMAXMEMORY,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__TOTALMAXMEMORY__HELP)
      Long prTotalMaxMemory, 
      @CliOption (key = CliStrings.CREATE_REGION__TOTALNUMBUCKETS,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__TOTALNUMBUCKETS__HELP)
      Integer prTotalNumBuckets,      
      @CliOption (key = CliStrings.CREATE_REGION__VALUECONSTRAINT,
                  help = CliStrings.CREATE_REGION__VALUECONSTRAINT__HELP)
      String valueConstraint
      // NOTICE: keep the region attributes params in alphabetical order
) {
    Result result = null;
    XmlEntity xmlEntity = null;

    try {
      Cache cache = CacheFactory.getAnyInstance();

      if (regionShortcut != null && useAttributesFrom != null) {
        throw new IllegalArgumentException(CliStrings.CREATE_REGION__MSG__ONLY_ONE_OF_REGIONSHORTCUT_AND_USEATTRIBUESFROM_CAN_BE_SPECIFIED);
      } else if (regionShortcut == null && useAttributesFrom == null) {
        throw new IllegalArgumentException(CliStrings.CREATE_REGION__MSG__ONE_OF_REGIONSHORTCUT_AND_USEATTRIBUESFROM_IS_REQUIRED);
      }
      
      validateRegionPathAndParent(cache, regionPath);
      validateGroups(cache, groups);

      RegionFunctionArgs.ExpirationAttrs entryIdle = null;
      if (entryExpirationIdleTime != null) {
        entryIdle = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.ENTRY_IDLE, entryExpirationIdleTime, entryExpirationIdleTimeAction);
      }
      RegionFunctionArgs.ExpirationAttrs entryTTL = null;
      if (entryExpirationTTL != null) {
        entryTTL = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.ENTRY_TTL, entryExpirationTTL, entryExpirationTTLAction);
      }
      RegionFunctionArgs.ExpirationAttrs regionIdle = null;
      if (regionExpirationIdleTime != null) {
        regionIdle = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.REGION_IDLE, regionExpirationIdleTime, regionExpirationIdleTimeAction);
      }
      RegionFunctionArgs.ExpirationAttrs regionTTL = null;
      if (regionExpirationTTL != null) {
        regionTTL = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.REGION_TTL, regionExpirationTTL, regionExpirationTTLAction);
      }
      
      RegionFunctionArgs regionFunctionArgs = null;
      if (useAttributesFrom != null) {
        if (!regionExists(cache, useAttributesFrom)) {
          throw new IllegalArgumentException(CliStrings.format(CliStrings.CREATE_REGION__MSG__SPECIFY_VALID_REGION_PATH_FOR_0_REGIONPATH_1_NOT_FOUND, new Object[] {CliStrings.CREATE_REGION__USEATTRIBUTESFROM, useAttributesFrom}));
        }
        
        
        FetchRegionAttributesFunctionResult<Object, Object> regionAttributesResult = getRegionAttributes(cache, useAttributesFrom);
        RegionAttributes<?, ?> regionAttributes = regionAttributesResult.getRegionAttributes();
           
        
        // give preference to user specified plugins than the ones retrieved from other region
        String[] cacheListenerClasses = cacheListener != null && cacheListener.length != 0 ? cacheListener : regionAttributesResult.getCacheListenerClasses();
        String cacheLoaderClass = cacheLoader != null ? cacheLoader : regionAttributesResult.getCacheLoaderClass();
        String cacheWriterClass = cacheWriter != null ? cacheWriter : regionAttributesResult.getCacheWriterClass();;

        regionFunctionArgs = new RegionFunctionArgs(regionPath,
            useAttributesFrom, skipIfExists, keyConstraint, valueConstraint,
            statisticsEnabled, entryIdle, entryTTL, regionIdle,
            regionTTL, diskStore, diskSynchronous, enableAsyncConflation,
            enableSubscriptionConflation, cacheListenerClasses, cacheLoaderClass,
            cacheWriterClass, asyncEventQueueIds, gatewaySenderIds,
            concurrencyChecksEnabled, cloningEnabled, concurrencyLevel, 
            prColocatedWith, prLocalMaxMemory, prRecoveryDelay,
            prRedundantCopies, prStartupRecoveryDelay,
            prTotalMaxMemory, prTotalNumBuckets,
            offHeap, hdfsStoreName , hdfsWriteOnly,  mcastEnabled, regionAttributes);
        

        if (regionAttributes.getPartitionAttributes() == null && regionFunctionArgs.hasPartitionAttributes()) {
          throw new IllegalArgumentException(
              CliStrings.format(CliStrings.CREATE_REGION__MSG__OPTION_0_CAN_BE_USED_ONLY_FOR_PARTITIONEDREGION, 
                                regionFunctionArgs.getPartitionArgs().getUserSpecifiedPartitionAttributes()) + "" "" +
              CliStrings.format(CliStrings.CREATE_REGION__MSG__0_IS_NOT_A_PARITIONEDREGION, 
                                    useAttributesFrom));
        }
      } else {
        regionFunctionArgs = new RegionFunctionArgs(
          regionPath, regionShortcut, useAttributesFrom, skipIfExists,
          keyConstraint, valueConstraint, statisticsEnabled, entryIdle, entryTTL,
          regionIdle, regionTTL, diskStore, diskSynchronous,
          enableAsyncConflation, enableSubscriptionConflation, cacheListener,
          cacheLoader, cacheWriter, asyncEventQueueIds, gatewaySenderIds,
          concurrencyChecksEnabled, cloningEnabled, concurrencyLevel, 
          prColocatedWith, prLocalMaxMemory, prRecoveryDelay,
          prRedundantCopies, prStartupRecoveryDelay,
          prTotalMaxMemory, prTotalNumBuckets, null,compressor, offHeap , hdfsStoreName , hdfsWriteOnly, mcastEnabled);
        
        if (!regionShortcut.name().startsWith(""PARTITION"") && regionFunctionArgs.hasPartitionAttributes()) {
          throw new IllegalArgumentException(
              CliStrings.format(CliStrings.CREATE_REGION__MSG__OPTION_0_CAN_BE_USED_ONLY_FOR_PARTITIONEDREGION, 
                                regionFunctionArgs.getPartitionArgs().getUserSpecifiedPartitionAttributes()) + "" "" +
              CliStrings.format(CliStrings.CREATE_REGION__MSG__0_IS_NOT_A_PARITIONEDREGION, 
                                    useAttributesFrom));
        }
      }

      validateRegionFunctionArgs(cache, regionFunctionArgs);

      Set<DistributedMember> membersToCreateRegionOn = null;
      if (groups != null && groups.length != 0) {
        membersToCreateRegionOn = CliUtil.getDistributedMembersByGroup(cache, groups);
        // have only normal members from the group
        for (Iterator<DistributedMember> it = membersToCreateRegionOn.iterator(); it.hasNext();) {
          DistributedMember distributedMember = it.next();
          if ( ((InternalDistributedMember)distributedMember).getVmKind() == DistributionManager.LOCATOR_DM_TYPE ) {
            it.remove();
          }
        }
      } else {
        membersToCreateRegionOn = CliUtil.getAllNormalMembers(cache);
      }

      if (membersToCreateRegionOn.isEmpty()) {
        return ResultBuilder.createUserErrorResult(CliStrings.NO_CACHING_MEMBERS_FOUND_MESSAGE);
      }

      ResultCollector<?, ?> resultCollector = CliUtil.executeFunction(RegionCreateFunction.INSTANCE, regionFunctionArgs, membersToCreateRegionOn);
      @SuppressWarnings(""unchecked"")
      List<CliFunctionResult> regionCreateResults = (List<CliFunctionResult>) resultCollector.getResult();

      TabularResultData tabularResultData = ResultBuilder.createTabularResultData();
      final String errorPrefix = ""ERROR: "";
      for (CliFunctionResult regionCreateResult : regionCreateResults) {
        boolean success  = regionCreateResult.isSuccessful();
        tabularResultData.accumulate(""Member"", regionCreateResult.getMemberIdOrName());
        tabularResultData.accumulate(""Status"", (success ? """" : errorPrefix) + regionCreateResult.getMessage());
        
        if (success) {
          xmlEntity = regionCreateResult.getXmlEntity();
        }
      }
      
      result = ResultBuilder.buildResult(tabularResultData);
      verifyDistributedRegionMbean(cache, regionPath); 
      
    } catch (IllegalArgumentException e) {
      LogWrapper.getInstance().info(e.getMessage());
      result = ResultBuilder.createUserErrorResult(e.getMessage());
    } catch (IllegalStateException e) {
      LogWrapper.getInstance().info(e.getMessage());
      result = ResultBuilder.createUserErrorResult(e.getMessage());
    } catch (RuntimeException e) {
      LogWrapper.getInstance().info(e.getMessage(), e);
      result = ResultBuilder.createGemFireErrorResult(e.getMessage());
      
    }",False
"  public Result alterRegion(
      @CliOption (key = CliStrings.ALTER_REGION__REGION,
                  mandatory = true,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.ALTER_REGION__REGION__HELP)
      String regionPath,
      @CliOption (key = CliStrings.ALTER_REGION__GROUP,
                  optionContext = ConverterHint.MEMBERGROUP,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.ALTER_REGION__GROUP__HELP)
      @CliMetaData (valueSeparator = "","")
      String[] groups, 
      @CliOption (key = CliStrings.ALTER_REGION__ENTRYEXPIRATIONIDLETIME,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = ""-1"",
                  help = CliStrings.ALTER_REGION__ENTRYEXPIRATIONIDLETIME__HELP)
      Integer entryExpirationIdleTime,
      @CliOption (key = CliStrings.ALTER_REGION__ENTRYEXPIRATIONIDLETIMEACTION,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = CliMetaData.ANNOTATION_DEFAULT_VALUE,
                  help = CliStrings.ALTER_REGION__ENTRYEXPIRATIONIDLETIMEACTION__HELP)
      String entryExpirationIdleTimeAction,
      @CliOption (key = CliStrings.ALTER_REGION__ENTRYEXPIRATIONTIMETOLIVE,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = ""-1"",
                  help = CliStrings.ALTER_REGION__ENTRYEXPIRATIONTIMETOLIVE__HELP)
      Integer entryExpirationTTL,
      @CliOption (key = CliStrings.ALTER_REGION__ENTRYEXPIRATIONTTLACTION,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = CliMetaData.ANNOTATION_DEFAULT_VALUE,
                  help = CliStrings.ALTER_REGION__ENTRYEXPIRATIONTTLACTION__HELP)
      String entryExpirationTTLAction,
      @CliOption (key = CliStrings.ALTER_REGION__REGIONEXPIRATIONIDLETIME,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = ""-1"",
                  help = CliStrings.ALTER_REGION__REGIONEXPIRATIONIDLETIME__HELP)
      Integer regionExpirationIdleTime, 
      @CliOption (key = CliStrings.ALTER_REGION__REGIONEXPIRATIONIDLETIMEACTION,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = CliMetaData.ANNOTATION_DEFAULT_VALUE,
                  help = CliStrings.ALTER_REGION__REGIONEXPIRATIONIDLETIMEACTION__HELP)
      String regionExpirationIdleTimeAction,
      @CliOption (key = CliStrings.ALTER_REGION__REGIONEXPIRATIONTTL,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = ""-1"",
                  help = CliStrings.ALTER_REGION__REGIONEXPIRATIONTTL__HELP)
      Integer regionExpirationTTL, 
      @CliOption (key = CliStrings.ALTER_REGION__REGIONEXPIRATIONTTLACTION,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = CliMetaData.ANNOTATION_DEFAULT_VALUE,
                  help = CliStrings.ALTER_REGION__REGIONEXPIRATIONTTLACTION__HELP)
      String regionExpirationTTLAction,          
      @CliOption (key = CliStrings.ALTER_REGION__CACHELISTENER,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = """",
                  help = CliStrings.ALTER_REGION__CACHELISTENER__HELP)
      @CliMetaData (valueSeparator = "","") 
      String[] cacheListeners,
      @CliOption (key = CliStrings.ALTER_REGION__CACHELOADER,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = CliMetaData.ANNOTATION_DEFAULT_VALUE,
                  help = CliStrings.ALTER_REGION__CACHELOADER__HELP)
      String cacheLoader,
      @CliOption (key = CliStrings.ALTER_REGION__CACHEWRITER,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = CliMetaData.ANNOTATION_DEFAULT_VALUE,
                  help = CliStrings.ALTER_REGION__CACHEWRITER__HELP)
      String cacheWriter,
      @CliOption (key = CliStrings.ALTER_REGION__ASYNCEVENTQUEUEID,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = """",
                  help = CliStrings.ALTER_REGION__ASYNCEVENTQUEUEID__HELP)
      @CliMetaData (valueSeparator = "","") 
      String[] asyncEventQueueIds,
      @CliOption (key = CliStrings.ALTER_REGION__GATEWAYSENDERID,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = """",
                  help = CliStrings.ALTER_REGION__GATEWAYSENDERID__HELP)
      @CliMetaData (valueSeparator = "","") 
      String[] gatewaySenderIds,
      @CliOption (key = CliStrings.ALTER_REGION__CLONINGENABLED,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = ""false"",
                  help = CliStrings.ALTER_REGION__CLONINGENABLED__HELP)
      Boolean cloningEnabled,
      @CliOption (key = CliStrings.ALTER_REGION__EVICTIONMAX,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = ""0"",
                  help = CliStrings.ALTER_REGION__EVICTIONMAX__HELP)
      Integer evictionMax) {
    Result result = null;
    XmlEntity xmlEntity = null;

    try {
      Cache cache = CacheFactory.getAnyInstance();

      if (groups != null) {
        validateGroups(cache, groups);
      }

      RegionFunctionArgs.ExpirationAttrs entryIdle = null;
      if (entryExpirationIdleTime != null || entryExpirationIdleTimeAction != null) {
        if (entryExpirationIdleTime != null && entryExpirationIdleTime == -1) {
          entryExpirationIdleTime = ExpirationAttributes.DEFAULT.getTimeout();
        }
        if (CliMetaData.ANNOTATION_DEFAULT_VALUE.equals(entryExpirationIdleTimeAction)) {
          entryExpirationIdleTimeAction = ExpirationAttributes.DEFAULT.getAction().toString();
        }
        entryIdle = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.ENTRY_IDLE,
            entryExpirationIdleTime, entryExpirationIdleTimeAction);
      }
      RegionFunctionArgs.ExpirationAttrs entryTTL = null;
      if (entryExpirationTTL != null || entryExpirationTTLAction != null) {
        if (entryExpirationTTL != null && entryExpirationTTL == -1) {
          entryExpirationTTL = ExpirationAttributes.DEFAULT.getTimeout();
        }
        if (CliMetaData.ANNOTATION_DEFAULT_VALUE.equals(entryExpirationTTLAction)) {
          entryExpirationTTLAction = ExpirationAttributes.DEFAULT.getAction().toString();
        }
        entryTTL = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.ENTRY_TTL,
            entryExpirationTTL, entryExpirationTTLAction);
      }
      RegionFunctionArgs.ExpirationAttrs regionIdle = null;
      if (regionExpirationIdleTime != null || regionExpirationIdleTimeAction != null) {
        if (regionExpirationIdleTime != null  && regionExpirationIdleTime == -1) {
          regionExpirationIdleTime = ExpirationAttributes.DEFAULT.getTimeout();
        }
        if (CliMetaData.ANNOTATION_DEFAULT_VALUE.equals(regionExpirationIdleTimeAction)) {
          regionExpirationIdleTimeAction = ExpirationAttributes.DEFAULT.getAction().toString();
        }
        regionIdle = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.REGION_IDLE,
            regionExpirationIdleTime, regionExpirationIdleTimeAction);
      }
      RegionFunctionArgs.ExpirationAttrs regionTTL = null;
      if (regionExpirationTTL != null || regionExpirationTTLAction != null) {
        if (regionExpirationTTL != null && regionExpirationTTL == -1) {
          regionExpirationTTL = ExpirationAttributes.DEFAULT.getTimeout();
        }
        if (CliMetaData.ANNOTATION_DEFAULT_VALUE.equals(regionExpirationTTLAction)) {
          regionExpirationTTLAction = ExpirationAttributes.DEFAULT.getAction().toString();
        }
        regionTTL = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.REGION_TTL,
            regionExpirationTTL, regionExpirationTTLAction);
      }

      cacheLoader = convertDefaultValue(cacheLoader, StringUtils.EMPTY_STRING);
      cacheWriter = convertDefaultValue(cacheWriter, StringUtils.EMPTY_STRING);

      RegionFunctionArgs regionFunctionArgs = null;
      regionFunctionArgs = new RegionFunctionArgs(regionPath, null, null, false, null, null, null, entryIdle, entryTTL,
        regionIdle, regionTTL, null, null, null, null, cacheListeners, cacheLoader, cacheWriter, asyncEventQueueIds,
        gatewaySenderIds, null, cloningEnabled, null, null, null, null, null, null, null, null, evictionMax, null, null);

      Set<String> cacheListenersSet = regionFunctionArgs.getCacheListeners();
      if (cacheListenersSet != null && !cacheListenersSet.isEmpty()) {
        for (String cacheListener : cacheListenersSet) {
          if (!isClassNameValid(cacheListener)) {
            throw new IllegalArgumentException(CliStrings.format(
                CliStrings.ALTER_REGION__MSG__SPECIFY_VALID_CLASSNAME_FOR_CACHELISTENER_0_IS_INVALID,
                new Object[] { cacheListener }));
          }
        }
      }

      if (cacheLoader != null && !isClassNameValid(cacheLoader)) {
        throw new IllegalArgumentException(CliStrings.format(
            CliStrings.ALTER_REGION__MSG__SPECIFY_VALID_CLASSNAME_FOR_CACHELOADER_0_IS_INVALID, new Object[] { cacheLoader }));
      }

      if (cacheWriter != null && !isClassNameValid(cacheWriter)) {
        throw new IllegalArgumentException(CliStrings.format(
            CliStrings.ALTER_REGION__MSG__SPECIFY_VALID_CLASSNAME_FOR_CACHEWRITER_0_IS_INVALID, new Object[] { cacheWriter }));
      }
              
      if (evictionMax != null && evictionMax < 0) {
        throw new IllegalArgumentException(CliStrings.format(
            CliStrings.ALTER_REGION__MSG__SPECIFY_POSITIVE_INT_FOR_EVICTIONMAX_0_IS_NOT_VALID, new Object[] { evictionMax }));
      }

      Set<DistributedMember> targetMembers;
      try {
        targetMembers = CliUtil.findAllMatchingMembers(groups, null);
      } catch (CommandResultException crex) {
        return crex.getResult();
      }

      ResultCollector<?, ?> resultCollector = CliUtil.executeFunction(new RegionAlterFunction(), regionFunctionArgs, targetMembers);
      List<CliFunctionResult> regionAlterResults = (List<CliFunctionResult>) resultCollector.getResult();

      TabularResultData tabularResultData = ResultBuilder.createTabularResultData();
      final String errorPrefix = ""ERROR: "";
      for (CliFunctionResult regionAlterResult : regionAlterResults) {
        boolean success  = regionAlterResult.isSuccessful();
        tabularResultData.accumulate(""Member"", regionAlterResult.getMemberIdOrName());
        if (success) {
          tabularResultData.accumulate(""Status"", regionAlterResult.getMessage());
          xmlEntity = regionAlterResult.getXmlEntity();
        } else {
          tabularResultData.accumulate(""Status"", errorPrefix + regionAlterResult.getMessage());
          tabularResultData.setStatus(Status.ERROR);
        }
      }
      result = ResultBuilder.buildResult(tabularResultData);
    } catch (IllegalArgumentException e) {
      LogWrapper.getInstance().info(e.getMessage());
      result = ResultBuilder.createUserErrorResult(e.getMessage());
    } catch (IllegalStateException e) {
      LogWrapper.getInstance().info(e.getMessage());
      result = ResultBuilder.createUserErrorResult(e.getMessage());
    } catch (RuntimeException e) {
      LogWrapper.getInstance().info(e.getMessage(), e);
      result = ResultBuilder.createGemFireErrorResult(e.getMessage());
    }
    if (xmlEntity != null) {
      result.setCommandPersisted((new SharedConfigurationWriter()).addXmlEntity(xmlEntity, groups));
    }
    return result;
  }",True
"  public Result alterRegion(
      @CliOption (key = CliStrings.ALTER_REGION__REGION,
                  mandatory = true,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.ALTER_REGION__REGION__HELP)
      String regionPath,
      @CliOption (key = CliStrings.ALTER_REGION__GROUP,
                  optionContext = ConverterHint.MEMBERGROUP,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.ALTER_REGION__GROUP__HELP)
      @CliMetaData (valueSeparator = "","")
      String[] groups, 
      @CliOption (key = CliStrings.ALTER_REGION__ENTRYEXPIRATIONIDLETIME,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = ""-1"",
                  help = CliStrings.ALTER_REGION__ENTRYEXPIRATIONIDLETIME__HELP)
      Integer entryExpirationIdleTime,
      @CliOption (key = CliStrings.ALTER_REGION__ENTRYEXPIRATIONIDLETIMEACTION,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = CliMetaData.ANNOTATION_DEFAULT_VALUE,
                  help = CliStrings.ALTER_REGION__ENTRYEXPIRATIONIDLETIMEACTION__HELP)
      String entryExpirationIdleTimeAction,
      @CliOption (key = CliStrings.ALTER_REGION__ENTRYEXPIRATIONTIMETOLIVE,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = ""-1"",
                  help = CliStrings.ALTER_REGION__ENTRYEXPIRATIONTIMETOLIVE__HELP)
      Integer entryExpirationTTL,
      @CliOption (key = CliStrings.ALTER_REGION__ENTRYEXPIRATIONTTLACTION,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = CliMetaData.ANNOTATION_DEFAULT_VALUE,
                  help = CliStrings.ALTER_REGION__ENTRYEXPIRATIONTTLACTION__HELP)
      String entryExpirationTTLAction,
      @CliOption (key = CliStrings.ALTER_REGION__REGIONEXPIRATIONIDLETIME,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = ""-1"",
                  help = CliStrings.ALTER_REGION__REGIONEXPIRATIONIDLETIME__HELP)
      Integer regionExpirationIdleTime, 
      @CliOption (key = CliStrings.ALTER_REGION__REGIONEXPIRATIONIDLETIMEACTION,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = CliMetaData.ANNOTATION_DEFAULT_VALUE,
                  help = CliStrings.ALTER_REGION__REGIONEXPIRATIONIDLETIMEACTION__HELP)
      String regionExpirationIdleTimeAction,
      @CliOption (key = CliStrings.ALTER_REGION__REGIONEXPIRATIONTTL,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = ""-1"",
                  help = CliStrings.ALTER_REGION__REGIONEXPIRATIONTTL__HELP)
      Integer regionExpirationTTL, 
      @CliOption (key = CliStrings.ALTER_REGION__REGIONEXPIRATIONTTLACTION,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = CliMetaData.ANNOTATION_DEFAULT_VALUE,
                  help = CliStrings.ALTER_REGION__REGIONEXPIRATIONTTLACTION__HELP)
      String regionExpirationTTLAction,          
      @CliOption (key = CliStrings.ALTER_REGION__CACHELISTENER,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = """",
                  help = CliStrings.ALTER_REGION__CACHELISTENER__HELP)
      @CliMetaData (valueSeparator = "","") 
      String[] cacheListeners,
      @CliOption (key = CliStrings.ALTER_REGION__CACHELOADER,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = CliMetaData.ANNOTATION_DEFAULT_VALUE,
                  help = CliStrings.ALTER_REGION__CACHELOADER__HELP)
      String cacheLoader,
      @CliOption (key = CliStrings.ALTER_REGION__CACHEWRITER,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = CliMetaData.ANNOTATION_DEFAULT_VALUE,
                  help = CliStrings.ALTER_REGION__CACHEWRITER__HELP)
      String cacheWriter,
      @CliOption (key = CliStrings.ALTER_REGION__ASYNCEVENTQUEUEID,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = """",
                  help = CliStrings.ALTER_REGION__ASYNCEVENTQUEUEID__HELP)
      @CliMetaData (valueSeparator = "","") 
      String[] asyncEventQueueIds,
      @CliOption (key = CliStrings.ALTER_REGION__GATEWAYSENDERID,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = """",
                  help = CliStrings.ALTER_REGION__GATEWAYSENDERID__HELP)
      @CliMetaData (valueSeparator = "","") 
      String[] gatewaySenderIds,
      @CliOption (key = CliStrings.ALTER_REGION__CLONINGENABLED,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = ""false"",
                  help = CliStrings.ALTER_REGION__CLONINGENABLED__HELP)
      Boolean cloningEnabled,
      @CliOption (key = CliStrings.ALTER_REGION__EVICTIONMAX,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = ""0"",
                  help = CliStrings.ALTER_REGION__EVICTIONMAX__HELP)
      Integer evictionMax) {
    Result result = null;
    XmlEntity xmlEntity = null;

    try {
      Cache cache = CacheFactory.getAnyInstance();

      if (groups != null) {
        validateGroups(cache, groups);
      }

      RegionFunctionArgs.ExpirationAttrs entryIdle = null;
      if (entryExpirationIdleTime != null || entryExpirationIdleTimeAction != null) {
        if (entryExpirationIdleTime != null && entryExpirationIdleTime == -1) {
          entryExpirationIdleTime = ExpirationAttributes.DEFAULT.getTimeout();
        }
        if (CliMetaData.ANNOTATION_DEFAULT_VALUE.equals(entryExpirationIdleTimeAction)) {
          entryExpirationIdleTimeAction = ExpirationAttributes.DEFAULT.getAction().toString();
        }
        entryIdle = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.ENTRY_IDLE,
            entryExpirationIdleTime, entryExpirationIdleTimeAction);
      }
      RegionFunctionArgs.ExpirationAttrs entryTTL = null;
      if (entryExpirationTTL != null || entryExpirationTTLAction != null) {
        if (entryExpirationTTL != null && entryExpirationTTL == -1) {
          entryExpirationTTL = ExpirationAttributes.DEFAULT.getTimeout();
        }
        if (CliMetaData.ANNOTATION_DEFAULT_VALUE.equals(entryExpirationTTLAction)) {
          entryExpirationTTLAction = ExpirationAttributes.DEFAULT.getAction().toString();
        }
        entryTTL = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.ENTRY_TTL,
            entryExpirationTTL, entryExpirationTTLAction);
      }
      RegionFunctionArgs.ExpirationAttrs regionIdle = null;
      if (regionExpirationIdleTime != null || regionExpirationIdleTimeAction != null) {
        if (regionExpirationIdleTime != null  && regionExpirationIdleTime == -1) {
          regionExpirationIdleTime = ExpirationAttributes.DEFAULT.getTimeout();
        }
        if (CliMetaData.ANNOTATION_DEFAULT_VALUE.equals(regionExpirationIdleTimeAction)) {
          regionExpirationIdleTimeAction = ExpirationAttributes.DEFAULT.getAction().toString();
        }
        regionIdle = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.REGION_IDLE,
            regionExpirationIdleTime, regionExpirationIdleTimeAction);
      }
      RegionFunctionArgs.ExpirationAttrs regionTTL = null;
      if (regionExpirationTTL != null || regionExpirationTTLAction != null) {
        if (regionExpirationTTL != null && regionExpirationTTL == -1) {
          regionExpirationTTL = ExpirationAttributes.DEFAULT.getTimeout();
        }
        if (CliMetaData.ANNOTATION_DEFAULT_VALUE.equals(regionExpirationTTLAction)) {
          regionExpirationTTLAction = ExpirationAttributes.DEFAULT.getAction().toString();
        }
        regionTTL = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.REGION_TTL,
            regionExpirationTTL, regionExpirationTTLAction);
      }

      cacheLoader = convertDefaultValue(cacheLoader, StringUtils.EMPTY_STRING);
      cacheWriter = convertDefaultValue(cacheWriter, StringUtils.EMPTY_STRING);

      RegionFunctionArgs regionFunctionArgs = null;
      regionFunctionArgs = new RegionFunctionArgs(regionPath, null, null, false, null, null, null, entryIdle, entryTTL,
        regionIdle, regionTTL, null, null, null, null, cacheListeners, cacheLoader, cacheWriter, asyncEventQueueIds,
        gatewaySenderIds, null, cloningEnabled, null, null, null, null, null, null, null, null, evictionMax, null, null, null);

      Set<String> cacheListenersSet = regionFunctionArgs.getCacheListeners();
      if (cacheListenersSet != null && !cacheListenersSet.isEmpty()) {
        for (String cacheListener : cacheListenersSet) {
          if (!isClassNameValid(cacheListener)) {
            throw new IllegalArgumentException(CliStrings.format(
                CliStrings.ALTER_REGION__MSG__SPECIFY_VALID_CLASSNAME_FOR_CACHELISTENER_0_IS_INVALID,
                new Object[] { cacheListener }));
          }
        }
      }

      if (cacheLoader != null && !isClassNameValid(cacheLoader)) {
        throw new IllegalArgumentException(CliStrings.format(
            CliStrings.ALTER_REGION__MSG__SPECIFY_VALID_CLASSNAME_FOR_CACHELOADER_0_IS_INVALID, new Object[] { cacheLoader }));
      }

      if (cacheWriter != null && !isClassNameValid(cacheWriter)) {
        throw new IllegalArgumentException(CliStrings.format(
            CliStrings.ALTER_REGION__MSG__SPECIFY_VALID_CLASSNAME_FOR_CACHEWRITER_0_IS_INVALID, new Object[] { cacheWriter }));
      }
              
      if (evictionMax != null && evictionMax < 0) {
        throw new IllegalArgumentException(CliStrings.format(
            CliStrings.ALTER_REGION__MSG__SPECIFY_POSITIVE_INT_FOR_EVICTIONMAX_0_IS_NOT_VALID, new Object[] { evictionMax }));
      }

      Set<DistributedMember> targetMembers;
      try {
        targetMembers = CliUtil.findAllMatchingMembers(groups, null);
      } catch (CommandResultException crex) {
        return crex.getResult();
      }

      ResultCollector<?, ?> resultCollector = CliUtil.executeFunction(new RegionAlterFunction(), regionFunctionArgs, targetMembers);
      List<CliFunctionResult> regionAlterResults = (List<CliFunctionResult>) resultCollector.getResult();

      TabularResultData tabularResultData = ResultBuilder.createTabularResultData();
      final String errorPrefix = ""ERROR: "";
      for (CliFunctionResult regionAlterResult : regionAlterResults) {
        boolean success  = regionAlterResult.isSuccessful();
        tabularResultData.accumulate(""Member"", regionAlterResult.getMemberIdOrName());
        if (success) {
          tabularResultData.accumulate(""Status"", regionAlterResult.getMessage());
          xmlEntity = regionAlterResult.getXmlEntity();
        } else {
          tabularResultData.accumulate(""Status"", errorPrefix + regionAlterResult.getMessage());
          tabularResultData.setStatus(Status.ERROR);
        }
      }
      result = ResultBuilder.buildResult(tabularResultData);
    } catch (IllegalArgumentException e) {
      LogWrapper.getInstance().info(e.getMessage());
      result = ResultBuilder.createUserErrorResult(e.getMessage());
    } catch (IllegalStateException e) {
      LogWrapper.getInstance().info(e.getMessage());
      result = ResultBuilder.createUserErrorResult(e.getMessage());
    } catch (RuntimeException e) {
      LogWrapper.getInstance().info(e.getMessage(), e);
      result = ResultBuilder.createGemFireErrorResult(e.getMessage());
    }
    if (xmlEntity != null) {
      result.setCommandPersisted((new SharedConfigurationWriter()).addXmlEntity(xmlEntity, groups));
    }
    return result;
  }",False
"  public Result createRegion(
      @CliOption (key = CliStrings.CREATE_REGION__REGION,
                  mandatory = true,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__REGION__HELP)
      String regionPath,
      @CliOption (key = CliStrings.CREATE_REGION__REGIONSHORTCUT,
                  mandatory = false,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__REGIONSHORTCUT__HELP)
      RegionShortcut regionShortcut,
      @CliOption (key = CliStrings.CREATE_REGION__USEATTRIBUTESFROM,
                  optionContext = ConverterHint.REGIONPATH,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__USEATTRIBUTESFROM__HELP)
      String useAttributesFrom, 
      @CliOption (key = CliStrings.CREATE_REGION__GROUP,
                  optionContext = ConverterHint.MEMBERGROUP,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__GROUP__HELP)
      @CliMetaData (valueSeparator = "","")
      String[] groups,
      @CliOption (key = CliStrings.CREATE_REGION__SKIPIFEXISTS,
                  unspecifiedDefaultValue = ""true"",
                  specifiedDefaultValue = ""true"",
                  help = CliStrings.CREATE_REGION__SKIPIFEXISTS__HELP)
      boolean skipIfExists,
      
      // the following should all be in alphabetical order according to
      // their key string
      @CliOption (key = CliStrings.CREATE_REGION__ASYNCEVENTQUEUEID,
                  help = CliStrings.CREATE_REGION__ASYNCEVENTQUEUEID__HELP)
      @CliMetaData (valueSeparator = "","") 
      String[] asyncEventQueueIds,
      @CliOption (key = CliStrings.CREATE_REGION__CACHELISTENER,
                  help = CliStrings.CREATE_REGION__CACHELISTENER__HELP)
      @CliMetaData (valueSeparator = "","") 
      String[] cacheListener,
      @CliOption (key = CliStrings.CREATE_REGION__CACHELOADER,
                  help = CliStrings.CREATE_REGION__CACHELOADER__HELP)
      String cacheLoader,
      @CliOption (key = CliStrings.CREATE_REGION__CACHEWRITER,
                  help = CliStrings.CREATE_REGION__CACHEWRITER__HELP)
      String cacheWriter,
      @CliOption (key = CliStrings.CREATE_REGION__COLOCATEDWITH,
                  optionContext = ConverterHint.REGIONPATH,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__COLOCATEDWITH__HELP)
      String prColocatedWith,
      @CliOption (key = CliStrings.CREATE_REGION__COMPRESSOR,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__COMPRESSOR__HELP)
      String compressor,
      @CliOption (key = CliStrings.CREATE_REGION__CONCURRENCYLEVEL,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__CONCURRENCYLEVEL__HELP)
      Integer concurrencyLevel,
      @CliOption (key = CliStrings.CREATE_REGION__DISKSTORE,
                  help = CliStrings.CREATE_REGION__DISKSTORE__HELP)
      String diskStore,
      @CliOption (key = CliStrings.CREATE_REGION__ENABLEASYNCCONFLATION,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__ENABLEASYNCCONFLATION__HELP)
      Boolean enableAsyncConflation,
      @CliOption (key = CliStrings.CREATE_REGION__CLONINGENABLED,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__CLONINGENABLED__HELP)
      Boolean cloningEnabled,
      @CliOption (key = CliStrings.CREATE_REGION__CONCURRENCYCHECKSENABLED,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__CONCURRENCYCHECKSENABLED__HELP)
      Boolean concurrencyChecksEnabled,
      @CliOption (key = CliStrings.CREATE_REGION__MULTICASTENABLED,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__MULTICASTENABLED__HELP)
      Boolean mcastEnabled,
      @CliOption (key = CliStrings.CREATE_REGION__STATISTICSENABLED,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__STATISTICSENABLED__HELP)
      Boolean statisticsEnabled,
      @CliOption (key = CliStrings.CREATE_REGION__ENABLESUBSCRIPTIONCONFLATION,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__ENABLESUBSCRIPTIONCONFLATION__HELP)
      Boolean enableSubscriptionConflation,
      @CliOption (key = CliStrings.CREATE_REGION__DISKSYNCHRONOUS,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__DISKSYNCHRONOUS__HELP)
      Boolean diskSynchronous,
      @CliOption (key = CliStrings.CREATE_REGION__ENTRYEXPIRATIONIDLETIME,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__ENTRYEXPIRATIONIDLETIME__HELP)
      Integer entryExpirationIdleTime,
      @CliOption (key = CliStrings.CREATE_REGION__ENTRYEXPIRATIONIDLETIMEACTION,
                  help = CliStrings.CREATE_REGION__ENTRYEXPIRATIONIDLETIMEACTION__HELP)
      String entryExpirationIdleTimeAction,
      @CliOption (key = CliStrings.CREATE_REGION__ENTRYEXPIRATIONTIMETOLIVE,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__ENTRYEXPIRATIONTIMETOLIVE__HELP)
      Integer entryExpirationTTL,
      @CliOption (key = CliStrings.CREATE_REGION__ENTRYEXPIRATIONTTLACTION,
                  help = CliStrings.CREATE_REGION__ENTRYEXPIRATIONTTLACTION__HELP)
      String entryExpirationTTLAction,
      @CliOption (key = CliStrings.CREATE_REGION__GATEWAYSENDERID,
                  help = CliStrings.CREATE_REGION__GATEWAYSENDERID__HELP)
      @CliMetaData (valueSeparator = "","") 
      String[] gatewaySenderIds,
      @CliOption (key = CliStrings.CREATE_REGION__HDFSSTORE_NAME,
                  help = CliStrings.CREATE_REGION__HDFSSTORE_NAME__HELP ,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE)
      String hdfsStoreName,
      @CliOption (key = CliStrings.CREATE_REGION__HDFSSTORE_WRITEONLY,      
                  help = CliStrings.CREATE_REGION__HDFSSTORE_WRITEONLY__HELP,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE)
      Boolean hdfsWriteOnly,      
      @CliOption (key = CliStrings.CREATE_REGION__KEYCONSTRAINT,
                  help = CliStrings.CREATE_REGION__KEYCONSTRAINT__HELP)
      String keyConstraint,
      @CliOption (key = CliStrings.CREATE_REGION__LOCALMAXMEMORY,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__LOCALMAXMEMORY__HELP)
      Integer prLocalMaxMemory, 
      @CliOption (key = CliStrings.CREATE_REGION__OFF_HEAP,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  specifiedDefaultValue = ""true"",
                  help = CliStrings.CREATE_REGION__OFF_HEAP__HELP)
      Boolean offHeap,
      @CliOption (key = CliStrings.CREATE_REGION__REGIONEXPIRATIONIDLETIME,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__REGIONEXPIRATIONIDLETIME__HELP)
      Integer regionExpirationIdleTime,
      @CliOption (key = CliStrings.CREATE_REGION__REGIONEXPIRATIONIDLETIMEACTION,
                  help = CliStrings.CREATE_REGION__REGIONEXPIRATIONIDLETIMEACTION__HELP)
      String regionExpirationIdleTimeAction,
      @CliOption (key = CliStrings.CREATE_REGION__REGIONEXPIRATIONTTL,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__REGIONEXPIRATIONTTL__HELP)
      Integer regionExpirationTTL,
      @CliOption (key = CliStrings.CREATE_REGION__REGIONEXPIRATIONTTLACTION,
                  help = CliStrings.CREATE_REGION__REGIONEXPIRATIONTTLACTION__HELP)
      String regionExpirationTTLAction,      
      @CliOption (key = CliStrings.CREATE_REGION__RECOVERYDELAY,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__RECOVERYDELAY__HELP)
      Long prRecoveryDelay,
      @CliOption (key = CliStrings.CREATE_REGION__REDUNDANTCOPIES,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__REDUNDANTCOPIES__HELP)
      Integer prRedundantCopies, 
      @CliOption (key = CliStrings.CREATE_REGION__STARTUPRECOVERYDDELAY,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__STARTUPRECOVERYDDELAY__HELP)
      Long prStartupRecoveryDelay,
      @CliOption (key = CliStrings.CREATE_REGION__TOTALMAXMEMORY,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__TOTALMAXMEMORY__HELP)
      Long prTotalMaxMemory, 
      @CliOption (key = CliStrings.CREATE_REGION__TOTALNUMBUCKETS,
                  unspecifiedDefaultValue = CliMetaData.ANNOTATION_NULL_VALUE,
                  help = CliStrings.CREATE_REGION__TOTALNUMBUCKETS__HELP)
      Integer prTotalNumBuckets,      
      @CliOption (key = CliStrings.CREATE_REGION__VALUECONSTRAINT,
                  help = CliStrings.CREATE_REGION__VALUECONSTRAINT__HELP)
      String valueConstraint
      // NOTICE: keep the region attributes params in alphabetical order
) {
    Result result = null;
    XmlEntity xmlEntity = null;

    try {
      Cache cache = CacheFactory.getAnyInstance();

      if (regionShortcut != null && useAttributesFrom != null) {
        throw new IllegalArgumentException(CliStrings.CREATE_REGION__MSG__ONLY_ONE_OF_REGIONSHORTCUT_AND_USEATTRIBUESFROM_CAN_BE_SPECIFIED);
      } else if (regionShortcut == null && useAttributesFrom == null) {
        throw new IllegalArgumentException(CliStrings.CREATE_REGION__MSG__ONE_OF_REGIONSHORTCUT_AND_USEATTRIBUESFROM_IS_REQUIRED);
      }
      
      validateRegionPathAndParent(cache, regionPath);
      validateGroups(cache, groups);

      RegionFunctionArgs.ExpirationAttrs entryIdle = null;
      if (entryExpirationIdleTime != null) {
        entryIdle = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.ENTRY_IDLE, entryExpirationIdleTime, entryExpirationIdleTimeAction);
      }
      RegionFunctionArgs.ExpirationAttrs entryTTL = null;
      if (entryExpirationTTL != null) {
        entryTTL = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.ENTRY_TTL, entryExpirationTTL, entryExpirationTTLAction);
      }
      RegionFunctionArgs.ExpirationAttrs regionIdle = null;
      if (regionExpirationIdleTime != null) {
        regionIdle = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.REGION_IDLE, regionExpirationIdleTime, regionExpirationIdleTimeAction);
      }
      RegionFunctionArgs.ExpirationAttrs regionTTL = null;
      if (regionExpirationTTL != null) {
        regionTTL = new RegionFunctionArgs.ExpirationAttrs(RegionFunctionArgs.ExpirationAttrs.ExpirationFor.REGION_TTL, regionExpirationTTL, regionExpirationTTLAction);
      }
      
      RegionFunctionArgs regionFunctionArgs = null;
      if (useAttributesFrom != null) {
        if (!regionExists(cache, useAttributesFrom)) {
          throw new IllegalArgumentException(CliStrings.format(CliStrings.CREATE_REGION__MSG__SPECIFY_VALID_REGION_PATH_FOR_0_REGIONPATH_1_NOT_FOUND, new Object[] {CliStrings.CREATE_REGION__USEATTRIBUTESFROM, useAttributesFrom}));
        }
        
        
        FetchRegionAttributesFunctionResult<Object, Object> regionAttributesResult = getRegionAttributes(cache, useAttributesFrom);
        RegionAttributes<?, ?> regionAttributes = regionAttributesResult.getRegionAttributes();
           
        
        // give preference to user specified plugins than the ones retrieved from other region
        String[] cacheListenerClasses = cacheListener != null && cacheListener.length != 0 ? cacheListener : regionAttributesResult.getCacheListenerClasses();
        String cacheLoaderClass = cacheLoader != null ? cacheLoader : regionAttributesResult.getCacheLoaderClass();
        String cacheWriterClass = cacheWriter != null ? cacheWriter : regionAttributesResult.getCacheWriterClass();;

        regionFunctionArgs = new RegionFunctionArgs(regionPath,
            useAttributesFrom, skipIfExists, keyConstraint, valueConstraint,
            statisticsEnabled, entryIdle, entryTTL, regionIdle,
            regionTTL, diskStore, diskSynchronous, enableAsyncConflation,
            enableSubscriptionConflation, cacheListenerClasses, cacheLoaderClass,
            cacheWriterClass, asyncEventQueueIds, gatewaySenderIds,
            concurrencyChecksEnabled, cloningEnabled, concurrencyLevel, 
            prColocatedWith, prLocalMaxMemory, prRecoveryDelay,
            prRedundantCopies, prStartupRecoveryDelay,
            prTotalMaxMemory, prTotalNumBuckets,
            offHeap, hdfsStoreName , hdfsWriteOnly,  mcastEnabled, regionAttributes);
        

        if (regionAttributes.getPartitionAttributes() == null && regionFunctionArgs.hasPartitionAttributes()) {
          throw new IllegalArgumentException(
              CliStrings.format(CliStrings.CREATE_REGION__MSG__OPTION_0_CAN_BE_USED_ONLY_FOR_PARTITIONEDREGION, 
                                regionFunctionArgs.getPartitionArgs().getUserSpecifiedPartitionAttributes()) + "" "" +
              CliStrings.format(CliStrings.CREATE_REGION__MSG__0_IS_NOT_A_PARITIONEDREGION, 
                                    useAttributesFrom));
        }
      } else {
        regionFunctionArgs = new RegionFunctionArgs(
          regionPath, regionShortcut, useAttributesFrom, skipIfExists,
          keyConstraint, valueConstraint, statisticsEnabled, entryIdle, entryTTL,
          regionIdle, regionTTL, diskStore, diskSynchronous,
          enableAsyncConflation, enableSubscriptionConflation, cacheListener,
          cacheLoader, cacheWriter, asyncEventQueueIds, gatewaySenderIds,
          concurrencyChecksEnabled, cloningEnabled, concurrencyLevel, 
          prColocatedWith, prLocalMaxMemory, prRecoveryDelay,
          prRedundantCopies, prStartupRecoveryDelay,
          prTotalMaxMemory, prTotalNumBuckets, null,compressor, offHeap , hdfsStoreName , hdfsWriteOnly, mcastEnabled);
        
        if (!regionShortcut.name().startsWith(""PARTITION"") && regionFunctionArgs.hasPartitionAttributes()) {
          throw new IllegalArgumentException(
              CliStrings.format(CliStrings.CREATE_REGION__MSG__OPTION_0_CAN_BE_USED_ONLY_FOR_PARTITIONEDREGION, 
                                regionFunctionArgs.getPartitionArgs().getUserSpecifiedPartitionAttributes()) + "" "" +
              CliStrings.format(CliStrings.CREATE_REGION__MSG__0_IS_NOT_A_PARITIONEDREGION, 
                                    useAttributesFrom));
        }
      }

      validateRegionFunctionArgs(cache, regionFunctionArgs);

      Set<DistributedMember> membersToCreateRegionOn = null;
      if (groups != null && groups.length != 0) {
        membersToCreateRegionOn = CliUtil.getDistributedMembersByGroup(cache, groups);
        // have only normal members from the group
        for (Iterator<DistributedMember> it = membersToCreateRegionOn.iterator(); it.hasNext();) {
          DistributedMember distributedMember = it.next();
          if ( ((InternalDistributedMember)distributedMember).getVmKind() == DistributionManager.LOCATOR_DM_TYPE ) {
            it.remove();
          }
        }
      } else {
        membersToCreateRegionOn = CliUtil.getAllNormalMembers(cache);
      }

      if (membersToCreateRegionOn.isEmpty()) {
        return ResultBuilder.createUserErrorResult(CliStrings.NO_CACHING_MEMBERS_FOUND_MESSAGE);
      }

      ResultCollector<?, ?> resultCollector = CliUtil.executeFunction(RegionCreateFunction.INSTANCE, regionFunctionArgs, membersToCreateRegionOn);
      @SuppressWarnings(""unchecked"")
      List<CliFunctionResult> regionCreateResults = (List<CliFunctionResult>) resultCollector.getResult();

      TabularResultData tabularResultData = ResultBuilder.createTabularResultData();
      final String errorPrefix = ""ERROR: "";
      for (CliFunctionResult regionCreateResult : regionCreateResults) {
        boolean success  = regionCreateResult.isSuccessful();
        tabularResultData.accumulate(""Member"", regionCreateResult.getMemberIdOrName());
        tabularResultData.accumulate(""Status"", (success ? """" : errorPrefix) + regionCreateResult.getMessage());
        
        if (success) {
          xmlEntity = regionCreateResult.getXmlEntity();
        }
      }
      
      result = ResultBuilder.buildResult(tabularResultData);
      verifyDistributedRegionMbean(cache, regionPath); 
      
    } catch (IllegalArgumentException e) {
      LogWrapper.getInstance().info(e.getMessage());
      result = ResultBuilder.createUserErrorResult(e.getMessage());
    } catch (IllegalStateException e) {
      LogWrapper.getInstance().info(e.getMessage());
      result = ResultBuilder.createUserErrorResult(e.getMessage());
    } catch (RuntimeException e) {
      LogWrapper.getInstance().info(e.getMessage(), e);
      result = ResultBuilder.createGemFireErrorResult(e.getMessage());
      
    }
    if (xmlEntity != null) {
      result.setCommandPersisted((new SharedConfigurationWriter()).addXmlEntity(xmlEntity, groups));
    }
    return result;
  }",False
"  public static <K, V> Region<?, ?> createRegion(Cache cache, RegionFunctionArgs regionCreateArgs) {
    Region<K, V> createdRegion = null;
    
    final String regionPath = regionCreateArgs.getRegionPath();
    final RegionShortcut regionShortcut = regionCreateArgs.getRegionShortcut();
    final String useAttributesFrom      = regionCreateArgs.getUseAttributesFrom();

    // If a region path indicates a sub-region, check whether the parent region exists
    RegionPath regionPathData = new RegionPath(regionPath);
    String parentRegionPath = regionPathData.getParent();
    Region<?, ?> parentRegion = null;
    if (parentRegionPath != null && !Region.SEPARATOR.equals(parentRegionPath)) {
      parentRegion = cache.getRegion(parentRegionPath);
      if (parentRegion == null) {
        throw new IllegalArgumentException(CliStrings.format(CliStrings.CREATE_REGION__MSG__PARENT_REGION_FOR_0_DOESNOT_EXIST, new Object[] {regionPath}));
      }

      if (parentRegion.getAttributes().getPartitionAttributes() != null) {
        // For a PR, sub-regions are not supported.
        throw new CreateSubregionException(
            CliStrings.format(CliStrings.CREATE_REGION__MSG__0_IS_A_PR_CANNOT_HAVE_SUBREGIONS, parentRegion.getFullPath()));
      }
    }

    // One of Region Shortcut OR Use Attributes From has to be given
    if (regionShortcut == null && useAttributesFrom == null) {
      throw new IllegalArgumentException(CliStrings.CREATE_REGION__MSG__ONE_OF_REGIONSHORTCUT_AND_USEATTRIBUESFROM_IS_REQUIRED);
    }

    boolean isPartitioned = false;
    RegionFactory<K, V> factory = null;
    RegionAttributes<K, V> regionAttributes = null;
    if (regionShortcut != null) {
      regionAttributes = cache.getRegionAttributes(regionShortcut.toString());
      if (logger.isDebugEnabled()) {
        logger.debug(""Using shortcut {} for {} region attributes : {}"", regionShortcut, regionPath, regionAttributes);
      }

      if (regionAttributes == null) {
        if (logger.isDebugEnabled()) {
          logger.debug(""Shortcut {} doesn't have attributes in {}"", regionShortcut, cache.listRegionAttributes());
        }
        throw new IllegalStateException(CliStrings.format(CliStrings.CREATE_REGION__MSG__COULDNOT_LOAD_REGION_ATTRIBUTES_FOR_SHORTCUT_0, regionShortcut));
      }
    } else {
      if (logger.isDebugEnabled()) {
        logger.debug(""Using Manager's region attributes for {}"", regionPath);
      }
      regionAttributes = regionCreateArgs.getRegionAttributes();
      if (logger.isDebugEnabled()) {
        logger.debug(""Using Attributes : {}"", regionAttributes);
      }
    }
    isPartitioned = regionAttributes.getPartitionAttributes() != null;

    factory = cache.createRegionFactory(regionAttributes);

    if (!isPartitioned && regionCreateArgs.hasPartitionAttributes()) {
      throw new IllegalArgumentException(
          CliStrings.format(
                  CliStrings.CREATE_REGION__MSG__OPTION_0_CAN_BE_USED_ONLY_FOR_PARTITIONEDREGION,
                  regionCreateArgs.getPartitionArgs().getUserSpecifiedPartitionAttributes()));
    }

    if (isPartitioned) {
      PartitionAttributes<K, V> partitionAttributes = extractPartitionAttributes(cache, regionAttributes, regionCreateArgs);

      DataPolicy originalDataPolicy = regionAttributes.getDataPolicy();
      factory.setPartitionAttributes(partitionAttributes);
      // We have to do this because AttributesFactory.setPartitionAttributes()
      // checks RegionAttributes.hasDataPolicy() which is set only when the data
      // policy is set explicitly
      factory.setDataPolicy(originalDataPolicy);      
    }
       
    // Set Constraints
    final String keyConstraint = regionCreateArgs.getKeyConstraint();
    final String valueConstraint = regionCreateArgs.getValueConstraint();
    if (keyConstraint != null && !keyConstraint.isEmpty()) {
      Class<K> keyConstraintClass = forName(keyConstraint, CliStrings.CREATE_REGION__KEYCONSTRAINT);
      factory.setKeyConstraint(keyConstraintClass);
    }

    if (valueConstraint != null && !valueConstraint.isEmpty()) {
      Class<V> valueConstraintClass = forName(valueConstraint, CliStrings.CREATE_REGION__VALUECONSTRAINT);
      factory.setValueConstraint(valueConstraintClass);
    }

    // Expiration attributes
    final RegionFunctionArgs.ExpirationAttrs entryExpirationIdleTime = regionCreateArgs.getEntryExpirationIdleTime();
    if (entryExpirationIdleTime != null) {
      factory.setEntryIdleTimeout(entryExpirationIdleTime.convertToExpirationAttributes());
    }
    final RegionFunctionArgs.ExpirationAttrs entryExpirationTTL = regionCreateArgs.getEntryExpirationTTL();
    if (entryExpirationTTL != null) {
      factory.setEntryTimeToLive(entryExpirationTTL.convertToExpirationAttributes());
    }
    final RegionFunctionArgs.ExpirationAttrs regionExpirationIdleTime = regionCreateArgs.getRegionExpirationIdleTime();
    if (regionExpirationIdleTime != null) {
      factory.setEntryIdleTimeout(regionExpirationIdleTime.convertToExpirationAttributes());
    }
    final RegionFunctionArgs.ExpirationAttrs regionExpirationTTL = regionCreateArgs.getRegionExpirationTTL();
    if (regionExpirationTTL != null) {
      factory.setEntryTimeToLive(regionExpirationTTL.convertToExpirationAttributes());
    }

    // Associate a Disk Store
    final String diskStore = regionCreateArgs.getDiskStore();
    if (diskStore != null && !diskStore.isEmpty()) {
      factory.setDiskStoreName(diskStore);
    }
    if (regionCreateArgs.isSetDiskSynchronous()) {
      factory.setDiskSynchronous(regionCreateArgs.isDiskSynchronous());
    }

    if (regionCreateArgs.isSetOffHeap()) {
      factory.setOffHeap(regionCreateArgs.isOffHeap());
    }

    // Set stats enabled
    if (regionCreateArgs.isSetStatisticsEnabled()) {
      factory.setStatisticsEnabled(regionCreateArgs.isStatisticsEnabled());
    }

    // Set conflation
    if (regionCreateArgs.isSetEnableAsyncConflation()) {
      factory.setEnableAsyncConflation(regionCreateArgs.isEnableAsyncConflation());
    }
    if (regionCreateArgs.isSetEnableSubscriptionConflation()) {
      factory.setEnableSubscriptionConflation(regionCreateArgs.isEnableSubscriptionConflation());
    }

    // Gateway Sender Ids
    final Set<String> gatewaySenderIds = regionCreateArgs.getGatewaySenderIds();
    if (gatewaySenderIds != null && !gatewaySenderIds.isEmpty()) {
      for (String gatewaySenderId : gatewaySenderIds) {
        factory.addGatewaySenderId(gatewaySenderId);
      }
    }

    // Async Queue Ids
    final Set<String> asyncEventQueueIds = regionCreateArgs.getAsyncEventQueueIds();
    if (asyncEventQueueIds != null && !asyncEventQueueIds.isEmpty()) {
      for (String asyncEventQueueId : asyncEventQueueIds) {
        factory.addAsyncEventQueueId(asyncEventQueueId);
      }
    }

    // concurrency check enabled & concurrency level
    if (regionCreateArgs.isSetConcurrencyChecksEnabled()) {
      factory.setConcurrencyChecksEnabled(regionCreateArgs.isConcurrencyChecksEnabled());
    }
    if (regionCreateArgs.isSetConcurrencyLevel()) {
      factory.setConcurrencyLevel(regionCreateArgs.getConcurrencyLevel());
    }

    // cloning enabled for delta
    if (regionCreateArgs.isSetCloningEnabled()) {
      factory.setCloningEnabled(regionCreateArgs.isCloningEnabled());
    }

    // Set plugins
    final Set<String> cacheListeners = regionCreateArgs.getCacheListeners();
    if (cacheListeners != null && !cacheListeners.isEmpty()) {
      for (String cacheListener : cacheListeners) {
        Class<CacheListener<K, V>> cacheListenerKlass = forName(cacheListener, CliStrings.CREATE_REGION__CACHELISTENER);
        factory.addCacheListener(newInstance(cacheListenerKlass, CliStrings.CREATE_REGION__CACHELISTENER));
      }
    }

    // Compression provider
    if(regionCreateArgs.isSetCompressor()) {
      Class<Compressor> compressorKlass = forName(regionCreateArgs.getCompressor(), CliStrings.CREATE_REGION__COMPRESSOR);
      factory.setCompressor(newInstance(compressorKlass, CliStrings.CREATE_REGION__COMPRESSOR));
    }
    
    final String cacheLoader = regionCreateArgs.getCacheLoader();
    if (cacheLoader != null) {
      Class<CacheLoader<K, V>> cacheLoaderKlass = forName(cacheLoader, CliStrings.CREATE_REGION__CACHELOADER);
      factory.setCacheLoader(newInstance(cacheLoaderKlass, CliStrings.CREATE_REGION__CACHELOADER));
    }

    final String cacheWriter = regionCreateArgs.getCacheWriter();
    if (cacheWriter != null) {
      Class<CacheWriter<K, V>> cacheWriterKlass = forName(cacheWriter, CliStrings.CREATE_REGION__CACHEWRITER);
      factory.setCacheWriter(newInstance(cacheWriterKlass, CliStrings.CREATE_REGION__CACHEWRITER));
    }
    
    String regionName = regionPathData.getName();
    
    final String hdfsStoreName = regionCreateArgs.getHDFSStoreName();
	if (hdfsStoreName != null && !hdfsStoreName.isEmpty()) {
		factory.setHDFSStoreName(hdfsStoreName);		
	}
	if (regionCreateArgs.isSetHDFSWriteOnly()) {
		factory.setHDFSWriteOnly(regionCreateArgs.getHDFSWriteOnly());
	}
	  
    if (parentRegion != null) {
      createdRegion = factory.createSubregion(parentRegion, regionName);
    } else {
      createdRegion = factory.create(regionName);
    }

    return createdRegion;
  }",True
"  public static <K, V> Region<?, ?> createRegion(Cache cache, RegionFunctionArgs regionCreateArgs) {
    Region<K, V> createdRegion = null;
    
    final String regionPath = regionCreateArgs.getRegionPath();
    final RegionShortcut regionShortcut = regionCreateArgs.getRegionShortcut();
    final String useAttributesFrom      = regionCreateArgs.getUseAttributesFrom();

    // If a region path indicates a sub-region, check whether the parent region exists
    RegionPath regionPathData = new RegionPath(regionPath);
    String parentRegionPath = regionPathData.getParent();
    Region<?, ?> parentRegion = null;
    if (parentRegionPath != null && !Region.SEPARATOR.equals(parentRegionPath)) {
      parentRegion = cache.getRegion(parentRegionPath);
      if (parentRegion == null) {
        throw new IllegalArgumentException(CliStrings.format(CliStrings.CREATE_REGION__MSG__PARENT_REGION_FOR_0_DOESNOT_EXIST, new Object[] {regionPath}));
      }

      if (parentRegion.getAttributes().getPartitionAttributes() != null) {
        // For a PR, sub-regions are not supported.
        throw new CreateSubregionException(
            CliStrings.format(CliStrings.CREATE_REGION__MSG__0_IS_A_PR_CANNOT_HAVE_SUBREGIONS, parentRegion.getFullPath()));
      }
    }

    // One of Region Shortcut OR Use Attributes From has to be given
    if (regionShortcut == null && useAttributesFrom == null) {
      throw new IllegalArgumentException(CliStrings.CREATE_REGION__MSG__ONE_OF_REGIONSHORTCUT_AND_USEATTRIBUESFROM_IS_REQUIRED);
    }

    boolean isPartitioned = false;
    RegionFactory<K, V> factory = null;
    RegionAttributes<K, V> regionAttributes = null;
    if (regionShortcut != null) {
      regionAttributes = cache.getRegionAttributes(regionShortcut.toString());
      if (logger.isDebugEnabled()) {
        logger.debug(""Using shortcut {} for {} region attributes : {}"", regionShortcut, regionPath, regionAttributes);
      }

      if (regionAttributes == null) {
        if (logger.isDebugEnabled()) {
          logger.debug(""Shortcut {} doesn't have attributes in {}"", regionShortcut, cache.listRegionAttributes());
        }
        throw new IllegalStateException(CliStrings.format(CliStrings.CREATE_REGION__MSG__COULDNOT_LOAD_REGION_ATTRIBUTES_FOR_SHORTCUT_0, regionShortcut));
      }
    } else {
      if (logger.isDebugEnabled()) {
        logger.debug(""Using Manager's region attributes for {}"", regionPath);
      }
      regionAttributes = regionCreateArgs.getRegionAttributes();
      if (logger.isDebugEnabled()) {
        logger.debug(""Using Attributes : {}"", regionAttributes);
      }
    }
    isPartitioned = regionAttributes.getPartitionAttributes() != null;

    factory = cache.createRegionFactory(regionAttributes);

    if (!isPartitioned && regionCreateArgs.hasPartitionAttributes()) {
      throw new IllegalArgumentException(
          CliStrings.format(
                  CliStrings.CREATE_REGION__MSG__OPTION_0_CAN_BE_USED_ONLY_FOR_PARTITIONEDREGION,
                  regionCreateArgs.getPartitionArgs().getUserSpecifiedPartitionAttributes()));
    }

    if (isPartitioned) {
      PartitionAttributes<K, V> partitionAttributes = extractPartitionAttributes(cache, regionAttributes, regionCreateArgs);

      DataPolicy originalDataPolicy = regionAttributes.getDataPolicy();
      factory.setPartitionAttributes(partitionAttributes);
      // We have to do this because AttributesFactory.setPartitionAttributes()
      // checks RegionAttributes.hasDataPolicy() which is set only when the data
      // policy is set explicitly
      factory.setDataPolicy(originalDataPolicy);      
    }
       
    // Set Constraints
    final String keyConstraint = regionCreateArgs.getKeyConstraint();
    final String valueConstraint = regionCreateArgs.getValueConstraint();
    if (keyConstraint != null && !keyConstraint.isEmpty()) {
      Class<K> keyConstraintClass = forName(keyConstraint, CliStrings.CREATE_REGION__KEYCONSTRAINT);
      factory.setKeyConstraint(keyConstraintClass);
    }

    if (valueConstraint != null && !valueConstraint.isEmpty()) {
      Class<V> valueConstraintClass = forName(valueConstraint, CliStrings.CREATE_REGION__VALUECONSTRAINT);
      factory.setValueConstraint(valueConstraintClass);
    }

    // Expiration attributes
    final RegionFunctionArgs.ExpirationAttrs entryExpirationIdleTime = regionCreateArgs.getEntryExpirationIdleTime();
    if (entryExpirationIdleTime != null) {
      factory.setEntryIdleTimeout(entryExpirationIdleTime.convertToExpirationAttributes());
    }
    final RegionFunctionArgs.ExpirationAttrs entryExpirationTTL = regionCreateArgs.getEntryExpirationTTL();
    if (entryExpirationTTL != null) {
      factory.setEntryTimeToLive(entryExpirationTTL.convertToExpirationAttributes());
    }
    final RegionFunctionArgs.ExpirationAttrs regionExpirationIdleTime = regionCreateArgs.getRegionExpirationIdleTime();
    if (regionExpirationIdleTime != null) {
      factory.setEntryIdleTimeout(regionExpirationIdleTime.convertToExpirationAttributes());
    }
    final RegionFunctionArgs.ExpirationAttrs regionExpirationTTL = regionCreateArgs.getRegionExpirationTTL();
    if (regionExpirationTTL != null) {
      factory.setEntryTimeToLive(regionExpirationTTL.convertToExpirationAttributes());
    }

    // Associate a Disk Store
    final String diskStore = regionCreateArgs.getDiskStore();
    if (diskStore != null && !diskStore.isEmpty()) {
      factory.setDiskStoreName(diskStore);
    }
    if (regionCreateArgs.isSetDiskSynchronous()) {
      factory.setDiskSynchronous(regionCreateArgs.isDiskSynchronous());
    }

    if (regionCreateArgs.isSetOffHeap()) {
      factory.setOffHeap(regionCreateArgs.isOffHeap());
    }

    // Set stats enabled
    if (regionCreateArgs.isSetStatisticsEnabled()) {
      factory.setStatisticsEnabled(regionCreateArgs.isStatisticsEnabled());
    }

    // Set conflation
    if (regionCreateArgs.isSetEnableAsyncConflation()) {
      factory.setEnableAsyncConflation(regionCreateArgs.isEnableAsyncConflation());
    }
    if (regionCreateArgs.isSetEnableSubscriptionConflation()) {
      factory.setEnableSubscriptionConflation(regionCreateArgs.isEnableSubscriptionConflation());
    }

    // Gateway Sender Ids
    final Set<String> gatewaySenderIds = regionCreateArgs.getGatewaySenderIds();
    if (gatewaySenderIds != null && !gatewaySenderIds.isEmpty()) {
      for (String gatewaySenderId : gatewaySenderIds) {
        factory.addGatewaySenderId(gatewaySenderId);
      }
    }

    // Async Queue Ids
    final Set<String> asyncEventQueueIds = regionCreateArgs.getAsyncEventQueueIds();
    if (asyncEventQueueIds != null && !asyncEventQueueIds.isEmpty()) {
      for (String asyncEventQueueId : asyncEventQueueIds) {
        factory.addAsyncEventQueueId(asyncEventQueueId);
      }
    }

    // concurrency check enabled & concurrency level
    if (regionCreateArgs.isSetConcurrencyChecksEnabled()) {
      factory.setConcurrencyChecksEnabled(regionCreateArgs.isConcurrencyChecksEnabled());
    }
    if (regionCreateArgs.isSetConcurrencyLevel()) {
      factory.setConcurrencyLevel(regionCreateArgs.getConcurrencyLevel());
    }

    // cloning enabled for delta
    if (regionCreateArgs.isSetCloningEnabled()) {
      factory.setCloningEnabled(regionCreateArgs.isCloningEnabled());
    }
    
    // multicast enabled for replication
    if (regionCreateArgs.isSetMcastEnabled()) {
      factory.setMulticastEnabled(regionCreateArgs.isMcastEnabled());
    }

    // Set plugins
    final Set<String> cacheListeners = regionCreateArgs.getCacheListeners();
    if (cacheListeners != null && !cacheListeners.isEmpty()) {
      for (String cacheListener : cacheListeners) {
        Class<CacheListener<K, V>> cacheListenerKlass = forName(cacheListener, CliStrings.CREATE_REGION__CACHELISTENER);
        factory.addCacheListener(newInstance(cacheListenerKlass, CliStrings.CREATE_REGION__CACHELISTENER));
      }
    }

    // Compression provider
    if(regionCreateArgs.isSetCompressor()) {
      Class<Compressor> compressorKlass = forName(regionCreateArgs.getCompressor(), CliStrings.CREATE_REGION__COMPRESSOR);
      factory.setCompressor(newInstance(compressorKlass, CliStrings.CREATE_REGION__COMPRESSOR));
    }
    
    final String cacheLoader = regionCreateArgs.getCacheLoader();
    if (cacheLoader != null) {
      Class<CacheLoader<K, V>> cacheLoaderKlass = forName(cacheLoader, CliStrings.CREATE_REGION__CACHELOADER);
      factory.setCacheLoader(newInstance(cacheLoaderKlass, CliStrings.CREATE_REGION__CACHELOADER));
    }

    final String cacheWriter = regionCreateArgs.getCacheWriter();
    if (cacheWriter != null) {
      Class<CacheWriter<K, V>> cacheWriterKlass = forName(cacheWriter, CliStrings.CREATE_REGION__CACHEWRITER);
      factory.setCacheWriter(newInstance(cacheWriterKlass, CliStrings.CREATE_REGION__CACHEWRITER));
    }
    
    String regionName = regionPathData.getName();
    
    final String hdfsStoreName = regionCreateArgs.getHDFSStoreName();
	if (hdfsStoreName != null && !hdfsStoreName.isEmpty()) {
		factory.setHDFSStoreName(hdfsStoreName);		
	}
	if (regionCreateArgs.isSetHDFSWriteOnly()) {
		factory.setHDFSWriteOnly(regionCreateArgs.getHDFSWriteOnly());
	}
	  
    if (parentRegion != null) {
      createdRegion = factory.createSubregion(parentRegion, regionName);
    } else {
      createdRegion = factory.create(regionName);
    }

    return createdRegion;
  }",False
"  public RegionFunctionArgs(String regionPath,
	      RegionShortcut regionShortcut, String useAttributesFrom,
	      boolean skipIfExists, String keyConstraint, String valueConstraint,
	      Boolean statisticsEnabled, 
	      RegionFunctionArgs.ExpirationAttrs entryExpirationIdleTime, 
	      RegionFunctionArgs.ExpirationAttrs entryExpirationTTL, 
	      RegionFunctionArgs.ExpirationAttrs regionExpirationIdleTime, 
	      RegionFunctionArgs.ExpirationAttrs regionExpirationTTL, String diskStore,
	      Boolean diskSynchronous, Boolean enableAsyncConflation,
	      Boolean enableSubscriptionConflation, String[] cacheListeners,
	      String cacheLoader, String cacheWriter, String[] asyncEventQueueIds,
	      String[] gatewaySenderIds, Boolean concurrencyChecksEnabled,
	      Boolean cloningEnabled, Integer concurrencyLevel, String prColocatedWith,
	      Integer prLocalMaxMemory, Long prRecoveryDelay,
	      Integer prRedundantCopies, Long prStartupRecoveryDelay,
	      Long prTotalMaxMemory, Integer prTotalNumBuckets, Integer evictionMax,
	      String compressor, Boolean offHeap , String hdfsStoreName , Boolean hdfsWriteOnly) {	
		this(regionPath, regionShortcut, useAttributesFrom, skipIfExists,
				keyConstraint, valueConstraint, statisticsEnabled,
				entryExpirationIdleTime, entryExpirationTTL,
				regionExpirationIdleTime, regionExpirationTTL, diskStore,
				diskSynchronous, enableAsyncConflation,
				enableSubscriptionConflation, cacheListeners, cacheLoader,
				cacheWriter, asyncEventQueueIds, gatewaySenderIds,
				concurrencyChecksEnabled, cloningEnabled, concurrencyLevel,
				prColocatedWith, prLocalMaxMemory, prRecoveryDelay,
				prRedundantCopies, prStartupRecoveryDelay, prTotalMaxMemory,
				prTotalNumBuckets, evictionMax, compressor, offHeap);	
		this.isSetHdfsWriteOnly = hdfsWriteOnly != null;
		if (isSetHdfsWriteOnly) {
			this.hdfsWriteOnly = hdfsWriteOnly;
		}
		if (hdfsStoreName != null )
		  this.hdfsStoreName = hdfsStoreName;
  }",True
"		  this.hdfsStoreName = hdfsStoreName;
		}
  }
  public RegionFunctionArgs(String regionPath,
      RegionShortcut regionShortcut, String useAttributesFrom,
      boolean skipIfExists, String keyConstraint, String valueConstraint,
      Boolean statisticsEnabled, 
      RegionFunctionArgs.ExpirationAttrs entryExpirationIdleTime, 
      RegionFunctionArgs.ExpirationAttrs entryExpirationTTL, 
      RegionFunctionArgs.ExpirationAttrs regionExpirationIdleTime, 
      RegionFunctionArgs.ExpirationAttrs regionExpirationTTL, String diskStore,
      Boolean diskSynchronous, Boolean enableAsyncConflation,
      Boolean enableSubscriptionConflation, String[] cacheListeners,
      String cacheLoader, String cacheWriter, String[] asyncEventQueueIds,
      String[] gatewaySenderIds, Boolean concurrencyChecksEnabled,
      Boolean cloningEnabled, Integer concurrencyLevel, String prColocatedWith,
      Integer prLocalMaxMemory, Long prRecoveryDelay,
      Integer prRedundantCopies, Long prStartupRecoveryDelay,
      Long prTotalMaxMemory, Integer prTotalNumBuckets, Integer evictionMax,
      String compressor, Boolean offHeap, Boolean mcastEnabled) {
    this.regionPath = regionPath;
    this.regionShortcut = regionShortcut;
    this.useAttributesFrom = useAttributesFrom;
    this.skipIfExists = skipIfExists;
    this.keyConstraint = keyConstraint;
    this.valueConstraint = valueConstraint;
    this.evictionMax = evictionMax;
    this.isSetStatisticsEnabled = statisticsEnabled != null;
    if (this.isSetStatisticsEnabled) {
      this.statisticsEnabled = statisticsEnabled;
    }
    this.entryExpirationIdleTime = entryExpirationIdleTime;
    this.entryExpirationTTL = entryExpirationTTL;
    this.regionExpirationIdleTime = regionExpirationIdleTime;
    this.regionExpirationTTL = regionExpirationTTL;
    this.diskStore = diskStore;
    this.isSetDiskSynchronous = diskSynchronous != null;
    if (this.isSetDiskSynchronous) {
      this.diskSynchronous = diskSynchronous;
    }
    this.isSetEnableAsyncConflation = enableAsyncConflation != null;
    if (this.isSetEnableAsyncConflation) {
      this.enableAsyncConflation = enableAsyncConflation;
    }
    this.isSetEnableSubscriptionConflation = enableSubscriptionConflation != null;
    if (this.isSetEnableSubscriptionConflation) {
      this.enableSubscriptionConflation = enableSubscriptionConflation;
    }
    if (cacheListeners != null) {
      this.cacheListeners = new LinkedHashSet<String>();
      this.cacheListeners.addAll(Arrays.asList(cacheListeners));
    } else {
      this.cacheListeners = null;
    }
    this.cacheLoader = cacheLoader;
    this.cacheWriter = cacheWriter;
    if (asyncEventQueueIds != null) {
      this.asyncEventQueueIds = new LinkedHashSet<String>();
      this.asyncEventQueueIds.addAll(Arrays.asList(asyncEventQueueIds));
    } else {
      this.asyncEventQueueIds = null;
    }
    if (gatewaySenderIds != null) {
      this.gatewaySenderIds = new LinkedHashSet<String>();
      this.gatewaySenderIds.addAll(Arrays.asList(gatewaySenderIds));
    } else {
      this.gatewaySenderIds = null;
    }
    this.isSetConcurrencyChecksEnabled = concurrencyChecksEnabled != null;
    if (this.isSetConcurrencyChecksEnabled) {
      this.concurrencyChecksEnabled = concurrencyChecksEnabled;
    }
    this.isSetCloningEnabled = cloningEnabled != null;
    if (this.isSetCloningEnabled) {
      this.cloningEnabled = cloningEnabled;
    }
    this.isSetMcastEnabled = mcastEnabled != null;
    if (isSetMcastEnabled) {
      this.mcastEnabled = mcastEnabled;
    }
    this.isSetConcurrencyLevel = concurrencyLevel != null;
    if (this.isSetConcurrencyLevel) {
      this.concurrencyLevel = concurrencyLevel;
    }
    this.partitionArgs = new PartitionArgs(prColocatedWith,
        prLocalMaxMemory, prRecoveryDelay, prRedundantCopies,
        prStartupRecoveryDelay, prTotalMaxMemory, prTotalNumBuckets);
    
    this.isSetCompressor = (compressor != null);
    if(this.isSetCompressor) {",False
"  public Boolean isSetMcastEnabled() {
    return this.isSetMcastEnabled;
  }",False
"    this.isSetOffHeap = (offHeap != null);
    if (this.isSetOffHeap) {
      this.offHeap = offHeap;
    }
  }

  // Constructor to be used for supplied region attributes
  public RegionFunctionArgs(String regionPath,
      String useAttributesFrom,
      boolean skipIfExists, String keyConstraint, String valueConstraint,
      Boolean statisticsEnabled, 
      RegionFunctionArgs.ExpirationAttrs entryExpirationIdleTime, 
      RegionFunctionArgs.ExpirationAttrs entryExpirationTTL, 
      RegionFunctionArgs.ExpirationAttrs regionExpirationIdleTime, 
      RegionFunctionArgs.ExpirationAttrs regionExpirationTTL, String diskStore,
      Boolean diskSynchronous, Boolean enableAsyncConflation,
      Boolean enableSubscriptionConflation, String[] cacheListeners,
      String cacheLoader, String cacheWriter, String[] asyncEventQueueIds,
      String[] gatewaySenderIds, Boolean concurrencyChecksEnabled,
      Boolean cloningEnabled, Integer concurrencyLevel, String prColocatedWith,
      Integer prLocalMaxMemory, Long prRecoveryDelay,
      Integer prRedundantCopies, Long prStartupRecoveryDelay,
      Long prTotalMaxMemory, Integer prTotalNumBuckets, 
      Boolean offHeap, String hdfsStoreName , Boolean hdfsWriteOnly , 
      Boolean mcastEnabled, RegionAttributes<?, ?> regionAttributes) {   
    this(regionPath, null, useAttributesFrom, skipIfExists, keyConstraint,
        valueConstraint, statisticsEnabled, entryExpirationIdleTime,
        entryExpirationTTL, regionExpirationIdleTime, regionExpirationTTL,
        diskStore, diskSynchronous, enableAsyncConflation,
        enableSubscriptionConflation, cacheListeners, cacheLoader,",False
"  public RegionFunctionArgs(String regionPath,
      RegionShortcut regionShortcut, String useAttributesFrom,
      boolean skipIfExists, String keyConstraint, String valueConstraint,
      Boolean statisticsEnabled, 
      RegionFunctionArgs.ExpirationAttrs entryExpirationIdleTime, 
      RegionFunctionArgs.ExpirationAttrs entryExpirationTTL, 
      RegionFunctionArgs.ExpirationAttrs regionExpirationIdleTime, 
      RegionFunctionArgs.ExpirationAttrs regionExpirationTTL, String diskStore,
      Boolean diskSynchronous, Boolean enableAsyncConflation,
      Boolean enableSubscriptionConflation, String[] cacheListeners,
      String cacheLoader, String cacheWriter, String[] asyncEventQueueIds,
      String[] gatewaySenderIds, Boolean concurrencyChecksEnabled,
      Boolean cloningEnabled, Integer concurrencyLevel, String prColocatedWith,
      Integer prLocalMaxMemory, Long prRecoveryDelay,
      Integer prRedundantCopies, Long prStartupRecoveryDelay,
      Long prTotalMaxMemory, Integer prTotalNumBuckets, Integer evictionMax,
      String compressor, Boolean offHeap, Boolean mcastEnabled) {
    this.regionPath = regionPath;
    this.regionShortcut = regionShortcut;
    this.useAttributesFrom = useAttributesFrom;
    this.skipIfExists = skipIfExists;
    this.keyConstraint = keyConstraint;
    this.valueConstraint = valueConstraint;
    this.evictionMax = evictionMax;
    this.isSetStatisticsEnabled = statisticsEnabled != null;
    if (this.isSetStatisticsEnabled) {
      this.statisticsEnabled = statisticsEnabled;
    }
    this.entryExpirationIdleTime = entryExpirationIdleTime;
    this.entryExpirationTTL = entryExpirationTTL;
    this.regionExpirationIdleTime = regionExpirationIdleTime;
    this.regionExpirationTTL = regionExpirationTTL;
    this.diskStore = diskStore;
    this.isSetDiskSynchronous = diskSynchronous != null;
    if (this.isSetDiskSynchronous) {
      this.diskSynchronous = diskSynchronous;
    }
    this.isSetEnableAsyncConflation = enableAsyncConflation != null;
    if (this.isSetEnableAsyncConflation) {
      this.enableAsyncConflation = enableAsyncConflation;
    }
    this.isSetEnableSubscriptionConflation = enableSubscriptionConflation != null;
    if (this.isSetEnableSubscriptionConflation) {
      this.enableSubscriptionConflation = enableSubscriptionConflation;
    }
    if (cacheListeners != null) {
      this.cacheListeners = new LinkedHashSet<String>();
      this.cacheListeners.addAll(Arrays.asList(cacheListeners));
    } else {
      this.cacheListeners = null;
    }
    this.cacheLoader = cacheLoader;
    this.cacheWriter = cacheWriter;
    if (asyncEventQueueIds != null) {
      this.asyncEventQueueIds = new LinkedHashSet<String>();
      this.asyncEventQueueIds.addAll(Arrays.asList(asyncEventQueueIds));
    } else {
      this.asyncEventQueueIds = null;
    }
    if (gatewaySenderIds != null) {
      this.gatewaySenderIds = new LinkedHashSet<String>();
      this.gatewaySenderIds.addAll(Arrays.asList(gatewaySenderIds));
    } else {
      this.gatewaySenderIds = null;
    }
    this.isSetConcurrencyChecksEnabled = concurrencyChecksEnabled != null;
    if (this.isSetConcurrencyChecksEnabled) {
      this.concurrencyChecksEnabled = concurrencyChecksEnabled;
    }
    this.isSetCloningEnabled = cloningEnabled != null;
    if (this.isSetCloningEnabled) {
      this.cloningEnabled = cloningEnabled;
    }
    this.isSetMcastEnabled = mcastEnabled != null;
    if (isSetMcastEnabled) {
      this.mcastEnabled = mcastEnabled;
    }
    this.isSetConcurrencyLevel = concurrencyLevel != null;
    if (this.isSetConcurrencyLevel) {
      this.concurrencyLevel = concurrencyLevel;
    }
    this.partitionArgs = new PartitionArgs(prColocatedWith,
        prLocalMaxMemory, prRecoveryDelay, prRedundantCopies,
        prStartupRecoveryDelay, prTotalMaxMemory, prTotalNumBuckets);
    
    this.isSetCompressor = (compressor != null);
    if(this.isSetCompressor) {
      this.compressor = compressor;
    }
    this.isSetOffHeap = (offHeap != null);
    if (this.isSetOffHeap) {
      this.offHeap = offHeap;
    }
  }",False
"  public Boolean isMcastEnabled() {
    return this.mcastEnabled;
  }",False
"  public RegionFunctionArgs(String regionPath,
	      RegionShortcut regionShortcut, String useAttributesFrom,
	      boolean skipIfExists, String keyConstraint, String valueConstraint,
	      Boolean statisticsEnabled, 
	      RegionFunctionArgs.ExpirationAttrs entryExpirationIdleTime, 
	      RegionFunctionArgs.ExpirationAttrs entryExpirationTTL, 
	      RegionFunctionArgs.ExpirationAttrs regionExpirationIdleTime, 
	      RegionFunctionArgs.ExpirationAttrs regionExpirationTTL, String diskStore,
	      Boolean diskSynchronous, Boolean enableAsyncConflation,
	      Boolean enableSubscriptionConflation, String[] cacheListeners,
	      String cacheLoader, String cacheWriter, String[] asyncEventQueueIds,
	      String[] gatewaySenderIds, Boolean concurrencyChecksEnabled,
	      Boolean cloningEnabled, Integer concurrencyLevel, String prColocatedWith,
	      Integer prLocalMaxMemory, Long prRecoveryDelay,
	      Integer prRedundantCopies, Long prStartupRecoveryDelay,
	      Long prTotalMaxMemory, Integer prTotalNumBuckets, Integer evictionMax,
	      String compressor, Boolean offHeap , String hdfsStoreName , Boolean hdfsWriteOnly, Boolean mcastEnabled) {	
		this(regionPath, regionShortcut, useAttributesFrom, skipIfExists,
				keyConstraint, valueConstraint, statisticsEnabled,
				entryExpirationIdleTime, entryExpirationTTL,
				regionExpirationIdleTime, regionExpirationTTL, diskStore,
				diskSynchronous, enableAsyncConflation,
				enableSubscriptionConflation, cacheListeners, cacheLoader,
				cacheWriter, asyncEventQueueIds, gatewaySenderIds,
				concurrencyChecksEnabled, cloningEnabled, concurrencyLevel,
				prColocatedWith, prLocalMaxMemory, prRecoveryDelay,
				prRedundantCopies, prStartupRecoveryDelay, prTotalMaxMemory,
				prTotalNumBuckets, evictionMax, compressor, offHeap, mcastEnabled);	
		this.isSetHdfsWriteOnly = hdfsWriteOnly != null;
		if (isSetHdfsWriteOnly) {
			this.hdfsWriteOnly = hdfsWriteOnly;
		}
		if (hdfsStoreName != null ) {
		  this.hdfsStoreName = hdfsStoreName;
		}
  }",False
"  public RegionFunctionArgs(String regionPath,
      String useAttributesFrom,
      boolean skipIfExists, String keyConstraint, String valueConstraint,
      Boolean statisticsEnabled, 
      RegionFunctionArgs.ExpirationAttrs entryExpirationIdleTime, 
      RegionFunctionArgs.ExpirationAttrs entryExpirationTTL, 
      RegionFunctionArgs.ExpirationAttrs regionExpirationIdleTime, 
      RegionFunctionArgs.ExpirationAttrs regionExpirationTTL, String diskStore,
      Boolean diskSynchronous, Boolean enableAsyncConflation,
      Boolean enableSubscriptionConflation, String[] cacheListeners,
      String cacheLoader, String cacheWriter, String[] asyncEventQueueIds,
      String[] gatewaySenderIds, Boolean concurrencyChecksEnabled,
      Boolean cloningEnabled, Integer concurrencyLevel, String prColocatedWith,
      Integer prLocalMaxMemory, Long prRecoveryDelay,
      Integer prRedundantCopies, Long prStartupRecoveryDelay,
      Long prTotalMaxMemory, Integer prTotalNumBuckets, 
      Boolean offHeap, String hdfsStoreName , Boolean hdfsWriteOnly , 
      Boolean mcastEnabled, RegionAttributes<?, ?> regionAttributes) {   
    this(regionPath, null, useAttributesFrom, skipIfExists, keyConstraint,
        valueConstraint, statisticsEnabled, entryExpirationIdleTime,
        entryExpirationTTL, regionExpirationIdleTime, regionExpirationTTL,
        diskStore, diskSynchronous, enableAsyncConflation,
        enableSubscriptionConflation, cacheListeners, cacheLoader,
        cacheWriter, asyncEventQueueIds, gatewaySenderIds,
        concurrencyChecksEnabled, cloningEnabled, concurrencyLevel, 
        prColocatedWith, prLocalMaxMemory, prRecoveryDelay,
        prRedundantCopies, prStartupRecoveryDelay,
        prTotalMaxMemory, prTotalNumBuckets, null, null, offHeap , hdfsStoreName , hdfsWriteOnly, mcastEnabled);
    this.regionAttributes = regionAttributes;
  }",False
"  private RegionAttributes<?, ?> regionAttributes;

  public RegionFunctionArgs(String regionPath,
	      RegionShortcut regionShortcut, String useAttributesFrom,
	      boolean skipIfExists, String keyConstraint, String valueConstraint,
	      Boolean statisticsEnabled, 
	      RegionFunctionArgs.ExpirationAttrs entryExpirationIdleTime, 
	      RegionFunctionArgs.ExpirationAttrs entryExpirationTTL, 
	      RegionFunctionArgs.ExpirationAttrs regionExpirationIdleTime, 
	      RegionFunctionArgs.ExpirationAttrs regionExpirationTTL, String diskStore,
	      Boolean diskSynchronous, Boolean enableAsyncConflation,
	      Boolean enableSubscriptionConflation, String[] cacheListeners,
	      String cacheLoader, String cacheWriter, String[] asyncEventQueueIds,
	      String[] gatewaySenderIds, Boolean concurrencyChecksEnabled,
	      Boolean cloningEnabled, Integer concurrencyLevel, String prColocatedWith,
	      Integer prLocalMaxMemory, Long prRecoveryDelay,
	      Integer prRedundantCopies, Long prStartupRecoveryDelay,
	      Long prTotalMaxMemory, Integer prTotalNumBuckets, Integer evictionMax,
	      String compressor, Boolean offHeap , String hdfsStoreName , Boolean hdfsWriteOnly, Boolean mcastEnabled) {	
		this(regionPath, regionShortcut, useAttributesFrom, skipIfExists,
				keyConstraint, valueConstraint, statisticsEnabled,
				entryExpirationIdleTime, entryExpirationTTL,
				regionExpirationIdleTime, regionExpirationTTL, diskStore,
				diskSynchronous, enableAsyncConflation,
				enableSubscriptionConflation, cacheListeners, cacheLoader,
				cacheWriter, asyncEventQueueIds, gatewaySenderIds,
				concurrencyChecksEnabled, cloningEnabled, concurrencyLevel,
				prColocatedWith, prLocalMaxMemory, prRecoveryDelay,
				prRedundantCopies, prStartupRecoveryDelay, prTotalMaxMemory,
				prTotalNumBuckets, evictionMax, compressor, offHeap, mcastEnabled);	
		this.isSetHdfsWriteOnly = hdfsWriteOnly != null;
		if (isSetHdfsWriteOnly) {
			this.hdfsWriteOnly = hdfsWriteOnly;
		}
		if (hdfsStoreName != null ) {",False
"  public AutoConnectionSourceWithUDPDUnitTest(String name) {
    super(name);
  }",True
"  public void testStartLocatorLater() throws InterruptedException {
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    VM vm2 = host.getVM(2);
    
    startBridgeServerInVM(vm1, null, null);
    
    int locatorPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    startLocatorInVM(vm0, locatorPort, """");
    
    startBridgeClientInVM(vm2, null, getServerHostName(vm0.getHost()), locatorPort);
    putAndWaitForSuccess(vm2, REGION_NAME, ""key"", ""value"");
    Assert.assertEquals(""value"", getInVM(vm1, ""key""));
  }",True
"  public void startLocatorInVM(final VM vm, final int locatorPort, final String otherLocators) {
    vm.invoke(new SerializableRunnable(""Create Locator"") {

      final String testName= getUniqueName();
      public void run() {
        disconnectFromDS();
        Properties props = new Properties();
        props.setProperty(DistributionConfig.MCAST_PORT_NAME, String.valueOf(mCastPort));
        props.setProperty(DistributionConfig.MCAST_ADDRESS_NAME, DistributionConfig.DEFAULT_MCAST_ADDRESS.getHostAddress());
        props.setProperty(DistributionConfig.LOCATORS_NAME, """");
        props.setProperty(DistributionConfig.LOG_LEVEL_NAME, getDUnitLogLevel());
        props.setProperty(DistributionConfig.ENABLE_CLUSTER_CONFIGURATION_NAME, ""false"");
        InetAddress bindAddr = null;
        try {
          bindAddr = InetAddress.getByName(getServerHostName(vm.getHost()));
        } catch (UnknownHostException uhe) {
          fail(""While resolving bind address "", uhe);
        }
        try {
          File logFile = new File(testName + ""-locator"" + locatorPort
              + "".log"");
          Locator locator = Locator.startLocatorAndDS(locatorPort, logFile, bindAddr, props, false, true, null);
          remoteObjects.put(LOCATOR_KEY, locator);
        } catch (IOException ex) {
          fail(""While starting locator on port "" + locatorPort, ex);
        }
      }
    });
  }",True
"  protected int startBridgeServerInVM(VM vm, final String[] groups, String locators,
      final String[] regions) {
    SerializableCallable connect =
      new SerializableCallable(""Start bridge server"") {
          public Object call() throws IOException  {
            Properties props = new Properties();
            props.setProperty(DistributionConfig.MCAST_PORT_NAME, String.valueOf(mCastPort));
            props.setProperty(DistributionConfig.MCAST_ADDRESS_NAME, DistributionConfig.DEFAULT_MCAST_ADDRESS.getHostAddress());
            props.setProperty(DistributionConfig.LOCATORS_NAME, """");
            DistributedSystem ds = getSystem(props);
            Cache cache = CacheFactory.create(ds);
            AttributesFactory factory = new AttributesFactory();
            factory.setScope(Scope.DISTRIBUTED_ACK);
            factory.setEnableBridgeConflation(true);
            factory.setDataPolicy(DataPolicy.REPLICATE);
            RegionAttributes attrs = factory.create();
            for(int i = 0; i < regions.length; i++) {
              cache.createRegion(regions[i], attrs);
            }
            BridgeServer server = cache.addBridgeServer();
            final int serverPort = AvailablePortHelper.getRandomAvailableTCPPort();
            server.setPort(serverPort);
            server.setGroups(groups);
            server.start();
            
            remoteObjects.put(CACHE_KEY, cache);
            
            return new Integer(serverPort);
          }
        };
    Integer port = (Integer) vm.invoke(connect);
    return port.intValue();
  }",True
"  public void setUp() throws Exception {
    super.setUp();
    mCastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    addExpectedException(""java.net.SocketException"");
  }",True
"  public void testDistributedRegionRemoteClientPutRejection() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM client = host.getVM(2);

    final String regionName = ""rejectRemoteClientOp"";

    ServerPorts ports1 = startCacheServer(server1, 0f, 0f, regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    ServerPorts ports2 = startCacheServer(server2, ports1.getMcastPort(), 0f, 90f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    startClient(client, server1, ports1.getPort(), regionName);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);

    doPuts(client, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(client, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/, Range.DEFAULT);

    //make server2 critical
    setUsageAboveCriticalThreshold(server2);

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, false);

    //make sure that client puts are rejected
    doPuts(client, regionName, true/*catchRejectedException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(client, regionName, true/*catchRejectedException*/,
        false/*catchLowMemoryException*/, new Range(Range.DEFAULT, Range.DEFAULT.width()+1));
  }",True
"  public void testDistributedRegionRemoteClientPutRejection() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM client = host.getVM(2);

    final String regionName = ""rejectRemoteClientOp"";

    ServerPorts ports1 = startCacheServer(server1, 0f, 0f, regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    ServerPorts ports2 = startCacheServer(server2, 0f, 90f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    startClient(client, server1, ports1.getPort(), regionName);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);

    doPuts(client, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(client, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/, Range.DEFAULT);

    //make server2 critical
    setUsageAboveCriticalThreshold(server2);

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, false);

    //make sure that client puts are rejected
    doPuts(client, regionName, true/*catchRejectedException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(client, regionName, true/*catchRejectedException*/,
        false/*catchLowMemoryException*/, new Range(Range.DEFAULT, Range.DEFAULT.width()+1));
  }",False
"  public void disabledtestPRFunctionExecutionRejection() throws Exception {
    addExpectedException(""LowMemoryException"");
    final Host host = Host.getHost(0);
    final VM accessor = host.getVM(0);
    final VM server1 = host.getVM(1);
    final VM server2 = host.getVM(2);
    final VM client = host.getVM(3);
    final String regionName = ""prFuncRej"";

    final ServerPorts ports1 = startCacheServer(server1, 80f, 90f, regionName, true/*createPR*/, false/*notifyBySubscription*/, 0);
    ServerPorts ports2 = startCacheServer(server2, ports1.getMcastPort(), 80f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, 0);
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        getSystem(getServerProperties(ports1.getMcastPort()));
        getCache();
        AttributesFactory factory = new AttributesFactory();
        PartitionAttributesFactory paf = new PartitionAttributesFactory();
        paf.setRedundantCopies(0);
        paf.setLocalMaxMemory(0);
        paf.setTotalNumBuckets(11);
        factory.setPartitionAttributes(paf.create());
        createRegion(regionName, factory.create());
        return null;
      }
    });
    
    startClient(client, server1, ports1.getPort(), regionName);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);
    
    final RejectFunction function = new RejectFunction();
    final RejectFunction function2 = new RejectFunction(""noRejFunc"", false);
    invokeInEveryVM(new SerializableCallable(""register function"") {
      public Object call() throws Exception {
        FunctionService.registerFunction(function);
        FunctionService.registerFunction(function2);
        return null;
      }
    });

    doPutAlls(accessor, regionName, false, false, Range.DEFAULT);
    doPuts(accessor, regionName, false, false);

    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
          .execute(function);
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
        .execute(function2);
        return null;
      }
    });
    //should not fail
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        FunctionService.onMembers(getSystem()).execute(function);
        FunctionService.onMembers(getSystem()).execute(function2);
        return null;
      }
    });    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
          .execute(function);
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
          .execute(function2);
        return null;
      }
    });
    
    setUsageAboveCriticalThreshold(server2);

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);

    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        try {
          getCache().getLoggerI18n().fine(addExpectedFunctionExString);
          FunctionService.onRegion(getRootRegion().getSubregion(regionName))
            .execute(function);
          getCache().getLoggerI18n().fine(removeExpectedFunctionExString);
          fail(""expected low memory exception was not thrown"");
        } catch (LowMemoryException e) {
          //expected
        }
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
        .execute(function2);
        return null;
      }
    });

    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        try {
          getCache().getLoggerI18n().fine(addExpectedFunctionExString);
          FunctionService.onMembers(getSystem()).execute(function);
          getCache().getLoggerI18n().fine(removeExpectedFunctionExString);
          fail(""expected low memory exception was not thrown"");
        } catch (LowMemoryException e) {
          //expected
        }
        FunctionService.onMembers(getSystem()).execute(function2);
        return null;
      }
    });

    server1.invoke(addExpectedFunctionException);
    server2.invoke(addExpectedFunctionException);

    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        try {
          FunctionService.onRegion(getRootRegion().getSubregion(regionName))
            .execute(function);
          fail(""expected low memory exception was not thrown"");
        } catch (FunctionException e) {
          if (!(e.getCause().getCause() instanceof LowMemoryException)) {
            fail(""unexpected exception"", e);
          }
          //expected
        }
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
          .execute(function2);
        return null;
      }
    });

    server1.invoke(removeExpectedFunctionException);
    server2.invoke(removeExpectedFunctionException);

    final DistributedMember server2Id = (DistributedMember)server2.invoke(
        new SerializableCallable() {
          public Object call() throws Exception {
            return ((GemFireCacheImpl)getCache()).getMyId();
          }
        });

    //test function execution on healthy & sick members
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        PartitionedRegion pr = (PartitionedRegion)getRootRegion().
                          getSubregion(regionName);
        Object sickKey1 = null;
        Object sickKey2 = null;
        Object healthyKey = null;
        for (int i=0; i < 20; i++) {
          Object key = i;
          DistributedMember m = pr.getMemberOwning(key);
          if (m.equals(server2Id)) {
            if (sickKey1 == null) {
              sickKey1 = key;
              //execute
              Set s = new HashSet();
              s.add(sickKey1);
              Execution e = FunctionService.onRegion(pr);
              try {
                getCache().getLoggerI18n().fine(addExpectedFunctionExString);
                e.withFilter(s).withArgs((Serializable)s).execute(function);
                getCache().getLoggerI18n().fine(removeExpectedFunctionExString);
                fail(""expected LowMemoryExcception was not thrown"");
              } catch (LowMemoryException ex) {
                //expected
              }
            } else if (sickKey2 == null) {
              sickKey2 = key;
              //execute
              Set s = new HashSet();
              s.add(sickKey1);
              s.add(sickKey2);
              Execution e = FunctionService.onRegion(pr);
              try {
                e.withFilter(s).withArgs((Serializable)s).execute(function);
                fail(""expected LowMemoryExcception was not thrown"");
              } catch (LowMemoryException ex) {
                //expected
              }
            }
          } else {
            healthyKey = key;
            //execute
            Set s = new HashSet();
            s.add(healthyKey);
            Execution e = FunctionService.onRegion(pr);
            e.withFilter(s).withArgs((Serializable)s).execute(function);
          }
          if (sickKey1 != null && sickKey2 != null && healthyKey != null) {
            break;
          }
        }
        return null;
      }
    });
  }",True
"  public void disabledtestPRFunctionExecutionRejection() throws Exception {
    addExpectedException(""LowMemoryException"");
    final Host host = Host.getHost(0);
    final VM accessor = host.getVM(0);
    final VM server1 = host.getVM(1);
    final VM server2 = host.getVM(2);
    final VM client = host.getVM(3);
    final String regionName = ""prFuncRej"";

    final ServerPorts ports1 = startCacheServer(server1, 80f, 90f, regionName, true/*createPR*/, false/*notifyBySubscription*/, 0);
    ServerPorts ports2 = startCacheServer(server2, 80f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, 0);
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        getSystem(getServerProperties());
        getCache();
        AttributesFactory factory = new AttributesFactory();
        PartitionAttributesFactory paf = new PartitionAttributesFactory();
        paf.setRedundantCopies(0);
        paf.setLocalMaxMemory(0);
        paf.setTotalNumBuckets(11);
        factory.setPartitionAttributes(paf.create());
        createRegion(regionName, factory.create());
        return null;
      }
    });
    
    startClient(client, server1, ports1.getPort(), regionName);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);
    
    final RejectFunction function = new RejectFunction();
    final RejectFunction function2 = new RejectFunction(""noRejFunc"", false);
    invokeInEveryVM(new SerializableCallable(""register function"") {
      public Object call() throws Exception {
        FunctionService.registerFunction(function);
        FunctionService.registerFunction(function2);
        return null;
      }
    });

    doPutAlls(accessor, regionName, false, false, Range.DEFAULT);
    doPuts(accessor, regionName, false, false);

    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
          .execute(function);
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
        .execute(function2);
        return null;
      }
    });
    //should not fail
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        FunctionService.onMembers(getSystem()).execute(function);
        FunctionService.onMembers(getSystem()).execute(function2);
        return null;
      }
    });    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
          .execute(function);
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
          .execute(function2);
        return null;
      }
    });
    
    setUsageAboveCriticalThreshold(server2);

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);

    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        try {
          getCache().getLoggerI18n().fine(addExpectedFunctionExString);
          FunctionService.onRegion(getRootRegion().getSubregion(regionName))
            .execute(function);
          getCache().getLoggerI18n().fine(removeExpectedFunctionExString);
          fail(""expected low memory exception was not thrown"");
        } catch (LowMemoryException e) {
          //expected
        }
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
        .execute(function2);
        return null;
      }
    });

    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        try {
          getCache().getLoggerI18n().fine(addExpectedFunctionExString);
          FunctionService.onMembers(getSystem()).execute(function);
          getCache().getLoggerI18n().fine(removeExpectedFunctionExString);
          fail(""expected low memory exception was not thrown"");
        } catch (LowMemoryException e) {
          //expected
        }
        FunctionService.onMembers(getSystem()).execute(function2);
        return null;
      }
    });

    server1.invoke(addExpectedFunctionException);
    server2.invoke(addExpectedFunctionException);

    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        try {
          FunctionService.onRegion(getRootRegion().getSubregion(regionName))
            .execute(function);
          fail(""expected low memory exception was not thrown"");
        } catch (FunctionException e) {
          if (!(e.getCause().getCause() instanceof LowMemoryException)) {
            fail(""unexpected exception"", e);
          }
          //expected
        }
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
          .execute(function2);
        return null;
      }
    });

    server1.invoke(removeExpectedFunctionException);
    server2.invoke(removeExpectedFunctionException);

    final DistributedMember server2Id = (DistributedMember)server2.invoke(
        new SerializableCallable() {
          public Object call() throws Exception {
            return ((GemFireCacheImpl)getCache()).getMyId();
          }
        });

    //test function execution on healthy & sick members
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        PartitionedRegion pr = (PartitionedRegion)getRootRegion().
                          getSubregion(regionName);
        Object sickKey1 = null;
        Object sickKey2 = null;
        Object healthyKey = null;
        for (int i=0; i < 20; i++) {
          Object key = i;
          DistributedMember m = pr.getMemberOwning(key);
          if (m.equals(server2Id)) {
            if (sickKey1 == null) {
              sickKey1 = key;
              //execute
              Set s = new HashSet();
              s.add(sickKey1);
              Execution e = FunctionService.onRegion(pr);
              try {
                getCache().getLoggerI18n().fine(addExpectedFunctionExString);
                e.withFilter(s).withArgs((Serializable)s).execute(function);
                getCache().getLoggerI18n().fine(removeExpectedFunctionExString);
                fail(""expected LowMemoryExcception was not thrown"");
              } catch (LowMemoryException ex) {
                //expected
              }
            } else if (sickKey2 == null) {
              sickKey2 = key;
              //execute
              Set s = new HashSet();
              s.add(sickKey1);
              s.add(sickKey2);
              Execution e = FunctionService.onRegion(pr);
              try {
                e.withFilter(s).withArgs((Serializable)s).execute(function);
                fail(""expected LowMemoryExcception was not thrown"");
              } catch (LowMemoryException ex) {
                //expected
              }
            }
          } else {
            healthyKey = key;
            //execute
            Set s = new HashSet();
            s.add(healthyKey);
            Execution e = FunctionService.onRegion(pr);
            e.withFilter(s).withArgs((Serializable)s).execute(function);
          }
          if (sickKey1 != null && sickKey2 != null && healthyKey != null) {
            break;
          }
        }
        return null;
      }
    });
  }",False
"    ServerPorts(int port,int mcastPort) {
      this.port = port;
      this.mcastPort = mcastPort;
    }",True
"    ServerPorts(int port) {
      this.port = port;
    }",False
"  private void doDistributedRegionRemotePutRejection(boolean localDestroy, boolean cacheClose) throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);

    final String regionName = ""rejectRemoteOp"";

    ServerPorts ports1 = startCacheServer(server1, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    ServerPorts ports2 = startCacheServer(server2, ports1.getMcastPort(), 0f, 90f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);

    doPuts(server1, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(server1, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/, Range.DEFAULT);

    //make server2 critical
    setUsageAboveCriticalThreshold(server2);

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, false);

    //make sure that local server1 puts are rejected
    doPuts(server1, regionName, false/*catchRejectedException*/,
        true/*catchLowMemoryException*/);
    Range r1 = new Range(Range.DEFAULT, Range.DEFAULT.width()+1);
    doPutAlls(server1, regionName, false/*catchRejectedException*/,
        true/*catchLowMemoryException*/, r1);

    if (localDestroy) {
    //local destroy the region on sick member
    server2.invoke(new SerializableCallable(""local destroy"") {
      public Object call() throws Exception {
        Region r = getRootRegion().getSubregion(regionName);
        r.localDestroyRegion();
        return null;
      }
    });
    } else if (cacheClose) {
      server2.invoke(new SerializableCallable() {
        public Object call() throws Exception {
          getCache().close();
          return null;
        }
      });
    } else {
      setUsageBelowEviction(server2);
    }
    
    //wait for remote region destroyed message to be processed
    server1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""remote localRegionDestroyed message not received"";
          }
          public boolean done() {
            DistributedRegion dr = (DistributedRegion)getRootRegion().
                                                getSubregion(regionName);
            return dr.getMemoryThresholdReachedMembers().size() == 0;
          }
        };
        waitForCriterion(wc, 10000, 10, true);
        return null;
      }
    });

    //make sure puts succeed
    doPuts(server1, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/);
    Range r2 = new Range(r1, r1.width()+1);
    doPutAlls(server1, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/, r2);
  }",True
"  private void doDistributedRegionRemotePutRejection(boolean localDestroy, boolean cacheClose) throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);

    final String regionName = ""rejectRemoteOp"";

    ServerPorts ports1 = startCacheServer(server1, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    ServerPorts ports2 = startCacheServer(server2, 0f, 90f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);

    doPuts(server1, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(server1, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/, Range.DEFAULT);

    //make server2 critical
    setUsageAboveCriticalThreshold(server2);

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, false);

    //make sure that local server1 puts are rejected
    doPuts(server1, regionName, false/*catchRejectedException*/,
        true/*catchLowMemoryException*/);
    Range r1 = new Range(Range.DEFAULT, Range.DEFAULT.width()+1);
    doPutAlls(server1, regionName, false/*catchRejectedException*/,
        true/*catchLowMemoryException*/, r1);

    if (localDestroy) {
    //local destroy the region on sick member
    server2.invoke(new SerializableCallable(""local destroy"") {
      public Object call() throws Exception {
        Region r = getRootRegion().getSubregion(regionName);
        r.localDestroyRegion();
        return null;
      }
    });
    } else if (cacheClose) {
      server2.invoke(new SerializableCallable() {
        public Object call() throws Exception {
          getCache().close();
          return null;
        }
      });
    } else {
      setUsageBelowEviction(server2);
    }
    
    //wait for remote region destroyed message to be processed
    server1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""remote localRegionDestroyed message not received"";
          }
          public boolean done() {
            DistributedRegion dr = (DistributedRegion)getRootRegion().
                                                getSubregion(regionName);
            return dr.getMemoryThresholdReachedMembers().size() == 0;
          }
        };
        waitForCriterion(wc, 10000, 10, true);
        return null;
      }
    });

    //make sure puts succeed
    doPuts(server1, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/);
    Range r2 = new Range(r1, r1.width()+1);
    doPutAlls(server1, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/, r2);
  }",False
"  public void disabledtestTxCommitInCritical() throws Exception {
    final Host host = Host.getHost(0);
    final VM accessor = host.getVM(0);
    final VM server1 = host.getVM(1);
    final VM server2 = host.getVM(2);
    final VM server3 = host.getVM(3);

    final String regionName = ""testPrRejection"";
    final int redundancy = 1;

    final ServerPorts ports1 = startCacheServer(server1, 80f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    ServerPorts ports2 = startCacheServer(server2, ports1.getMcastPort(), 80f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    ServerPorts ports3 = startCacheServer(server3, ports1.getMcastPort(), 80f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    
    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);
    registerTestMemoryThresholdListener(server3);
    
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        getSystem(getServerProperties(ports1.getMcastPort()));
        getCache();
        AttributesFactory factory = new AttributesFactory();        
        PartitionAttributesFactory paf = new PartitionAttributesFactory();
        paf.setRedundantCopies(redundancy);
        paf.setLocalMaxMemory(0);
        paf.setTotalNumBuckets(11);
        factory.setPartitionAttributes(paf.create());
        createRegion(regionName, factory.create());
        return null;
      }
    });
    
    doPuts(accessor, regionName, false, false);
    final Range r1 = Range.DEFAULT;
    doPutAlls(accessor, regionName, false, false, r1);
    
    SerializableCallable getMyId = new SerializableCallable() {
      public Object call() throws Exception {        
        return ((GemFireCacheImpl)getCache()).getMyId();
      }
    };
    
    final DistributedMember server1Id = 
      (DistributedMember)server1.invoke(getMyId); 
    
    final Integer lastKey = (Integer)accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        final PartitionedRegion pr = (PartitionedRegion)getRootRegion().getSubregion(regionName);
        getCache().getCacheTransactionManager().begin();
        for (int i=0; i< 20; i++) {
          Integer key = Integer.valueOf(i);
          int hKey = PartitionedRegionHelper.getHashKey(pr, key);
          Set<InternalDistributedMember> owners = pr.getRegionAdvisor().getBucketOwners(hKey);
          if (owners.contains(server1Id)) {
            pr.put(key, ""txTest"");
            return i;
          }
        }
        return null;
      }
    });
    assertNotNull(lastKey);
    
    setUsageAboveCriticalThreshold(server1);

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);

    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        final PartitionedRegion pr = (PartitionedRegion)getRootRegion().getSubregion(regionName);
        assertTrue(getCache().getCacheTransactionManager().exists());
        boolean exceptionThrown = false;
        for (int i= lastKey; i< 20; i++) {
          Integer key = Integer.valueOf(i);
          int hKey = PartitionedRegionHelper.getHashKey(pr, key);
          Set<InternalDistributedMember> owners = pr.getRegionAdvisor().getBucketOwners(hKey);
          if (owners.contains(server1Id)) {
            try {
              pr.put(key, ""txTest"");
            } catch (LowMemoryException e) {
              exceptionThrown = true;
              break;
            }
          }
        }
        if (!exceptionThrown) {
          fail(""expected exception not thrown"");
        }
        getCache().getCacheTransactionManager().commit();
        int seenCount = 0;
        for (int i=0; i<20; i++) {
          if (""txTest"".equals(pr.get(i))) {
            seenCount++;
          }
        }
        assertEquals(1, seenCount);
        return null;
      }
    });
  }",True
"  public void disabledtestTxCommitInCritical() throws Exception {
    final Host host = Host.getHost(0);
    final VM accessor = host.getVM(0);
    final VM server1 = host.getVM(1);
    final VM server2 = host.getVM(2);
    final VM server3 = host.getVM(3);

    final String regionName = ""testPrRejection"";
    final int redundancy = 1;

    final ServerPorts ports1 = startCacheServer(server1, 80f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    ServerPorts ports2 = startCacheServer(server2, 80f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    ServerPorts ports3 = startCacheServer(server3, 80f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    
    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);
    registerTestMemoryThresholdListener(server3);
    
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        getSystem(getServerProperties());
        getCache();
        AttributesFactory factory = new AttributesFactory();        
        PartitionAttributesFactory paf = new PartitionAttributesFactory();
        paf.setRedundantCopies(redundancy);
        paf.setLocalMaxMemory(0);
        paf.setTotalNumBuckets(11);
        factory.setPartitionAttributes(paf.create());
        createRegion(regionName, factory.create());
        return null;
      }
    });
    
    doPuts(accessor, regionName, false, false);
    final Range r1 = Range.DEFAULT;
    doPutAlls(accessor, regionName, false, false, r1);
    
    SerializableCallable getMyId = new SerializableCallable() {
      public Object call() throws Exception {        
        return ((GemFireCacheImpl)getCache()).getMyId();
      }
    };
    
    final DistributedMember server1Id = 
      (DistributedMember)server1.invoke(getMyId); 
    
    final Integer lastKey = (Integer)accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        final PartitionedRegion pr = (PartitionedRegion)getRootRegion().getSubregion(regionName);
        getCache().getCacheTransactionManager().begin();
        for (int i=0; i< 20; i++) {
          Integer key = Integer.valueOf(i);
          int hKey = PartitionedRegionHelper.getHashKey(pr, key);
          Set<InternalDistributedMember> owners = pr.getRegionAdvisor().getBucketOwners(hKey);
          if (owners.contains(server1Id)) {
            pr.put(key, ""txTest"");
            return i;
          }
        }
        return null;
      }
    });
    assertNotNull(lastKey);
    
    setUsageAboveCriticalThreshold(server1);

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);

    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        final PartitionedRegion pr = (PartitionedRegion)getRootRegion().getSubregion(regionName);
        assertTrue(getCache().getCacheTransactionManager().exists());
        boolean exceptionThrown = false;
        for (int i= lastKey; i< 20; i++) {
          Integer key = Integer.valueOf(i);
          int hKey = PartitionedRegionHelper.getHashKey(pr, key);
          Set<InternalDistributedMember> owners = pr.getRegionAdvisor().getBucketOwners(hKey);
          if (owners.contains(server1Id)) {
            try {
              pr.put(key, ""txTest"");
            } catch (LowMemoryException e) {
              exceptionThrown = true;
              break;
            }
          }
        }
        if (!exceptionThrown) {
          fail(""expected exception not thrown"");
        }
        getCache().getCacheTransactionManager().commit();
        int seenCount = 0;
        for (int i=0; i<20; i++) {
          if (""txTest"".equals(pr.get(i))) {
            seenCount++;
          }
        }
        assertEquals(1, seenCount);
        return null;
      }
    });
  }",False
"  public void testFunctionExecutionRejection() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM client = host.getVM(2);
    final String regionName = ""FuncRej"";

    ServerPorts ports1 = startCacheServer(server1, 80f, 90f, regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    ServerPorts ports2 = startCacheServer(server2, ports1.getMcastPort(), 80f, 90f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    startClient(client, server1, ports1.getPort(), regionName);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);
    
    final RejectFunction function = new RejectFunction();
    final RejectFunction function2 = new RejectFunction(""noRejFunc"", false);
    invokeInEveryVM(new SerializableCallable(""register function"") {
      public Object call() throws Exception {
        FunctionService.registerFunction(function);
        FunctionService.registerFunction(function2);
        return null;
      }
    });

    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Pool p = PoolManager.find(""pool1"");
        assertTrue(p != null);
        FunctionService.onServers(p).execute(function);
        FunctionService.onServers(p).execute(function2);
        return null;
      }
    });
    
    final DistributedMember s1 = (DistributedMember)server1.invoke(getDistributedMember);

    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        FunctionService.onMembers(getSystem()).execute(function);
        FunctionService.onMember(getSystem(), s1).execute(function);
        FunctionService.onMembers(getSystem()).execute(function2);
        FunctionService.onMember(getSystem(), s1).execute(function2);
        return null;
      }
    });

    setUsageAboveCriticalThreshold(server1);

    verifyListenerValue(server2, MemoryState.CRITICAL, 1, true);

    server1.invoke(addExpectedFunctionException);
    server2.invoke(addExpectedFunctionException);

    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Pool p = PoolManager.find(""pool1"");
        assertTrue(p != null);
        try {
          FunctionService.onServers(p).execute(function);
          fail(""expected LowMemoryExcception was not thrown"");
        } catch (ServerOperationException e) {
          if (!(e.getCause().getMessage().matches("".*low.*memory.*""))) {
            fail(""unexpected exception"", e);
          }
          //expected
        }
        FunctionService.onServers(p).execute(function2);
        return null;
      }
    });

    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        try {
          FunctionService.onMembers(getSystem()).execute(function);
          fail(""expected LowMemoryExcception was not thrown"");
        } catch (LowMemoryException e) {          
          //expected
        }
        try {
          FunctionService.onMember(getSystem(), s1).execute(function);
          fail(""expected LowMemoryExcception was not thrown"");
        } catch (LowMemoryException e) {
          //expected
        }
        FunctionService.onMembers(getSystem()).execute(function2);
        FunctionService.onMember(getSystem(), s1).execute(function2);
        return null;
      }
    });
    server1.invoke(removeExpectedFunctionException);
    server2.invoke(removeExpectedFunctionException);
  }",True
"  public void testFunctionExecutionRejection() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM client = host.getVM(2);
    final String regionName = ""FuncRej"";

    ServerPorts ports1 = startCacheServer(server1, 80f, 90f, regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    ServerPorts ports2 = startCacheServer(server2, 80f, 90f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    startClient(client, server1, ports1.getPort(), regionName);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);
    
    final RejectFunction function = new RejectFunction();
    final RejectFunction function2 = new RejectFunction(""noRejFunc"", false);
    invokeInEveryVM(new SerializableCallable(""register function"") {
      public Object call() throws Exception {
        FunctionService.registerFunction(function);
        FunctionService.registerFunction(function2);
        return null;
      }
    });

    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Pool p = PoolManager.find(""pool1"");
        assertTrue(p != null);
        FunctionService.onServers(p).execute(function);
        FunctionService.onServers(p).execute(function2);
        return null;
      }
    });
    
    final DistributedMember s1 = (DistributedMember)server1.invoke(getDistributedMember);

    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        FunctionService.onMembers(getSystem()).execute(function);
        FunctionService.onMember(getSystem(), s1).execute(function);
        FunctionService.onMembers(getSystem()).execute(function2);
        FunctionService.onMember(getSystem(), s1).execute(function2);
        return null;
      }
    });

    setUsageAboveCriticalThreshold(server1);

    verifyListenerValue(server2, MemoryState.CRITICAL, 1, true);

    server1.invoke(addExpectedFunctionException);
    server2.invoke(addExpectedFunctionException);

    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Pool p = PoolManager.find(""pool1"");
        assertTrue(p != null);
        try {
          FunctionService.onServers(p).execute(function);
          fail(""expected LowMemoryExcception was not thrown"");
        } catch (ServerOperationException e) {
          if (!(e.getCause().getMessage().matches("".*low.*memory.*""))) {
            fail(""unexpected exception"", e);
          }
          //expected
        }
        FunctionService.onServers(p).execute(function2);
        return null;
      }
    });

    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        try {
          FunctionService.onMembers(getSystem()).execute(function);
          fail(""expected LowMemoryExcception was not thrown"");
        } catch (LowMemoryException e) {          
          //expected
        }
        try {
          FunctionService.onMember(getSystem(), s1).execute(function);
          fail(""expected LowMemoryExcception was not thrown"");
        } catch (LowMemoryException e) {
          //expected
        }
        FunctionService.onMembers(getSystem()).execute(function2);
        FunctionService.onMember(getSystem(), s1).execute(function2);
        return null;
      }
    });
    server1.invoke(removeExpectedFunctionException);
    server2.invoke(removeExpectedFunctionException);
  }",False
"  private ServerPorts startCacheServer(VM server, final int mcastPort, final float evictionThreshold, final float criticalThreshold, final String regionName,
      final boolean createPR, final boolean notifyBySubscription, final int prRedundancy) throws Exception {

    return (ServerPorts) server.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        getSystem(getServerProperties(mcastPort));
        GemFireCacheImpl cache = (GemFireCacheImpl)getCache();

        InternalResourceManager irm = cache.getResourceManager();
        HeapMemoryMonitor hmm = irm.getHeapMonitor();
        hmm.setTestMaxMemoryBytes(1000);
        HeapMemoryMonitor.setTestBytesUsedForThresholdSet(500);
        irm.setEvictionHeapPercentage(evictionThreshold);
        irm.setCriticalHeapPercentage(criticalThreshold);

        AttributesFactory factory = new AttributesFactory();
        if (createPR) {
          PartitionAttributesFactory paf = new PartitionAttributesFactory();
          paf.setRedundantCopies(prRedundancy);
          paf.setTotalNumBuckets(11);
          factory.setPartitionAttributes(paf.create());
        } else {
          factory.setScope(Scope.DISTRIBUTED_ACK);
          factory.setDataPolicy(DataPolicy.REPLICATE);
        }
        Region region = createRegion(regionName, factory.create());
        if (createPR) {
          assertTrue(region instanceof PartitionedRegion);
        } else {
          assertTrue(region instanceof DistributedRegion);
        }
        CacheServer cacheServer = getCache().addCacheServer();
        int port = AvailablePortHelper.getRandomAvailableTCPPorts(1)[0];
        cacheServer.setPort(port);
        cacheServer.setNotifyBySubscription(notifyBySubscription);
        cacheServer.start();
        
        return new ServerPorts(port, mcastPort);
      }
    });
  }",True
"  private ServerPorts startCacheServer(VM server, final float evictionThreshold, final float criticalThreshold, final String regionName,
      final boolean createPR, final boolean notifyBySubscription, final int prRedundancy) throws Exception {

    return (ServerPorts) server.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        getSystem(getServerProperties());
        GemFireCacheImpl cache = (GemFireCacheImpl)getCache();

        InternalResourceManager irm = cache.getResourceManager();
        HeapMemoryMonitor hmm = irm.getHeapMonitor();
        hmm.setTestMaxMemoryBytes(1000);
        HeapMemoryMonitor.setTestBytesUsedForThresholdSet(500);
        irm.setEvictionHeapPercentage(evictionThreshold);
        irm.setCriticalHeapPercentage(criticalThreshold);

        AttributesFactory factory = new AttributesFactory();
        if (createPR) {
          PartitionAttributesFactory paf = new PartitionAttributesFactory();
          paf.setRedundantCopies(prRedundancy);
          paf.setTotalNumBuckets(11);
          factory.setPartitionAttributes(paf.create());
        } else {
          factory.setScope(Scope.DISTRIBUTED_ACK);
          factory.setDataPolicy(DataPolicy.REPLICATE);
        }
        Region region = createRegion(regionName, factory.create());
        if (createPR) {
          assertTrue(region instanceof PartitionedRegion);
        } else {
          assertTrue(region instanceof DistributedRegion);
        }
        CacheServer cacheServer = getCache().addCacheServer();
        int port = AvailablePortHelper.getRandomAvailableTCPPorts(1)[0];
        cacheServer.setPort(port);
        cacheServer.setNotifyBySubscription(notifyBySubscription);
        cacheServer.start();
        
        return new ServerPorts(port);
      }
    });
  }",False
"  public void testDisabledThresholds() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);

    final String regionName = ""disableThresholdPr"";

    ServerPorts ports1 = startCacheServer(server1, 0f, 0f, regionName, true/*createPR*/, false/*notifyBySubscription*/, 0);
    ServerPorts ports2 = startCacheServer(server2, ports1.getMcastPort(), 0f, 0f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, 0);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);

    setUsageAboveEvictionThreshold(server1);
    verifyListenerValue(server1, MemoryState.EVICTION, 0, false);
    verifyListenerValue(server2, MemoryState.EVICTION, 0, true);

    setThresholds(server1, 80f, 0f);
    verifyListenerValue(server1, MemoryState.EVICTION, 1, false);
    verifyListenerValue(server2, MemoryState.EVICTION, 1, true);

    setUsageAboveCriticalThreshold(server1);
    verifyListenerValue(server1, MemoryState.CRITICAL, 0, false);
    verifyListenerValue(server2, MemoryState.CRITICAL, 0, true);

    setThresholds(server1, 0f, 0f);
    verifyListenerValue(server1, MemoryState.EVICTION_DISABLED, 1, false);
    verifyListenerValue(server2, MemoryState.EVICTION_DISABLED, 1, true);

    setThresholds(server1, 0f, 90f);
    verifyListenerValue(server1, MemoryState.CRITICAL, 1, false);
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, true);

    //verify that stats on server2 are not changed by events on server1
    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        InternalResourceManager irm = ((GemFireCacheImpl)getCache()).getResourceManager();
        assertEquals(0, irm.getStats().getEvictionStartEvents());
        assertEquals(0, irm.getStats().getHeapCriticalEvents());
        assertEquals(0, irm.getStats().getCriticalThreshold());
        assertEquals(0, irm.getStats().getEvictionThreshold());
        return null;
      }
    });
  }",True
"  public void testDisabledThresholds() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);

    final String regionName = ""disableThresholdPr"";

    ServerPorts ports1 = startCacheServer(server1, 0f, 0f, regionName, true/*createPR*/, false/*notifyBySubscription*/, 0);
    ServerPorts ports2 = startCacheServer(server2, 0f, 0f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, 0);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);

    setUsageAboveEvictionThreshold(server1);
    verifyListenerValue(server1, MemoryState.EVICTION, 0, false);
    verifyListenerValue(server2, MemoryState.EVICTION, 0, true);

    setThresholds(server1, 80f, 0f);
    verifyListenerValue(server1, MemoryState.EVICTION, 1, false);
    verifyListenerValue(server2, MemoryState.EVICTION, 1, true);

    setUsageAboveCriticalThreshold(server1);
    verifyListenerValue(server1, MemoryState.CRITICAL, 0, false);
    verifyListenerValue(server2, MemoryState.CRITICAL, 0, true);

    setThresholds(server1, 0f, 0f);
    verifyListenerValue(server1, MemoryState.EVICTION_DISABLED, 1, false);
    verifyListenerValue(server2, MemoryState.EVICTION_DISABLED, 1, true);

    setThresholds(server1, 0f, 90f);
    verifyListenerValue(server1, MemoryState.CRITICAL, 1, false);
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, true);

    //verify that stats on server2 are not changed by events on server1
    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        InternalResourceManager irm = ((GemFireCacheImpl)getCache()).getResourceManager();
        assertEquals(0, irm.getStats().getEvictionStartEvents());
        assertEquals(0, irm.getStats().getHeapCriticalEvents());
        assertEquals(0, irm.getStats().getCriticalThreshold());
        assertEquals(0, irm.getStats().getEvictionThreshold());
        return null;
      }
    });
  }",False
"  protected Properties getServerProperties(int mcastPort) {
    Properties p = new Properties();
    p.setProperty(DistributionConfig.MCAST_PORT_NAME, mcastPort+"""");
    p.setProperty(DistributionConfig.LOCATORS_NAME, """");
    return p;
  }",True
"        regionContext.getResultSender().lastResult(""executed"");
      } else {
        context.getResultSender().lastResult(""executed"");
      }
    }
    @Override",False
"    int getMcastPort() {
      return this.mcastPort;
    }",True
"  public void testDRFunctionExecutionRejection() throws Exception {
    addExpectedException(""LowMemoryException"");
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM client = host.getVM(2);
    final String regionName = ""drFuncRej"";

    ServerPorts ports1 = startCacheServer(server1, 80f, 90f, regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    ServerPorts ports2 = startCacheServer(server2, ports1.getMcastPort(), 80f, 90f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    startClient(client, server1, ports1.getPort(), regionName);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);
    
    final RejectFunction function = new RejectFunction();
    final RejectFunction function2 = new RejectFunction(""noRejFunc"", false);
    invokeInEveryVM(new SerializableCallable(""register function"") {
      public Object call() throws Exception {
        FunctionService.registerFunction(function);
        FunctionService.registerFunction(function2);
        return null;
      }
    });

    doPutAlls(server1, regionName, false, false, Range.DEFAULT);
    doPuts(server1, regionName, false, false);

    server1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
          .execute(function);
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
        .execute(function2);
        return null;
      }
    });
    //should not fail
    server1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        FunctionService.onMembers(getSystem()).execute(function);
        FunctionService.onMembers(getSystem()).execute(function2);
        return null;
      }
    });    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
          .execute(function).getResult(30, TimeUnit.SECONDS);
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
          .execute(function2).getResult(30, TimeUnit.SECONDS);
        return null;
      }
    });
    
    setUsageAboveCriticalThreshold(server2);

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);

    server1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        try {
          getCache().getLoggerI18n().fine(addExpectedFunctionExString);
          FunctionService.onRegion(getRootRegion().getSubregion(regionName))
            .execute(function);
          getCache().getLoggerI18n().fine(removeExpectedFunctionExString);
          fail(""expected low memory exception was not thrown"");
        } catch (LowMemoryException e) {
          //expected
        }
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
        .execute(function2);
        return null;
      }
    });

    server1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        try {
          getCache().getLoggerI18n().fine(addExpectedFunctionExString);
          FunctionService.onMembers(getSystem()).execute(function);
          getCache().getLoggerI18n().fine(removeExpectedFunctionExString);
          fail(""expected low memory exception was not thrown"");
        } catch (LowMemoryException e) {
          //expected
        }
        FunctionService.onMembers(getSystem()).execute(function2);
        return null;
      }
    });
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        try {
          getCache().getLoggerI18n().fine(addExpectedFunctionExString);
          FunctionService.onRegion(getRootRegion().getSubregion(regionName))
            .execute(function);
          getCache().getLoggerI18n().fine(removeExpectedFunctionExString);
          fail(""expected low memory exception was not thrown"");
        } catch (FunctionException e) {
          if (!(e.getCause().getCause() instanceof LowMemoryException)) {
            fail(""unexpected exception "", e);
          }
          //expected
        }
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
          .execute(function2);
        return null;
      }
    });
  }",True
"  public void testDRFunctionExecutionRejection() throws Exception {
    addExpectedException(""LowMemoryException"");
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM client = host.getVM(2);
    final String regionName = ""drFuncRej"";

    ServerPorts ports1 = startCacheServer(server1, 80f, 90f, regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    ServerPorts ports2 = startCacheServer(server2, 80f, 90f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    startClient(client, server1, ports1.getPort(), regionName);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);
    
    final RejectFunction function = new RejectFunction();
    final RejectFunction function2 = new RejectFunction(""noRejFunc"", false);
    invokeInEveryVM(new SerializableCallable(""register function"") {
      public Object call() throws Exception {
        FunctionService.registerFunction(function);
        FunctionService.registerFunction(function2);
        return null;
      }
    });

    doPutAlls(server1, regionName, false, false, Range.DEFAULT);
    doPuts(server1, regionName, false, false);

    server1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
          .execute(function);
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
        .execute(function2);
        return null;
      }
    });
    //should not fail
    server1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        FunctionService.onMembers(getSystem()).execute(function);
        FunctionService.onMembers(getSystem()).execute(function2);
        return null;
      }
    });    
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
          .execute(function).getResult(30, TimeUnit.SECONDS);
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
          .execute(function2).getResult(30, TimeUnit.SECONDS);
        return null;
      }
    });
    
    setUsageAboveCriticalThreshold(server2);

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);

    server1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        try {
          getCache().getLoggerI18n().fine(addExpectedFunctionExString);
          FunctionService.onRegion(getRootRegion().getSubregion(regionName))
            .execute(function);
          getCache().getLoggerI18n().fine(removeExpectedFunctionExString);
          fail(""expected low memory exception was not thrown"");
        } catch (LowMemoryException e) {
          //expected
        }
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
        .execute(function2);
        return null;
      }
    });

    server1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        try {
          getCache().getLoggerI18n().fine(addExpectedFunctionExString);
          FunctionService.onMembers(getSystem()).execute(function);
          getCache().getLoggerI18n().fine(removeExpectedFunctionExString);
          fail(""expected low memory exception was not thrown"");
        } catch (LowMemoryException e) {
          //expected
        }
        FunctionService.onMembers(getSystem()).execute(function2);
        return null;
      }
    });
    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        try {
          getCache().getLoggerI18n().fine(addExpectedFunctionExString);
          FunctionService.onRegion(getRootRegion().getSubregion(regionName))
            .execute(function);
          getCache().getLoggerI18n().fine(removeExpectedFunctionExString);
          fail(""expected low memory exception was not thrown"");
        } catch (FunctionException e) {
          if (!(e.getCause().getCause() instanceof LowMemoryException)) {
            fail(""unexpected exception "", e);
          }
          //expected
        }
        FunctionService.onRegion(getRootRegion().getSubregion(regionName))
          .execute(function2);
        return null;
      }
    });
  }",False
"  public void testCleanAdvisorClose() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM server3 = host.getVM(2);

    final String regionName = ""testEventOrger"";

    ServerPorts ports1 = startCacheServer(server1, 0f, 0f, regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    ServerPorts ports2 = startCacheServer(server2, ports1.getMcastPort(), 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    verifyProfiles(server1, 1);
    verifyProfiles(server2, 1);

    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        closeCache();
        return null;
      }
    });

    verifyProfiles(server1, 0);

    startCacheServer(server3, ports1.getMcastPort(), 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    verifyProfiles(server1, 1);
    verifyProfiles(server3, 1);
  }",True
"  public void testCleanAdvisorClose() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM server3 = host.getVM(2);

    final String regionName = ""testEventOrger"";

    ServerPorts ports1 = startCacheServer(server1, 0f, 0f, regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    ServerPorts ports2 = startCacheServer(server2, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    verifyProfiles(server1, 1);
    verifyProfiles(server2, 1);

    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        closeCache();
        return null;
      }
    });

    verifyProfiles(server1, 0);

    startCacheServer(server3, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    verifyProfiles(server1, 1);
    verifyProfiles(server3, 1);
  }",False
"  protected Properties getServerProperties() {
    Properties p = new Properties();
    p.setProperty(DistributionConfig.LOCATORS_NAME, ""localhost[""+getDUnitLocatorPort()+""]"");
    return p;
  }",False
"  private void prRemotePutRejection(boolean cacheClose, boolean localDestroy, final boolean useTx) throws Exception {
    final Host host = Host.getHost(0);
    final VM accessor = host.getVM(0);
    final VM server1 = host.getVM(1);
    final VM server2 = host.getVM(2);
    final VM server3 = host.getVM(3);

    final String regionName = ""testPrRejection"";
    final int redundancy = 1;

    final ServerPorts ports1 = startCacheServer(server1, 80f, 90f, regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    ServerPorts ports2 = startCacheServer(server2, ports1.getMcastPort(), 80f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    ServerPorts ports3 = startCacheServer(server3, ports1.getMcastPort(), 80f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        getSystem(getServerProperties(ports1.getMcastPort()));
        getCache();
        AttributesFactory factory = new AttributesFactory();        
        PartitionAttributesFactory paf = new PartitionAttributesFactory();
        paf.setRedundantCopies(redundancy);
        paf.setLocalMaxMemory(0);
        paf.setTotalNumBuckets(11);
        factory.setPartitionAttributes(paf.create());
        createRegion(regionName, factory.create());
        return null;
      }
    });
    
    doPuts(accessor, regionName, false, false);
    final Range r1 = Range.DEFAULT;
    doPutAlls(accessor, regionName, false, false, r1);
    
    SerializableCallable getMyId = new SerializableCallable() {
      public Object call() throws Exception {        
        return ((GemFireCacheImpl)getCache()).getMyId();
      }
    };
    
    final DistributedMember server1Id = 
      (DistributedMember)server1.invoke(getMyId); 
    
    setUsageAboveCriticalThreshold(server1);
     
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        final PartitionedRegion pr = (PartitionedRegion)getRootRegion().
                                getSubregion(regionName);
        final String regionPath = getRootRegion().getSubregion(regionName).getFullPath();
        //server1 is sick, look for a key on server1, and attempt put again
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""remote bucket not marked sick"";
          }
          public boolean done() {
            boolean keyFoundOnSickMember = false;
            boolean caughtException = false;
            for (int i=0; i<20; i++) {
              Integer key = Integer.valueOf(i);
              int hKey = PartitionedRegionHelper.getHashKey(pr, null, key, null, null);
              Set<InternalDistributedMember> owners = pr.getRegionAdvisor().getBucketOwners(hKey);
              if (owners.contains(server1Id)) {
                keyFoundOnSickMember = true;
                try {
                  if (useTx) getCache().getCacheTransactionManager().begin();
                  pr.getCache().getLogger().fine(""SWAP:putting in tx:""+useTx);
                  pr.put(key, ""value"");
                  if (useTx) getCache().getCacheTransactionManager().commit();
                } catch (LowMemoryException ex) {
                  caughtException = true;
                  if (useTx) getCache().getCacheTransactionManager().rollback();
                }
              } else {
                //puts on healthy member should continue
                pr.put(key, ""value"");
              }
            }
            return keyFoundOnSickMember && caughtException;
          }
        };
        waitForCriterion(wc, 10000, 10, true);
        return null;
      }
    });

    {
      Range r2 = new Range(r1, r1.width()+1);
      doPutAlls(accessor, regionName, false, true, r2);
    }

    if (localDestroy) {
    //local destroy the region on sick member
      server1.invoke(new SerializableCallable(""local destroy sick member"") {
        public Object call() throws Exception {
          Region r = getRootRegion().getSubregion(regionName);
          getLogWriter().info(""PRLocalDestroy"");
          r.localDestroyRegion();
          return null;
        }
      });
    } else if (cacheClose) {
      //close cache on sick member
      server1.invoke(new SerializableCallable(""close cache sick member"") {
        public Object call() throws Exception {
          getCache().close();
          return null;
        }
      });
    } else {
      setUsageBelowEviction(server1);
    }
    
    //do put all in a loop to allow distribution of message
    accessor.invoke(new SerializableCallable(""Put in a loop"") {
      public Object call() throws Exception {
        final Region r = getRootRegion().getSubregion(regionName);
        WaitCriterion wc = new WaitCriterion() {
          public String description() {            
            return ""pr should have gone un-critical"";
          }
          public boolean done() {
            boolean done = true;
            for (int i=0; i<20; i++) {
              try {
                r.put(i,""value"");
              } catch (LowMemoryException e) {
                //expected
                done = false;
              }
            }            
            return done;
          }
        };
        waitForCriterion(wc, 10000, 10, true);
        return null;
      }
    });
    doPutAlls(accessor, regionName, false, false, r1);
  }",True
"  private void prRemotePutRejection(boolean cacheClose, boolean localDestroy, final boolean useTx) throws Exception {
    final Host host = Host.getHost(0);
    final VM accessor = host.getVM(0);
    final VM server1 = host.getVM(1);
    final VM server2 = host.getVM(2);
    final VM server3 = host.getVM(3);

    final String regionName = ""testPrRejection"";
    final int redundancy = 1;

    final ServerPorts ports1 = startCacheServer(server1, 80f, 90f, regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    ServerPorts ports2 = startCacheServer(server2, 80f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    ServerPorts ports3 = startCacheServer(server3, 80f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        getSystem(getServerProperties());
        getCache();
        AttributesFactory factory = new AttributesFactory();        
        PartitionAttributesFactory paf = new PartitionAttributesFactory();
        paf.setRedundantCopies(redundancy);
        paf.setLocalMaxMemory(0);
        paf.setTotalNumBuckets(11);
        factory.setPartitionAttributes(paf.create());
        createRegion(regionName, factory.create());
        return null;
      }
    });
    
    doPuts(accessor, regionName, false, false);
    final Range r1 = Range.DEFAULT;
    doPutAlls(accessor, regionName, false, false, r1);
    
    SerializableCallable getMyId = new SerializableCallable() {
      public Object call() throws Exception {        
        return ((GemFireCacheImpl)getCache()).getMyId();
      }
    };
    
    final DistributedMember server1Id = 
      (DistributedMember)server1.invoke(getMyId); 
    
    setUsageAboveCriticalThreshold(server1);
     
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        final PartitionedRegion pr = (PartitionedRegion)getRootRegion().
                                getSubregion(regionName);
        final String regionPath = getRootRegion().getSubregion(regionName).getFullPath();
        //server1 is sick, look for a key on server1, and attempt put again
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""remote bucket not marked sick"";
          }
          public boolean done() {
            boolean keyFoundOnSickMember = false;
            boolean caughtException = false;
            for (int i=0; i<20; i++) {
              Integer key = Integer.valueOf(i);
              int hKey = PartitionedRegionHelper.getHashKey(pr, null, key, null, null);
              Set<InternalDistributedMember> owners = pr.getRegionAdvisor().getBucketOwners(hKey);
              if (owners.contains(server1Id)) {
                keyFoundOnSickMember = true;
                try {
                  if (useTx) getCache().getCacheTransactionManager().begin();
                  pr.getCache().getLogger().fine(""SWAP:putting in tx:""+useTx);
                  pr.put(key, ""value"");
                  if (useTx) getCache().getCacheTransactionManager().commit();
                } catch (LowMemoryException ex) {
                  caughtException = true;
                  if (useTx) getCache().getCacheTransactionManager().rollback();
                }
              } else {
                //puts on healthy member should continue
                pr.put(key, ""value"");
              }
            }
            return keyFoundOnSickMember && caughtException;
          }
        };
        waitForCriterion(wc, 10000, 10, true);
        return null;
      }
    });

    {
      Range r2 = new Range(r1, r1.width()+1);
      doPutAlls(accessor, regionName, false, true, r2);
    }

    if (localDestroy) {
    //local destroy the region on sick member
      server1.invoke(new SerializableCallable(""local destroy sick member"") {
        public Object call() throws Exception {
          Region r = getRootRegion().getSubregion(regionName);
          getLogWriter().info(""PRLocalDestroy"");
          r.localDestroyRegion();
          return null;
        }
      });
    } else if (cacheClose) {
      //close cache on sick member
      server1.invoke(new SerializableCallable(""close cache sick member"") {
        public Object call() throws Exception {
          getCache().close();
          return null;
        }
      });
    } else {
      setUsageBelowEviction(server1);
    }
    
    //do put all in a loop to allow distribution of message
    accessor.invoke(new SerializableCallable(""Put in a loop"") {
      public Object call() throws Exception {
        final Region r = getRootRegion().getSubregion(regionName);
        WaitCriterion wc = new WaitCriterion() {
          public String description() {            
            return ""pr should have gone un-critical"";
          }
          public boolean done() {
            boolean done = true;
            for (int i=0; i<20; i++) {
              try {
                r.put(i,""value"");
              } catch (LowMemoryException e) {
                //expected
                done = false;
              }
            }            
            return done;
          }
        };
        waitForCriterion(wc, 10000, 10, true);
        return null;
      }
    });
    doPutAlls(accessor, regionName, false, false, r1);
  }",False
"  public void testEventDelivery() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);

    final String regionName = ""testEventDelivery"";

    ServerPorts ports1 = startCacheServer(server1, 0f, 0f, regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    ServerPorts ports2 = startCacheServer(server2, ports1.getMcastPort(), 80f, 90f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);

    //NORMAL -> CRITICAL
    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        GemFireCacheImpl gfCache = (GemFireCacheImpl)getCache();
        getCache().getLoggerI18n().fine(addExpectedExString);
        gfCache.getResourceManager().getHeapMonitor().updateStateAndSendEvent(950);
        getCache().getLoggerI18n().fine(removeExpectedExString);
        return null;
      }
    });

    //make sure we get two events on remote server
    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server1, MemoryState.EVICTION, 1, true);
    verifyListenerValue(server1, MemoryState.NORMAL, 0, true);;

    //CRITICAL -> EVICTION
    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        GemFireCacheImpl gfCache = (GemFireCacheImpl)getCache();
        getCache().getLoggerI18n().fine(addExpectedBelow);
        gfCache.getResourceManager().getHeapMonitor().updateStateAndSendEvent(850);
        getCache().getLoggerI18n().fine(removeExpectedBelow);
        return null;
      }
    });
    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server1, MemoryState.EVICTION, 2, true);
    verifyListenerValue(server1, MemoryState.NORMAL, 0, true);;
    
    //EVICTION -> EVICTION
    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        GemFireCacheImpl gfCache = (GemFireCacheImpl)getCache();
        gfCache.getResourceManager().getHeapMonitor().updateStateAndSendEvent(840);
        return null;
      }
    });
    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server1, MemoryState.EVICTION, 2, true);
    verifyListenerValue(server1, MemoryState.NORMAL, 0, true);

    //EVICTION -> NORMAL
    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        GemFireCacheImpl gfCache = (GemFireCacheImpl)getCache();
        gfCache.getResourceManager().getHeapMonitor().updateStateAndSendEvent(750);
        return null;
      }
    });

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server1, MemoryState.EVICTION, 2, true);
    verifyListenerValue(server1, MemoryState.NORMAL, 1, true);
    
    //NORMAL -> EVICTION -> NORMAL
    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        GemFireCacheImpl gfCache = (GemFireCacheImpl)getCache();
        gfCache.getResourceManager().getHeapMonitor().updateStateAndSendEvent(950);
        gfCache.getResourceManager().getHeapMonitor().updateStateAndSendEvent(750);
        return null;
      }
    });

    verifyListenerValue(server1, MemoryState.CRITICAL, 2, true);
    verifyListenerValue(server1, MemoryState.EVICTION, 3, true);
    verifyListenerValue(server1, MemoryState.NORMAL, 2, true);
    
    //NORMAL -> EVICTION
    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        GemFireCacheImpl gfCache = (GemFireCacheImpl)getCache();
        gfCache.getResourceManager().getHeapMonitor().updateStateAndSendEvent(850);
        return null;
      }
    });

    verifyListenerValue(server1, MemoryState.CRITICAL, 2, true);
    verifyListenerValue(server1, MemoryState.EVICTION, 4, true);
    verifyListenerValue(server1, MemoryState.NORMAL, 2, true);
  }",True
"  public void testEventDelivery() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);

    final String regionName = ""testEventDelivery"";

    ServerPorts ports1 = startCacheServer(server1, 0f, 0f, regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    ServerPorts ports2 = startCacheServer(server2, 80f, 90f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);

    //NORMAL -> CRITICAL
    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        GemFireCacheImpl gfCache = (GemFireCacheImpl)getCache();
        getCache().getLoggerI18n().fine(addExpectedExString);
        gfCache.getResourceManager().getHeapMonitor().updateStateAndSendEvent(950);
        getCache().getLoggerI18n().fine(removeExpectedExString);
        return null;
      }
    });

    //make sure we get two events on remote server
    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server1, MemoryState.EVICTION, 1, true);
    verifyListenerValue(server1, MemoryState.NORMAL, 0, true);;

    //CRITICAL -> EVICTION
    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        GemFireCacheImpl gfCache = (GemFireCacheImpl)getCache();
        getCache().getLoggerI18n().fine(addExpectedBelow);
        gfCache.getResourceManager().getHeapMonitor().updateStateAndSendEvent(850);
        getCache().getLoggerI18n().fine(removeExpectedBelow);
        return null;
      }
    });
    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server1, MemoryState.EVICTION, 2, true);
    verifyListenerValue(server1, MemoryState.NORMAL, 0, true);;
    
    //EVICTION -> EVICTION
    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        GemFireCacheImpl gfCache = (GemFireCacheImpl)getCache();
        gfCache.getResourceManager().getHeapMonitor().updateStateAndSendEvent(840);
        return null;
      }
    });
    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server1, MemoryState.EVICTION, 2, true);
    verifyListenerValue(server1, MemoryState.NORMAL, 0, true);

    //EVICTION -> NORMAL
    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        GemFireCacheImpl gfCache = (GemFireCacheImpl)getCache();
        gfCache.getResourceManager().getHeapMonitor().updateStateAndSendEvent(750);
        return null;
      }
    });

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server1, MemoryState.EVICTION, 2, true);
    verifyListenerValue(server1, MemoryState.NORMAL, 1, true);
    
    //NORMAL -> EVICTION -> NORMAL
    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        GemFireCacheImpl gfCache = (GemFireCacheImpl)getCache();
        gfCache.getResourceManager().getHeapMonitor().updateStateAndSendEvent(950);
        gfCache.getResourceManager().getHeapMonitor().updateStateAndSendEvent(750);
        return null;
      }
    });

    verifyListenerValue(server1, MemoryState.CRITICAL, 2, true);
    verifyListenerValue(server1, MemoryState.EVICTION, 3, true);
    verifyListenerValue(server1, MemoryState.NORMAL, 2, true);
    
    //NORMAL -> EVICTION
    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        GemFireCacheImpl gfCache = (GemFireCacheImpl)getCache();
        gfCache.getResourceManager().getHeapMonitor().updateStateAndSendEvent(850);
        return null;
      }
    });

    verifyListenerValue(server1, MemoryState.CRITICAL, 2, true);
    verifyListenerValue(server1, MemoryState.EVICTION, 4, true);
    verifyListenerValue(server1, MemoryState.NORMAL, 2, true);
  }",False
"  public void testLRLoadRejection() throws Exception {
    final Host host = Host.getHost(0);
    final VM vm = host.getVM(2);
    final String rName = getUniqueName();
    final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();

    vm.invoke(DistributedTestCase.class, ""disconnectFromDS"");
    
    vm.invoke(new CacheSerializableRunnable(""test LocalRegion load passthrough when critical"") {
      @Override
      public void run2() throws CacheException {
        getSystem(getServerProperties(mcastPort));
        InternalResourceManager irm = (InternalResourceManager)getCache().getResourceManager();
        final OffHeapMemoryMonitor ohmm = irm.getOffHeapMonitor();
        irm.setCriticalOffHeapPercentage(90f);
        AttributesFactory<Integer, String> af = new AttributesFactory<Integer, String>();
        af.setScope(Scope.LOCAL);
        af.setOffHeap(true);
        final AtomicInteger numLoaderInvocations = new AtomicInteger(0);
        af.setCacheLoader(new CacheLoader<Integer, String>() {
          public String load(LoaderHelper<Integer, String> helper)
          throws CacheLoaderException {
            numLoaderInvocations.incrementAndGet();
            return helper.getKey().toString();
          }
          public void close() {}
        });
        final LocalRegion r = (LocalRegion) getCache().createRegion(rName, af.create());
        
        assertFalse(ohmm.getState().isCritical());
        int expectedInvocations = 0;
        assertEquals(expectedInvocations++, numLoaderInvocations.get());
        {
          Integer k = new Integer(1);
          assertEquals(k.toString(), r.get(k));
        }
        assertEquals(expectedInvocations++, numLoaderInvocations.get());
        expectedInvocations++; expectedInvocations++;
        r.getAll(createRanges(10, 12));
        assertEquals(expectedInvocations++, numLoaderInvocations.get());
        
        getCache().getLoggerI18n().fine(addExpectedExString);
        r.put(""oh1"", new byte[838860]);
        r.put(""oh3"", new byte[157287]);
        getCache().getLoggerI18n().fine(removeExpectedExString);
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return r.memoryThresholdReached.get();
          }
        };
        waitForCriterion(wc, 3000, 100, true);
        { 
          Integer k = new Integer(2);
          assertEquals(k.toString(), r.get(k));
        }
        assertEquals(expectedInvocations++, numLoaderInvocations.get());
        expectedInvocations++; expectedInvocations++;
        r.getAll(createRanges(13, 15));
        assertEquals(expectedInvocations++, numLoaderInvocations.get());
        
        getCache().getLoggerI18n().fine(addExpectedBelow);
        r.destroy(""oh3"");
        getCache().getLoggerI18n().fine(removeExpectedBelow);
        wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return !r.memoryThresholdReached.get();
          }
        };
        waitForCriterion(wc, 3000, 100, true);
        
        {
          Integer k = new Integer(3);
          assertEquals(k.toString(), r.get(k));
        }
        assertEquals(expectedInvocations++, numLoaderInvocations.get());
        expectedInvocations++; expectedInvocations++;
        r.getAll(createRanges(16, 18));
        assertEquals(expectedInvocations, numLoaderInvocations.get());

        // Do extra validation that the entry doesn't exist in the local region
        for (Integer i: createRanges(2, 2, 13, 15)) {
          if (r.containsKey(i)) {
            fail(""Expected containsKey return false for key"" + i);
          }
          if (r.getEntry(i) != null) {
            fail(""Expected getEntry to return null for key"" + i);
          }
        }
      }
    });
  }",True
"  public void testLRLoadRejection() throws Exception {
    final Host host = Host.getHost(0);
    final VM vm = host.getVM(2);
    final String rName = getUniqueName();

    vm.invoke(DistributedTestCase.class, ""disconnectFromDS"");
    
    vm.invoke(new CacheSerializableRunnable(""test LocalRegion load passthrough when critical"") {
      @Override
      public void run2() throws CacheException {
        getSystem(getServerProperties());
        InternalResourceManager irm = (InternalResourceManager)getCache().getResourceManager();
        final OffHeapMemoryMonitor ohmm = irm.getOffHeapMonitor();
        irm.setCriticalOffHeapPercentage(90f);
        AttributesFactory<Integer, String> af = new AttributesFactory<Integer, String>();
        af.setScope(Scope.LOCAL);
        af.setOffHeap(true);
        final AtomicInteger numLoaderInvocations = new AtomicInteger(0);
        af.setCacheLoader(new CacheLoader<Integer, String>() {
          public String load(LoaderHelper<Integer, String> helper)
          throws CacheLoaderException {
            numLoaderInvocations.incrementAndGet();
            return helper.getKey().toString();
          }
          public void close() {}
        });
        final LocalRegion r = (LocalRegion) getCache().createRegion(rName, af.create());
        
        assertFalse(ohmm.getState().isCritical());
        int expectedInvocations = 0;
        assertEquals(expectedInvocations++, numLoaderInvocations.get());
        {
          Integer k = new Integer(1);
          assertEquals(k.toString(), r.get(k));
        }
        assertEquals(expectedInvocations++, numLoaderInvocations.get());
        expectedInvocations++; expectedInvocations++;
        r.getAll(createRanges(10, 12));
        assertEquals(expectedInvocations++, numLoaderInvocations.get());
        
        getCache().getLoggerI18n().fine(addExpectedExString);
        r.put(""oh1"", new byte[838860]);
        r.put(""oh3"", new byte[157287]);
        getCache().getLoggerI18n().fine(removeExpectedExString);
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return r.memoryThresholdReached.get();
          }
        };
        waitForCriterion(wc, 3000, 100, true);
        { 
          Integer k = new Integer(2);
          assertEquals(k.toString(), r.get(k));
        }
        assertEquals(expectedInvocations++, numLoaderInvocations.get());
        expectedInvocations++; expectedInvocations++;
        r.getAll(createRanges(13, 15));
        assertEquals(expectedInvocations++, numLoaderInvocations.get());
        
        getCache().getLoggerI18n().fine(addExpectedBelow);
        r.destroy(""oh3"");
        getCache().getLoggerI18n().fine(removeExpectedBelow);
        wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return !r.memoryThresholdReached.get();
          }
        };
        waitForCriterion(wc, 3000, 100, true);
        
        {
          Integer k = new Integer(3);
          assertEquals(k.toString(), r.get(k));
        }
        assertEquals(expectedInvocations++, numLoaderInvocations.get());
        expectedInvocations++; expectedInvocations++;
        r.getAll(createRanges(16, 18));
        assertEquals(expectedInvocations, numLoaderInvocations.get());

        // Do extra validation that the entry doesn't exist in the local region
        for (Integer i: createRanges(2, 2, 13, 15)) {
          if (r.containsKey(i)) {
            fail(""Expected containsKey return false for key"" + i);
          }
          if (r.getEntry(i) != null) {
            fail(""Expected getEntry to return null for key"" + i);
          }
        }
      }
    });
  }",False
"  public void testEventDelivery() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    
    final int[] ports = AvailablePortHelper.getRandomAvailableTCPPorts(2);
    final int port1 = ports[0];
    final int port2 = ports[1];
    final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
    final String regionName = ""offHeapEventDelivery"";

    startCacheServer(server1, port1, mcastPort, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    startCacheServer(server2, port2, mcastPort, 70f, 90f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);
    
    // NORMAL -> EVICTION
    setUsageAboveEvictionThreshold(server2, regionName);
    verifyListenerValue(server1, MemoryState.EVICTION, 1, true);
    verifyListenerValue(server2, MemoryState.EVICTION, 1, false);
    
    // EVICTION -> CRITICAL
    setUsageAboveCriticalThreshold(server2, regionName);
    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, false);
    verifyListenerValue(server1, MemoryState.EVICTION, 2, true);
    verifyListenerValue(server2, MemoryState.EVICTION, 2, false);
    
    // CRITICAL -> CRITICAL
    server2.invoke(new SerializableCallable() {
      private static final long serialVersionUID = 1L;

      @Override
      public Object call() throws Exception {
        getCache().getLogger().fine(MemoryThresholdsOffHeapDUnitTest.this.addExpectedExString);
        getRootRegion().getSubregion(regionName).destroy(""oh3"");
        getCache().getLogger().fine(MemoryThresholdsOffHeapDUnitTest.this.removeExpectedExString);
        return null;
      }
    });
    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, false);
    verifyListenerValue(server1, MemoryState.EVICTION, 2, true);
    verifyListenerValue(server2, MemoryState.EVICTION, 2, false);
    
    // CRITICAL -> EVICTION
    server2.invoke(new SerializableCallable() {
      private static final long serialVersionUID = 1L;

      @Override
      public Object call() throws Exception {
        getCache().getLogger().fine(MemoryThresholdsOffHeapDUnitTest.this.addExpectedBelow);
        getRootRegion().getSubregion(regionName).destroy(""oh2"");
        getCache().getLogger().fine(MemoryThresholdsOffHeapDUnitTest.this.removeExpectedBelow);
        return null;
      }
    });
    verifyListenerValue(server1, MemoryState.EVICTION, 3, true);
    verifyListenerValue(server2, MemoryState.EVICTION, 3, false);

    // EVICTION -> EVICTION
    server2.invoke(new SerializableCallable() {
      private static final long serialVersionUID = 1L;

      @Override
      public Object call() throws Exception {
        getRootRegion().getSubregion(regionName).put(""oh6"", new byte[20480]);
        return null;
      }
    });
    verifyListenerValue(server1, MemoryState.EVICTION, 3, true);
    verifyListenerValue(server2, MemoryState.EVICTION, 3, false);

    // EVICTION -> NORMAL
    server2.invoke(new SerializableCallable() {
      private static final long serialVersionUID = 1L;

      @Override
      public Object call() throws Exception {
        getRootRegion().getSubregion(regionName).destroy(""oh4"");
        return null;
      }
    });

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server1, MemoryState.EVICTION, 3, true);
    verifyListenerValue(server1, MemoryState.NORMAL, 1, true);
    
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, false);
    verifyListenerValue(server2, MemoryState.EVICTION, 3, false);
    verifyListenerValue(server2, MemoryState.NORMAL, 1, false);
  }",True
"  public void testEventDelivery() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    
    final int[] ports = AvailablePortHelper.getRandomAvailableTCPPorts(2);
    final int port1 = ports[0];
    final int port2 = ports[1];
    final String regionName = ""offHeapEventDelivery"";

    startCacheServer(server1, port1, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    startCacheServer(server2, port2, 70f, 90f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);
    
    // NORMAL -> EVICTION
    setUsageAboveEvictionThreshold(server2, regionName);
    verifyListenerValue(server1, MemoryState.EVICTION, 1, true);
    verifyListenerValue(server2, MemoryState.EVICTION, 1, false);
    
    // EVICTION -> CRITICAL
    setUsageAboveCriticalThreshold(server2, regionName);
    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, false);
    verifyListenerValue(server1, MemoryState.EVICTION, 2, true);
    verifyListenerValue(server2, MemoryState.EVICTION, 2, false);
    
    // CRITICAL -> CRITICAL
    server2.invoke(new SerializableCallable() {
      private static final long serialVersionUID = 1L;

      @Override
      public Object call() throws Exception {
        getCache().getLogger().fine(MemoryThresholdsOffHeapDUnitTest.this.addExpectedExString);
        getRootRegion().getSubregion(regionName).destroy(""oh3"");
        getCache().getLogger().fine(MemoryThresholdsOffHeapDUnitTest.this.removeExpectedExString);
        return null;
      }
    });
    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, false);
    verifyListenerValue(server1, MemoryState.EVICTION, 2, true);
    verifyListenerValue(server2, MemoryState.EVICTION, 2, false);
    
    // CRITICAL -> EVICTION
    server2.invoke(new SerializableCallable() {
      private static final long serialVersionUID = 1L;

      @Override
      public Object call() throws Exception {
        getCache().getLogger().fine(MemoryThresholdsOffHeapDUnitTest.this.addExpectedBelow);
        getRootRegion().getSubregion(regionName).destroy(""oh2"");
        getCache().getLogger().fine(MemoryThresholdsOffHeapDUnitTest.this.removeExpectedBelow);
        return null;
      }
    });
    verifyListenerValue(server1, MemoryState.EVICTION, 3, true);
    verifyListenerValue(server2, MemoryState.EVICTION, 3, false);

    // EVICTION -> EVICTION
    server2.invoke(new SerializableCallable() {
      private static final long serialVersionUID = 1L;

      @Override
      public Object call() throws Exception {
        getRootRegion().getSubregion(regionName).put(""oh6"", new byte[20480]);
        return null;
      }
    });
    verifyListenerValue(server1, MemoryState.EVICTION, 3, true);
    verifyListenerValue(server2, MemoryState.EVICTION, 3, false);

    // EVICTION -> NORMAL
    server2.invoke(new SerializableCallable() {
      private static final long serialVersionUID = 1L;

      @Override
      public Object call() throws Exception {
        getRootRegion().getSubregion(regionName).destroy(""oh4"");
        return null;
      }
    });

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server1, MemoryState.EVICTION, 3, true);
    verifyListenerValue(server1, MemoryState.NORMAL, 1, true);
    
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, false);
    verifyListenerValue(server2, MemoryState.EVICTION, 3, false);
    verifyListenerValue(server2, MemoryState.NORMAL, 1, false);
  }",False
"  private void startCacheServer(VM server, final int port, final int mcastPort,
      final float evictionThreshold, final float criticalThreshold, final String regionName,
      final boolean createPR, final boolean notifyBySubscription, final int prRedundancy) throws Exception {

    server.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        getSystem(getServerProperties(mcastPort));
        GemFireCacheImpl cache = (GemFireCacheImpl)getCache();

        InternalResourceManager irm = cache.getResourceManager();
        irm.setEvictionOffHeapPercentage(evictionThreshold);
        irm.setCriticalOffHeapPercentage(criticalThreshold);

        AttributesFactory factory = new AttributesFactory();
        if (createPR) {
          PartitionAttributesFactory paf = new PartitionAttributesFactory();
          paf.setRedundantCopies(prRedundancy);
          paf.setTotalNumBuckets(11);
          factory.setPartitionAttributes(paf.create());
          factory.setOffHeap(true);
        } else {
          factory.setScope(Scope.DISTRIBUTED_ACK);
          factory.setDataPolicy(DataPolicy.REPLICATE);
          factory.setOffHeap(true);
        }
        Region region = createRegion(regionName, factory.create());
        if (createPR) {
          assertTrue(region instanceof PartitionedRegion);
        } else {
          assertTrue(region instanceof DistributedRegion);
        }
        CacheServer cacheServer = getCache().addCacheServer();
        cacheServer.setPort(port);
        cacheServer.setNotifyBySubscription(notifyBySubscription);
        cacheServer.start();
        return null;
      }
    });
  }",True
"        irm.setEvictionOffHeapPercentage(evictionThreshold);
        irm.setCriticalOffHeapPercentage(criticalThreshold);

        AttributesFactory factory = new AttributesFactory();
        if (createPR) {
          PartitionAttributesFactory paf = new PartitionAttributesFactory();
          paf.setRedundantCopies(prRedundancy);
          paf.setTotalNumBuckets(11);
          factory.setPartitionAttributes(paf.create());
          factory.setOffHeap(true);
        } else {
          factory.setScope(Scope.DISTRIBUTED_ACK);
          factory.setDataPolicy(DataPolicy.REPLICATE);
          factory.setOffHeap(true);
        }
        Region region = createRegion(regionName, factory.create());
        if (createPR) {
          assertTrue(region instanceof PartitionedRegion);
        } else {
          assertTrue(region instanceof DistributedRegion);
        }
        CacheServer cacheServer = getCache().addCacheServer();
        cacheServer.setPort(port);
        cacheServer.setNotifyBySubscription(notifyBySubscription);
        cacheServer.start();
        return null;
      }
    });
  }
  
  private void startClient(VM client, final VM server, final int serverPort,
      final String regionName) {

    client.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        getSystem(getClientProps());
        getCache();

        PoolFactory pf = PoolManager.createFactory();",False
"  public void testPRLoadRejection() throws Exception {
    final Host host = Host.getHost(0);
    final VM accessor = host.getVM(1);
    final VM ds1 = host.getVM(2);
    final String rName = getUniqueName();
    final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();

    // Make sure the desired VMs will have a fresh DS.
    AsyncInvocation d0 = accessor.invokeAsync(DistributedTestCase.class, ""disconnectFromDS"");
    AsyncInvocation d1 = ds1.invokeAsync(DistributedTestCase.class, ""disconnectFromDS"");
    d0.join();
    assertFalse(d0.exceptionOccurred());
    d1.join();
    assertFalse(d1.exceptionOccurred());
    CacheSerializableRunnable establishConnectivity = new CacheSerializableRunnable(""establishcConnectivity"") {
      @Override
      public void run2() throws CacheException { getSystem();  }
    };
    ds1.invoke(establishConnectivity);
    accessor.invoke(establishConnectivity);

    ds1.invoke(createPR(rName, false, mcastPort));
    accessor.invoke(createPR(rName, true, mcastPort));
    
    final AtomicInteger expectedInvocations = new AtomicInteger(0);

    Integer ex = (Integer) accessor.invoke(new SerializableCallable(""Invoke loader from accessor, non-critical"") {
      public Object call() throws Exception {
        Region<Integer, String> r = getCache().getRegion(rName);
        Integer k = new Integer(1);
        Integer expectedInvocations0 = new Integer(expectedInvocations.getAndIncrement());
        assertEquals(k.toString(), r.get(k, expectedInvocations0)); // should load for new key
        assertTrue(r.containsKey(k));
        Integer expectedInvocations1 = new Integer(expectedInvocations.get());
        assertEquals(k.toString(), r.get(k, expectedInvocations1)); // no load
        assertEquals(k.toString(), r.get(k, expectedInvocations1)); // no load
        return expectedInvocations1;
      }
    });
    expectedInvocations.set(ex.intValue());

    ex = (Integer)ds1.invoke(new SerializableCallable(""Invoke loader from datastore, non-critical"") {
      public Object call() throws Exception {
        Region<Integer, String> r = getCache().getRegion(rName);
        Integer k = new Integer(2);
        Integer expectedInvocations1 = new Integer(expectedInvocations.getAndIncrement());
        assertEquals(k.toString(), r.get(k, expectedInvocations1)); // should load for new key
        assertTrue(r.containsKey(k));
        Integer expectedInvocations2 = new Integer(expectedInvocations.get());
        assertEquals(k.toString(), r.get(k, expectedInvocations2)); // no load
        assertEquals(k.toString(), r.get(k, expectedInvocations2)); // no load
        String oldVal = r.remove(k);
        assertFalse(r.containsKey(k));
        assertEquals(k.toString(), oldVal);
        return expectedInvocations2;
      }
    });
    expectedInvocations.set(ex.intValue());

    accessor.invoke(addExpectedException);
    ds1.invoke(addExpectedException);

    ex = (Integer)ds1.invoke(new SerializableCallable(""Set critical state, assert local load behavior"") {
      public Object call() throws Exception {
        final OffHeapMemoryMonitor ohmm = ((InternalResourceManager)getCache().getResourceManager()).getOffHeapMonitor();
        final PartitionedRegion pr = (PartitionedRegion) getCache().getRegion(rName);
        final RegionAdvisor advisor = pr.getRegionAdvisor();
        
        pr.put(""oh1"", new byte[838860]);
        pr.put(""oh3"", new byte[157287]);
        
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            for (final ProxyBucketRegion bucket : advisor.getProxyBucketArray()) {
              if (bucket.isBucketSick()) {
                return true;
              }
            }
            return false;
          }
        };
        waitForCriterion(wc, 3000, 100, true);
        
        final Integer k = new Integer(2); // reload with same key again and again
        final Integer expectedInvocations3 = new Integer(expectedInvocations.getAndIncrement());
        assertEquals(k.toString(), pr.get(k, expectedInvocations3)); // load
        assertFalse(pr.containsKey(k));
        Integer expectedInvocations4 = new Integer(expectedInvocations.getAndIncrement());
        assertEquals(k.toString(), pr.get(k, expectedInvocations4)); // load
        assertFalse(pr.containsKey(k));
        Integer expectedInvocations5 = new Integer(expectedInvocations.get());
        assertEquals(k.toString(), pr.get(k, expectedInvocations5)); // load
        assertFalse(pr.containsKey(k));
        return expectedInvocations5;
      }
    });
    expectedInvocations.set(ex.intValue());

    ex = (Integer)accessor.invoke(new SerializableCallable(""During critical state on datastore, assert accesor load behavior"") {
      public Object call() throws Exception {
        final Integer k = new Integer(2);  // reload with same key again and again
        Integer expectedInvocations6 = new Integer(expectedInvocations.incrementAndGet());
        Region<Integer, String> r = getCache().getRegion(rName);
        assertEquals(k.toString(), r.get(k, expectedInvocations6)); // load
        assertFalse(r.containsKey(k));
        Integer expectedInvocations7 = new Integer(expectedInvocations.incrementAndGet());
        assertEquals(k.toString(), r.get(k, expectedInvocations7)); // load
        assertFalse(r.containsKey(k));
        return expectedInvocations7;
      }
    });
    expectedInvocations.set(ex.intValue());
    
    ex = (Integer)ds1.invoke(new SerializableCallable(""Set safe state on datastore, assert local load behavior"") {
      public Object call() throws Exception {
        final PartitionedRegion r = (PartitionedRegion) getCache().getRegion(rName);
        
        r.destroy(""oh3"");
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return !r.memoryThresholdReached.get();
          }
        };
        waitForCriterion(wc, 3000, 100, true);
        
        Integer k = new Integer(3); // same key as previously used, this time is should stick
        Integer expectedInvocations8 = new Integer(expectedInvocations.incrementAndGet());
        assertEquals(k.toString(), r.get(k, expectedInvocations8)); // last load for 3
        assertTrue(r.containsKey(k));
        return expectedInvocations8;
      }
    });
    expectedInvocations.set(ex.intValue());

    accessor.invoke(new SerializableCallable(""Data store in safe state, assert load behavior, accessor sets critical state, assert load behavior"") {
      public Object call() throws Exception {
        final OffHeapMemoryMonitor ohmm = ((InternalResourceManager)getCache().getResourceManager()).getOffHeapMonitor();
        assertFalse(ohmm.getState().isCritical());
        Integer k = new Integer(4);
        Integer expectedInvocations9 = new Integer(expectedInvocations.incrementAndGet());
        final PartitionedRegion r = (PartitionedRegion) getCache().getRegion(rName);
        assertEquals(k.toString(), r.get(k, expectedInvocations9)); // load for 4
        assertTrue(r.containsKey(k));
        assertEquals(k.toString(), r.get(k, expectedInvocations9)); // no load

        // Go critical in accessor
        r.put(""oh3"", new byte[157287]);
        
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return r.memoryThresholdReached.get();
          }
        };

        k = new Integer(5);
        Integer expectedInvocations10 = new Integer(expectedInvocations.incrementAndGet());
        assertEquals(k.toString(), r.get(k, expectedInvocations10)); // load for key 5
        assertTrue(r.containsKey(k));
        assertEquals(k.toString(), r.get(k, expectedInvocations10)); // no load
        
        // Clean up critical state
        r.destroy(""oh3"");
        wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return !ohmm.getState().isCritical();
          }
        };
        return expectedInvocations10;
      }
    });

    accessor.invoke(removeExpectedException);
    ds1.invoke(removeExpectedException);
  }",True
"  public void testPRLoadRejection() throws Exception {
    final Host host = Host.getHost(0);
    final VM accessor = host.getVM(1);
    final VM ds1 = host.getVM(2);
    final String rName = getUniqueName();

    // Make sure the desired VMs will have a fresh DS.
    AsyncInvocation d0 = accessor.invokeAsync(DistributedTestCase.class, ""disconnectFromDS"");
    AsyncInvocation d1 = ds1.invokeAsync(DistributedTestCase.class, ""disconnectFromDS"");
    d0.join();
    assertFalse(d0.exceptionOccurred());
    d1.join();
    assertFalse(d1.exceptionOccurred());
    CacheSerializableRunnable establishConnectivity = new CacheSerializableRunnable(""establishcConnectivity"") {
      @Override
      public void run2() throws CacheException { getSystem();  }
    };
    ds1.invoke(establishConnectivity);
    accessor.invoke(establishConnectivity);

    ds1.invoke(createPR(rName, false));
    accessor.invoke(createPR(rName, true));
    
    final AtomicInteger expectedInvocations = new AtomicInteger(0);

    Integer ex = (Integer) accessor.invoke(new SerializableCallable(""Invoke loader from accessor, non-critical"") {
      public Object call() throws Exception {
        Region<Integer, String> r = getCache().getRegion(rName);
        Integer k = new Integer(1);
        Integer expectedInvocations0 = new Integer(expectedInvocations.getAndIncrement());
        assertEquals(k.toString(), r.get(k, expectedInvocations0)); // should load for new key
        assertTrue(r.containsKey(k));
        Integer expectedInvocations1 = new Integer(expectedInvocations.get());
        assertEquals(k.toString(), r.get(k, expectedInvocations1)); // no load
        assertEquals(k.toString(), r.get(k, expectedInvocations1)); // no load
        return expectedInvocations1;
      }
    });
    expectedInvocations.set(ex.intValue());

    ex = (Integer)ds1.invoke(new SerializableCallable(""Invoke loader from datastore, non-critical"") {
      public Object call() throws Exception {
        Region<Integer, String> r = getCache().getRegion(rName);
        Integer k = new Integer(2);
        Integer expectedInvocations1 = new Integer(expectedInvocations.getAndIncrement());
        assertEquals(k.toString(), r.get(k, expectedInvocations1)); // should load for new key
        assertTrue(r.containsKey(k));
        Integer expectedInvocations2 = new Integer(expectedInvocations.get());
        assertEquals(k.toString(), r.get(k, expectedInvocations2)); // no load
        assertEquals(k.toString(), r.get(k, expectedInvocations2)); // no load
        String oldVal = r.remove(k);
        assertFalse(r.containsKey(k));
        assertEquals(k.toString(), oldVal);
        return expectedInvocations2;
      }
    });
    expectedInvocations.set(ex.intValue());

    accessor.invoke(addExpectedException);
    ds1.invoke(addExpectedException);

    ex = (Integer)ds1.invoke(new SerializableCallable(""Set critical state, assert local load behavior"") {
      public Object call() throws Exception {
        final OffHeapMemoryMonitor ohmm = ((InternalResourceManager)getCache().getResourceManager()).getOffHeapMonitor();
        final PartitionedRegion pr = (PartitionedRegion) getCache().getRegion(rName);
        final RegionAdvisor advisor = pr.getRegionAdvisor();
        
        pr.put(""oh1"", new byte[838860]);
        pr.put(""oh3"", new byte[157287]);
        
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            for (final ProxyBucketRegion bucket : advisor.getProxyBucketArray()) {
              if (bucket.isBucketSick()) {
                return true;
              }
            }
            return false;
          }
        };
        waitForCriterion(wc, 3000, 100, true);
        
        final Integer k = new Integer(2); // reload with same key again and again
        final Integer expectedInvocations3 = new Integer(expectedInvocations.getAndIncrement());
        assertEquals(k.toString(), pr.get(k, expectedInvocations3)); // load
        assertFalse(pr.containsKey(k));
        Integer expectedInvocations4 = new Integer(expectedInvocations.getAndIncrement());
        assertEquals(k.toString(), pr.get(k, expectedInvocations4)); // load
        assertFalse(pr.containsKey(k));
        Integer expectedInvocations5 = new Integer(expectedInvocations.get());
        assertEquals(k.toString(), pr.get(k, expectedInvocations5)); // load
        assertFalse(pr.containsKey(k));
        return expectedInvocations5;
      }
    });
    expectedInvocations.set(ex.intValue());

    ex = (Integer)accessor.invoke(new SerializableCallable(""During critical state on datastore, assert accesor load behavior"") {
      public Object call() throws Exception {
        final Integer k = new Integer(2);  // reload with same key again and again
        Integer expectedInvocations6 = new Integer(expectedInvocations.incrementAndGet());
        Region<Integer, String> r = getCache().getRegion(rName);
        assertEquals(k.toString(), r.get(k, expectedInvocations6)); // load
        assertFalse(r.containsKey(k));
        Integer expectedInvocations7 = new Integer(expectedInvocations.incrementAndGet());
        assertEquals(k.toString(), r.get(k, expectedInvocations7)); // load
        assertFalse(r.containsKey(k));
        return expectedInvocations7;
      }
    });
    expectedInvocations.set(ex.intValue());
    
    ex = (Integer)ds1.invoke(new SerializableCallable(""Set safe state on datastore, assert local load behavior"") {
      public Object call() throws Exception {
        final PartitionedRegion r = (PartitionedRegion) getCache().getRegion(rName);
        
        r.destroy(""oh3"");
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return !r.memoryThresholdReached.get();
          }
        };
        waitForCriterion(wc, 3000, 100, true);
        
        Integer k = new Integer(3); // same key as previously used, this time is should stick
        Integer expectedInvocations8 = new Integer(expectedInvocations.incrementAndGet());
        assertEquals(k.toString(), r.get(k, expectedInvocations8)); // last load for 3
        assertTrue(r.containsKey(k));
        return expectedInvocations8;
      }
    });
    expectedInvocations.set(ex.intValue());

    accessor.invoke(new SerializableCallable(""Data store in safe state, assert load behavior, accessor sets critical state, assert load behavior"") {
      public Object call() throws Exception {
        final OffHeapMemoryMonitor ohmm = ((InternalResourceManager)getCache().getResourceManager()).getOffHeapMonitor();
        assertFalse(ohmm.getState().isCritical());
        Integer k = new Integer(4);
        Integer expectedInvocations9 = new Integer(expectedInvocations.incrementAndGet());
        final PartitionedRegion r = (PartitionedRegion) getCache().getRegion(rName);
        assertEquals(k.toString(), r.get(k, expectedInvocations9)); // load for 4
        assertTrue(r.containsKey(k));
        assertEquals(k.toString(), r.get(k, expectedInvocations9)); // no load

        // Go critical in accessor
        r.put(""oh3"", new byte[157287]);
        
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return r.memoryThresholdReached.get();
          }
        };

        k = new Integer(5);
        Integer expectedInvocations10 = new Integer(expectedInvocations.incrementAndGet());
        assertEquals(k.toString(), r.get(k, expectedInvocations10)); // load for key 5
        assertTrue(r.containsKey(k));
        assertEquals(k.toString(), r.get(k, expectedInvocations10)); // no load
        
        // Clean up critical state
        r.destroy(""oh3"");
        wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return !ohmm.getState().isCritical();
          }
        };
        return expectedInvocations10;
      }
    });

    accessor.invoke(removeExpectedException);
    ds1.invoke(removeExpectedException);
  }",False
"  public void testDisabledThresholds() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    
    final int[] ports = AvailablePortHelper.getRandomAvailableTCPPorts(2);
    final int port1 = ports[0];
    final int port2 = ports[1];
    final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
    final String regionName = ""offHeapDisabledThresholds"";

    startCacheServer(server1, port1, mcastPort, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    startCacheServer(server2, port2, mcastPort, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);
    
    setUsageAboveEvictionThreshold(server1, regionName);
    verifyListenerValue(server1, MemoryState.EVICTION, 0, false);
    verifyListenerValue(server2, MemoryState.EVICTION, 0, true);

    setThresholds(server1, 70f, 0f);
    verifyListenerValue(server1, MemoryState.EVICTION, 1, false);
    verifyListenerValue(server2, MemoryState.EVICTION, 1, true);

    setUsageAboveCriticalThreshold(server1, regionName);
    verifyListenerValue(server1, MemoryState.CRITICAL, 0, false);
    verifyListenerValue(server2, MemoryState.CRITICAL, 0, true);

    setThresholds(server1, 0f, 0f);
    verifyListenerValue(server1, MemoryState.EVICTION_DISABLED, 1, false);
    verifyListenerValue(server2, MemoryState.EVICTION_DISABLED, 1, true);

    setThresholds(server1, 0f, 90f);
    verifyListenerValue(server1, MemoryState.CRITICAL, 1, false);
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, true);

    //verify that stats on server2 are not changed by events on server1
    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        InternalResourceManager irm = ((GemFireCacheImpl)getCache()).getResourceManager();
        assertEquals(0, irm.getStats().getOffHeapEvictionStartEvents());
        assertEquals(0, irm.getStats().getOffHeapCriticalEvents());
        assertEquals(0, irm.getStats().getOffHeapCriticalThreshold());
        assertEquals(0, irm.getStats().getOffHeapEvictionThreshold());
        return null;
      }
    });
  }",True
"  public void testDisabledThresholds() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    
    final int[] ports = AvailablePortHelper.getRandomAvailableTCPPorts(2);
    final int port1 = ports[0];
    final int port2 = ports[1];
    final String regionName = ""offHeapDisabledThresholds"";

    startCacheServer(server1, port1, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    startCacheServer(server2, port2, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);
    
    setUsageAboveEvictionThreshold(server1, regionName);
    verifyListenerValue(server1, MemoryState.EVICTION, 0, false);
    verifyListenerValue(server2, MemoryState.EVICTION, 0, true);

    setThresholds(server1, 70f, 0f);
    verifyListenerValue(server1, MemoryState.EVICTION, 1, false);
    verifyListenerValue(server2, MemoryState.EVICTION, 1, true);

    setUsageAboveCriticalThreshold(server1, regionName);
    verifyListenerValue(server1, MemoryState.CRITICAL, 0, false);
    verifyListenerValue(server2, MemoryState.CRITICAL, 0, true);

    setThresholds(server1, 0f, 0f);
    verifyListenerValue(server1, MemoryState.EVICTION_DISABLED, 1, false);
    verifyListenerValue(server2, MemoryState.EVICTION_DISABLED, 1, true);

    setThresholds(server1, 0f, 90f);
    verifyListenerValue(server1, MemoryState.CRITICAL, 1, false);
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, true);

    //verify that stats on server2 are not changed by events on server1
    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        InternalResourceManager irm = ((GemFireCacheImpl)getCache()).getResourceManager();
        assertEquals(0, irm.getStats().getOffHeapEvictionStartEvents());
        assertEquals(0, irm.getStats().getOffHeapCriticalEvents());
        assertEquals(0, irm.getStats().getOffHeapCriticalThreshold());
        assertEquals(0, irm.getStats().getOffHeapEvictionThreshold());
        return null;
      }
    });
  }",False
"  public void testCleanAdvisorClose() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM server3 = host.getVM(2);

    final int[] ports = AvailablePortHelper.getRandomAvailableTCPPorts(3);
    final int port1 = ports[0];
    final int port2 = ports[1];
    final int port3 = ports[2];
    final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
    final String regionName = ""testEventOrger"";

    startCacheServer(server1, port1, mcastPort, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    startCacheServer(server2, port2, mcastPort, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    verifyProfiles(server1, 1);
    verifyProfiles(server2, 1);

    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        closeCache();
        return null;
      }
    });

    verifyProfiles(server1, 0);

    startCacheServer(server3, port3, mcastPort, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    verifyProfiles(server1, 1);
    verifyProfiles(server3, 1);
  }",True
"  public void testCleanAdvisorClose() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM server3 = host.getVM(2);

    final int[] ports = AvailablePortHelper.getRandomAvailableTCPPorts(3);
    final int port1 = ports[0];
    final int port2 = ports[1];
    final int port3 = ports[2];
    final String regionName = ""testEventOrger"";

    startCacheServer(server1, port1, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    startCacheServer(server2, port2, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    verifyProfiles(server1, 1);
    verifyProfiles(server2, 1);

    server2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        closeCache();
        return null;
      }
    });

    verifyProfiles(server1, 0);

    startCacheServer(server3, port3, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    verifyProfiles(server1, 1);
    verifyProfiles(server3, 1);
  }",False
"  private void prRemotePutRejection(boolean cacheClose, boolean localDestroy, final boolean useTx) throws Exception {
    final Host host = Host.getHost(0);
    final VM accessor = host.getVM(0);
    final VM servers[] = new VM[3];
    servers[0] = host.getVM(1);
    servers[1] = host.getVM(2);
    servers[2] = host.getVM(3);

    final int[] ports = AvailablePortHelper.getRandomAvailableTCPPorts(3);
    final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
    final String regionName = ""offHeapPRRemotePutRejection"";
    final int redundancy = 1;

    startCacheServer(servers[0], ports[0], mcastPort, 0f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    startCacheServer(servers[1], ports[1], mcastPort, 0f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    startCacheServer(servers[2], ports[2], mcastPort, 0f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        getSystem(getServerProperties(mcastPort));
        getCache();
        AttributesFactory factory = new AttributesFactory();        
        PartitionAttributesFactory paf = new PartitionAttributesFactory();
        paf.setRedundantCopies(redundancy);
        paf.setLocalMaxMemory(0);
        paf.setTotalNumBuckets(11);
        factory.setPartitionAttributes(paf.create());
        factory.setOffHeap(true);
        createRegion(regionName, factory.create());
        return null;
      }
    });
    
    doPuts(accessor, regionName, false, false);
    final Range r1 = Range.DEFAULT;
    doPutAlls(accessor, regionName, false, false, r1);

    servers[0].invoke(addExpectedException);
    servers[1].invoke(addExpectedException);
    servers[2].invoke(addExpectedException);
    setUsageAboveCriticalThreshold(servers[0], regionName);
    
    final Set<InternalDistributedMember> criticalMembers = (Set) servers[0].invoke(new SerializableCallable() {
      public Object call() throws Exception {
        final PartitionedRegion pr = (PartitionedRegion)getRootRegion().getSubregion(regionName);
        final int hashKey = PartitionedRegionHelper.getHashKey(pr, null, ""oh5"", null, null);
        return pr.getRegionAdvisor().getBucketOwners(hashKey);
      }
    });
    
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {     
        final PartitionedRegion pr = (PartitionedRegion)getRootRegion().getSubregion(regionName);
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""remote bucket not marked sick"";
          }
          public boolean done() {
            boolean keyFoundOnSickMember = false;
            boolean caughtException = false;
            for (int i=0; i<20; i++) {
              Integer key = Integer.valueOf(i);
              int hKey = PartitionedRegionHelper.getHashKey(pr, null, key, null, null);
              Set<InternalDistributedMember> owners = pr.getRegionAdvisor().getBucketOwners(hKey);
              final boolean hasCriticalOwners = owners.removeAll(criticalMembers);
              if (hasCriticalOwners) {
                keyFoundOnSickMember = true;
                try {
                  if (useTx) getCache().getCacheTransactionManager().begin();
                  pr.getCache().getLogger().fine(""SWAP:putting in tx:""+useTx);
                  pr.put(key, ""value"");
                  if (useTx) getCache().getCacheTransactionManager().commit();
                } catch (LowMemoryException ex) {
                  caughtException = true;
                  if (useTx) getCache().getCacheTransactionManager().rollback();
                }
              } else {
                //puts on healthy member should continue
                pr.put(key, ""value"");
              }
            }
            return keyFoundOnSickMember && caughtException;
          }
        };
        waitForCriterion(wc, 10000, 10, true);
        return null;
      }
    });

    {
      Range r2 = new Range(r1, r1.width()+1);
      doPutAlls(accessor, regionName, false, true, r2);
    }
    
    // Find all VMs that have a critical region
    SerializableCallable getMyId = new SerializableCallable() {
      public Object call() throws Exception {        
        return ((GemFireCacheImpl)getCache()).getMyId();
      }
    };
    final Set<VM> criticalServers = new HashSet<VM>();
    for (final VM server : servers) {
      DistributedMember member = (DistributedMember) server.invoke(getMyId);
      if (criticalMembers.contains(member)) {
        criticalServers.add(server);
      }
    }
    
    if (localDestroy) {
    //local destroy the region on sick members
      for (final VM vm : criticalServers) {
        vm.invoke(new SerializableCallable(""local destroy sick member"") {
          public Object call() throws Exception {
            Region r = getRootRegion().getSubregion(regionName);
            getLogWriter().info(""PRLocalDestroy"");
            r.localDestroyRegion();
            return null;
          }
        });
      }
    } else if (cacheClose) {
      // close cache on sick members
      for (final VM vm : criticalServers) {
        vm.invoke(new SerializableCallable(""close cache sick member"") {
          public Object call() throws Exception {
            getCache().close();
            return null;
          }
        });
      }
    } else {
      setUsageBelowEviction(servers[0], regionName);
      servers[0].invoke(removeExpectedException);
      servers[1].invoke(removeExpectedException);
      servers[2].invoke(removeExpectedException);
    }
    
    //do put all in a loop to allow distribution of message
    accessor.invoke(new SerializableCallable(""Put in a loop"") {
      public Object call() throws Exception {
        final Region r = getRootRegion().getSubregion(regionName);
        WaitCriterion wc = new WaitCriterion() {
          public String description() {            
            return ""pr should have gone un-critical"";
          }
          public boolean done() {
            boolean done = true;
            for (int i=0; i<20; i++) {
              try {
                r.put(i,""value"");
              } catch (LowMemoryException e) {
                //expected
                done = false;
              }
            }            
            return done;
          }
        };
        waitForCriterion(wc, 10000, 10, true);
        return null;
      }
    });
    doPutAlls(accessor, regionName, false, false, r1);
  }",True
"  private void prRemotePutRejection(boolean cacheClose, boolean localDestroy, final boolean useTx) throws Exception {
    final Host host = Host.getHost(0);
    final VM accessor = host.getVM(0);
    final VM servers[] = new VM[3];
    servers[0] = host.getVM(1);
    servers[1] = host.getVM(2);
    servers[2] = host.getVM(3);

    final int[] ports = AvailablePortHelper.getRandomAvailableTCPPorts(3);
    final String regionName = ""offHeapPRRemotePutRejection"";
    final int redundancy = 1;

    startCacheServer(servers[0], ports[0], 0f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    startCacheServer(servers[1], ports[1], 0f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    startCacheServer(servers[2], ports[2], 0f, 90f,
        regionName, true/*createPR*/, false/*notifyBySubscription*/, redundancy);
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        getSystem(getServerProperties());
        getCache();
        AttributesFactory factory = new AttributesFactory();        
        PartitionAttributesFactory paf = new PartitionAttributesFactory();
        paf.setRedundantCopies(redundancy);
        paf.setLocalMaxMemory(0);
        paf.setTotalNumBuckets(11);
        factory.setPartitionAttributes(paf.create());
        factory.setOffHeap(true);
        createRegion(regionName, factory.create());
        return null;
      }
    });
    
    doPuts(accessor, regionName, false, false);
    final Range r1 = Range.DEFAULT;
    doPutAlls(accessor, regionName, false, false, r1);

    servers[0].invoke(addExpectedException);
    servers[1].invoke(addExpectedException);
    servers[2].invoke(addExpectedException);
    setUsageAboveCriticalThreshold(servers[0], regionName);
    
    final Set<InternalDistributedMember> criticalMembers = (Set) servers[0].invoke(new SerializableCallable() {
      public Object call() throws Exception {
        final PartitionedRegion pr = (PartitionedRegion)getRootRegion().getSubregion(regionName);
        final int hashKey = PartitionedRegionHelper.getHashKey(pr, null, ""oh5"", null, null);
        return pr.getRegionAdvisor().getBucketOwners(hashKey);
      }
    });
    
    accessor.invoke(new SerializableCallable() {
      public Object call() throws Exception {     
        final PartitionedRegion pr = (PartitionedRegion)getRootRegion().getSubregion(regionName);
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""remote bucket not marked sick"";
          }
          public boolean done() {
            boolean keyFoundOnSickMember = false;
            boolean caughtException = false;
            for (int i=0; i<20; i++) {
              Integer key = Integer.valueOf(i);
              int hKey = PartitionedRegionHelper.getHashKey(pr, null, key, null, null);
              Set<InternalDistributedMember> owners = pr.getRegionAdvisor().getBucketOwners(hKey);
              final boolean hasCriticalOwners = owners.removeAll(criticalMembers);
              if (hasCriticalOwners) {
                keyFoundOnSickMember = true;
                try {
                  if (useTx) getCache().getCacheTransactionManager().begin();
                  pr.getCache().getLogger().fine(""SWAP:putting in tx:""+useTx);
                  pr.put(key, ""value"");
                  if (useTx) getCache().getCacheTransactionManager().commit();
                } catch (LowMemoryException ex) {
                  caughtException = true;
                  if (useTx) getCache().getCacheTransactionManager().rollback();
                }
              } else {
                //puts on healthy member should continue
                pr.put(key, ""value"");
              }
            }
            return keyFoundOnSickMember && caughtException;
          }
        };
        waitForCriterion(wc, 10000, 10, true);
        return null;
      }
    });

    {
      Range r2 = new Range(r1, r1.width()+1);
      doPutAlls(accessor, regionName, false, true, r2);
    }
    
    // Find all VMs that have a critical region
    SerializableCallable getMyId = new SerializableCallable() {
      public Object call() throws Exception {        
        return ((GemFireCacheImpl)getCache()).getMyId();
      }
    };
    final Set<VM> criticalServers = new HashSet<VM>();
    for (final VM server : servers) {
      DistributedMember member = (DistributedMember) server.invoke(getMyId);
      if (criticalMembers.contains(member)) {
        criticalServers.add(server);
      }
    }
    
    if (localDestroy) {
    //local destroy the region on sick members
      for (final VM vm : criticalServers) {
        vm.invoke(new SerializableCallable(""local destroy sick member"") {
          public Object call() throws Exception {
            Region r = getRootRegion().getSubregion(regionName);
            getLogWriter().info(""PRLocalDestroy"");
            r.localDestroyRegion();
            return null;
          }
        });
      }
    } else if (cacheClose) {
      // close cache on sick members
      for (final VM vm : criticalServers) {
        vm.invoke(new SerializableCallable(""close cache sick member"") {
          public Object call() throws Exception {
            getCache().close();
            return null;
          }
        });
      }
    } else {
      setUsageBelowEviction(servers[0], regionName);
      servers[0].invoke(removeExpectedException);
      servers[1].invoke(removeExpectedException);
      servers[2].invoke(removeExpectedException);
    }
    
    //do put all in a loop to allow distribution of message
    accessor.invoke(new SerializableCallable(""Put in a loop"") {
      public Object call() throws Exception {
        final Region r = getRootRegion().getSubregion(regionName);
        WaitCriterion wc = new WaitCriterion() {
          public String description() {            
            return ""pr should have gone un-critical"";
          }
          public boolean done() {
            boolean done = true;
            for (int i=0; i<20; i++) {
              try {
                r.put(i,""value"");
              } catch (LowMemoryException e) {
                //expected
                done = false;
              }
            }            
            return done;
          }
        };
        waitForCriterion(wc, 10000, 10, true);
        return null;
      }
    });
    doPutAlls(accessor, regionName, false, false, r1);
  }",False
"  private void doClientServerTest(final String regionName, boolean createPR)
      throws Exception {
    //create region on the server
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);

    final int port = AvailablePortHelper.getRandomAvailableTCPPort();
    final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
    startCacheServer(server, port, mcastPort, 0f, 90f,
        regionName, createPR, false, 0);
    startClient(client, server, port, regionName);
    doPuts(client, regionName, false/*catchServerException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(client, regionName, false/*catchServerException*/,
        false/*catchLowMemoryException*/, Range.DEFAULT);

    //make the region sick in the server
    server.invoke(new SerializableRunnable() {
      public void run() {
        InternalResourceManager irm = ((GemFireCacheImpl)getCache()).getResourceManager();
        final OffHeapMemoryMonitor ohm = irm.getOffHeapMonitor();
        assertTrue(ohm.getState().isNormal());
        getCache().getLoggerI18n().fine(addExpectedExString);
        final LocalRegion r = (LocalRegion) getRootRegion().getSubregion(regionName);
        final Object key = 1;
        r.put(key, new byte[943720]);
        WaitCriterion wc;
        if (r instanceof PartitionedRegion) {
          final PartitionedRegion pr = (PartitionedRegion) r;
          final int bucketId = PartitionedRegionHelper.getHashKey(pr, null, key, null, null);
          wc = new WaitCriterion() {
            @Override
            public String description() {
              return ""Expected to go critical: isCritical="" + ohm.getState().isCritical();
            }

            @Override
            public boolean done() {
              if (!ohm.getState().isCritical()) return false;
              // Only done once the bucket has been marked sick
              try {
                pr.getRegionAdvisor().checkIfBucketSick(bucketId, key);
                return false;
              } catch (LowMemoryException ignore) {
                return true;
              }
            }
          };
        } else {
          wc = new WaitCriterion() {
            @Override
            public String description() {
              return ""Expected to go critical: isCritical="" + ohm.getState().isCritical() + "" memoryThresholdReached="" + r.memoryThresholdReached.get();
            }

            @Override
            public boolean done() {
              return ohm.getState().isCritical() && r.memoryThresholdReached.get();
            }
          };
        }
        waitForCriterion(wc, 5000, 100, true);
        getCache().getLoggerI18n().fine(removeExpectedExString);
        return;
      }
    });

    //make sure client puts are rejected
    doPuts(client, regionName, true/*catchServerException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(client, regionName, true/*catchServerException*/,
        false/*catchLowMemoryException*/, new Range(Range.DEFAULT, Range.DEFAULT.width()+1));
    
    //make the region healthy in the server
    server.invoke(new SerializableRunnable() {
      public void run() {
        InternalResourceManager irm = ((GemFireCacheImpl)getCache()).getResourceManager();
        final OffHeapMemoryMonitor ohm = irm.getOffHeapMonitor();
        assertTrue(ohm.getState().isCritical());
        getCache().getLogger().fine(MemoryThresholdsOffHeapDUnitTest.this.addExpectedBelow);
        getRootRegion().getSubregion(regionName).destroy(1);
        WaitCriterion wc = new WaitCriterion() {
          @Override
          public String description() {
            return ""Expected to go normal"";
          }

          @Override
          public boolean done() {
            return ohm.getState().isNormal();
          }
        };
        waitForCriterion(wc, 5000, 100, true);
        getCache().getLogger().fine(MemoryThresholdsOffHeapDUnitTest.this.removeExpectedBelow);
        return;
      }
    });
  }",True
"  private void doClientServerTest(final String regionName, boolean createPR)
      throws Exception {
    //create region on the server
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);

    final int port = AvailablePortHelper.getRandomAvailableTCPPort();
    startCacheServer(server, port, 0f, 90f,
        regionName, createPR, false, 0);
    startClient(client, server, port, regionName);
    doPuts(client, regionName, false/*catchServerException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(client, regionName, false/*catchServerException*/,
        false/*catchLowMemoryException*/, Range.DEFAULT);

    //make the region sick in the server
    server.invoke(new SerializableRunnable() {
      public void run() {
        InternalResourceManager irm = ((GemFireCacheImpl)getCache()).getResourceManager();
        final OffHeapMemoryMonitor ohm = irm.getOffHeapMonitor();
        assertTrue(ohm.getState().isNormal());
        getCache().getLoggerI18n().fine(addExpectedExString);
        final LocalRegion r = (LocalRegion) getRootRegion().getSubregion(regionName);
        final Object key = 1;
        r.put(key, new byte[943720]);
        WaitCriterion wc;
        if (r instanceof PartitionedRegion) {
          final PartitionedRegion pr = (PartitionedRegion) r;
          final int bucketId = PartitionedRegionHelper.getHashKey(pr, null, key, null, null);
          wc = new WaitCriterion() {
            @Override
            public String description() {
              return ""Expected to go critical: isCritical="" + ohm.getState().isCritical();
            }

            @Override
            public boolean done() {
              if (!ohm.getState().isCritical()) return false;
              // Only done once the bucket has been marked sick
              try {
                pr.getRegionAdvisor().checkIfBucketSick(bucketId, key);
                return false;
              } catch (LowMemoryException ignore) {
                return true;
              }
            }
          };
        } else {
          wc = new WaitCriterion() {
            @Override
            public String description() {
              return ""Expected to go critical: isCritical="" + ohm.getState().isCritical() + "" memoryThresholdReached="" + r.memoryThresholdReached.get();
            }

            @Override
            public boolean done() {
              return ohm.getState().isCritical() && r.memoryThresholdReached.get();
            }
          };
        }
        waitForCriterion(wc, 5000, 100, true);
        getCache().getLoggerI18n().fine(removeExpectedExString);
        return;
      }
    });

    //make sure client puts are rejected
    doPuts(client, regionName, true/*catchServerException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(client, regionName, true/*catchServerException*/,
        false/*catchLowMemoryException*/, new Range(Range.DEFAULT, Range.DEFAULT.width()+1));
    
    //make the region healthy in the server
    server.invoke(new SerializableRunnable() {
      public void run() {
        InternalResourceManager irm = ((GemFireCacheImpl)getCache()).getResourceManager();
        final OffHeapMemoryMonitor ohm = irm.getOffHeapMonitor();
        assertTrue(ohm.getState().isCritical());
        getCache().getLogger().fine(MemoryThresholdsOffHeapDUnitTest.this.addExpectedBelow);
        getRootRegion().getSubregion(regionName).destroy(1);
        WaitCriterion wc = new WaitCriterion() {
          @Override
          public String description() {
            return ""Expected to go normal"";
          }

          @Override
          public boolean done() {
            return ohm.getState().isNormal();
          }
        };
        waitForCriterion(wc, 5000, 100, true);
        getCache().getLogger().fine(MemoryThresholdsOffHeapDUnitTest.this.removeExpectedBelow);
        return;
      }
    });
  }",False
"  public void testDRLoadRejection() throws Exception {
    final Host host = Host.getHost(0);
    final VM replicate1 = host.getVM(1);
    final VM replicate2 = host.getVM(2);
    final String rName = getUniqueName();
    final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
    
    // Make sure the desired VMs will have a fresh DS.
    AsyncInvocation d1 = replicate1.invokeAsync(DistributedTestCase.class, ""disconnectFromDS"");
    AsyncInvocation d2 = replicate2.invokeAsync(DistributedTestCase.class, ""disconnectFromDS"");
    d1.join();
    assertFalse(d1.exceptionOccurred());
    d2.join();
    assertFalse(d2.exceptionOccurred());
    CacheSerializableRunnable establishConnectivity = new CacheSerializableRunnable(""establishcConnectivity"") {
      @SuppressWarnings(""synthetic-access"")
      @Override
      public void run2() throws CacheException {
        getSystem(getServerProperties(mcastPort));
      }
    };
    replicate1.invoke(establishConnectivity);
    replicate2.invoke(establishConnectivity);
    
    CacheSerializableRunnable createRegion = new CacheSerializableRunnable(""create DistributedRegion"") {
      @Override
      public void run2() throws CacheException {
        // Assert some level of connectivity
        InternalDistributedSystem ds = getSystem(getServerProperties(mcastPort));
        assertTrue(ds.getDistributionManager().getNormalDistributionManagerIds().size() >= 1);

        InternalResourceManager irm = (InternalResourceManager)getCache().getResourceManager();
        irm.setCriticalOffHeapPercentage(90f);
        AttributesFactory af = new AttributesFactory();
        af.setScope(Scope.DISTRIBUTED_ACK);
        af.setDataPolicy(DataPolicy.REPLICATE);
        af.setOffHeap(true);
        Region region = getCache().createRegion(rName, af.create());
      }
    };
    replicate1.invoke(createRegion);
    replicate2.invoke(createRegion);
    
    replicate1.invoke(addExpectedException);
    replicate2.invoke(addExpectedException);
    
    final Integer expected = (Integer)replicate1.invoke(new SerializableCallable(""test Local DistributedRegion Load"") {
      public Object call() throws Exception {
        final DistributedRegion r = (DistributedRegion) getCache().getRegion(rName);
        AttributesMutator<Integer, String> am = r.getAttributesMutator();
        am.setCacheLoader(new CacheLoader<Integer, String>() {
          final AtomicInteger numLoaderInvocations = new AtomicInteger(0);
          public String load(LoaderHelper<Integer, String> helper) throws CacheLoaderException {
            Integer expectedInvocations = (Integer)helper.getArgument();
            final int actualInvocations = this.numLoaderInvocations.getAndIncrement();
            if (expectedInvocations.intValue() != actualInvocations) {
              throw new CacheLoaderException(""Expected "" + expectedInvocations 
                  + "" invocations, actual is "" + actualInvocations);
            }
            return helper.getKey().toString();
          }
          public void close() {}
        });

        int expectedInvocations = 0;
        final OffHeapMemoryMonitor ohmm = ((InternalResourceManager)getCache().getResourceManager()).getOffHeapMonitor();
        assertFalse(ohmm.getState().isCritical());
        {
          Integer k = new Integer(1);
          assertEquals(k.toString(), r.get(k, new Integer(expectedInvocations++)));
        }

        r.put(""oh1"", new byte[838860]);
        r.put(""oh3"", new byte[157287]);
        
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return r.memoryThresholdReached.get();
          }
        };
        waitForCriterion(wc, 3000, 100, true);
        {
          Integer k = new Integer(2); 
          assertEquals(k.toString(), r.get(k, new Integer(expectedInvocations++)));
        }
        
        r.destroy(""oh3"");
        wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return !r.memoryThresholdReached.get();
          }
        };
        waitForCriterion(wc, 3000, 100, true);
        {
          Integer k = new Integer(3);
          assertEquals(k.toString(), r.get(k, new Integer(expectedInvocations++)));
        }
        return new Integer(expectedInvocations);
      }
    });

    final CacheSerializableRunnable validateData1 = new CacheSerializableRunnable(""Validate data 1"") {
      @Override
      public void run2() throws CacheException {
        Region r = getCache().getRegion(rName);
        Integer i1 = new Integer(1);
        assertTrue(r.containsKey(i1));
        assertNotNull(r.getEntry(i1));
        Integer i2 = new Integer(2);
        assertFalse(r.containsKey(i2));
        assertNull(r.getEntry(i2));
        Integer i3 = new Integer(3);
        assertTrue(r.containsKey(i3));
        assertNotNull(r.getEntry(i3));
      }
    };
    replicate1.invoke(validateData1);
    replicate2.invoke(validateData1);
    
    replicate2.invoke(new SerializableCallable(""test DistributedRegion netLoad"") {
      public Object call() throws Exception {
        final DistributedRegion r = (DistributedRegion) getCache().getRegion(rName);
        final OffHeapMemoryMonitor ohmm = ((InternalResourceManager)getCache().getResourceManager()).getOffHeapMonitor();
        assertFalse(ohmm.getState().isCritical());
        
        int expectedInvocations = expected.intValue();
        {
          Integer k = new Integer(4);
          assertEquals(k.toString(), r.get(k, new Integer(expectedInvocations++)));
        }
        
        // Place in a critical state for the next test
        r.put(""oh3"", new byte[157287]);
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return r.memoryThresholdReached.get();
          }
        };
        waitForCriterion(wc, 3000, 100, true);
        {
          Integer k = new Integer(5);
          assertEquals(k.toString(), r.get(k, new Integer(expectedInvocations++)));
        }

        r.destroy(""oh3"");
        wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return !r.memoryThresholdReached.get();
          }
        };
        waitForCriterion(wc, 3000, 100, true);
        {
          Integer k = new Integer(6);
          assertEquals(k.toString(), r.get(k, new Integer(expectedInvocations++)));
        }
        return new Integer(expectedInvocations);
      }
    });
    
    replicate1.invoke(removeExpectedException);
    replicate2.invoke(removeExpectedException);
    
    final CacheSerializableRunnable validateData2 = new CacheSerializableRunnable(""Validate data 2"") {
      @Override
      public void run2() throws CacheException {
        Region<Integer, String> r = getCache().getRegion(rName);
        Integer i4 = new Integer(4);
        assertTrue(r.containsKey(i4));
        assertNotNull(r.getEntry(i4));
        Integer i5 = new Integer(5);
        assertFalse(r.containsKey(i5));
        assertNull(r.getEntry(i5));
        Integer i6 = new Integer(6);
        assertTrue(r.containsKey(i6));
        assertNotNull(r.getEntry(i6));
      }
    };
    replicate1.invoke(validateData2);
    replicate2.invoke(validateData2);
  }",True
"  public void testDRLoadRejection() throws Exception {
    final Host host = Host.getHost(0);
    final VM replicate1 = host.getVM(1);
    final VM replicate2 = host.getVM(2);
    final String rName = getUniqueName();
    
    // Make sure the desired VMs will have a fresh DS.
    AsyncInvocation d1 = replicate1.invokeAsync(DistributedTestCase.class, ""disconnectFromDS"");
    AsyncInvocation d2 = replicate2.invokeAsync(DistributedTestCase.class, ""disconnectFromDS"");
    d1.join();
    assertFalse(d1.exceptionOccurred());
    d2.join();
    assertFalse(d2.exceptionOccurred());
    CacheSerializableRunnable establishConnectivity = new CacheSerializableRunnable(""establishcConnectivity"") {
      @SuppressWarnings(""synthetic-access"")
      @Override
      public void run2() throws CacheException {
        getSystem(getServerProperties());
      }
    };
    replicate1.invoke(establishConnectivity);
    replicate2.invoke(establishConnectivity);
    
    CacheSerializableRunnable createRegion = new CacheSerializableRunnable(""create DistributedRegion"") {
      @Override
      public void run2() throws CacheException {
        // Assert some level of connectivity
        InternalDistributedSystem ds = getSystem(getServerProperties());
        assertTrue(ds.getDistributionManager().getNormalDistributionManagerIds().size() >= 1);

        InternalResourceManager irm = (InternalResourceManager)getCache().getResourceManager();
        irm.setCriticalOffHeapPercentage(90f);
        AttributesFactory af = new AttributesFactory();
        af.setScope(Scope.DISTRIBUTED_ACK);
        af.setDataPolicy(DataPolicy.REPLICATE);
        af.setOffHeap(true);
        Region region = getCache().createRegion(rName, af.create());
      }
    };
    replicate1.invoke(createRegion);
    replicate2.invoke(createRegion);
    
    replicate1.invoke(addExpectedException);
    replicate2.invoke(addExpectedException);
    
    final Integer expected = (Integer)replicate1.invoke(new SerializableCallable(""test Local DistributedRegion Load"") {
      public Object call() throws Exception {
        final DistributedRegion r = (DistributedRegion) getCache().getRegion(rName);
        AttributesMutator<Integer, String> am = r.getAttributesMutator();
        am.setCacheLoader(new CacheLoader<Integer, String>() {
          final AtomicInteger numLoaderInvocations = new AtomicInteger(0);
          public String load(LoaderHelper<Integer, String> helper) throws CacheLoaderException {
            Integer expectedInvocations = (Integer)helper.getArgument();
            final int actualInvocations = this.numLoaderInvocations.getAndIncrement();
            if (expectedInvocations.intValue() != actualInvocations) {
              throw new CacheLoaderException(""Expected "" + expectedInvocations 
                  + "" invocations, actual is "" + actualInvocations);
            }
            return helper.getKey().toString();
          }
          public void close() {}
        });

        int expectedInvocations = 0;
        final OffHeapMemoryMonitor ohmm = ((InternalResourceManager)getCache().getResourceManager()).getOffHeapMonitor();
        assertFalse(ohmm.getState().isCritical());
        {
          Integer k = new Integer(1);
          assertEquals(k.toString(), r.get(k, new Integer(expectedInvocations++)));
        }

        r.put(""oh1"", new byte[838860]);
        r.put(""oh3"", new byte[157287]);
        
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return r.memoryThresholdReached.get();
          }
        };
        waitForCriterion(wc, 3000, 100, true);
        {
          Integer k = new Integer(2); 
          assertEquals(k.toString(), r.get(k, new Integer(expectedInvocations++)));
        }
        
        r.destroy(""oh3"");
        wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return !r.memoryThresholdReached.get();
          }
        };
        waitForCriterion(wc, 3000, 100, true);
        {
          Integer k = new Integer(3);
          assertEquals(k.toString(), r.get(k, new Integer(expectedInvocations++)));
        }
        return new Integer(expectedInvocations);
      }
    });

    final CacheSerializableRunnable validateData1 = new CacheSerializableRunnable(""Validate data 1"") {
      @Override
      public void run2() throws CacheException {
        Region r = getCache().getRegion(rName);
        Integer i1 = new Integer(1);
        assertTrue(r.containsKey(i1));
        assertNotNull(r.getEntry(i1));
        Integer i2 = new Integer(2);
        assertFalse(r.containsKey(i2));
        assertNull(r.getEntry(i2));
        Integer i3 = new Integer(3);
        assertTrue(r.containsKey(i3));
        assertNotNull(r.getEntry(i3));
      }
    };
    replicate1.invoke(validateData1);
    replicate2.invoke(validateData1);
    
    replicate2.invoke(new SerializableCallable(""test DistributedRegion netLoad"") {
      public Object call() throws Exception {
        final DistributedRegion r = (DistributedRegion) getCache().getRegion(rName);
        final OffHeapMemoryMonitor ohmm = ((InternalResourceManager)getCache().getResourceManager()).getOffHeapMonitor();
        assertFalse(ohmm.getState().isCritical());
        
        int expectedInvocations = expected.intValue();
        {
          Integer k = new Integer(4);
          assertEquals(k.toString(), r.get(k, new Integer(expectedInvocations++)));
        }
        
        // Place in a critical state for the next test
        r.put(""oh3"", new byte[157287]);
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return r.memoryThresholdReached.get();
          }
        };
        waitForCriterion(wc, 3000, 100, true);
        {
          Integer k = new Integer(5);
          assertEquals(k.toString(), r.get(k, new Integer(expectedInvocations++)));
        }

        r.destroy(""oh3"");
        wc = new WaitCriterion() {
          public String description() {
            return ""verify critical state"";
          }
          public boolean done() {
            return !r.memoryThresholdReached.get();
          }
        };
        waitForCriterion(wc, 3000, 100, true);
        {
          Integer k = new Integer(6);
          assertEquals(k.toString(), r.get(k, new Integer(expectedInvocations++)));
        }
        return new Integer(expectedInvocations);
      }
    });
    
    replicate1.invoke(removeExpectedException);
    replicate2.invoke(removeExpectedException);
    
    final CacheSerializableRunnable validateData2 = new CacheSerializableRunnable(""Validate data 2"") {
      @Override
      public void run2() throws CacheException {
        Region<Integer, String> r = getCache().getRegion(rName);
        Integer i4 = new Integer(4);
        assertTrue(r.containsKey(i4));
        assertNotNull(r.getEntry(i4));
        Integer i5 = new Integer(5);
        assertFalse(r.containsKey(i5));
        assertNull(r.getEntry(i5));
        Integer i6 = new Integer(6);
        assertTrue(r.containsKey(i6));
        assertNotNull(r.getEntry(i6));
      }
    };
    replicate1.invoke(validateData2);
    replicate2.invoke(validateData2);
  }",False
"  private CacheSerializableRunnable createPR(final String rName, final boolean accessor, final int mcastPort) {
    return new CacheSerializableRunnable(""create PR accessor"") {
    @Override
    public void run2() throws CacheException {
      // Assert some level of connectivity
      getSystem(getServerProperties(mcastPort));      
      InternalResourceManager irm = (InternalResourceManager)getCache().getResourceManager();
      irm.setCriticalOffHeapPercentage(90f);
      AttributesFactory<Integer, String> af = new AttributesFactory<Integer, String>();
      if (!accessor) {
        af.setCacheLoader(new CacheLoader<Integer, String>() {
          final AtomicInteger numLoaderInvocations = new AtomicInteger(0);
          public String load(LoaderHelper<Integer, String> helper) throws CacheLoaderException {
            Integer expectedInvocations = (Integer)helper.getArgument();
            final int actualInvocations = this.numLoaderInvocations.getAndIncrement();
            if (expectedInvocations.intValue() != actualInvocations) {
              throw new CacheLoaderException(""Expected "" + expectedInvocations 
                  + "" invocations, actual is "" + actualInvocations);
            }
            return helper.getKey().toString();
          }
          public void close() {}
        });

        af.setPartitionAttributes(new PartitionAttributesFactory().create());
      } else {
        af.setPartitionAttributes(new PartitionAttributesFactory().setLocalMaxMemory(0).create());
      }
      af.setOffHeap(true);
      getCache().createRegion(rName, af.create());
    }
  };
  }",True
"      irm.setCriticalOffHeapPercentage(90f);
      AttributesFactory<Integer, String> af = new AttributesFactory<Integer, String>();
      if (!accessor) {
        af.setCacheLoader(new CacheLoader<Integer, String>() {
          final AtomicInteger numLoaderInvocations = new AtomicInteger(0);
          public String load(LoaderHelper<Integer, String> helper) throws CacheLoaderException {
            Integer expectedInvocations = (Integer)helper.getArgument();
            final int actualInvocations = this.numLoaderInvocations.getAndIncrement();
            if (expectedInvocations.intValue() != actualInvocations) {
              throw new CacheLoaderException(""Expected "" + expectedInvocations 
                  + "" invocations, actual is "" + actualInvocations);
            }
            return helper.getKey().toString();
          }
          public void close() {}
        });

        af.setPartitionAttributes(new PartitionAttributesFactory().create());
      } else {
        af.setPartitionAttributes(new PartitionAttributesFactory().setLocalMaxMemory(0).create());
      }
      af.setOffHeap(true);
      getCache().createRegion(rName, af.create());
    }
  };
  }
  
  /**
   * Test that LocalRegion cache Loads are not stored in the Region
   * if the VM is in a critical state, then test that they are allowed
   * once the VM is no longer critical
   * @throws Exception
   */",False
"  private void startCacheServer(VM server, final int port,
      final float evictionThreshold, final float criticalThreshold, final String regionName,
      final boolean createPR, final boolean notifyBySubscription, final int prRedundancy) throws Exception {

    server.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        getSystem(getServerProperties());
        GemFireCacheImpl cache = (GemFireCacheImpl)getCache();

        InternalResourceManager irm = cache.getResourceManager();
        irm.setEvictionOffHeapPercentage(evictionThreshold);
        irm.setCriticalOffHeapPercentage(criticalThreshold);

        AttributesFactory factory = new AttributesFactory();
        if (createPR) {
          PartitionAttributesFactory paf = new PartitionAttributesFactory();
          paf.setRedundantCopies(prRedundancy);
          paf.setTotalNumBuckets(11);
          factory.setPartitionAttributes(paf.create());
          factory.setOffHeap(true);
        } else {
          factory.setScope(Scope.DISTRIBUTED_ACK);
          factory.setDataPolicy(DataPolicy.REPLICATE);
          factory.setOffHeap(true);
        }
        Region region = createRegion(regionName, factory.create());
        if (createPR) {
          assertTrue(region instanceof PartitionedRegion);
        } else {
          assertTrue(region instanceof DistributedRegion);
        }
        CacheServer cacheServer = getCache().addCacheServer();
        cacheServer.setPort(port);
        cacheServer.setNotifyBySubscription(notifyBySubscription);
        cacheServer.start();
        return null;
      }
    });
  }",False
"  private Properties getServerProperties(int mcastPort) {
    Properties p = new Properties();
    p.setProperty(DistributionConfig.MCAST_PORT_NAME, mcastPort + """");
    p.setProperty(DistributionConfig.MCAST_TTL_NAME, ""0"");
    p.setProperty(DistributionConfig.LOCATORS_NAME, """");
    p.setProperty(DistributionConfig.OFF_HEAP_MEMORY_SIZE_NAME, ""1m"");
    return p;
  }",True
"  private Properties getServerProperties() {
    Properties p = new Properties();
    p.setProperty(DistributionConfig.LOCATORS_NAME, ""localhost[""+getDUnitLocatorPort()+""]"");
    p.setProperty(DistributionConfig.OFF_HEAP_MEMORY_SIZE_NAME, ""1m"");
    return p;
  }",False
"  private CacheSerializableRunnable createPR(final String rName, final boolean accessor) {
    return new CacheSerializableRunnable(""create PR accessor"") {
    @Override
    public void run2() throws CacheException {
      // Assert some level of connectivity
      getSystem(getServerProperties());      
      InternalResourceManager irm = (InternalResourceManager)getCache().getResourceManager();
      irm.setCriticalOffHeapPercentage(90f);
      AttributesFactory<Integer, String> af = new AttributesFactory<Integer, String>();
      if (!accessor) {
        af.setCacheLoader(new CacheLoader<Integer, String>() {
          final AtomicInteger numLoaderInvocations = new AtomicInteger(0);
          public String load(LoaderHelper<Integer, String> helper) throws CacheLoaderException {
            Integer expectedInvocations = (Integer)helper.getArgument();
            final int actualInvocations = this.numLoaderInvocations.getAndIncrement();
            if (expectedInvocations.intValue() != actualInvocations) {
              throw new CacheLoaderException(""Expected "" + expectedInvocations 
                  + "" invocations, actual is "" + actualInvocations);
            }
            return helper.getKey().toString();
          }
          public void close() {}
        });

        af.setPartitionAttributes(new PartitionAttributesFactory().create());
      } else {
        af.setPartitionAttributes(new PartitionAttributesFactory().setLocalMaxMemory(0).create());
      }
      af.setOffHeap(true);
      getCache().createRegion(rName, af.create());
    }
  };
  }",False
"  public void testGettersAndSetters() {
    getSystem(getServerProperties(0));
    ResourceManager rm = getCache().getResourceManager();
    assertEquals(0.0f, rm.getCriticalOffHeapPercentage());
    assertEquals(0.0f, rm.getEvictionOffHeapPercentage());
    
    rm.setEvictionOffHeapPercentage(50);
    rm.setCriticalOffHeapPercentage(90);
    
    // verify
    assertEquals(50.0f, rm.getEvictionOffHeapPercentage());
    assertEquals(90.0f, rm.getCriticalOffHeapPercentage());
    
    getCache().createRegionFactory(RegionShortcut.REPLICATE_HEAP_LRU).create(getName());
    
    assertEquals(50.0f, rm.getEvictionOffHeapPercentage());
    assertEquals(90.0f, rm.getCriticalOffHeapPercentage());
  }",True
"  public void testGettersAndSetters() {
    getSystem(getServerProperties());
    ResourceManager rm = getCache().getResourceManager();
    assertEquals(0.0f, rm.getCriticalOffHeapPercentage());
    assertEquals(0.0f, rm.getEvictionOffHeapPercentage());
    
    rm.setEvictionOffHeapPercentage(50);
    rm.setCriticalOffHeapPercentage(90);
    
    // verify
    assertEquals(50.0f, rm.getEvictionOffHeapPercentage());
    assertEquals(90.0f, rm.getCriticalOffHeapPercentage());
    
    getCache().createRegionFactory(RegionShortcut.REPLICATE_HEAP_LRU).create(getName());
    
    assertEquals(50.0f, rm.getEvictionOffHeapPercentage());
    assertEquals(90.0f, rm.getCriticalOffHeapPercentage());
  }",False
"    p.setProperty(DistributionConfig.LOCATORS_NAME, """");
    return p;
  }
}
",False
"  public void testDistributedRegionRemoteClientPutRejection() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM client = host.getVM(2);

    final int[] ports = AvailablePortHelper.getRandomAvailableTCPPorts(2);
    final int port1 = ports[0];
    final int port2 = ports[1];
    final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
    final String regionName = ""offHeapDRRemoteClientPutReject"";

    startCacheServer(server1, port1, mcastPort, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    startCacheServer(server2, port2, mcastPort, 0f, 90f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    startClient(client, server1, port1, regionName);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);

    doPuts(client, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(client, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/, Range.DEFAULT);

    //make server2 critical
    setUsageAboveCriticalThreshold(server2, regionName);

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, false);

    //make sure that client puts are rejected
    doPuts(client, regionName, true/*catchRejectedException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(client, regionName, true/*catchRejectedException*/,
        false/*catchLowMemoryException*/, new Range(Range.DEFAULT, Range.DEFAULT.width()+1));
    
    setUsageBelowEviction(server2, regionName);
  }",True
"  public void testDistributedRegionRemoteClientPutRejection() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM client = host.getVM(2);

    final int[] ports = AvailablePortHelper.getRandomAvailableTCPPorts(2);
    final int port1 = ports[0];
    final int port2 = ports[1];
    final String regionName = ""offHeapDRRemoteClientPutReject"";

    startCacheServer(server1, port1, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    startCacheServer(server2, port2, 0f, 90f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    startClient(client, server1, port1, regionName);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);

    doPuts(client, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(client, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/, Range.DEFAULT);

    //make server2 critical
    setUsageAboveCriticalThreshold(server2, regionName);

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, false);

    //make sure that client puts are rejected
    doPuts(client, regionName, true/*catchRejectedException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(client, regionName, true/*catchRejectedException*/,
        false/*catchLowMemoryException*/, new Range(Range.DEFAULT, Range.DEFAULT.width()+1));
    
    setUsageBelowEviction(server2, regionName);
  }",False
"  private void doDistributedRegionRemotePutRejection(boolean localDestroy, boolean cacheClose) throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);

    final int[] ports = AvailablePortHelper.getRandomAvailableTCPPorts(2);
    final int port1 = ports[0];
    final int port2 = ports[1];
    final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
    final String regionName = ""offHeapDRRemotePutRejection"";

    startCacheServer(server1, port1, mcastPort, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    startCacheServer(server2, port2, mcastPort, 0f, 90f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);

    doPuts(server1, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(server1, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/, Range.DEFAULT);

    //make server2 critical
    setUsageAboveCriticalThreshold(server2, regionName);

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, false);

    //make sure that local server1 puts are rejected
    doPuts(server1, regionName, false/*catchRejectedException*/,
        true/*catchLowMemoryException*/);
    Range r1 = new Range(Range.DEFAULT, Range.DEFAULT.width()+1);
    doPutAlls(server1, regionName, false/*catchRejectedException*/,
        true/*catchLowMemoryException*/, r1);

    if (localDestroy) {
    //local destroy the region on sick member
    server2.invoke(new SerializableCallable(""local destroy"") {
      public Object call() throws Exception {
        Region r = getRootRegion().getSubregion(regionName);
        r.localDestroyRegion();
        return null;
      }
    });
    } else if (cacheClose) {
      server2.invoke(new SerializableCallable() {
        public Object call() throws Exception {
          getCache().close();
          return null;
        }
      });
    } else {
      setUsageBelowEviction(server2, regionName);
    }
    
    //wait for remote region destroyed message to be processed
    server1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""remote localRegionDestroyed message not received"";
          }
          public boolean done() {
            DistributedRegion dr = (DistributedRegion)getRootRegion().
                                                getSubregion(regionName);
            return dr.getMemoryThresholdReachedMembers().size() == 0;
          }
        };
        waitForCriterion(wc, 10000, 10, true);
        return null;
      }
    });

    //make sure puts succeed
    doPuts(server1, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/);
    Range r2 = new Range(r1, r1.width()+1);
    doPutAlls(server1, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/, r2);
  }",True
"  private void doDistributedRegionRemotePutRejection(boolean localDestroy, boolean cacheClose) throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);

    final int[] ports = AvailablePortHelper.getRandomAvailableTCPPorts(2);
    final int port1 = ports[0];
    final int port2 = ports[1];
    final String regionName = ""offHeapDRRemotePutRejection"";

    startCacheServer(server1, port1, 0f, 0f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);
    startCacheServer(server2, port2, 0f, 90f,
        regionName, false/*createPR*/, false/*notifyBySubscription*/, 0);

    registerTestMemoryThresholdListener(server1);
    registerTestMemoryThresholdListener(server2);

    doPuts(server1, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/);
    doPutAlls(server1, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/, Range.DEFAULT);

    //make server2 critical
    setUsageAboveCriticalThreshold(server2, regionName);

    verifyListenerValue(server1, MemoryState.CRITICAL, 1, true);
    verifyListenerValue(server2, MemoryState.CRITICAL, 1, false);

    //make sure that local server1 puts are rejected
    doPuts(server1, regionName, false/*catchRejectedException*/,
        true/*catchLowMemoryException*/);
    Range r1 = new Range(Range.DEFAULT, Range.DEFAULT.width()+1);
    doPutAlls(server1, regionName, false/*catchRejectedException*/,
        true/*catchLowMemoryException*/, r1);

    if (localDestroy) {
    //local destroy the region on sick member
    server2.invoke(new SerializableCallable(""local destroy"") {
      public Object call() throws Exception {
        Region r = getRootRegion().getSubregion(regionName);
        r.localDestroyRegion();
        return null;
      }
    });
    } else if (cacheClose) {
      server2.invoke(new SerializableCallable() {
        public Object call() throws Exception {
          getCache().close();
          return null;
        }
      });
    } else {
      setUsageBelowEviction(server2, regionName);
    }
    
    //wait for remote region destroyed message to be processed
    server1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        WaitCriterion wc = new WaitCriterion() {
          public String description() {
            return ""remote localRegionDestroyed message not received"";
          }
          public boolean done() {
            DistributedRegion dr = (DistributedRegion)getRootRegion().
                                                getSubregion(regionName);
            return dr.getMemoryThresholdReachedMembers().size() == 0;
          }
        };
        waitForCriterion(wc, 10000, 10, true);
        return null;
      }
    });

    //make sure puts succeed
    doPuts(server1, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/);
    Range r2 = new Range(r1, r1.width()+1);
    doPutAlls(server1, regionName, false/*catchRejectedException*/,
        false/*catchLowMemoryException*/, r2);
  }",False
"  public void testRemoteBridgeClientQueries() throws CacheException {

    final String name = this.getName();
    final String rootRegionName = ""root"";

    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    VM vm2 = host.getVM(2);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
        config.setProperty(""mcast-port"", String.valueOf(unusedPort));
        system = (InternalDistributedSystem) DistributedSystem.connect(config);
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        createRegion(name, factory.create());
        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        for (int i=0; i<numberOfEntries; i++) {
          region.put(""key-""+i, new TestObject(i, ""ibm""));
        }
      }
    });

    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());

    final String regionName = ""/"" + rootRegionName + ""/"" + name;

    // Create client pool.
    final String poolName1 = ""testRemoteBridgeClientQueries1""; 
    final String poolName2 = ""testRemoteBridgeClientQueries2""; 

    createPool(vm1, poolName1, host0, port);
    createPool(vm2, poolName2, host0, port);

    // Execute client queries in VM1
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        String queryString = null;
        SelectResults results = null;
        QueryService qService = null;

        try {
          qService = (PoolManager.find(poolName1)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }          

        queryString = ""SELECT DISTINCT itr.value FROM "" + regionName + "".entries itr where itr.key = 'key-1'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());
        assertTrue(results.asList().get(0) instanceof TestObject);

        queryString = ""SELECT DISTINCT itr.key FROM "" + regionName + "".entries itr where itr.key = 'key-1'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());
        assertEquals(""key-1"", results.asList().get(0));
      }
    });

    // Execute client queries in VM2
    vm2.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        String queryString = null;
        SelectResults results = null;
        QueryService qService = null;

        try {
          qService = (PoolManager.find(poolName2)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }          

        queryString = ""SELECT DISTINCT itr.value FROM "" + regionName + "".entries itr where itr.key = 'key-1'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());
        assertTrue(results.asList().get(0) instanceof TestObject);

        queryString = ""SELECT DISTINCT itr.key FROM "" + regionName + "".entries itr where itr.key = 'key-1'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());
        assertEquals(""key-1"", results.asList().get(0));
      }
    });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",True
"  public void testRemoteBridgeClientQueries() throws CacheException {

    final String name = this.getName();
    final String rootRegionName = ""root"";

    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    VM vm2 = host.getVM(2);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
        system = (InternalDistributedSystem) DistributedSystem.connect(config);
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        createRegion(name, factory.create());
        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        for (int i=0; i<numberOfEntries; i++) {
          region.put(""key-""+i, new TestObject(i, ""ibm""));
        }
      }
    });

    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());

    final String regionName = ""/"" + rootRegionName + ""/"" + name;

    // Create client pool.
    final String poolName1 = ""testRemoteBridgeClientQueries1""; 
    final String poolName2 = ""testRemoteBridgeClientQueries2""; 

    createPool(vm1, poolName1, host0, port);
    createPool(vm2, poolName2, host0, port);

    // Execute client queries in VM1
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        String queryString = null;
        SelectResults results = null;
        QueryService qService = null;

        try {
          qService = (PoolManager.find(poolName1)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }          

        queryString = ""SELECT DISTINCT itr.value FROM "" + regionName + "".entries itr where itr.key = 'key-1'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());
        assertTrue(results.asList().get(0) instanceof TestObject);

        queryString = ""SELECT DISTINCT itr.key FROM "" + regionName + "".entries itr where itr.key = 'key-1'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());
        assertEquals(""key-1"", results.asList().get(0));
      }
    });

    // Execute client queries in VM2
    vm2.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        String queryString = null;
        SelectResults results = null;
        QueryService qService = null;

        try {
          qService = (PoolManager.find(poolName2)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }          

        queryString = ""SELECT DISTINCT itr.value FROM "" + regionName + "".entries itr where itr.key = 'key-1'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());
        assertTrue(results.asList().get(0) instanceof TestObject);

        queryString = ""SELECT DISTINCT itr.key FROM "" + regionName + "".entries itr where itr.key = 'key-1'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());
        assertEquals(""key-1"", results.asList().get(0));
      }
    });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",False
"  public void __testRemoteComplexQueries() throws CacheException {

    final String name = this.getName();
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
//    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
        config.setProperty(""mcast-port"", String.valueOf(unusedPort));
        system = (InternalDistributedSystem) DistributedSystem.connect(config);
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        createRegion(name, factory.create());
        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        Portfolio portfolio = null;
        Position position1 = null;
        Position position2 = null;
        Properties portfolioProperties= null;
        Properties position1Properties = null;
        Properties position2Properties = null;

        // Create portfolio 1
        portfolio = new Portfolio();
        portfolioProperties = new Properties();
        portfolioProperties.put(""id"", new Integer(1));
        portfolioProperties.put(""type"", ""type1"");
        portfolioProperties.put(""status"", ""active"");

        position1 = new Position();
        position1Properties = new Properties();
        position1Properties.put(""secId"", ""SUN"");
        position1Properties.put(""qty"", new Double(34000.0));
        position1Properties.put(""mktValue"", new Double(24.42));
        position1.init(position1Properties);
        portfolioProperties.put(""position1"", position1);

        position2 = new Position();
        position2Properties = new Properties();
        position2Properties.put(""secId"", ""IBM"");
        position2Properties.put(""qty"", new Double(8765.0));
        position2Properties.put(""mktValue"", new Double(34.29));
        position2.init(position2Properties);
        portfolioProperties.put(""position2"", position2);

        portfolio.init(portfolioProperties);
        region.put(new Integer(1), portfolio);

        // Create portfolio 2
        portfolio = new Portfolio();
        portfolioProperties = new Properties();
        portfolioProperties.put(""id"", new Integer(2));
        portfolioProperties.put(""type"", ""type2"");
        portfolioProperties.put(""status"", ""inactive"");

        position1 = new Position();
        position1Properties = new Properties();
        position1Properties.put(""secId"", ""YHOO"");
        position1Properties.put(""qty"", new Double(9834.0));
        position1Properties.put(""mktValue"", new Double(12.925));
        position1.init(position1Properties);
        portfolioProperties.put(""position1"", position1);

        position2 = new Position();
        position2Properties = new Properties();
        position2Properties.put(""secId"", ""GOOG"");
        position2Properties.put(""qty"", new Double(12176.0));
        position2Properties.put(""mktValue"", new Double(21.972));
        position2.init(position2Properties);
        portfolioProperties.put(""position2"", position2);

        portfolio.init(portfolioProperties);
        region.put(new Integer(2), portfolio);

        // Create portfolio 3
        portfolio = new Portfolio();
        portfolioProperties = new Properties();
        portfolioProperties.put(""id"", new Integer(3));
        portfolioProperties.put(""type"", ""type3"");
        portfolioProperties.put(""status"", ""active"");

        position1 = new Position();
        position1Properties = new Properties();
        position1Properties.put(""secId"", ""MSFT"");
        position1Properties.put(""qty"", new Double(98327.0));
        position1Properties.put(""mktValue"", new Double(23.32));
        position1.init(position1Properties);
        portfolioProperties.put(""position1"", position1);

        position2 = new Position();
        position2Properties = new Properties();
        position2Properties.put(""secId"", ""AOL"");
        position2Properties.put(""qty"", new Double(978.0));
        position2Properties.put(""mktValue"", new Double(40.373));
        position2.init(position2Properties);
        portfolioProperties.put(""position2"", position2);

        portfolio.init(portfolioProperties);
        region.put(new Integer(3), portfolio);

        // Create portfolio 4
        portfolio = new Portfolio();
        portfolioProperties = new Properties();
        portfolioProperties.put(""id"", new Integer(4));
        portfolioProperties.put(""type"", ""type1"");
        portfolioProperties.put(""status"", ""inactive"");

        position1 = new Position();
        position1Properties = new Properties();
        position1Properties.put(""secId"", ""APPL"");
        position1Properties.put(""qty"", new Double(90.0));
        position1Properties.put(""mktValue"", new Double(67.356572));
        position1.init(position1Properties);
        portfolioProperties.put(""position1"", position1);

        position2 = new Position();
        position2Properties = new Properties();
        position2Properties.put(""secId"", ""ORCL"");
        position2Properties.put(""qty"", new Double(376.0));
        position2Properties.put(""mktValue"", new Double(101.34));
        position2.init(position2Properties);
        portfolioProperties.put(""position2"", position2);

        portfolio.init(portfolioProperties);
        region.put(new Integer(4), portfolio);
      }
    });

    // Create client region
    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        config.setProperty(""mcast-port"", ""0"");
        system = (InternalDistributedSystem) DistributedSystem.connect(config);
        getCache();
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        BridgeTestCase.configureConnectionPool(factory, host0, port,-1, true, -1, -1, null);
        createRegion(name, factory.create());
      }
    });

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        String queryString = null;
        SelectResults results = null;

        queryString =
          ""IMPORT cacheRunner.Position; "" +
          ""SELECT DISTINCT id, status FROM "" + region.getFullPath() +
          ""WHERE NOT (SELECT DISTINCT * FROM positions.values posnVal TYPE Position "" +
          ""WHERE posnVal.secId='AOL' OR posnVal.secId='SAP').isEmpty"";
        try {
          results = region.query(queryString);
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        getLogWriter().fine(""size: "" + results.size());
        //assertEquals(numberOfEntries, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());
      }
    });


    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",True
"  public void __testRemoteComplexQueries() throws CacheException {

    final String name = this.getName();
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
//    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
        system = (InternalDistributedSystem) DistributedSystem.connect(config);
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        createRegion(name, factory.create());
        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        Portfolio portfolio = null;
        Position position1 = null;
        Position position2 = null;
        Properties portfolioProperties= null;
        Properties position1Properties = null;
        Properties position2Properties = null;

        // Create portfolio 1
        portfolio = new Portfolio();
        portfolioProperties = new Properties();
        portfolioProperties.put(""id"", new Integer(1));
        portfolioProperties.put(""type"", ""type1"");
        portfolioProperties.put(""status"", ""active"");

        position1 = new Position();
        position1Properties = new Properties();
        position1Properties.put(""secId"", ""SUN"");
        position1Properties.put(""qty"", new Double(34000.0));
        position1Properties.put(""mktValue"", new Double(24.42));
        position1.init(position1Properties);
        portfolioProperties.put(""position1"", position1);

        position2 = new Position();
        position2Properties = new Properties();
        position2Properties.put(""secId"", ""IBM"");
        position2Properties.put(""qty"", new Double(8765.0));
        position2Properties.put(""mktValue"", new Double(34.29));
        position2.init(position2Properties);
        portfolioProperties.put(""position2"", position2);

        portfolio.init(portfolioProperties);
        region.put(new Integer(1), portfolio);

        // Create portfolio 2
        portfolio = new Portfolio();
        portfolioProperties = new Properties();
        portfolioProperties.put(""id"", new Integer(2));
        portfolioProperties.put(""type"", ""type2"");
        portfolioProperties.put(""status"", ""inactive"");

        position1 = new Position();
        position1Properties = new Properties();
        position1Properties.put(""secId"", ""YHOO"");
        position1Properties.put(""qty"", new Double(9834.0));
        position1Properties.put(""mktValue"", new Double(12.925));
        position1.init(position1Properties);
        portfolioProperties.put(""position1"", position1);

        position2 = new Position();
        position2Properties = new Properties();
        position2Properties.put(""secId"", ""GOOG"");
        position2Properties.put(""qty"", new Double(12176.0));
        position2Properties.put(""mktValue"", new Double(21.972));
        position2.init(position2Properties);
        portfolioProperties.put(""position2"", position2);

        portfolio.init(portfolioProperties);
        region.put(new Integer(2), portfolio);

        // Create portfolio 3
        portfolio = new Portfolio();
        portfolioProperties = new Properties();
        portfolioProperties.put(""id"", new Integer(3));
        portfolioProperties.put(""type"", ""type3"");
        portfolioProperties.put(""status"", ""active"");

        position1 = new Position();
        position1Properties = new Properties();
        position1Properties.put(""secId"", ""MSFT"");
        position1Properties.put(""qty"", new Double(98327.0));
        position1Properties.put(""mktValue"", new Double(23.32));
        position1.init(position1Properties);
        portfolioProperties.put(""position1"", position1);

        position2 = new Position();
        position2Properties = new Properties();
        position2Properties.put(""secId"", ""AOL"");
        position2Properties.put(""qty"", new Double(978.0));
        position2Properties.put(""mktValue"", new Double(40.373));
        position2.init(position2Properties);
        portfolioProperties.put(""position2"", position2);

        portfolio.init(portfolioProperties);
        region.put(new Integer(3), portfolio);

        // Create portfolio 4
        portfolio = new Portfolio();
        portfolioProperties = new Properties();
        portfolioProperties.put(""id"", new Integer(4));
        portfolioProperties.put(""type"", ""type1"");
        portfolioProperties.put(""status"", ""inactive"");

        position1 = new Position();
        position1Properties = new Properties();
        position1Properties.put(""secId"", ""APPL"");
        position1Properties.put(""qty"", new Double(90.0));
        position1Properties.put(""mktValue"", new Double(67.356572));
        position1.init(position1Properties);
        portfolioProperties.put(""position1"", position1);

        position2 = new Position();
        position2Properties = new Properties();
        position2Properties.put(""secId"", ""ORCL"");
        position2Properties.put(""qty"", new Double(376.0));
        position2Properties.put(""mktValue"", new Double(101.34));
        position2.init(position2Properties);
        portfolioProperties.put(""position2"", position2);

        portfolio.init(portfolioProperties);
        region.put(new Integer(4), portfolio);
      }
    });

    // Create client region
    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        config.setProperty(""mcast-port"", ""0"");
        system = (InternalDistributedSystem) DistributedSystem.connect(config);
        getCache();
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        BridgeTestCase.configureConnectionPool(factory, host0, port,-1, true, -1, -1, null);
        createRegion(name, factory.create());
      }
    });

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        String queryString = null;
        SelectResults results = null;

        queryString =
          ""IMPORT cacheRunner.Position; "" +
          ""SELECT DISTINCT id, status FROM "" + region.getFullPath() +
          ""WHERE NOT (SELECT DISTINCT * FROM positions.values posnVal TYPE Position "" +
          ""WHERE posnVal.secId='AOL' OR posnVal.secId='SAP').isEmpty"";
        try {
          results = region.query(queryString);
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        getLogWriter().fine(""size: "" + results.size());
        //assertEquals(numberOfEntries, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());
      }
    });


    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",False
"  public void testBug36969() throws Exception
  {
    final String name = this.getName();
    final String rootRegionName = ""root"";

    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
        config.setProperty(""mcast-port"", String.valueOf(unusedPort));
        system = (InternalDistributedSystem) DistributedSystem.connect(config);

        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    vm0.invoke(new CacheSerializableRunnable(""Create two regions"") {
      public void run2() throws CacheException {
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        final Region region1 = createRegion(name, factory.createRegionAttributes());
        final Region region2 = createRegion(name+""_2"", factory.createRegionAttributes());
        QueryObserverHolder.setInstance(new QueryObserverAdapter() {
          public void afterQueryEvaluation(Object result) {
            //Destroy the region in the test
            region1.close();
          }

        });
        pause(1000);
        for (int i=0; i<numberOfEntries; i++) {
          region1.put(""key-""+i, new TestObject(i, ""ibm""));
          region2.put(""key-""+i, new TestObject(i, ""ibm""));
        }

      }
    });

    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());

    final String regionName1 = ""/"" + rootRegionName + ""/"" + name;
    final String regionName2 = ""/"" + rootRegionName + ""/"" + name + ""_2"";

    // Create client pool.
    final String poolName = ""testBug36969"";
    createPool(vm1, poolName, host0, port);

    // Execute client queries in VM1      
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        String queryString = ""select distinct * from "" + regionName1 + "", ""+regionName2;
//        SelectResults results = null;
        QueryService qService = null;

        try {
          qService = (PoolManager.find(poolName)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }

        try {
          Query query = qService.newQuery(queryString);
          query.execute();
          fail(""The query should have experienced RegionDestroyedException"");
        } catch(Exception e) {
          // OK
        }
      }
    });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        QueryObserverHolder.setInstance(new QueryObserverAdapter());
        stopBridgeServer(getCache());
      }
    });



  }",True
"  public void testBug36969() throws Exception
  {
    final String name = this.getName();
    final String rootRegionName = ""root"";

    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
        system = (InternalDistributedSystem) DistributedSystem.connect(config);

        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    vm0.invoke(new CacheSerializableRunnable(""Create two regions"") {
      public void run2() throws CacheException {
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        final Region region1 = createRegion(name, factory.createRegionAttributes());
        final Region region2 = createRegion(name+""_2"", factory.createRegionAttributes());
        QueryObserverHolder.setInstance(new QueryObserverAdapter() {
          public void afterQueryEvaluation(Object result) {
            //Destroy the region in the test
            region1.close();
          }

        });
        pause(1000);
        for (int i=0; i<numberOfEntries; i++) {
          region1.put(""key-""+i, new TestObject(i, ""ibm""));
          region2.put(""key-""+i, new TestObject(i, ""ibm""));
        }

      }
    });

    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());

    final String regionName1 = ""/"" + rootRegionName + ""/"" + name;
    final String regionName2 = ""/"" + rootRegionName + ""/"" + name + ""_2"";

    // Create client pool.
    final String poolName = ""testBug36969"";
    createPool(vm1, poolName, host0, port);

    // Execute client queries in VM1      
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        String queryString = ""select distinct * from "" + regionName1 + "", ""+regionName2;
//        SelectResults results = null;
        QueryService qService = null;

        try {
          qService = (PoolManager.find(poolName)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }

        try {
          Query query = qService.newQuery(queryString);
          query.execute();
          fail(""The query should have experienced RegionDestroyedException"");
        } catch(Exception e) {
          // OK
        }
      }
    });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        QueryObserverHolder.setInstance(new QueryObserverAdapter());
        stopBridgeServer(getCache());
      }
    });



  }",False
"  protected void configAndStartBridgeServer() {
    Properties config = new Properties();
    int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    config.setProperty(""mcast-port"", String.valueOf(unusedPort));
    system = (InternalDistributedSystem) DistributedSystem.connect(config);
    AttributesFactory factory = new AttributesFactory();
    factory.setScope(Scope.LOCAL);
    createRegion(this.regionName, this.rootRegionName, factory.create());
    pause(1000);
    try {
      startBridgeServer(0, false);
    } catch (Exception ex) {
      fail(""While starting CacheServer"", ex);
    }
  }",True
"  protected void configAndStartBridgeServer() {
    Properties config = new Properties();
    config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
    system = (InternalDistributedSystem) DistributedSystem.connect(config);
    AttributesFactory factory = new AttributesFactory();
    factory.setScope(Scope.LOCAL);
    createRegion(this.regionName, this.rootRegionName, factory.create());
    pause(1000);
    try {
      startBridgeServer(0, false);
    } catch (Exception ex) {
      fail(""While starting CacheServer"", ex);
    }
  }",False
"  public void testRemoteStructQueries() throws CacheException {

    final String name = this.getName();
    final String rootRegionName = ""root"";

    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
        config.setProperty(""mcast-port"", String.valueOf(unusedPort));
        system = (InternalDistributedSystem) DistributedSystem.connect(config);
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        createRegion(name, factory.create());
        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        for (int i=0; i<numberOfEntries; i++) {
          region.put(""key-""+i, new TestObject(i, ""ibm""));
        }
      }
    });

    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());

    final String regionName = ""/"" + rootRegionName + ""/"" + name;

    // Create client pool.
    final String poolName = ""testRemoteStructQueries""; 
    createPool(vm1, poolName, host0, port);

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        String queryString = null;
        SelectResults results = null;

        QueryService qService = null;

        try {
          qService = (PoolManager.find(poolName)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }          

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct ticker, price from "" + regionName;
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(numberOfEntries, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct ticker, price from "" + regionName + "" where ticker = 'ibm'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(numberOfEntries, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct ticker, price from "" + regionName + "" where ticker = 'IBM'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(0, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct ticker, price from "" + regionName + "" where price > 49"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(numberOfEntries/2, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct ticker, price from "" + regionName + "" where price = 50"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct ticker, price from "" + regionName + "" where ticker = 'ibm' and price = 50"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());
      }
    });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",True
"  public void testRemoteStructQueries() throws CacheException {

    final String name = this.getName();
    final String rootRegionName = ""root"";

    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
        system = (InternalDistributedSystem) DistributedSystem.connect(config);
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        createRegion(name, factory.create());
        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        for (int i=0; i<numberOfEntries; i++) {
          region.put(""key-""+i, new TestObject(i, ""ibm""));
        }
      }
    });

    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());

    final String regionName = ""/"" + rootRegionName + ""/"" + name;

    // Create client pool.
    final String poolName = ""testRemoteStructQueries""; 
    createPool(vm1, poolName, host0, port);

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        String queryString = null;
        SelectResults results = null;

        QueryService qService = null;

        try {
          qService = (PoolManager.find(poolName)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }          

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct ticker, price from "" + regionName;
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(numberOfEntries, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct ticker, price from "" + regionName + "" where ticker = 'ibm'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(numberOfEntries, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct ticker, price from "" + regionName + "" where ticker = 'IBM'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(0, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct ticker, price from "" + regionName + "" where price > 49"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(numberOfEntries/2, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct ticker, price from "" + regionName + "" where price = 50"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct ticker, price from "" + regionName + "" where ticker = 'ibm' and price = 50"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());
      }
    });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",False
"  public void testUnSupportedOps() throws Exception
  {
    final String name = this.getName();
    final String rootRegionName = ""root"";

    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
        config.setProperty(""mcast-port"", String.valueOf(unusedPort));
        system = (InternalDistributedSystem) DistributedSystem.connect(config);

        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    vm0.invoke(new CacheSerializableRunnable(""Create two regions"") {
      public void run2() throws CacheException {
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        final Region region1 = createRegion(name, factory.createRegionAttributes());
        final Region region2 = createRegion(name+""_2"", factory.createRegionAttributes());
        for (int i=0; i<numberOfEntries; i++) {
          region1.put(""key-""+i, new TestObject(i, ""ibm""));
          region2.put(""key-""+i, new TestObject(i, ""ibm""));
        }

      }
    });

    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());

    final String regionName1 = ""/"" + rootRegionName + ""/"" + name;
//    final String regionName2 = ""/"" + rootRegionName + ""/"" + name + ""_2"";

    // Create client pool.
    final String poolName = ""testUnSupportedOps"";
    createPool(vm1, poolName, host0, port);

    // Execute client queries in VM1      
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        final Region region1 = createRegion(name, factory.createRegionAttributes());

        String queryString = ""select distinct * from "" + regionName1 + "" where ticker = $1"";
        Object[] params = new Object[] { new String(""ibm"")};
//        SelectResults results = null;
        QueryService qService = null;

        try {
          qService = (PoolManager.find(poolName)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }

        // Testing Remote Query with params.
        try {
          Query query = qService.newQuery(queryString);
          query.execute(params);
        } catch(UnsupportedOperationException e) {
          // Expected behavior.
        } catch (Exception e){
          fail(""Failed with UnExpected Exception."", e);
        }

        // Test with Index.
        try {
          qService.createIndex(""test"", IndexType.FUNCTIONAL,""ticker"",regionName1);
        } catch(UnsupportedOperationException e) {
          // Expected behavior.
        } catch (Exception e){
          fail(""Failed with UnExpected Exception."", e);
        }

        try {
          String importString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject;"";
          qService.createIndex(""test"", IndexType.FUNCTIONAL,""ticker"",regionName1, importString);
        } catch(UnsupportedOperationException e) {
          // Expected behavior.
        } catch (Exception e){
          fail(""Failed with UnExpected Exception."", e);
        }

        try {
          qService.getIndex(region1, ""test"");
        } catch(UnsupportedOperationException e) {
          // Expected behavior.
        } 

        try {
          qService.getIndexes(region1);
        } catch(UnsupportedOperationException e) {
          // Expected behavior.
        } 

        try {
          qService.getIndexes(region1, IndexType.FUNCTIONAL);
        } catch(UnsupportedOperationException e) {
          // Expected behavior.
        } 

        //try {                        
        //  qService.getIndex(Index index);
        //} catch(UnsupportedOperationException e) {
        // // Expected behavior.
        //} 

        try {
          qService.removeIndexes(region1);
        } catch(UnsupportedOperationException e) {
          // Expected behavior.
        } 

        try {
          qService.removeIndexes();
        } catch(UnsupportedOperationException e) {
          // Expected behavior.
        } 

      }
    });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        QueryObserverHolder.setInstance(new QueryObserverAdapter());
        stopBridgeServer(getCache());
      }
    });

  }",True
"  public void testUnSupportedOps() throws Exception
  {
    final String name = this.getName();
    final String rootRegionName = ""root"";

    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
        system = (InternalDistributedSystem) DistributedSystem.connect(config);

        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    vm0.invoke(new CacheSerializableRunnable(""Create two regions"") {
      public void run2() throws CacheException {
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        final Region region1 = createRegion(name, factory.createRegionAttributes());
        final Region region2 = createRegion(name+""_2"", factory.createRegionAttributes());
        for (int i=0; i<numberOfEntries; i++) {
          region1.put(""key-""+i, new TestObject(i, ""ibm""));
          region2.put(""key-""+i, new TestObject(i, ""ibm""));
        }

      }
    });

    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());

    final String regionName1 = ""/"" + rootRegionName + ""/"" + name;
//    final String regionName2 = ""/"" + rootRegionName + ""/"" + name + ""_2"";

    // Create client pool.
    final String poolName = ""testUnSupportedOps"";
    createPool(vm1, poolName, host0, port);

    // Execute client queries in VM1      
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        final Region region1 = createRegion(name, factory.createRegionAttributes());

        String queryString = ""select distinct * from "" + regionName1 + "" where ticker = $1"";
        Object[] params = new Object[] { new String(""ibm"")};
//        SelectResults results = null;
        QueryService qService = null;

        try {
          qService = (PoolManager.find(poolName)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }

        // Testing Remote Query with params.
        try {
          Query query = qService.newQuery(queryString);
          query.execute(params);
        } catch(UnsupportedOperationException e) {
          // Expected behavior.
        } catch (Exception e){
          fail(""Failed with UnExpected Exception."", e);
        }

        // Test with Index.
        try {
          qService.createIndex(""test"", IndexType.FUNCTIONAL,""ticker"",regionName1);
        } catch(UnsupportedOperationException e) {
          // Expected behavior.
        } catch (Exception e){
          fail(""Failed with UnExpected Exception."", e);
        }

        try {
          String importString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject;"";
          qService.createIndex(""test"", IndexType.FUNCTIONAL,""ticker"",regionName1, importString);
        } catch(UnsupportedOperationException e) {
          // Expected behavior.
        } catch (Exception e){
          fail(""Failed with UnExpected Exception."", e);
        }

        try {
          qService.getIndex(region1, ""test"");
        } catch(UnsupportedOperationException e) {
          // Expected behavior.
        } 

        try {
          qService.getIndexes(region1);
        } catch(UnsupportedOperationException e) {
          // Expected behavior.
        } 

        try {
          qService.getIndexes(region1, IndexType.FUNCTIONAL);
        } catch(UnsupportedOperationException e) {
          // Expected behavior.
        } 

        //try {                        
        //  qService.getIndex(Index index);
        //} catch(UnsupportedOperationException e) {
        // // Expected behavior.
        //} 

        try {
          qService.removeIndexes(region1);
        } catch(UnsupportedOperationException e) {
          // Expected behavior.
        } 

        try {
          qService.removeIndexes();
        } catch(UnsupportedOperationException e) {
          // Expected behavior.
        } 

      }
    });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        QueryObserverHolder.setInstance(new QueryObserverAdapter());
        stopBridgeServer(getCache());
      }
    });

  }",False
"  public void testRemoteFullRegionQueries() throws CacheException {

    final String name = this.getName();
    final String rootRegionName = ""root"";

    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
        config.setProperty(""mcast-port"", String.valueOf(unusedPort));
        system = (InternalDistributedSystem) DistributedSystem.connect(config);
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        createRegion(name, factory.create());
        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        for (int i=0; i<numberOfEntries; i++) {
          region.put(""key-""+i, new TestObject(i, ""ibm""));
        }
      }
    });

    // Create client region
    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());

    final String regionName = ""/"" + rootRegionName + ""/"" + name;

    // Create client pool.
    final String poolName = ""testRemoteFullRegionQueries""; 
    createPool(vm1, poolName, host0, port);


    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        String queryString = null;
        SelectResults results = null;
        Comparator comparator = null;
        Object[] resultsArray = null;
        QueryService qService = null;

        try {
          qService = (PoolManager.find(poolName)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }          

        // value query
        queryString = ""SELECT DISTINCT itr.value FROM "" + regionName + "".entries itr where itr.key = 'key-1'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates());
        assertTrue(results.asList().get(0) instanceof TestObject);

        // key query
        queryString = ""SELECT DISTINCT itr.key FROM "" + regionName + "".entries itr where itr.key = 'key-1'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates());
        assertEquals(""key-1"", results.asList().get(0));

        // order by value query
        queryString = ""SELECT DISTINCT * FROM "" + regionName + "" WHERE id < 101 ORDER BY id"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(numberOfEntries, results.size());
        // All order-by query results are stored in a ResultsCollectionWrapper
        // wrapping a list, so the assertion below is not correct even though
        // it should be.
        //assertTrue(!results.getCollectionType().allowsDuplicates());
        assertTrue(results.getCollectionType().isOrdered());
        comparator = new IdComparator();
        resultsArray = results.toArray();
        for (int i=0; i<resultsArray.length; i++) {
          if (i+1 != resultsArray.length) {
            // The id of the current element in the result set must be less
            // than the id of the next one to pass.
            assertTrue(""The id for "" + resultsArray[i] + "" should be less than the id for "" + resultsArray[i+1], comparator.compare(resultsArray[i], resultsArray[i+1]) == -1);
          }
        }

        // order by struct query
        queryString = ""SELECT DISTINCT id, ticker, price FROM "" + regionName + "" WHERE id < 101 ORDER BY id"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(numberOfEntries, results.size());
        // All order-by query results are stored in a ResultsCollectionWrapper
        // wrapping a list, so the assertion below is not correct even though
        // it should be.
        //assertTrue(!results.getCollectionType().allowsDuplicates());
        assertTrue(results.getCollectionType().isOrdered());
        comparator = new StructIdComparator();
        resultsArray = results.toArray();
        for (int i=0; i<resultsArray.length; i++) {
          if (i+1 != resultsArray.length) {
            // The id of the current element in the result set must be less
            // than the id of the next one to pass.
            assertTrue(""The id for "" + resultsArray[i] + "" should be less than the id for "" + resultsArray[i+1], comparator.compare(resultsArray[i], resultsArray[i+1]) == -1);
          }
        }

        // size query
        queryString = ""(SELECT DISTINCT * FROM "" + regionName + "" WHERE id < 101).size"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        Object result = results.iterator().next();
        assertTrue(result instanceof Integer);
        int resultInt = ((Integer) result).intValue();
        assertEquals(resultInt, 100);

        // query with leading/trailing spaces
        queryString = "" SELECT DISTINCT itr.key FROM "" + regionName + "".entries itr where itr.key = 'key-1' "";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertEquals(""key-1"", results.asList().get(0));
      }
    });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",True
"  public void testRemoteFullRegionQueries() throws CacheException {

    final String name = this.getName();
    final String rootRegionName = ""root"";

    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
        system = (InternalDistributedSystem) DistributedSystem.connect(config);
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        createRegion(name, factory.create());
        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        for (int i=0; i<numberOfEntries; i++) {
          region.put(""key-""+i, new TestObject(i, ""ibm""));
        }
      }
    });

    // Create client region
    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());

    final String regionName = ""/"" + rootRegionName + ""/"" + name;

    // Create client pool.
    final String poolName = ""testRemoteFullRegionQueries""; 
    createPool(vm1, poolName, host0, port);


    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        String queryString = null;
        SelectResults results = null;
        Comparator comparator = null;
        Object[] resultsArray = null;
        QueryService qService = null;

        try {
          qService = (PoolManager.find(poolName)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }          

        // value query
        queryString = ""SELECT DISTINCT itr.value FROM "" + regionName + "".entries itr where itr.key = 'key-1'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates());
        assertTrue(results.asList().get(0) instanceof TestObject);

        // key query
        queryString = ""SELECT DISTINCT itr.key FROM "" + regionName + "".entries itr where itr.key = 'key-1'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates());
        assertEquals(""key-1"", results.asList().get(0));

        // order by value query
        queryString = ""SELECT DISTINCT * FROM "" + regionName + "" WHERE id < 101 ORDER BY id"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(numberOfEntries, results.size());
        // All order-by query results are stored in a ResultsCollectionWrapper
        // wrapping a list, so the assertion below is not correct even though
        // it should be.
        //assertTrue(!results.getCollectionType().allowsDuplicates());
        assertTrue(results.getCollectionType().isOrdered());
        comparator = new IdComparator();
        resultsArray = results.toArray();
        for (int i=0; i<resultsArray.length; i++) {
          if (i+1 != resultsArray.length) {
            // The id of the current element in the result set must be less
            // than the id of the next one to pass.
            assertTrue(""The id for "" + resultsArray[i] + "" should be less than the id for "" + resultsArray[i+1], comparator.compare(resultsArray[i], resultsArray[i+1]) == -1);
          }
        }

        // order by struct query
        queryString = ""SELECT DISTINCT id, ticker, price FROM "" + regionName + "" WHERE id < 101 ORDER BY id"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(numberOfEntries, results.size());
        // All order-by query results are stored in a ResultsCollectionWrapper
        // wrapping a list, so the assertion below is not correct even though
        // it should be.
        //assertTrue(!results.getCollectionType().allowsDuplicates());
        assertTrue(results.getCollectionType().isOrdered());
        comparator = new StructIdComparator();
        resultsArray = results.toArray();
        for (int i=0; i<resultsArray.length; i++) {
          if (i+1 != resultsArray.length) {
            // The id of the current element in the result set must be less
            // than the id of the next one to pass.
            assertTrue(""The id for "" + resultsArray[i] + "" should be less than the id for "" + resultsArray[i+1], comparator.compare(resultsArray[i], resultsArray[i+1]) == -1);
          }
        }

        // size query
        queryString = ""(SELECT DISTINCT * FROM "" + regionName + "" WHERE id < 101).size"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        Object result = results.iterator().next();
        assertTrue(result instanceof Integer);
        int resultInt = ((Integer) result).intValue();
        assertEquals(resultInt, 100);

        // query with leading/trailing spaces
        queryString = "" SELECT DISTINCT itr.key FROM "" + regionName + "".entries itr where itr.key = 'key-1' "";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertEquals(""key-1"", results.asList().get(0));
      }
    });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",False
"  public void testRemoteJoinRegionQueries() throws CacheException {

    final String name = this.getName();
    final String rootRegionName = ""root"";

    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
        config.setProperty(""mcast-port"", String.valueOf(unusedPort));
        system = (InternalDistributedSystem) DistributedSystem.connect(config);
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        createRegion(name+""1"", factory.create());
        createRegion(name+""2"", factory.create());
        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Region region1 = getRootRegion().getSubregion(name+""1"");
        for (int i=0; i<numberOfEntries; i++) {
          region1.put(""key-""+i, new TestObject(i, ""ibm""));
        }
        Region region2 = getRootRegion().getSubregion(name+""2"");
        for (int i=0; i<numberOfEntries; i++) {
          region2.put(""key-""+i, new TestObject(i, ""ibm""));
        }
      }
    });

    // Create client region
    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    final String regionName1 = ""/"" + rootRegionName + ""/"" + name+""1"";
    final String regionName2 = ""/"" + rootRegionName + ""/"" + name+""2"";

    // Create client pool.
    final String poolName = ""testRemoteJoinRegionQueries""; 
    createPool(vm1, poolName, host0, port);

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        String queryString = null;
        SelectResults results = null;
        QueryService qService = null;

        try {
          qService = (PoolManager.find(poolName)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }          

        queryString =
          ""select distinct a, b.price from "" + regionName1 + "" a, "" + regionName2 + "" b where a.price = b.price"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(numberOfEntries, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

        queryString =
          ""select distinct a, b.price from "" + regionName1 + "" a, "" + regionName2 + "" b where a.price = b.price and a.price = 50"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());
      }
    });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",True
"  public void testRemoteJoinRegionQueries() throws CacheException {

    final String name = this.getName();
    final String rootRegionName = ""root"";

    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
        system = (InternalDistributedSystem) DistributedSystem.connect(config);
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        createRegion(name+""1"", factory.create());
        createRegion(name+""2"", factory.create());
        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Region region1 = getRootRegion().getSubregion(name+""1"");
        for (int i=0; i<numberOfEntries; i++) {
          region1.put(""key-""+i, new TestObject(i, ""ibm""));
        }
        Region region2 = getRootRegion().getSubregion(name+""2"");
        for (int i=0; i<numberOfEntries; i++) {
          region2.put(""key-""+i, new TestObject(i, ""ibm""));
        }
      }
    });

    // Create client region
    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    final String regionName1 = ""/"" + rootRegionName + ""/"" + name+""1"";
    final String regionName2 = ""/"" + rootRegionName + ""/"" + name+""2"";

    // Create client pool.
    final String poolName = ""testRemoteJoinRegionQueries""; 
    createPool(vm1, poolName, host0, port);

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        String queryString = null;
        SelectResults results = null;
        QueryService qService = null;

        try {
          qService = (PoolManager.find(poolName)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }          

        queryString =
          ""select distinct a, b.price from "" + regionName1 + "" a, "" + regionName2 + "" b where a.price = b.price"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(numberOfEntries, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

        queryString =
          ""select distinct a, b.price from "" + regionName1 + "" a, "" + regionName2 + "" b where a.price = b.price and a.price = 50"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());
      }
    });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",False
"  public void testRemoteImportQueries() throws CacheException {

    final String name = this.getName();
    final String rootRegionName = ""root"";

    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
        config.setProperty(""mcast-port"", String.valueOf(unusedPort));
        system = (InternalDistributedSystem) DistributedSystem.connect(config);
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        createRegion(name, rootRegionName, factory.create());
        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        for (int i=0; i<numberOfEntries; i++) {
          region.put(""key-""+i, new TestObject(i, ""ibm""));
        }
      }
    });


    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    final String regionName = ""/"" + rootRegionName + ""/"" + name;

    // Create client pool.
    final String poolName = ""testRemoteImportQueries""; 
    createPool(vm1, poolName, host0, port);

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        String queryString = null;
        SelectResults results = null;

        QueryService qService = null;

        try {
          qService = (PoolManager.find(poolName)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }          

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct * from "" + regionName;

        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }          

        assertEquals(numberOfEntries, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct * from "" + regionName + "" where ticker = 'ibm'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(numberOfEntries, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct * from "" + regionName + "" where ticker = 'IBM'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(0, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct * from "" + regionName + "" where price > 49"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(numberOfEntries/2, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct * from "" + regionName + "" where price = 50"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct * from "" + regionName + "" where ticker = 'ibm' and price = 50"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates());
      }
    });


    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",True
"  public void testRemoteImportQueries() throws CacheException {

    final String name = this.getName();
    final String rootRegionName = ""root"";

    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
        system = (InternalDistributedSystem) DistributedSystem.connect(config);
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        createRegion(name, rootRegionName, factory.create());
        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        for (int i=0; i<numberOfEntries; i++) {
          region.put(""key-""+i, new TestObject(i, ""ibm""));
        }
      }
    });


    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    final String regionName = ""/"" + rootRegionName + ""/"" + name;

    // Create client pool.
    final String poolName = ""testRemoteImportQueries""; 
    createPool(vm1, poolName, host0, port);

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        String queryString = null;
        SelectResults results = null;

        QueryService qService = null;

        try {
          qService = (PoolManager.find(poolName)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }          

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct * from "" + regionName;

        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }          

        assertEquals(numberOfEntries, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct * from "" + regionName + "" where ticker = 'ibm'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(numberOfEntries, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct * from "" + regionName + "" where ticker = 'IBM'"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(0, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct * from "" + regionName + "" where price > 49"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(numberOfEntries/2, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct * from "" + regionName + "" where price = 50"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates());

        queryString = ""import com.gemstone.gemfire.admin.QueryUsingPoolDUnitTest.TestObject; select distinct * from "" + regionName + "" where ticker = 'ibm' and price = 50"";
        try {
          Query query = qService.newQuery(queryString);
          results = (SelectResults)query.execute();
        } catch (Exception e) {
          fail(""Failed executing "" + queryString, e);
        }
        assertEquals(1, results.size());
        assertTrue(!results.getCollectionType().allowsDuplicates());
      }
    });


    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",False
"  public void testRemoteSortQueriesUsingIndex() throws CacheException {

    final String name = this.getName();
    final String rootRegionName = ""root"";

    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
        config.setProperty(""mcast-port"", String.valueOf(unusedPort));
        system = (InternalDistributedSystem) DistributedSystem.connect(config);
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        createRegion(name, factory.create());
        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        for (int i=0; i<numberOfEntries; i++) {
          region.put(""key-""+i, new TestObject(i, ""ibm""));
        }
        // Create index
        try {
          QueryService qService = region.getCache().getQueryService();
          qService.createIndex(""idIndex"",IndexType.FUNCTIONAL, ""id"", region.getFullPath());
        } catch (Exception e) {
          fail(""Failed to create index."", e);
        }          

      }
    });

    // Create client region
    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());

    final String regionName = ""/"" + rootRegionName + ""/"" + name;

    // Create client pool.
    final String poolName = ""testRemoteFullRegionQueries""; 
    createPool(vm1, poolName, host0, port);


    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        String queryString = null;
        SelectResults results = null;
        Comparator comparator = null;
        Object[] resultsArray = null;
        QueryService qService = null;
        Integer v1 = 0;
        Integer v2 = 0;
        
        try {
          qService = (PoolManager.find(poolName)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }          

        // order by value query
        String[] qString = {
            ""SELECT DISTINCT * FROM "" + regionName + "" WHERE id < 101 ORDER BY id"",
            ""SELECT DISTINCT id FROM "" + regionName + "" WHERE id < 101 ORDER BY id"",
        };
        
        for (int cnt=0; cnt < qString.length; cnt++) {
          queryString = qString[cnt];
          try {
            Query query = qService.newQuery(queryString);
            results = (SelectResults)query.execute();
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          // All order-by query results are stored in a ResultsCollectionWrapper
          // wrapping a list, so the assertion below is not correct even though
          // it should be.
          //assertTrue(!results.getCollectionType().allowsDuplicates());
          assertTrue(results.getCollectionType().isOrdered());
          comparator = new IdValueComparator();

          resultsArray = results.toArray();
          for (int i=0; i<resultsArray.length; i++) {
            if (i+1 != resultsArray.length) {
              // The id of the current element in the result set must be less
              // than the id of the next one to pass.
              if (resultsArray[i] instanceof TestObject) {
                v1 = ((TestObject)resultsArray[i]).getId();
                v2 = ((TestObject)resultsArray[i+1]).getId();
              } else {
                v1 = (Integer)resultsArray[i];
                v2 = (Integer)resultsArray[i + 1];
              }
              assertTrue(""The id for "" + resultsArray[i] + "" should be less than the id for "" + resultsArray[i+1], 
                  comparator.compare(v1, v2) == -1);
            }
          }
        }
      
        // order by struct query
        String[] qString2 = {
            ""SELECT DISTINCT id, ticker, price FROM "" + regionName + "" WHERE id < 101 ORDER BY id"",
            ""SELECT DISTINCT ticker, id FROM "" + regionName + "" WHERE id < 101  ORDER BY id"",
            ""SELECT DISTINCT id, ticker FROM "" + regionName + "" WHERE id < 101  ORDER BY id asc"",
        };

        for (int cnt=0; cnt < qString2.length; cnt++) {
          queryString = qString2[cnt];
          try {
            Query query = qService.newQuery(queryString);
            results = (SelectResults)query.execute();
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          // All order-by query results are stored in a ResultsCollectionWrapper
          // wrapping a list, so the assertion below is not correct even though
          // it should be.
          //assertTrue(!results.getCollectionType().allowsDuplicates());
          assertTrue(results.getCollectionType().isOrdered());
          comparator = new StructIdComparator();
          resultsArray = results.toArray();
          for (int i=0; i<resultsArray.length; i++) {
            if (i+1 != resultsArray.length) {
              // The id of the current element in the result set must be less
              // than the id of the next one to pass.
              assertTrue(""The id for "" + resultsArray[i] + "" should be less than the id for "" + resultsArray[i+1], comparator.compare(resultsArray[i], resultsArray[i+1]) == -1);
            }
          }
        }
      }
    });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",True
"  public void testRemoteSortQueriesUsingIndex() throws CacheException {

    final String name = this.getName();
    final String rootRegionName = ""root"";

    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Properties config = new Properties();
        config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
        system = (InternalDistributedSystem) DistributedSystem.connect(config);
        AttributesFactory factory = new AttributesFactory();
        factory.setScope(Scope.LOCAL);
        createRegion(name, factory.create());
        pause(1000);
        try {
          startBridgeServer(0, false);
        } catch (Exception ex) {
          fail(""While starting CacheServer"", ex);
        }
      }
    });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
      public void run2() throws CacheException {
        Region region = getRootRegion().getSubregion(name);
        for (int i=0; i<numberOfEntries; i++) {
          region.put(""key-""+i, new TestObject(i, ""ibm""));
        }
        // Create index
        try {
          QueryService qService = region.getCache().getQueryService();
          qService.createIndex(""idIndex"",IndexType.FUNCTIONAL, ""id"", region.getFullPath());
        } catch (Exception e) {
          fail(""Failed to create index."", e);
        }          

      }
    });

    // Create client region
    final int port = vm0.invokeInt(QueryUsingPoolDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());

    final String regionName = ""/"" + rootRegionName + ""/"" + name;

    // Create client pool.
    final String poolName = ""testRemoteFullRegionQueries""; 
    createPool(vm1, poolName, host0, port);


    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
      public void run2() throws CacheException {
        String queryString = null;
        SelectResults results = null;
        Comparator comparator = null;
        Object[] resultsArray = null;
        QueryService qService = null;
        Integer v1 = 0;
        Integer v2 = 0;
        
        try {
          qService = (PoolManager.find(poolName)).getQueryService();
        } catch (Exception e) {
          fail(""Failed to get QueryService."", e);
        }          

        // order by value query
        String[] qString = {
            ""SELECT DISTINCT * FROM "" + regionName + "" WHERE id < 101 ORDER BY id"",
            ""SELECT DISTINCT id FROM "" + regionName + "" WHERE id < 101 ORDER BY id"",
        };
        
        for (int cnt=0; cnt < qString.length; cnt++) {
          queryString = qString[cnt];
          try {
            Query query = qService.newQuery(queryString);
            results = (SelectResults)query.execute();
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          // All order-by query results are stored in a ResultsCollectionWrapper
          // wrapping a list, so the assertion below is not correct even though
          // it should be.
          //assertTrue(!results.getCollectionType().allowsDuplicates());
          assertTrue(results.getCollectionType().isOrdered());
          comparator = new IdValueComparator();

          resultsArray = results.toArray();
          for (int i=0; i<resultsArray.length; i++) {
            if (i+1 != resultsArray.length) {
              // The id of the current element in the result set must be less
              // than the id of the next one to pass.
              if (resultsArray[i] instanceof TestObject) {
                v1 = ((TestObject)resultsArray[i]).getId();
                v2 = ((TestObject)resultsArray[i+1]).getId();
              } else {
                v1 = (Integer)resultsArray[i];
                v2 = (Integer)resultsArray[i + 1];
              }
              assertTrue(""The id for "" + resultsArray[i] + "" should be less than the id for "" + resultsArray[i+1], 
                  comparator.compare(v1, v2) == -1);
            }
          }
        }
      
        // order by struct query
        String[] qString2 = {
            ""SELECT DISTINCT id, ticker, price FROM "" + regionName + "" WHERE id < 101 ORDER BY id"",
            ""SELECT DISTINCT ticker, id FROM "" + regionName + "" WHERE id < 101  ORDER BY id"",
            ""SELECT DISTINCT id, ticker FROM "" + regionName + "" WHERE id < 101  ORDER BY id asc"",
        };

        for (int cnt=0; cnt < qString2.length; cnt++) {
          queryString = qString2[cnt];
          try {
            Query query = qService.newQuery(queryString);
            results = (SelectResults)query.execute();
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          // All order-by query results are stored in a ResultsCollectionWrapper
          // wrapping a list, so the assertion below is not correct even though
          // it should be.
          //assertTrue(!results.getCollectionType().allowsDuplicates());
          assertTrue(results.getCollectionType().isOrdered());
          comparator = new StructIdComparator();
          resultsArray = results.toArray();
          for (int i=0; i<resultsArray.length; i++) {
            if (i+1 != resultsArray.length) {
              // The id of the current element in the result set must be less
              // than the id of the next one to pass.
              assertTrue(""The id for "" + resultsArray[i] + "" should be less than the id for "" + resultsArray[i+1], comparator.compare(resultsArray[i], resultsArray[i+1]) == -1);
            }
          }
        }
      }
    });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",False
"  public void testRemoteStructQueries() throws CacheException {

    final String name = this.getName();
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
          config.setProperty(""mcast-port"", String.valueOf(unusedPort));
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          createRegion(name, factory.create());
          pause(1000);
          try {
            startBridgeServer(0, false);
          } catch (Exception ex) {
            fail(""While starting CacheServer"", ex);
          }
        }
      });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          for (int i=0; i<numberOfEntries; i++) {
            region.put(""key-""+i, new TestObject(i, ""ibm""));
          }
        }
      });

    // Create client region
    final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          getCache();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          BridgeTestCase.configureConnectionPool(factory, host0, port,-1, true, -1, -1, null);
          createRegion(name, factory.create());
        }
      });

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          String queryString = null;
          SelectResults results = null;

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct ticker, price from "" + region.getFullPath();
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct ticker, price from "" + region.getFullPath() + "" where ticker = 'ibm'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct ticker, price from "" + region.getFullPath() + "" where ticker = 'IBM'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(0, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct ticker, price from "" + region.getFullPath() + "" where price > 49"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries/2, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct ticker, price from "" + region.getFullPath() + "" where price = 50"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct ticker, price from "" + region.getFullPath() + "" where ticker = 'ibm' and price = 50"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());
        }
      });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",True
"  public void testRemoteStructQueries() throws CacheException {

    final String name = this.getName();
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          createRegion(name, factory.create());
          pause(1000);
          try {
            startBridgeServer(0, false);
          } catch (Exception ex) {
            fail(""While starting CacheServer"", ex);
          }
        }
      });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          for (int i=0; i<numberOfEntries; i++) {
            region.put(""key-""+i, new TestObject(i, ""ibm""));
          }
        }
      });

    // Create client region
    final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          getCache();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          BridgeTestCase.configureConnectionPool(factory, host0, port,-1, true, -1, -1, null);
          createRegion(name, factory.create());
        }
      });

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          String queryString = null;
          SelectResults results = null;

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct ticker, price from "" + region.getFullPath();
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct ticker, price from "" + region.getFullPath() + "" where ticker = 'ibm'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct ticker, price from "" + region.getFullPath() + "" where ticker = 'IBM'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(0, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct ticker, price from "" + region.getFullPath() + "" where price > 49"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries/2, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct ticker, price from "" + region.getFullPath() + "" where price = 50"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct ticker, price from "" + region.getFullPath() + "" where ticker = 'ibm' and price = 50"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());
        }
      });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",False
"  public void testRemoteJoinRegionQueries() throws CacheException {

    final String name = this.getName();
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
          config.setProperty(""mcast-port"", String.valueOf(unusedPort));
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          createRegion(name+""1"", factory.create());
          createRegion(name+""2"", factory.create());
          pause(1000);
          try {
            startBridgeServer(0, false);
          } catch (Exception ex) {
            fail(""While starting CacheServer"", ex);
          }
        }
      });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Region region1 = getRootRegion().getSubregion(name+""1"");
          for (int i=0; i<numberOfEntries; i++) {
            region1.put(""key-""+i, new TestObject(i, ""ibm""));
          }
          Region region2 = getRootRegion().getSubregion(name+""2"");
          for (int i=0; i<numberOfEntries; i++) {
            region2.put(""key-""+i, new TestObject(i, ""ibm""));
          }
        }
      });

    // Create client region
    final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          getCache();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          BridgeTestCase.configureConnectionPool(factory, host0, port,-1, true, -1, -1, null);
          createRegion(name+""1"", factory.create());
          createRegion(name+""2"", factory.create());
        }
      });

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
        public void run2() throws CacheException {
          Region region1 = getRootRegion().getSubregion(name+""1"");
          Region region2 = getRootRegion().getSubregion(name+""2"");
          String queryString = null;
          SelectResults results = null;

          queryString =
            ""select distinct a, b.price from "" + region1.getFullPath() + "" a, "" + region2.getFullPath() + "" b where a.price = b.price"";
          try {
            results = region1.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

          queryString =
            ""select distinct a, b.price from "" + region1.getFullPath() + "" a, "" + region2.getFullPath() + "" b where a.price = b.price and a.price = 50"";
          try {
            results = region1.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());
        }
      });

          // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",True
"  public void testRemoteJoinRegionQueries() throws CacheException {

    final String name = this.getName();
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          createRegion(name+""1"", factory.create());
          createRegion(name+""2"", factory.create());
          pause(1000);
          try {
            startBridgeServer(0, false);
          } catch (Exception ex) {
            fail(""While starting CacheServer"", ex);
          }
        }
      });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Region region1 = getRootRegion().getSubregion(name+""1"");
          for (int i=0; i<numberOfEntries; i++) {
            region1.put(""key-""+i, new TestObject(i, ""ibm""));
          }
          Region region2 = getRootRegion().getSubregion(name+""2"");
          for (int i=0; i<numberOfEntries; i++) {
            region2.put(""key-""+i, new TestObject(i, ""ibm""));
          }
        }
      });

    // Create client region
    final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          getCache();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          BridgeTestCase.configureConnectionPool(factory, host0, port,-1, true, -1, -1, null);
          createRegion(name+""1"", factory.create());
          createRegion(name+""2"", factory.create());
        }
      });

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
        public void run2() throws CacheException {
          Region region1 = getRootRegion().getSubregion(name+""1"");
          Region region2 = getRootRegion().getSubregion(name+""2"");
          String queryString = null;
          SelectResults results = null;

          queryString =
            ""select distinct a, b.price from "" + region1.getFullPath() + "" a, "" + region2.getFullPath() + "" b where a.price = b.price"";
          try {
            results = region1.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());

          queryString =
            ""select distinct a, b.price from "" + region1.getFullPath() + "" a, "" + region2.getFullPath() + "" b where a.price = b.price and a.price = 50"";
          try {
            results = region1.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());
        }
      });

          // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",False
"   public void testBug36434() throws Exception
   {
     final String name = this.getName();
     final Host host = Host.getHost(0);
     VM vm0 = host.getVM(0);
     VM vm1 = host.getVM(1);

     final int numberOfEntries = 100;

     // Start server
     vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
         public void run2() throws CacheException {
           Properties config = new Properties();
           int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
           config.setProperty(""mcast-port"", String.valueOf(unusedPort));
           system = (InternalDistributedSystem) DistributedSystem.connect(config);
           AttributesFactory factory = new AttributesFactory();
           factory.setScope(Scope.LOCAL);
           createRegion(name, factory.createRegionAttributes());
           pause(1000);
           try {
             startBridgeServer(0, false);
           } catch (Exception ex) {
             fail(""While starting CacheServer"", ex);
           }
         }
       });

     // Initialize server region
     vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
         public void run2() throws CacheException {
           Region region = getRootRegion().getSubregion(name);
           for (int i=0; i<numberOfEntries; i++) {
             region.put(""key-""+i, new TestObject(i, ""ibm""));
           }
         }
       });

     final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
     final String host0 = getServerHostName(vm0.getHost());

     // Create client region in VM1
     vm1.invoke(new CacheSerializableRunnable(""Create region"") {
         public void run2() throws CacheException {
           Properties config = new Properties();
           config.setProperty(""mcast-port"", ""0"");
           system = (InternalDistributedSystem) DistributedSystem.connect(config);
           getCache();
           AttributesFactory factory = new AttributesFactory();
           factory.setScope(Scope.LOCAL);
           BridgeClient writer = new BridgeClient();
           Properties props = new Properties();
           props.setProperty(""endpoints"", ""server="" + host0 + "":"" +
                             port);
           props.setProperty(""establishCallbackConnection"", ""true"");
           writer.init(props);
           factory.setCacheWriter(writer);
           createRegion(name, factory.createRegionAttributes());
         }
       });


     // Execute client queries in VM1
     vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
         public void run2() throws CacheException {
           Region region = getRootRegion().getSubregion(name);
           String queryStrings [] ={""id<9"", ""selection<9"", ""important<9"",""\""select\""<9"" };
           for(int i =0 ; i <queryStrings.length;++i) {
             SelectResults results = null;

             try {
               results = region.query(queryStrings[i]);
             } catch (Exception e) {
               fail(""Failed executing "" + queryStrings[i], e);
             }
             assertEquals(9, results.size());
             String msg = ""results expected to be instance of ResultsBag,""
               + "" but was found to be is instance of '"";
             assertTrue(msg + results.getClass().getName() + ""'"",
                        results instanceof ResultsBag);
             assertTrue(results.asList().get(0) instanceof TestObject);
           }
         }
       });

       // Close client VM1
       vm1.invoke(new CacheSerializableRunnable(""Close client"") {
         public void run2() throws CacheException {
           Region region = getRootRegion().getSubregion(name);
           BridgeClient writer = (BridgeClient)
             region.getAttributes().getCacheWriter();
           writer.close();
           region.getAttributesMutator().setCacheWriter(null);
         }
       });


     // Stop server
     vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
       public void run() {
         stopBridgeServer(getCache());
       }
     });



   }",True
"   public void testBug36434() throws Exception
   {
     final String name = this.getName();
     final Host host = Host.getHost(0);
     VM vm0 = host.getVM(0);
     VM vm1 = host.getVM(1);

     final int numberOfEntries = 100;

     // Start server
     vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
         public void run2() throws CacheException {
           Properties config = new Properties();
           config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
           system = (InternalDistributedSystem) DistributedSystem.connect(config);
           AttributesFactory factory = new AttributesFactory();
           factory.setScope(Scope.LOCAL);
           createRegion(name, factory.createRegionAttributes());
           pause(1000);
           try {
             startBridgeServer(0, false);
           } catch (Exception ex) {
             fail(""While starting CacheServer"", ex);
           }
         }
       });

     // Initialize server region
     vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
         public void run2() throws CacheException {
           Region region = getRootRegion().getSubregion(name);
           for (int i=0; i<numberOfEntries; i++) {
             region.put(""key-""+i, new TestObject(i, ""ibm""));
           }
         }
       });

     final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
     final String host0 = getServerHostName(vm0.getHost());

     // Create client region in VM1
     vm1.invoke(new CacheSerializableRunnable(""Create region"") {
         public void run2() throws CacheException {
           Properties config = new Properties();
           config.setProperty(""mcast-port"", ""0"");
           system = (InternalDistributedSystem) DistributedSystem.connect(config);
           getCache();
           AttributesFactory factory = new AttributesFactory();
           factory.setScope(Scope.LOCAL);
           BridgeClient writer = new BridgeClient();
           Properties props = new Properties();
           props.setProperty(""endpoints"", ""server="" + host0 + "":"" +
                             port);
           props.setProperty(""establishCallbackConnection"", ""true"");
           writer.init(props);
           factory.setCacheWriter(writer);
           createRegion(name, factory.createRegionAttributes());
         }
       });


     // Execute client queries in VM1
     vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
         public void run2() throws CacheException {
           Region region = getRootRegion().getSubregion(name);
           String queryStrings [] ={""id<9"", ""selection<9"", ""important<9"",""\""select\""<9"" };
           for(int i =0 ; i <queryStrings.length;++i) {
             SelectResults results = null;

             try {
               results = region.query(queryStrings[i]);
             } catch (Exception e) {
               fail(""Failed executing "" + queryStrings[i], e);
             }
             assertEquals(9, results.size());
             String msg = ""results expected to be instance of ResultsBag,""
               + "" but was found to be is instance of '"";
             assertTrue(msg + results.getClass().getName() + ""'"",
                        results instanceof ResultsBag);
             assertTrue(results.asList().get(0) instanceof TestObject);
           }
         }
       });

       // Close client VM1
       vm1.invoke(new CacheSerializableRunnable(""Close client"") {
         public void run2() throws CacheException {
           Region region = getRootRegion().getSubregion(name);
           BridgeClient writer = (BridgeClient)
             region.getAttributes().getCacheWriter();
           writer.close();
           region.getAttributesMutator().setCacheWriter(null);
         }
       });


     // Stop server
     vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
       public void run() {
         stopBridgeServer(getCache());
       }
     });



   }",False
"    public void testBug36969() throws Exception
    {
      final String name = this.getName();
      final Host host = Host.getHost(0);
      VM vm0 = host.getVM(0);
      VM vm1 = host.getVM(1);

      final int numberOfEntries = 100;

      // Start server
      vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
          public void run2() throws CacheException {
            Properties config = new Properties();
            int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
            config.setProperty(""mcast-port"", String.valueOf(unusedPort));
            system = (InternalDistributedSystem) DistributedSystem.connect(config);
            AttributesFactory factory = new AttributesFactory();
            factory.setScope(Scope.LOCAL);
            final Region region = createRegion(name, factory.createRegionAttributes());
            QueryObserverHolder.setInstance(new QueryObserverAdapter() {
              public void afterQueryEvaluation(Object result) {
                //Destroy the region in the test
                region.close();
              }

            });
            pause(1000);
            try {
              startBridgeServer(0, false);
            } catch (Exception ex) {
              fail(""While starting CacheServer"", ex);
            }
          }
        });

      // Initialize server region
      vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
          public void run2() throws CacheException {
            Region region = getRootRegion().getSubregion(name);
            for (int i=0; i<numberOfEntries; i++) {
              region.put(""key-""+i, new TestObject(i, ""ibm""));
            }
          }
        });

      final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
      final String host0 = getServerHostName(vm0.getHost());

      // Create client region in VM1
      vm1.invoke(new CacheSerializableRunnable(""Create region"") {
          public void run2() throws CacheException {
            Properties config = new Properties();
            config.setProperty(""mcast-port"", ""0"");
            system = (InternalDistributedSystem) DistributedSystem.connect(config);
            getCache();
            AttributesFactory factory = new AttributesFactory();
            factory.setScope(Scope.LOCAL);
            BridgeClient writer = new BridgeClient();
            Properties props = new Properties();
            props.setProperty(""endpoints"", ""server="" + host0 + "":"" +
                              port);
            props.setProperty(""establishCallbackConnection"", ""true"");
            writer.init(props);
            factory.setCacheWriter(writer);
            createRegion(name, factory.createRegionAttributes());
          }
        });


      // Execute client queries in VM1
      vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
          public void run2() throws CacheException {
            Region region = getRootRegion().getSubregion(name);
            String queryStrings = ""id<9"";
//            SelectResults results = null;
              try {
                region.query(queryStrings);
                fail(""The query should have experienced RegionDestroyedException"");
              } catch (QueryInvocationTargetException qte) {
                //Ok test passed
              } catch(Exception e) {
                fail(""Failed executing query "" + queryStrings+ "" due  to unexpected Excecption"", e);
            }
          }
        });

      // Start server
      vm0.invoke(new CacheSerializableRunnable(""Create two regions"") {
          public void run2() throws CacheException {
            AttributesFactory factory = new AttributesFactory();
            factory.setScope(Scope.LOCAL);
            final Region region1 = createRegion(name, factory.createRegionAttributes());
            final Region region2 = createRegion(name+""_2"", factory.createRegionAttributes());
            QueryObserverHolder.setInstance(new QueryObserverAdapter() {
              public void afterQueryEvaluation(Object result) {
                //Destroy the region in the test
                region1.close();
              }

            });
            pause(1000);
            for (int i=0; i<numberOfEntries; i++) {
              region1.put(""key-""+i, new TestObject(i, ""ibm""));
              region2.put(""key-""+i, new TestObject(i, ""ibm""));
            }

          }
        });

   // Execute client queries in VM1
      vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
          public void run2() throws CacheException {
            Region region = getRootRegion().getSubregion(name);
            String queryString = ""select distinct * from /""+name+"",/""+name + ""_2"";
//            SelectResults results = null;
              try {
                region.query(queryString);
                fail(""The query should have experienced RegionDestroyedException"");
              } catch (QueryInvocationTargetException qte) {
                //Ok test passed
              } catch(Exception e) {
                fail(""Failed executing query "" + queryString+ "" due  to unexpected Excecption"", e);
            }
          }
        });

        // Close client VM1
        vm1.invoke(new CacheSerializableRunnable(""Close client"") {
          public void run2() throws CacheException {
            Region region = getRootRegion().getSubregion(name);
            BridgeClient writer = (BridgeClient)
              region.getAttributes().getCacheWriter();
            writer.close();
            region.getAttributesMutator().setCacheWriter(null);
          }
        });


      // Stop server
      vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
        public void run() {
          QueryObserverHolder.setInstance(new QueryObserverAdapter());
          stopBridgeServer(getCache());
        }
      });



    }",True
"    public void testBug36969() throws Exception
    {
      final String name = this.getName();
      final Host host = Host.getHost(0);
      VM vm0 = host.getVM(0);
      VM vm1 = host.getVM(1);

      final int numberOfEntries = 100;

      // Start server
      vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
          public void run2() throws CacheException {
            Properties config = new Properties();
            config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
            system = (InternalDistributedSystem) DistributedSystem.connect(config);
            AttributesFactory factory = new AttributesFactory();
            factory.setScope(Scope.LOCAL);
            final Region region = createRegion(name, factory.createRegionAttributes());
            QueryObserverHolder.setInstance(new QueryObserverAdapter() {
              public void afterQueryEvaluation(Object result) {
                //Destroy the region in the test
                region.close();
              }

            });
            pause(1000);
            try {
              startBridgeServer(0, false);
            } catch (Exception ex) {
              fail(""While starting CacheServer"", ex);
            }
          }
        });

      // Initialize server region
      vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
          public void run2() throws CacheException {
            Region region = getRootRegion().getSubregion(name);
            for (int i=0; i<numberOfEntries; i++) {
              region.put(""key-""+i, new TestObject(i, ""ibm""));
            }
          }
        });

      final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
      final String host0 = getServerHostName(vm0.getHost());

      // Create client region in VM1
      vm1.invoke(new CacheSerializableRunnable(""Create region"") {
          public void run2() throws CacheException {
            Properties config = new Properties();
            config.setProperty(""mcast-port"", ""0"");
            system = (InternalDistributedSystem) DistributedSystem.connect(config);
            getCache();
            AttributesFactory factory = new AttributesFactory();
            factory.setScope(Scope.LOCAL);
            BridgeClient writer = new BridgeClient();
            Properties props = new Properties();
            props.setProperty(""endpoints"", ""server="" + host0 + "":"" +
                              port);
            props.setProperty(""establishCallbackConnection"", ""true"");
            writer.init(props);
            factory.setCacheWriter(writer);
            createRegion(name, factory.createRegionAttributes());
          }
        });


      // Execute client queries in VM1
      vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
          public void run2() throws CacheException {
            Region region = getRootRegion().getSubregion(name);
            String queryStrings = ""id<9"";
//            SelectResults results = null;
              try {
                region.query(queryStrings);
                fail(""The query should have experienced RegionDestroyedException"");
              } catch (QueryInvocationTargetException qte) {
                //Ok test passed
              } catch(Exception e) {
                fail(""Failed executing query "" + queryStrings+ "" due  to unexpected Excecption"", e);
            }
          }
        });

      // Start server
      vm0.invoke(new CacheSerializableRunnable(""Create two regions"") {
          public void run2() throws CacheException {
            AttributesFactory factory = new AttributesFactory();
            factory.setScope(Scope.LOCAL);
            final Region region1 = createRegion(name, factory.createRegionAttributes());
            final Region region2 = createRegion(name+""_2"", factory.createRegionAttributes());
            QueryObserverHolder.setInstance(new QueryObserverAdapter() {
              public void afterQueryEvaluation(Object result) {
                //Destroy the region in the test
                region1.close();
              }

            });
            pause(1000);
            for (int i=0; i<numberOfEntries; i++) {
              region1.put(""key-""+i, new TestObject(i, ""ibm""));
              region2.put(""key-""+i, new TestObject(i, ""ibm""));
            }

          }
        });

   // Execute client queries in VM1
      vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
          public void run2() throws CacheException {
            Region region = getRootRegion().getSubregion(name);
            String queryString = ""select distinct * from /""+name+"",/""+name + ""_2"";
//            SelectResults results = null;
              try {
                region.query(queryString);
                fail(""The query should have experienced RegionDestroyedException"");
              } catch (QueryInvocationTargetException qte) {
                //Ok test passed
              } catch(Exception e) {
                fail(""Failed executing query "" + queryString+ "" due  to unexpected Excecption"", e);
            }
          }
        });

        // Close client VM1
        vm1.invoke(new CacheSerializableRunnable(""Close client"") {
          public void run2() throws CacheException {
            Region region = getRootRegion().getSubregion(name);
            BridgeClient writer = (BridgeClient)
              region.getAttributes().getCacheWriter();
            writer.close();
            region.getAttributesMutator().setCacheWriter(null);
          }
        });


      // Stop server
      vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
        public void run() {
          QueryObserverHolder.setInstance(new QueryObserverAdapter());
          stopBridgeServer(getCache());
        }
      });



    }",False
"  public void testRemoteImportQueries() throws CacheException {

    final String name = this.getName();
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
          config.setProperty(""mcast-port"", String.valueOf(unusedPort));
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          createRegion(name, factory.create());
          pause(1000);
          try {
            startBridgeServer(0, false);
          } catch (Exception ex) {
            fail(""While starting CacheServer"", ex);
          }
        }
      });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          for (int i=0; i<numberOfEntries; i++) {
            region.put(""key-""+i, new TestObject(i, ""ibm""));
          }
        }
      });

    // Create client region
    final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          getCache();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          
          BridgeTestCase.configureConnectionPool(factory, host0, port,-1, true, -1, -1, null);
          createRegion(name, factory.create());
        }
      });

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          String queryString = null;
          SelectResults results = null;

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct * from "" + region.getFullPath();
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct * from "" + region.getFullPath() + "" where ticker = 'ibm'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct * from "" + region.getFullPath() + "" where ticker = 'IBM'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(0, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct * from "" + region.getFullPath() + "" where price > 49"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries/2, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct * from "" + region.getFullPath() + "" where price = 50"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct * from "" + region.getFullPath() + "" where ticker = 'ibm' and price = 50"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates());
        }
      });


    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",True
"  public void testRemoteImportQueries() throws CacheException {

    final String name = this.getName();
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          createRegion(name, factory.create());
          pause(1000);
          try {
            startBridgeServer(0, false);
          } catch (Exception ex) {
            fail(""While starting CacheServer"", ex);
          }
        }
      });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          for (int i=0; i<numberOfEntries; i++) {
            region.put(""key-""+i, new TestObject(i, ""ibm""));
          }
        }
      });

    // Create client region
    final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          getCache();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          
          BridgeTestCase.configureConnectionPool(factory, host0, port,-1, true, -1, -1, null);
          createRegion(name, factory.create());
        }
      });

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          String queryString = null;
          SelectResults results = null;

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct * from "" + region.getFullPath();
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct * from "" + region.getFullPath() + "" where ticker = 'ibm'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct * from "" + region.getFullPath() + "" where ticker = 'IBM'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(0, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct * from "" + region.getFullPath() + "" where price > 49"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries/2, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct * from "" + region.getFullPath() + "" where price = 50"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates());

          queryString = ""import com.gemstone.gemfire.admin.RemoteQueryDUnitTest.TestObject; select distinct * from "" + region.getFullPath() + "" where ticker = 'ibm' and price = 50"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates());
        }
      });


    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",False
"  public void testRemotePredicateQueries() throws CacheException {

    final String name = this.getName();
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
          config.setProperty(""mcast-port"", String.valueOf(unusedPort));
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          createRegion(name, factory.create());
          pause(1000);
          try {
            startBridgeServer(0, false);
          } catch (Exception ex) {
            fail(""While starting CacheServer"", ex);
          }
        }
      });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          for (int i=0; i<numberOfEntries; i++) {
            region.put(""key-""+i, new TestObject(i, ""ibm""));
          }
        }
      });

    // Create client region
    final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          getCache();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          BridgeTestCase.configureConnectionPool(factory, host0, port,-1, true, -1, -1, null);
          createRegion(name, factory.create());
        }
      });

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          String queryString = null;
          SelectResults results = null;

          queryString = ""ticker = 'ibm'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          assertTrue(results.getClass() == ResultsBag.class);
          assertTrue(results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());

          queryString = ""ticker = 'IBM'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(0, results.size());
          assertTrue(results.getClass() == ResultsBag.class);
          assertTrue(results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());

          queryString = ""price > 49"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries/2, results.size());
          assertTrue(results.getClass() == ResultsBag.class);
          assertTrue(results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());

          queryString = ""price = 50"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(results.getClass() == ResultsBag.class);
          assertTrue(results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());

          queryString = ""ticker = 'ibm' and price = 50"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(results.getClass() == ResultsBag.class);
          assertTrue(results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());

          /* Non-distinct order by query not yet supported
          queryString = ""id < 101 ORDER BY id"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
        }
          assertEquals(100, results.size());
          assertTrue(results instanceof ResultsCollectionWrapper);
          IdComparator comparator = new IdComparator();
          Object[] resultsArray = results.toArray();
          for (int i=0; i<resultsArray.length; i++) {
            if (i+1 != resultsArray.length) {
              // The id of the current element in the result set must be less
              // than the id of the next one to pass.
              assertTrue(""The id for "" + resultsArray[i] + "" should be less than the id for "" + resultsArray[i+1], comparator.compare(resultsArray[i], resultsArray[i+1]) == -1);
            }
          }
          */
        }
      });


    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",True
"  public void testRemotePredicateQueries() throws CacheException {

    final String name = this.getName();
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          createRegion(name, factory.create());
          pause(1000);
          try {
            startBridgeServer(0, false);
          } catch (Exception ex) {
            fail(""While starting CacheServer"", ex);
          }
        }
      });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          for (int i=0; i<numberOfEntries; i++) {
            region.put(""key-""+i, new TestObject(i, ""ibm""));
          }
        }
      });

    // Create client region
    final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          getCache();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          BridgeTestCase.configureConnectionPool(factory, host0, port,-1, true, -1, -1, null);
          createRegion(name, factory.create());
        }
      });

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          String queryString = null;
          SelectResults results = null;

          queryString = ""ticker = 'ibm'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          assertTrue(results.getClass() == ResultsBag.class);
          assertTrue(results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());

          queryString = ""ticker = 'IBM'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(0, results.size());
          assertTrue(results.getClass() == ResultsBag.class);
          assertTrue(results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());

          queryString = ""price > 49"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries/2, results.size());
          assertTrue(results.getClass() == ResultsBag.class);
          assertTrue(results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());

          queryString = ""price = 50"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(results.getClass() == ResultsBag.class);
          assertTrue(results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());

          queryString = ""ticker = 'ibm' and price = 50"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(results.getClass() == ResultsBag.class);
          assertTrue(results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());

          /* Non-distinct order by query not yet supported
          queryString = ""id < 101 ORDER BY id"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
        }
          assertEquals(100, results.size());
          assertTrue(results instanceof ResultsCollectionWrapper);
          IdComparator comparator = new IdComparator();
          Object[] resultsArray = results.toArray();
          for (int i=0; i<resultsArray.length; i++) {
            if (i+1 != resultsArray.length) {
              // The id of the current element in the result set must be less
              // than the id of the next one to pass.
              assertTrue(""The id for "" + resultsArray[i] + "" should be less than the id for "" + resultsArray[i+1], comparator.compare(resultsArray[i], resultsArray[i+1]) == -1);
            }
          }
          */
        }
      });


    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",False
"  public void testRemoteBridgeClientQueries() throws CacheException {

    final String name = this.getName();
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    VM vm2 = host.getVM(2);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
          config.setProperty(""mcast-port"", String.valueOf(unusedPort));
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          createRegion(name, factory.create());
          pause(1000);
          try {
            startBridgeServer(0, false);
          } catch (Exception ex) {
            fail(""While starting CacheServer"", ex);
          }
        }
      });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          for (int i=0; i<numberOfEntries; i++) {
            region.put(""key-""+i, new TestObject(i, ""ibm""));
          }
        }
      });

    final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());

    // Create client region in VM1
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          getCache();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          BridgeClient writer = new BridgeClient();
          Properties props = new Properties();
          props.setProperty(""endpoints"", ""server="" + host0 + "":"" +
                            port);
          props.setProperty(""establishCallbackConnection"", ""true"");
          writer.init(props);
          factory.setCacheWriter(writer);
          createRegion(name, factory.create());
        }
      });

    // Create client region in VM2
    vm2.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          getCache();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          BridgeClient loader = new BridgeClient();
          Properties props = new Properties();
          props.setProperty(""endpoints"", ""server="" + host0 + "":"" +
                            port);
          props.setProperty(""establishCallbackConnection"", ""true"");
          loader.init(props);
          factory.setCacheLoader(loader);
          createRegion(name, factory.create());
        }
      });

    // Execute client queries in VM1
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          String queryString = null;
          SelectResults results = null;

          queryString = ""SELECT DISTINCT itr.value FROM "" + region.getFullPath() + "".entries itr where itr.key = 'key-1'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());
          assertTrue(results.asList().get(0) instanceof TestObject);

          queryString = ""SELECT DISTINCT itr.key FROM "" + region.getFullPath() + "".entries itr where itr.key = 'key-1'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());
          assertEquals(""key-1"", results.asList().get(0));
        }
      });

    // Execute client queries in VM2
    vm2.invoke(new CacheSerializableRunnable(""Execute queries"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          String queryString = null;
          SelectResults results = null;

          queryString = ""SELECT DISTINCT itr.value FROM "" + region.getFullPath() + "".entries itr where itr.key = 'key-1'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());
          assertTrue(results.asList().get(0) instanceof TestObject);

          queryString = ""SELECT DISTINCT itr.key FROM "" + region.getFullPath() + "".entries itr where itr.key = 'key-1'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());
          assertEquals(""key-1"", results.asList().get(0));
        }
      });

      // Close client VM1
      vm1.invoke(new CacheSerializableRunnable(""Close client"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          BridgeClient writer = (BridgeClient)
            region.getAttributes().getCacheWriter();
          writer.close();
          region.getAttributesMutator().setCacheWriter(null);
        }
      });

      // Close client VM2
      vm2.invoke(new CacheSerializableRunnable(""Close client"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          BridgeClient loader = (BridgeClient)
            region.getAttributes().getCacheLoader();
          loader.close();
          region.getAttributesMutator().setCacheLoader(null);
        }
      });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",True
"  public void testRemoteBridgeClientQueries() throws CacheException {

    final String name = this.getName();
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    VM vm2 = host.getVM(2);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          createRegion(name, factory.create());
          pause(1000);
          try {
            startBridgeServer(0, false);
          } catch (Exception ex) {
            fail(""While starting CacheServer"", ex);
          }
        }
      });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          for (int i=0; i<numberOfEntries; i++) {
            region.put(""key-""+i, new TestObject(i, ""ibm""));
          }
        }
      });

    final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());

    // Create client region in VM1
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          getCache();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          BridgeClient writer = new BridgeClient();
          Properties props = new Properties();
          props.setProperty(""endpoints"", ""server="" + host0 + "":"" +
                            port);
          props.setProperty(""establishCallbackConnection"", ""true"");
          writer.init(props);
          factory.setCacheWriter(writer);
          createRegion(name, factory.create());
        }
      });

    // Create client region in VM2
    vm2.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          getCache();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          BridgeClient loader = new BridgeClient();
          Properties props = new Properties();
          props.setProperty(""endpoints"", ""server="" + host0 + "":"" +
                            port);
          props.setProperty(""establishCallbackConnection"", ""true"");
          loader.init(props);
          factory.setCacheLoader(loader);
          createRegion(name, factory.create());
        }
      });

    // Execute client queries in VM1
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          String queryString = null;
          SelectResults results = null;

          queryString = ""SELECT DISTINCT itr.value FROM "" + region.getFullPath() + "".entries itr where itr.key = 'key-1'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());
          assertTrue(results.asList().get(0) instanceof TestObject);

          queryString = ""SELECT DISTINCT itr.key FROM "" + region.getFullPath() + "".entries itr where itr.key = 'key-1'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());
          assertEquals(""key-1"", results.asList().get(0));
        }
      });

    // Execute client queries in VM2
    vm2.invoke(new CacheSerializableRunnable(""Execute queries"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          String queryString = null;
          SelectResults results = null;

          queryString = ""SELECT DISTINCT itr.value FROM "" + region.getFullPath() + "".entries itr where itr.key = 'key-1'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());
          assertTrue(results.asList().get(0) instanceof TestObject);

          queryString = ""SELECT DISTINCT itr.key FROM "" + region.getFullPath() + "".entries itr where itr.key = 'key-1'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && !results.getCollectionType().getElementType().isStructType());
          assertEquals(""key-1"", results.asList().get(0));
        }
      });

      // Close client VM1
      vm1.invoke(new CacheSerializableRunnable(""Close client"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          BridgeClient writer = (BridgeClient)
            region.getAttributes().getCacheWriter();
          writer.close();
          region.getAttributesMutator().setCacheWriter(null);
        }
      });

      // Close client VM2
      vm2.invoke(new CacheSerializableRunnable(""Close client"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          BridgeClient loader = (BridgeClient)
            region.getAttributes().getCacheLoader();
          loader.close();
          region.getAttributesMutator().setCacheLoader(null);
        }
      });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",False
"  public void testRemoteFullRegionQueries() throws CacheException {

    final String name = this.getName();
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
          config.setProperty(""mcast-port"", String.valueOf(unusedPort));
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          createRegion(name, factory.create());
          pause(1000);
          try {
            startBridgeServer(0, false);
          } catch (Exception ex) {
            fail(""While starting CacheServer"", ex);
          }
        }
      });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          for (int i=0; i<numberOfEntries; i++) {
            region.put(""key-""+i, new TestObject(i, ""ibm""));
          }
        }
      });

    // Create client region
    final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          getCache();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          BridgeTestCase.configureConnectionPool(factory, host0, port,-1, true, -1, -1, null);
          createRegion(name, factory.create());
        }
      });

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          String queryString = null;
          SelectResults results = null;
          Comparator comparator = null;
          Object[] resultsArray = null;

          // value query
          queryString = ""SELECT DISTINCT itr.value FROM "" + region.getFullPath() + "".entries itr where itr.key = 'key-1'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates());
          assertTrue(results.asList().get(0) instanceof TestObject);

          // key query
          queryString = ""SELECT DISTINCT itr.key FROM "" + region.getFullPath() + "".entries itr where itr.key = 'key-1'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates());
          assertEquals(""key-1"", results.asList().get(0));

          // order by value query
          queryString = ""SELECT DISTINCT * FROM "" + region.getFullPath() + "" WHERE id < 101 ORDER BY id"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
        }
          assertEquals(numberOfEntries, results.size());
          // All order-by query results are stored in a ResultsCollectionWrapper
          // wrapping a list, so the assertion below is not correct even though
          // it should be.
          //assertTrue(!results.getCollectionType().allowsDuplicates());
          assertTrue(results.getCollectionType().isOrdered());
          comparator = new IdComparator();
          resultsArray = results.toArray();
          for (int i=0; i<resultsArray.length; i++) {
            if (i+1 != resultsArray.length) {
              // The id of the current element in the result set must be less
              // than the id of the next one to pass.
              assertTrue(""The id for "" + resultsArray[i] + "" should be less than the id for "" + resultsArray[i+1], comparator.compare(resultsArray[i], resultsArray[i+1]) == -1);
            }
          }

          // order by struct query
          queryString = ""SELECT DISTINCT id, ticker, price FROM "" + region.getFullPath() + "" WHERE id < 101 ORDER BY id"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          // All order-by query results are stored in a ResultsCollectionWrapper
          // wrapping a list, so the assertion below is not correct even though
          // it should be.
          //assertTrue(!results.getCollectionType().allowsDuplicates());
          assertTrue(results.getCollectionType().isOrdered());
          comparator = new StructIdComparator();
          resultsArray = results.toArray();
          for (int i=0; i<resultsArray.length; i++) {
            if (i+1 != resultsArray.length) {
              // The id of the current element in the result set must be less
              // than the id of the next one to pass.
              assertTrue(""The id for "" + resultsArray[i] + "" should be less than the id for "" + resultsArray[i+1], comparator.compare(resultsArray[i], resultsArray[i+1]) == -1);
            }
          }

          // size query
          queryString = ""(SELECT DISTINCT * FROM "" + region.getFullPath() + "" WHERE id < 101).size"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          Object result = results.iterator().next();
          assertTrue(result instanceof Integer);
          int resultInt = ((Integer) result).intValue();
          assertEquals(resultInt, 100);

          // query with leading/trailing spaces
          queryString = "" SELECT DISTINCT itr.key FROM "" + region.getFullPath() + "".entries itr where itr.key = 'key-1' "";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertEquals(""key-1"", results.asList().get(0));
        }
      });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",True
"  public void testRemoteFullRegionQueries() throws CacheException {

    final String name = this.getName();
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          createRegion(name, factory.create());
          pause(1000);
          try {
            startBridgeServer(0, false);
          } catch (Exception ex) {
            fail(""While starting CacheServer"", ex);
          }
        }
      });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          for (int i=0; i<numberOfEntries; i++) {
            region.put(""key-""+i, new TestObject(i, ""ibm""));
          }
        }
      });

    // Create client region
    final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          getCache();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          BridgeTestCase.configureConnectionPool(factory, host0, port,-1, true, -1, -1, null);
          createRegion(name, factory.create());
        }
      });

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          String queryString = null;
          SelectResults results = null;
          Comparator comparator = null;
          Object[] resultsArray = null;

          // value query
          queryString = ""SELECT DISTINCT itr.value FROM "" + region.getFullPath() + "".entries itr where itr.key = 'key-1'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates());
          assertTrue(results.asList().get(0) instanceof TestObject);

          // key query
          queryString = ""SELECT DISTINCT itr.key FROM "" + region.getFullPath() + "".entries itr where itr.key = 'key-1'"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates());
          assertEquals(""key-1"", results.asList().get(0));

          // order by value query
          queryString = ""SELECT DISTINCT * FROM "" + region.getFullPath() + "" WHERE id < 101 ORDER BY id"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
        }
          assertEquals(numberOfEntries, results.size());
          // All order-by query results are stored in a ResultsCollectionWrapper
          // wrapping a list, so the assertion below is not correct even though
          // it should be.
          //assertTrue(!results.getCollectionType().allowsDuplicates());
          assertTrue(results.getCollectionType().isOrdered());
          comparator = new IdComparator();
          resultsArray = results.toArray();
          for (int i=0; i<resultsArray.length; i++) {
            if (i+1 != resultsArray.length) {
              // The id of the current element in the result set must be less
              // than the id of the next one to pass.
              assertTrue(""The id for "" + resultsArray[i] + "" should be less than the id for "" + resultsArray[i+1], comparator.compare(resultsArray[i], resultsArray[i+1]) == -1);
            }
          }

          // order by struct query
          queryString = ""SELECT DISTINCT id, ticker, price FROM "" + region.getFullPath() + "" WHERE id < 101 ORDER BY id"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(numberOfEntries, results.size());
          // All order-by query results are stored in a ResultsCollectionWrapper
          // wrapping a list, so the assertion below is not correct even though
          // it should be.
          //assertTrue(!results.getCollectionType().allowsDuplicates());
          assertTrue(results.getCollectionType().isOrdered());
          comparator = new StructIdComparator();
          resultsArray = results.toArray();
          for (int i=0; i<resultsArray.length; i++) {
            if (i+1 != resultsArray.length) {
              // The id of the current element in the result set must be less
              // than the id of the next one to pass.
              assertTrue(""The id for "" + resultsArray[i] + "" should be less than the id for "" + resultsArray[i+1], comparator.compare(resultsArray[i], resultsArray[i+1]) == -1);
            }
          }

          // size query
          queryString = ""(SELECT DISTINCT * FROM "" + region.getFullPath() + "" WHERE id < 101).size"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          Object result = results.iterator().next();
          assertTrue(result instanceof Integer);
          int resultInt = ((Integer) result).intValue();
          assertEquals(resultInt, 100);

          // query with leading/trailing spaces
          queryString = "" SELECT DISTINCT itr.key FROM "" + region.getFullPath() + "".entries itr where itr.key = 'key-1' "";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          assertEquals(1, results.size());
          assertEquals(""key-1"", results.asList().get(0));
        }
      });

    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",False
"  public void __testRemoteComplexQueries() throws CacheException {

    final String name = this.getName();
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
//    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
          config.setProperty(""mcast-port"", String.valueOf(unusedPort));
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          createRegion(name, factory.create());
          pause(1000);
          try {
            startBridgeServer(0, false);
          } catch (Exception ex) {
            fail(""While starting CacheServer"", ex);
          }
        }
      });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          Portfolio portfolio = null;
          Position position1 = null;
          Position position2 = null;
          Properties portfolioProperties= null;
          Properties position1Properties = null;
          Properties position2Properties = null;

          // Create portfolio 1
          portfolio = new Portfolio();
          portfolioProperties = new Properties();
          portfolioProperties.put(""id"", new Integer(1));
          portfolioProperties.put(""type"", ""type1"");
          portfolioProperties.put(""status"", ""active"");

          position1 = new Position();
          position1Properties = new Properties();
          position1Properties.put(""secId"", ""SUN"");
          position1Properties.put(""qty"", new Double(34000.0));
          position1Properties.put(""mktValue"", new Double(24.42));
          position1.init(position1Properties);
          portfolioProperties.put(""position1"", position1);

          position2 = new Position();
          position2Properties = new Properties();
          position2Properties.put(""secId"", ""IBM"");
          position2Properties.put(""qty"", new Double(8765.0));
          position2Properties.put(""mktValue"", new Double(34.29));
          position2.init(position2Properties);
          portfolioProperties.put(""position2"", position2);

          portfolio.init(portfolioProperties);
          region.put(new Integer(1), portfolio);

          // Create portfolio 2
          portfolio = new Portfolio();
          portfolioProperties = new Properties();
          portfolioProperties.put(""id"", new Integer(2));
          portfolioProperties.put(""type"", ""type2"");
          portfolioProperties.put(""status"", ""inactive"");

          position1 = new Position();
          position1Properties = new Properties();
          position1Properties.put(""secId"", ""YHOO"");
          position1Properties.put(""qty"", new Double(9834.0));
          position1Properties.put(""mktValue"", new Double(12.925));
          position1.init(position1Properties);
          portfolioProperties.put(""position1"", position1);

          position2 = new Position();
          position2Properties = new Properties();
          position2Properties.put(""secId"", ""GOOG"");
          position2Properties.put(""qty"", new Double(12176.0));
          position2Properties.put(""mktValue"", new Double(21.972));
          position2.init(position2Properties);
          portfolioProperties.put(""position2"", position2);

          portfolio.init(portfolioProperties);
          region.put(new Integer(2), portfolio);

          // Create portfolio 3
          portfolio = new Portfolio();
          portfolioProperties = new Properties();
          portfolioProperties.put(""id"", new Integer(3));
          portfolioProperties.put(""type"", ""type3"");
          portfolioProperties.put(""status"", ""active"");

          position1 = new Position();
          position1Properties = new Properties();
          position1Properties.put(""secId"", ""MSFT"");
          position1Properties.put(""qty"", new Double(98327.0));
          position1Properties.put(""mktValue"", new Double(23.32));
          position1.init(position1Properties);
          portfolioProperties.put(""position1"", position1);

          position2 = new Position();
          position2Properties = new Properties();
          position2Properties.put(""secId"", ""AOL"");
          position2Properties.put(""qty"", new Double(978.0));
          position2Properties.put(""mktValue"", new Double(40.373));
          position2.init(position2Properties);
          portfolioProperties.put(""position2"", position2);

          portfolio.init(portfolioProperties);
          region.put(new Integer(3), portfolio);

          // Create portfolio 4
          portfolio = new Portfolio();
          portfolioProperties = new Properties();
          portfolioProperties.put(""id"", new Integer(4));
          portfolioProperties.put(""type"", ""type1"");
          portfolioProperties.put(""status"", ""inactive"");

          position1 = new Position();
          position1Properties = new Properties();
          position1Properties.put(""secId"", ""APPL"");
          position1Properties.put(""qty"", new Double(90.0));
          position1Properties.put(""mktValue"", new Double(67.356572));
          position1.init(position1Properties);
          portfolioProperties.put(""position1"", position1);

          position2 = new Position();
          position2Properties = new Properties();
          position2Properties.put(""secId"", ""ORCL"");
          position2Properties.put(""qty"", new Double(376.0));
          position2Properties.put(""mktValue"", new Double(101.34));
          position2.init(position2Properties);
          portfolioProperties.put(""position2"", position2);

          portfolio.init(portfolioProperties);
          region.put(new Integer(4), portfolio);
        }
      });

    // Create client region
    final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          getCache();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          BridgeTestCase.configureConnectionPool(factory, host0, port,-1, true, -1, -1, null);
          createRegion(name, factory.create());
        }
      });

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          String queryString = null;
          SelectResults results = null;

          queryString =
            ""IMPORT cacheRunner.Position; "" +
            ""SELECT DISTINCT id, status FROM "" + region.getFullPath() +
            ""WHERE NOT (SELECT DISTINCT * FROM positions.values posnVal TYPE Position "" +
            ""WHERE posnVal.secId='AOL' OR posnVal.secId='SAP').isEmpty"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          getLogWriter().fine(""size: "" + results.size());
          //assertEquals(numberOfEntries, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());
        }
      });


    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",True
"  public void __testRemoteComplexQueries() throws CacheException {

    final String name = this.getName();
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
//    final int numberOfEntries = 100;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          createRegion(name, factory.create());
          pause(1000);
          try {
            startBridgeServer(0, false);
          } catch (Exception ex) {
            fail(""While starting CacheServer"", ex);
          }
        }
      });

    // Initialize server region
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          Portfolio portfolio = null;
          Position position1 = null;
          Position position2 = null;
          Properties portfolioProperties= null;
          Properties position1Properties = null;
          Properties position2Properties = null;

          // Create portfolio 1
          portfolio = new Portfolio();
          portfolioProperties = new Properties();
          portfolioProperties.put(""id"", new Integer(1));
          portfolioProperties.put(""type"", ""type1"");
          portfolioProperties.put(""status"", ""active"");

          position1 = new Position();
          position1Properties = new Properties();
          position1Properties.put(""secId"", ""SUN"");
          position1Properties.put(""qty"", new Double(34000.0));
          position1Properties.put(""mktValue"", new Double(24.42));
          position1.init(position1Properties);
          portfolioProperties.put(""position1"", position1);

          position2 = new Position();
          position2Properties = new Properties();
          position2Properties.put(""secId"", ""IBM"");
          position2Properties.put(""qty"", new Double(8765.0));
          position2Properties.put(""mktValue"", new Double(34.29));
          position2.init(position2Properties);
          portfolioProperties.put(""position2"", position2);

          portfolio.init(portfolioProperties);
          region.put(new Integer(1), portfolio);

          // Create portfolio 2
          portfolio = new Portfolio();
          portfolioProperties = new Properties();
          portfolioProperties.put(""id"", new Integer(2));
          portfolioProperties.put(""type"", ""type2"");
          portfolioProperties.put(""status"", ""inactive"");

          position1 = new Position();
          position1Properties = new Properties();
          position1Properties.put(""secId"", ""YHOO"");
          position1Properties.put(""qty"", new Double(9834.0));
          position1Properties.put(""mktValue"", new Double(12.925));
          position1.init(position1Properties);
          portfolioProperties.put(""position1"", position1);

          position2 = new Position();
          position2Properties = new Properties();
          position2Properties.put(""secId"", ""GOOG"");
          position2Properties.put(""qty"", new Double(12176.0));
          position2Properties.put(""mktValue"", new Double(21.972));
          position2.init(position2Properties);
          portfolioProperties.put(""position2"", position2);

          portfolio.init(portfolioProperties);
          region.put(new Integer(2), portfolio);

          // Create portfolio 3
          portfolio = new Portfolio();
          portfolioProperties = new Properties();
          portfolioProperties.put(""id"", new Integer(3));
          portfolioProperties.put(""type"", ""type3"");
          portfolioProperties.put(""status"", ""active"");

          position1 = new Position();
          position1Properties = new Properties();
          position1Properties.put(""secId"", ""MSFT"");
          position1Properties.put(""qty"", new Double(98327.0));
          position1Properties.put(""mktValue"", new Double(23.32));
          position1.init(position1Properties);
          portfolioProperties.put(""position1"", position1);

          position2 = new Position();
          position2Properties = new Properties();
          position2Properties.put(""secId"", ""AOL"");
          position2Properties.put(""qty"", new Double(978.0));
          position2Properties.put(""mktValue"", new Double(40.373));
          position2.init(position2Properties);
          portfolioProperties.put(""position2"", position2);

          portfolio.init(portfolioProperties);
          region.put(new Integer(3), portfolio);

          // Create portfolio 4
          portfolio = new Portfolio();
          portfolioProperties = new Properties();
          portfolioProperties.put(""id"", new Integer(4));
          portfolioProperties.put(""type"", ""type1"");
          portfolioProperties.put(""status"", ""inactive"");

          position1 = new Position();
          position1Properties = new Properties();
          position1Properties.put(""secId"", ""APPL"");
          position1Properties.put(""qty"", new Double(90.0));
          position1Properties.put(""mktValue"", new Double(67.356572));
          position1.init(position1Properties);
          portfolioProperties.put(""position1"", position1);

          position2 = new Position();
          position2Properties = new Properties();
          position2Properties.put(""secId"", ""ORCL"");
          position2Properties.put(""qty"", new Double(376.0));
          position2Properties.put(""mktValue"", new Double(101.34));
          position2.init(position2Properties);
          portfolioProperties.put(""position2"", position2);

          portfolio.init(portfolioProperties);
          region.put(new Integer(4), portfolio);
        }
      });

    // Create client region
    final int port = vm0.invokeInt(RemoteQueryDUnitTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          system = (InternalDistributedSystem) DistributedSystem.connect(config);
          getCache();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          BridgeTestCase.configureConnectionPool(factory, host0, port,-1, true, -1, -1, null);
          createRegion(name, factory.create());
        }
      });

    // Execute client queries
    vm1.invoke(new CacheSerializableRunnable(""Execute queries"") {
        public void run2() throws CacheException {
          Region region = getRootRegion().getSubregion(name);
          String queryString = null;
          SelectResults results = null;

          queryString =
            ""IMPORT cacheRunner.Position; "" +
            ""SELECT DISTINCT id, status FROM "" + region.getFullPath() +
            ""WHERE NOT (SELECT DISTINCT * FROM positions.values posnVal TYPE Position "" +
            ""WHERE posnVal.secId='AOL' OR posnVal.secId='SAP').isEmpty"";
          try {
            results = region.query(queryString);
          } catch (Exception e) {
            fail(""Failed executing "" + queryString, e);
          }
          getLogWriter().fine(""size: "" + results.size());
          //assertEquals(numberOfEntries, results.size());
          assertTrue(!results.getCollectionType().allowsDuplicates() && results.getCollectionType().getElementType().isStructType());
        }
      });


    // Stop server
    vm0.invoke(new SerializableRunnable(""Stop CacheServer"") {
      public void run() {
        stopBridgeServer(getCache());
      }
    });
  }",False
"  private void doCriticalMemoryHitWithIndexTest(final String regionName, boolean createPR, final int criticalThreshold, final boolean disabledQueryMonitorForLowMem, final int queryTimeout, final boolean hitCriticalThreshold, final String indexType)
      throws Exception {
    //create region on the server
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(2);
    final VM client = host.getVM(1);
    final int numObjects = 200;
    try  {
      final int[] port = AvailablePortHelper.getRandomAvailableTCPPorts(2);
      final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
      startCacheServer(server1, port[0], mcastPort, 
          criticalThreshold, disabledQueryMonitorForLowMem, queryTimeout,
          regionName, createPR, 0);
      startCacheServer(server2, port[1], mcastPort, 
          criticalThreshold, true, -1,
          regionName, createPR, 0);
      
      startClient(client, server1, port[0], regionName);
      populateData(server1, regionName, numObjects);
     
      createCancelDuringGatherTestHook(server1);
      server1.invoke(new SerializableCallable(""create index"") {
          public Object call() {
            QueryService qs = null;
            try {
              qs = getCache().getQueryService();
              Index index = null;
              if (indexType.equals(""compact"")) {
                index = qs.createIndex(""newIndex"", ""ID"", ""/"" + regionName);
              }
              else if (indexType.equals(""hash"")){
                index = qs.createHashIndex(""newIndex"", ""ID"", ""/"" + regionName);
              }
              assertNotNull(index);
              assertTrue(((CancelDuringGatherHook)DefaultQuery.testHook).triggeredOOME);
              
              if (hitCriticalThreshold && !disabledQueryMonitorForLowMem) {
                throw new CacheException(""Should have hit low memory""){};
              }
              assertEquals(1, qs.getIndexes().size());
            }
            catch (Exception e) {
              if (e instanceof IndexInvalidException) {
                if (!hitCriticalThreshold || disabledQueryMonitorForLowMem) {
                  throw new CacheException(""Should not have run into low memory exception""){};
                }
              }
              else {
                throw new CacheException(e){};
              }
            }
            return 0;
          }
      });
    }
    finally {
      stopServer(server1);
      stopServer(server2);
    }
  }",True
"  private void doCriticalMemoryHitWithIndexTest(final String regionName, boolean createPR, final int criticalThreshold, final boolean disabledQueryMonitorForLowMem, final int queryTimeout, final boolean hitCriticalThreshold, final String indexType)
      throws Exception {
    //create region on the server
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(2);
    final VM client = host.getVM(1);
    final int numObjects = 200;
    try  {
      final int[] port = AvailablePortHelper.getRandomAvailableTCPPorts(2);
      startCacheServer(server1, port[0],  
          criticalThreshold, disabledQueryMonitorForLowMem, queryTimeout,
          regionName, createPR, 0);
      startCacheServer(server2, port[1],  
          criticalThreshold, true, -1,
          regionName, createPR, 0);
      
      startClient(client, server1, port[0], regionName);
      populateData(server1, regionName, numObjects);
     
      createCancelDuringGatherTestHook(server1);
      server1.invoke(new SerializableCallable(""create index"") {
          public Object call() {
            QueryService qs = null;
            try {
              qs = getCache().getQueryService();
              Index index = null;
              if (indexType.equals(""compact"")) {
                index = qs.createIndex(""newIndex"", ""ID"", ""/"" + regionName);
              }
              else if (indexType.equals(""hash"")){
                index = qs.createHashIndex(""newIndex"", ""ID"", ""/"" + regionName);
              }
              assertNotNull(index);
              assertTrue(((CancelDuringGatherHook)DefaultQuery.testHook).triggeredOOME);
              
              if (hitCriticalThreshold && !disabledQueryMonitorForLowMem) {
                throw new CacheException(""Should have hit low memory""){};
              }
              assertEquals(1, qs.getIndexes().size());
            }
            catch (Exception e) {
              if (e instanceof IndexInvalidException) {
                if (!hitCriticalThreshold || disabledQueryMonitorForLowMem) {
                  throw new CacheException(""Should not have run into low memory exception""){};
                }
              }
              else {
                throw new CacheException(e){};
              }
            }
            return 0;
          }
      });
    }
    finally {
      stopServer(server1);
      stopServer(server2);
    }
  }",False
"  private void doCriticalMemoryHitDuringGatherTestWithMultipleServers(final String regionName, boolean createPR, final int criticalThreshold, final boolean disabledQueryMonitorForLowMem, final int queryTimeout, final boolean hitCriticalThreshold)
      throws Exception {
    //create region on the server
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM client = host.getVM(2);
    final int numObjects = 200;
    try {
      final int[] port = AvailablePortHelper.getRandomAvailableTCPPorts(2);
      final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
      startCacheServer(server1, port[0], mcastPort, 
          criticalThreshold, disabledQueryMonitorForLowMem, queryTimeout,
          regionName, createPR, 0);
      startCacheServer(server2, port[1], mcastPort, 
          criticalThreshold, true, -1,
          regionName, createPR, 0);
      
      startClient(client, server1, port[0], regionName);
      populateData(server2, regionName, numObjects);
      
      createCancelDuringGatherTestHook(server1);
      client.invoke(new SerializableCallable(""executing query to be canceled by gather"") {
        public Object call() {
          QueryService qs = null;
          try {
            qs = getCache().getQueryService();
            Query query = qs.newQuery(""Select * From /"" + regionName);
            query.execute();
          }
          catch (ServerOperationException soe) {
            if (soe.getRootCause() instanceof QueryException) {
              QueryException e = (QueryException) soe.getRootCause();
              if (!isExceptionDueToLowMemory(e, CRITICAL_HEAP_USED)) {
                throw new CacheException(soe){};
              }
              else {
                return 0;
              }
            }
          }
          catch (Exception e) {
            throw new CacheException(e){};
          }
          //assertTrue(((CancelDuringGatherHook)DefaultQuery.testHook).triggeredOOME);
          throw new CacheException(""should have hit low memory""){};
        }
      });
      
      verifyRejectedObjects(server1, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
      //Pause for a second and then let's recover
      try {
        Thread.sleep(1000);
      }
      catch (InterruptedException e) {
        Thread.currentThread().interrupt();
      }
      
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server1);
      }
      
      //Check to see if query execution is ok under ""normal"" or ""healthy"" conditions
      client.invoke(new CacheSerializableRunnable(""Executing query when system is 'Normal'"") {
        public void run2() {
          try {
            QueryService qs = getCache().getQueryService();
            Query query = qs.newQuery(""Select * From /"" + regionName);
            SelectResults results = (SelectResults)query.execute();
            assertEquals(numObjects, results.size());
          }
          catch (QueryInvocationTargetException e) {
            assertFalse(true);
          }
          catch (NameResolutionException e) {
            assertFalse(true);
          }
          catch (TypeMismatchException e) {
            assertFalse(true);
          }
          catch (FunctionDomainException e) {
            assertFalse(true);
          }
        }
      });
      
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server1);
      }    
    }
    finally {
      stopServer(server1);
      stopServer(server2);
    }
  }",True
"  private void doCriticalMemoryHitDuringGatherTestWithMultipleServers(final String regionName, boolean createPR, final int criticalThreshold, final boolean disabledQueryMonitorForLowMem, final int queryTimeout, final boolean hitCriticalThreshold)
      throws Exception {
    //create region on the server
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM client = host.getVM(2);
    final int numObjects = 200;
    try {
      final int[] port = AvailablePortHelper.getRandomAvailableTCPPorts(2);
      startCacheServer(server1, port[0],  
          criticalThreshold, disabledQueryMonitorForLowMem, queryTimeout,
          regionName, createPR, 0);
      startCacheServer(server2, port[1],  
          criticalThreshold, true, -1,
          regionName, createPR, 0);
      
      startClient(client, server1, port[0], regionName);
      populateData(server2, regionName, numObjects);
      
      createCancelDuringGatherTestHook(server1);
      client.invoke(new SerializableCallable(""executing query to be canceled by gather"") {
        public Object call() {
          QueryService qs = null;
          try {
            qs = getCache().getQueryService();
            Query query = qs.newQuery(""Select * From /"" + regionName);
            query.execute();
          }
          catch (ServerOperationException soe) {
            if (soe.getRootCause() instanceof QueryException) {
              QueryException e = (QueryException) soe.getRootCause();
              if (!isExceptionDueToLowMemory(e, CRITICAL_HEAP_USED)) {
                throw new CacheException(soe){};
              }
              else {
                return 0;
              }
            }
          }
          catch (Exception e) {
            throw new CacheException(e){};
          }
          //assertTrue(((CancelDuringGatherHook)DefaultQuery.testHook).triggeredOOME);
          throw new CacheException(""should have hit low memory""){};
        }
      });
      
      verifyRejectedObjects(server1, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
      //Pause for a second and then let's recover
      try {
        Thread.sleep(1000);
      }
      catch (InterruptedException e) {
        Thread.currentThread().interrupt();
      }
      
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server1);
      }
      
      //Check to see if query execution is ok under ""normal"" or ""healthy"" conditions
      client.invoke(new CacheSerializableRunnable(""Executing query when system is 'Normal'"") {
        public void run2() {
          try {
            QueryService qs = getCache().getQueryService();
            Query query = qs.newQuery(""Select * From /"" + regionName);
            SelectResults results = (SelectResults)query.execute();
            assertEquals(numObjects, results.size());
          }
          catch (QueryInvocationTargetException e) {
            assertFalse(true);
          }
          catch (NameResolutionException e) {
            assertFalse(true);
          }
          catch (TypeMismatchException e) {
            assertFalse(true);
          }
          catch (FunctionDomainException e) {
            assertFalse(true);
          }
        }
      });
      
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server1);
      }    
    }
    finally {
      stopServer(server1);
      stopServer(server2);
    }
  }",False
"  private void startCacheServer(VM server, final int port, final int mcastPort,
      final int criticalThreshold, final boolean disableQueryMonitorForLowMemory,
      final int queryTimeout, final String regionName,
      final boolean createPR, final int prRedundancy) throws Exception {

    server.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        getSystem(getServerProperties(mcastPort, disableQueryMonitorForLowMemory, queryTimeout));
        if (disableQueryMonitorForLowMemory == true) {
          System.setProperty(""gemfire.Cache.DISABLE_QUERY_MONITOR_FOR_LOW_MEMORY"", ""true"");
        }
        else {
          System.clearProperty(""gemfire.Cache.DISABLE_QUERY_MONITOR_FOR_LOW_MEMORY"");
        }
        
        GemFireCacheImpl cache = (GemFireCacheImpl)getCache();
    
        if (queryTimeout != -1) {
          cache.TEST_MAX_QUERY_EXECUTION_TIME_OVERRIDE_EXCEPTION = true;
          cache.TEST_MAX_QUERY_EXECUTION_TIME = queryTimeout;
        }
        else {
          cache.TEST_MAX_QUERY_EXECUTION_TIME_OVERRIDE_EXCEPTION = false;
          cache.TEST_MAX_QUERY_EXECUTION_TIME = -1;
        }
                
        if (criticalThreshold != 0) {
          InternalResourceManager resourceManager = (InternalResourceManager) cache.getResourceManager();
          HeapMemoryMonitor heapMonitor = resourceManager.getHeapMonitor();
          heapMonitor.setTestMaxMemoryBytes(1000);
          HeapMemoryMonitor.setTestBytesUsedForThresholdSet(NORMAL_HEAP_USED);
          resourceManager.setCriticalHeapPercentage(criticalThreshold);
        }
        
        AttributesFactory factory = new AttributesFactory();
        if (createPR) {
          PartitionAttributesFactory paf = new PartitionAttributesFactory();
          paf.setRedundantCopies(prRedundancy);
          paf.setTotalNumBuckets(11);
          factory.setPartitionAttributes(paf.create());
        } else {
          factory.setScope(Scope.DISTRIBUTED_ACK);
          factory.setDataPolicy(DataPolicy.REPLICATE);
        }
        Region region = createRootRegion(regionName, factory.create());
        if (createPR) {
          assertTrue(region instanceof PartitionedRegion);
        } else {
          assertTrue(region instanceof DistributedRegion);
        }
        CacheServer cacheServer = getCache().addCacheServer();
        cacheServer.setPort(port);
        cacheServer.start();
       
        return null;
      }
    });
  }",True
"  private void startCacheServer(VM server, final int port,
      final int criticalThreshold, final boolean disableQueryMonitorForLowMemory,
      final int queryTimeout, final String regionName,
      final boolean createPR, final int prRedundancy) throws Exception {

    server.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        getSystem(getServerProperties(disableQueryMonitorForLowMemory, queryTimeout));
        if (disableQueryMonitorForLowMemory == true) {
          System.setProperty(""gemfire.Cache.DISABLE_QUERY_MONITOR_FOR_LOW_MEMORY"", ""true"");
        }
        else {
          System.clearProperty(""gemfire.Cache.DISABLE_QUERY_MONITOR_FOR_LOW_MEMORY"");
        }
        
        GemFireCacheImpl cache = (GemFireCacheImpl)getCache();
    
        if (queryTimeout != -1) {
          cache.TEST_MAX_QUERY_EXECUTION_TIME_OVERRIDE_EXCEPTION = true;
          cache.TEST_MAX_QUERY_EXECUTION_TIME = queryTimeout;
        }
        else {
          cache.TEST_MAX_QUERY_EXECUTION_TIME_OVERRIDE_EXCEPTION = false;
          cache.TEST_MAX_QUERY_EXECUTION_TIME = -1;
        }
                
        if (criticalThreshold != 0) {
          InternalResourceManager resourceManager = (InternalResourceManager) cache.getResourceManager();
          HeapMemoryMonitor heapMonitor = resourceManager.getHeapMonitor();
          heapMonitor.setTestMaxMemoryBytes(1000);
          HeapMemoryMonitor.setTestBytesUsedForThresholdSet(NORMAL_HEAP_USED);
          resourceManager.setCriticalHeapPercentage(criticalThreshold);
        }
        
        AttributesFactory factory = new AttributesFactory();
        if (createPR) {
          PartitionAttributesFactory paf = new PartitionAttributesFactory();
          paf.setRedundantCopies(prRedundancy);
          paf.setTotalNumBuckets(11);
          factory.setPartitionAttributes(paf.create());
        } else {
          factory.setScope(Scope.DISTRIBUTED_ACK);
          factory.setDataPolicy(DataPolicy.REPLICATE);
        }
        Region region = createRootRegion(regionName, factory.create());
        if (createPR) {
          assertTrue(region instanceof PartitionedRegion);
        } else {
          assertTrue(region instanceof DistributedRegion);
        }
        CacheServer cacheServer = getCache().addCacheServer();
        cacheServer.setPort(port);
        cacheServer.start();
       
        return null;
      }
    });
  }",False
"  protected Properties getServerProperties(int mcastPort, boolean disableQueryMonitorForMemory, int queryTimeout) {
    Properties p = new Properties();
    p.setProperty(DistributionConfig.MCAST_PORT_NAME, mcastPort+"""");
    p.setProperty(DistributionConfig.LOCATORS_NAME, """");
    return p;
  }",True
"  protected Properties getServerProperties(boolean disableQueryMonitorForMemory, int queryTimeout) {
    Properties p = new Properties();
    p.setProperty(DistributionConfig.LOCATORS_NAME, ""localhost[""+getDUnitLocatorPort()+""]"");
    return p;
  }",False
"      public Object call() throws Exception {
        getSystem(getServerProperties(disableQueryMonitorForLowMemory, queryTimeout));
        if (disableQueryMonitorForLowMemory == true) {
          System.setProperty(""gemfire.Cache.DISABLE_QUERY_MONITOR_FOR_LOW_MEMORY"", ""true"");
        }
        else {
          System.clearProperty(""gemfire.Cache.DISABLE_QUERY_MONITOR_FOR_LOW_MEMORY"");
        }
        
        GemFireCacheImpl cache = (GemFireCacheImpl)getCache();
    
        if (queryTimeout != -1) {
          cache.TEST_MAX_QUERY_EXECUTION_TIME_OVERRIDE_EXCEPTION = true;
          cache.TEST_MAX_QUERY_EXECUTION_TIME = queryTimeout;
        }
        else {
          cache.TEST_MAX_QUERY_EXECUTION_TIME_OVERRIDE_EXCEPTION = false;
          cache.TEST_MAX_QUERY_EXECUTION_TIME = -1;
        }
                
        if (criticalThreshold != 0) {
          InternalResourceManager resourceManager = (InternalResourceManager) cache.getResourceManager();
          HeapMemoryMonitor heapMonitor = resourceManager.getHeapMonitor();
          heapMonitor.setTestMaxMemoryBytes(1000);
          HeapMemoryMonitor.setTestBytesUsedForThresholdSet(NORMAL_HEAP_USED);
          resourceManager.setCriticalHeapPercentage(criticalThreshold);
        }
        
        AttributesFactory factory = new AttributesFactory();
        if (createPR) {
          PartitionAttributesFactory paf = new PartitionAttributesFactory();
          paf.setRedundantCopies(prRedundancy);
          paf.setTotalNumBuckets(11);
          factory.setPartitionAttributes(paf.create());
        } else {
          factory.setScope(Scope.DISTRIBUTED_ACK);
          factory.setDataPolicy(DataPolicy.REPLICATE);
        }
        Region region = createRootRegion(regionName, factory.create());
        if (createPR) {
          assertTrue(region instanceof PartitionedRegion);
        } else {
          assertTrue(region instanceof DistributedRegion);
        }
        CacheServer cacheServer = getCache().addCacheServer();
        cacheServer.setPort(port);
        cacheServer.start();
       
        return null;
      }
    });
  }

  private void startClient(VM client, final VM server, final int port,
      final String regionName) {

    client.invoke(new CacheSerializableRunnable(""Start client"") {
      public void run2() throws CacheException {",False
"  private void doCriticalMemoryHitTestOnServer(final String regionName, boolean createPR, final int criticalThreshold, final boolean disabledQueryMonitorForLowMem, final int queryTimeout, final boolean hitCriticalThreshold)
      throws Exception {
    //create region on the server
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final int numObjects = 200;
      try {
      final int port = AvailablePortHelper.getRandomAvailableTCPPort();
      final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
      startCacheServer(server, port, mcastPort, 
          criticalThreshold, disabledQueryMonitorForLowMem, queryTimeout,
          regionName, createPR, 0);
      
      //startPeerClient(client, server, port, regionName);
      populateData(server, regionName, numObjects);
      
      doTestCriticalHeapAndQueryTimeout(server, server, regionName, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
      
      //Pause for a second and then let's recover
      try {
        Thread.sleep(1000);
      }
      catch (InterruptedException e) {
        Thread.currentThread().interrupt();
      }
      
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server);
      }
      
      //Check to see if query execution is ok under ""normal"" or ""healthy"" conditions
      server.invoke(new CacheSerializableRunnable(""Executing query when system is 'Normal'"") {
        public void run2() {
          try {
            QueryService qs = getCache().getQueryService();
            Query query = qs.newQuery(""Select * From /"" + regionName);
            SelectResults results = (SelectResults)query.execute();
            assertEquals(numObjects, results.size());
          }
          catch (QueryInvocationTargetException e) {
            assertFalse(true);
          }
          catch (NameResolutionException e) {
            assertFalse(true);
          }
          catch (TypeMismatchException e) {
            assertFalse(true);
          }
          catch (FunctionDomainException e) {
            assertFalse(true);
          }
        }
      });
      
      //Execute a critical heap event/ query timeout test again
      doTestCriticalHeapAndQueryTimeout(server, server, regionName, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
     
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server);
      }
    }
    finally {
      stopServer(server);
    }
  }",True
"  private void doCriticalMemoryHitTestOnServer(final String regionName, boolean createPR, final int criticalThreshold, final boolean disabledQueryMonitorForLowMem, final int queryTimeout, final boolean hitCriticalThreshold)
      throws Exception {
    //create region on the server
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final int numObjects = 200;
      try {
      final int port = AvailablePortHelper.getRandomAvailableTCPPort();
      startCacheServer(server, port,  
          criticalThreshold, disabledQueryMonitorForLowMem, queryTimeout,
          regionName, createPR, 0);
      
      //startPeerClient(client, server, port, regionName);
      populateData(server, regionName, numObjects);
      
      doTestCriticalHeapAndQueryTimeout(server, server, regionName, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
      
      //Pause for a second and then let's recover
      try {
        Thread.sleep(1000);
      }
      catch (InterruptedException e) {
        Thread.currentThread().interrupt();
      }
      
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server);
      }
      
      //Check to see if query execution is ok under ""normal"" or ""healthy"" conditions
      server.invoke(new CacheSerializableRunnable(""Executing query when system is 'Normal'"") {
        public void run2() {
          try {
            QueryService qs = getCache().getQueryService();
            Query query = qs.newQuery(""Select * From /"" + regionName);
            SelectResults results = (SelectResults)query.execute();
            assertEquals(numObjects, results.size());
          }
          catch (QueryInvocationTargetException e) {
            assertFalse(true);
          }
          catch (NameResolutionException e) {
            assertFalse(true);
          }
          catch (TypeMismatchException e) {
            assertFalse(true);
          }
          catch (FunctionDomainException e) {
            assertFalse(true);
          }
        }
      });
      
      //Execute a critical heap event/ query timeout test again
      doTestCriticalHeapAndQueryTimeout(server, server, regionName, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
     
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server);
      }
    }
    finally {
      stopServer(server);
    }
  }",False
"  private boolean isExceptionDueToLowMemory(QueryException e, int HEAP_USED) {
    String message = e.getMessage();
    return (message.contains(LocalizedStrings.QueryMonitor_LOW_MEMORY_CANCELED_QUERY.toLocalizedString(HEAP_USED)) || message.contains(LocalizedStrings.QueryMonitor_LOW_MEMORY_WHILE_GATHERING_RESULTS_FROM_PARTITION_REGION.toLocalizedString()));
  }
  
  private boolean isExceptionDueToTimeout(QueryException e, long queryTimeout) {",False
"  private void doCriticalMemoryHitTestWithMultipleServers(final String regionName, boolean createPR, final int criticalThreshold, final boolean disabledQueryMonitorForLowMem, final int queryTimeout, final boolean hitCriticalThreshold)
      throws Exception {
    //create region on the server
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM client = host.getVM(2);
    final int numObjects = 200;

    try {
      final int[] port = AvailablePortHelper.getRandomAvailableTCPPorts(2);
      final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
      startCacheServer(server1, port[0], mcastPort, 
          criticalThreshold, disabledQueryMonitorForLowMem, queryTimeout,
          regionName, createPR, 0);
      startCacheServer(server2, port[1], mcastPort, 
          criticalThreshold, true, -1,
          regionName, createPR, 0);
      
      startClient(client, server1, port[0], regionName);
      populateData(server2, regionName, numObjects);
      
      doTestCriticalHeapAndQueryTimeout(server1, client, regionName, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
      verifyRejectedObjects(server1, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
      //Pause for a second and then let's recover
      try {
        Thread.sleep(1000);
      }
      catch (InterruptedException e) {
        Thread.currentThread().interrupt();
      }
      
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server1);
      }
      
      //Check to see if query execution is ok under ""normal"" or ""healthy"" conditions
      client.invoke(new CacheSerializableRunnable(""Executing query when system is 'Normal'"") {
        public void run2() {
          try {
            QueryService qs = getCache().getQueryService();
            Query query = qs.newQuery(""Select * From /"" + regionName);
            SelectResults results = (SelectResults)query.execute();
            assertEquals(numObjects, results.size());
          }
          catch (QueryInvocationTargetException e) {
            assertFalse(true);
          }
          catch (NameResolutionException e) {
            assertFalse(true);
          }
          catch (TypeMismatchException e) {
            assertFalse(true);
          }
          catch (FunctionDomainException e) {
            assertFalse(true);
          }
        }
      });
      
      //Execute a critical heap event/ query timeout test again
      doTestCriticalHeapAndQueryTimeout(server1, client, regionName, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
      verifyRejectedObjects(server1, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
     //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server1);
      }
    }
    finally {
      stopServer(server1);
      stopServer(server2);
    }
  }",True
"  private void doCriticalMemoryHitTestWithMultipleServers(final String regionName, boolean createPR, final int criticalThreshold, final boolean disabledQueryMonitorForLowMem, final int queryTimeout, final boolean hitCriticalThreshold)
      throws Exception {
    //create region on the server
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM client = host.getVM(2);
    final int numObjects = 200;

    try {
      final int[] port = AvailablePortHelper.getRandomAvailableTCPPorts(2);
      startCacheServer(server1, port[0],  
          criticalThreshold, disabledQueryMonitorForLowMem, queryTimeout,
          regionName, createPR, 0);
      startCacheServer(server2, port[1],  
          criticalThreshold, true, -1,
          regionName, createPR, 0);
      
      startClient(client, server1, port[0], regionName);
      populateData(server2, regionName, numObjects);
      
      doTestCriticalHeapAndQueryTimeout(server1, client, regionName, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
      verifyRejectedObjects(server1, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
      //Pause for a second and then let's recover
      try {
        Thread.sleep(1000);
      }
      catch (InterruptedException e) {
        Thread.currentThread().interrupt();
      }
      
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server1);
      }
      
      //Check to see if query execution is ok under ""normal"" or ""healthy"" conditions
      client.invoke(new CacheSerializableRunnable(""Executing query when system is 'Normal'"") {
        public void run2() {
          try {
            QueryService qs = getCache().getQueryService();
            Query query = qs.newQuery(""Select * From /"" + regionName);
            SelectResults results = (SelectResults)query.execute();
            assertEquals(numObjects, results.size());
          }
          catch (QueryInvocationTargetException e) {
            assertFalse(true);
          }
          catch (NameResolutionException e) {
            assertFalse(true);
          }
          catch (TypeMismatchException e) {
            assertFalse(true);
          }
          catch (FunctionDomainException e) {
            assertFalse(true);
          }
        }
      });
      
      //Execute a critical heap event/ query timeout test again
      doTestCriticalHeapAndQueryTimeout(server1, client, regionName, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
      verifyRejectedObjects(server1, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
     //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server1);
      }
    }
    finally {
      stopServer(server1);
      stopServer(server2);
    }
  }",False
"  private void doCriticalMemoryHitAddResultsTestWithMultipleServers(final String regionName, boolean createPR, final int criticalThreshold, final boolean disabledQueryMonitorForLowMem, final int queryTimeout, final boolean hitCriticalThreshold)
      throws Exception {
    //create region on the server
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM client = host.getVM(2);
    final int numObjects = 200;
    try {
      final int[] port = AvailablePortHelper.getRandomAvailableTCPPorts(2);
      final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
      startCacheServer(server1, port[0], mcastPort, 
          criticalThreshold, disabledQueryMonitorForLowMem, queryTimeout,
          regionName, createPR, 0);
      startCacheServer(server2, port[1], mcastPort, 
          criticalThreshold, true, -1,
          regionName, createPR, 0);
      
      startClient(client, server1, port[0], regionName);
      populateData(server2, regionName, numObjects);
      
      createCancelDuringAddResultsTestHook(server1);
      client.invoke(new SerializableCallable(""executing query to be canceled during add results"") {
        public Object call() {
          QueryService qs = null;
          try {
            qs = getCache().getQueryService();
            Query query = qs.newQuery(""Select * From /"" + regionName);
            SelectResults results = (SelectResults) query.execute();
            if (hitCriticalThreshold && disabledQueryMonitorForLowMem == false) {
              throw new CacheException(""should have hit low memory""){};
            }
          }
          catch (Exception e) {
            handleException(e, hitCriticalThreshold, disabledQueryMonitorForLowMem, queryTimeout);
          }
          return 0;
        }
      });
      
      verifyRejectedObjects(server1, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
      //Pause for a second and then let's recover
      try {
        Thread.sleep(1000);
      }
      catch (InterruptedException e) {
        Thread.currentThread().interrupt();
      }
      
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server1);
      }
      
      //Check to see if query execution is ok under ""normal"" or ""healthy"" conditions
      client.invoke(new CacheSerializableRunnable(""Executing query when system is 'Normal'"") {
        public void run2() {
          try {
            QueryService qs = getCache().getQueryService();
            Query query = qs.newQuery(""Select * From /"" + regionName);
            SelectResults results = (SelectResults)query.execute();
            assertEquals(numObjects, results.size());
          }
          catch (QueryInvocationTargetException e) {
            assertFalse(true);
          }
          catch (NameResolutionException e) {
            assertFalse(true);
          }
          catch (TypeMismatchException e) {
            assertFalse(true);
          }
          catch (FunctionDomainException e) {
            assertFalse(true);
          }
        }
      });
      
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server1);
      }    
    }
    finally {
      stopServer(server1);
      stopServer(server2);
    }
  }",True
"  private void doCriticalMemoryHitAddResultsTestWithMultipleServers(final String regionName, boolean createPR, final int criticalThreshold, final boolean disabledQueryMonitorForLowMem, final int queryTimeout, final boolean hitCriticalThreshold)
      throws Exception {
    //create region on the server
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM client = host.getVM(2);
    final int numObjects = 200;
    try {
      final int[] port = AvailablePortHelper.getRandomAvailableTCPPorts(2);
      startCacheServer(server1, port[0],  
          criticalThreshold, disabledQueryMonitorForLowMem, queryTimeout,
          regionName, createPR, 0);
      startCacheServer(server2, port[1],  
          criticalThreshold, true, -1,
          regionName, createPR, 0);
      
      startClient(client, server1, port[0], regionName);
      populateData(server2, regionName, numObjects);
      
      createCancelDuringAddResultsTestHook(server1);
      client.invoke(new SerializableCallable(""executing query to be canceled during add results"") {
        public Object call() {
          QueryService qs = null;
          try {
            qs = getCache().getQueryService();
            Query query = qs.newQuery(""Select * From /"" + regionName);
            SelectResults results = (SelectResults) query.execute();
            if (hitCriticalThreshold && disabledQueryMonitorForLowMem == false) {
              throw new CacheException(""should have hit low memory""){};
            }
          }
          catch (Exception e) {
            handleException(e, hitCriticalThreshold, disabledQueryMonitorForLowMem, queryTimeout);
          }
          return 0;
        }
      });
      
      verifyRejectedObjects(server1, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
      //Pause for a second and then let's recover
      try {
        Thread.sleep(1000);
      }
      catch (InterruptedException e) {
        Thread.currentThread().interrupt();
      }
      
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server1);
      }
      
      //Check to see if query execution is ok under ""normal"" or ""healthy"" conditions
      client.invoke(new CacheSerializableRunnable(""Executing query when system is 'Normal'"") {
        public void run2() {
          try {
            QueryService qs = getCache().getQueryService();
            Query query = qs.newQuery(""Select * From /"" + regionName);
            SelectResults results = (SelectResults)query.execute();
            assertEquals(numObjects, results.size());
          }
          catch (QueryInvocationTargetException e) {
            assertFalse(true);
          }
          catch (NameResolutionException e) {
            assertFalse(true);
          }
          catch (TypeMismatchException e) {
            assertFalse(true);
          }
          catch (FunctionDomainException e) {
            assertFalse(true);
          }
        }
      });
      
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server1);
      }    
    }
    finally {
      stopServer(server1);
      stopServer(server2);
    }
  }",False
"  private void doCriticalMemoryHitTest(final String regionName, boolean createPR, final int criticalThreshold, final boolean disabledQueryMonitorForLowMem, final int queryTimeout, final boolean hitCriticalThreshold)
      throws Exception {
    //create region on the server
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final int numObjects = 200;
    try {
      final int port = AvailablePortHelper.getRandomAvailableTCPPort();
      final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
      startCacheServer(server, port, mcastPort, 
          criticalThreshold, disabledQueryMonitorForLowMem, queryTimeout,
          regionName, createPR, 0);
      
      startClient(client, server, port, regionName);
      populateData(server, regionName, numObjects);
      
      doTestCriticalHeapAndQueryTimeout(server, client, regionName, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
      
      //Pause for a second and then let's recover
      try {
        Thread.sleep(1000);
      }
      catch (InterruptedException e) {
        Thread.currentThread().interrupt();
      }
      
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server);
      }
      
      //Check to see if query execution is ok under ""normal"" or ""healthy"" conditions
      client.invoke(new CacheSerializableRunnable(""Executing query when system is 'Normal'"") {
        public void run2() {
          try {
            QueryService qs = getCache().getQueryService();
            Query query = qs.newQuery(""Select * From /"" + regionName);
            SelectResults results = (SelectResults)query.execute();
            assertEquals(numObjects, results.size());
          }
          catch (QueryInvocationTargetException e) {
            assertFalse(true);
          }
          catch (NameResolutionException e) {
            assertFalse(true);
          }
          catch (TypeMismatchException e) {
            assertFalse(true);
          }
          catch (FunctionDomainException e) {
            assertFalse(true);
          }
        }
      });
      
      //Execute a critical heap event/ query timeout test again
      doTestCriticalHeapAndQueryTimeout(server, client, regionName, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server);
      } 
    }
    finally {
      stopServer(server);
    } 
  }",True
"  private void doCriticalMemoryHitTest(final String regionName, boolean createPR, final int criticalThreshold, final boolean disabledQueryMonitorForLowMem, final int queryTimeout, final boolean hitCriticalThreshold)
      throws Exception {
    //create region on the server
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final int numObjects = 200;
    try {
      final int port = AvailablePortHelper.getRandomAvailableTCPPort();
      startCacheServer(server, port, 
          criticalThreshold, disabledQueryMonitorForLowMem, queryTimeout,
          regionName, createPR, 0);
      
      startClient(client, server, port, regionName);
      populateData(server, regionName, numObjects);
      
      doTestCriticalHeapAndQueryTimeout(server, client, regionName, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
      
      //Pause for a second and then let's recover
      try {
        Thread.sleep(1000);
      }
      catch (InterruptedException e) {
        Thread.currentThread().interrupt();
      }
      
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server);
      }
      
      //Check to see if query execution is ok under ""normal"" or ""healthy"" conditions
      client.invoke(new CacheSerializableRunnable(""Executing query when system is 'Normal'"") {
        public void run2() {
          try {
            QueryService qs = getCache().getQueryService();
            Query query = qs.newQuery(""Select * From /"" + regionName);
            SelectResults results = (SelectResults)query.execute();
            assertEquals(numObjects, results.size());
          }
          catch (QueryInvocationTargetException e) {
            assertFalse(true);
          }
          catch (NameResolutionException e) {
            assertFalse(true);
          }
          catch (TypeMismatchException e) {
            assertFalse(true);
          }
          catch (FunctionDomainException e) {
            assertFalse(true);
          }
        }
      });
      
      //Execute a critical heap event/ query timeout test again
      doTestCriticalHeapAndQueryTimeout(server, client, regionName, disabledQueryMonitorForLowMem, queryTimeout, hitCriticalThreshold);
      //Recover from critical heap
      if (hitCriticalThreshold) {
        vmRecoversFromCriticalHeap(server);
      } 
    }
    finally {
      stopServer(server);
    } 
  }",False
"  public void testIndexInitializationForOverFlowRegions() throws Exception {
    InternalDistributedSystem.getAnyInstance().disconnect();
    File file = new File(""persistData0"");
    file.mkdir();
    
    {
      Properties props = new Properties();
      props.setProperty(DistributionConfig.NAME_NAME, ""test"");
      int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
      props.setProperty(""mcast-port"", ""0"");
      props.setProperty(""statistic-sampling-enabled"", ""true"");
      props.setProperty(""enable-time-statistics"", ""true"");
      props.setProperty(""cache-xml-file"", IndexCreationJUnitTest.class.getResource(""index-recovery-overflow.xml"").toURI().getPath());
      DistributedSystem ds = DistributedSystem.connect(props);

      // Create the cache which causes the cache-xml-file to be parsed
      Cache cache = CacheFactory.create(ds);
      QueryService qs = cache.getQueryService();
      Region region = cache.getRegion(""mainReportRegion"");
      for (int i = 0; i < 100; i++) {
        Portfolio pf = new Portfolio(i);
        pf.setCreateTime(i);
        region.put(""""+ i, pf);
      }
      
      IndexStatistics is1 = qs.getIndex(region, ""status"").getStatistics();
      assertEquals(2, is1.getNumberOfKeys());
      assertEquals(100, is1.getNumberOfValues());
      
      IndexStatistics is2 = qs.getIndex(region, ""ID"").getStatistics();
      assertEquals(100, is2.getNumberOfKeys());
      assertEquals(100, is2.getNumberOfValues());
            
      //verify that a query on the creation time works as expected
      SelectResults results = (SelectResults)qs.newQuery(""<trace>SELECT * FROM /mainReportRegion.entrySet mr Where mr.value.createTime > 1L and mr.value.createTime < 3L"").execute();
      assertEquals(""OQL index results did not match"", 1, results.size());
      cache.close();
      ds.disconnect();
    }

    {
      Properties props = new Properties();
      props.setProperty(DistributionConfig.NAME_NAME, ""test"");
      props.setProperty(""mcast-port"", ""0"");
      props.setProperty(""statistic-sampling-enabled"", ""true"");
      props.setProperty(""enable-time-statistics"", ""true"");
      props.setProperty(""cache-xml-file"", IndexCreationJUnitTest.class.getResource(""index-recovery-overflow.xml"").toURI().getPath());
      DistributedSystem ds = DistributedSystem.connect(props);
      Cache cache = CacheFactory.create(ds);
      QueryService qs = cache.getQueryService();
      Region region = cache.getRegion(""mainReportRegion"");
      
      assertTrue(""Index initialization time should not be 0."", ((LocalRegion)region).getCachePerfStats().getIndexInitializationTime() > 0);

      IndexStatistics is1 = qs.getIndex(region, ""status"").getStatistics();
      assertEquals(2, is1.getNumberOfKeys());
      assertEquals(100, is1.getNumberOfValues());
      
      IndexStatistics is2 = qs.getIndex(region, ""ID"").getStatistics();
      assertEquals(100, is2.getNumberOfKeys());
      assertEquals(100, is2.getNumberOfValues());
            
      //verify that a query on the creation time works as expected
      SelectResults results = (SelectResults)qs.newQuery(""<trace>SELECT * FROM /mainReportRegion.entrySet mr Where mr.value.createTime > 1L and mr.value.createTime < 3L"").execute();
      assertEquals(""OQL index results did not match"", 1, results.size());
      ds.disconnect();
      FileUtil.delete(file);
    }
  }",True
"    InternalDistributedSystem.getAnyInstance().disconnect();
    File file = new File(""persistData0"");
    file.mkdir();
    
    {
      Properties props = new Properties();
      props.setProperty(DistributionConfig.NAME_NAME, ""test"");
      props.setProperty(""mcast-port"", ""0"");
      props.setProperty(""statistic-sampling-enabled"", ""true"");
      props.setProperty(""enable-time-statistics"", ""true"");
      props.setProperty(""cache-xml-file"", IndexCreationJUnitTest.class.getResource(""index-recovery-overflow.xml"").toURI().getPath());
      DistributedSystem ds = DistributedSystem.connect(props);

      // Create the cache which causes the cache-xml-file to be parsed
      Cache cache = CacheFactory.create(ds);
      QueryService qs = cache.getQueryService();
      Region region = cache.getRegion(""mainReportRegion"");
      for (int i = 0; i < 100; i++) {
        Portfolio pf = new Portfolio(i);
        pf.setCreateTime(i);
        region.put(""""+ i, pf);
      }
      
      IndexStatistics is1 = qs.getIndex(region, ""status"").getStatistics();
      assertEquals(2, is1.getNumberOfKeys());
      assertEquals(100, is1.getNumberOfValues());
      
      IndexStatistics is2 = qs.getIndex(region, ""ID"").getStatistics();
      assertEquals(100, is2.getNumberOfKeys());
      assertEquals(100, is2.getNumberOfValues());
            
      //verify that a query on the creation time works as expected
      SelectResults results = (SelectResults)qs.newQuery(""<trace>SELECT * FROM /mainReportRegion.entrySet mr Where mr.value.createTime > 1L and mr.value.createTime < 3L"").execute();
      assertEquals(""OQL index results did not match"", 1, results.size());
      cache.close();
      ds.disconnect();
    }

    {
      Properties props = new Properties();
      props.setProperty(DistributionConfig.NAME_NAME, ""test"");
      props.setProperty(""mcast-port"", ""0"");
      props.setProperty(""statistic-sampling-enabled"", ""true"");
      props.setProperty(""enable-time-statistics"", ""true"");
      props.setProperty(""cache-xml-file"", IndexCreationJUnitTest.class.getResource(""index-recovery-overflow.xml"").toURI().getPath());
      DistributedSystem ds = DistributedSystem.connect(props);
      Cache cache = CacheFactory.create(ds);
      QueryService qs = cache.getQueryService();
      Region region = cache.getRegion(""mainReportRegion"");
      
      assertTrue(""Index initialization time should not be 0."", ((LocalRegion)region).getCachePerfStats().getIndexInitializationTime() > 0);

      IndexStatistics is1 = qs.getIndex(region, ""status"").getStatistics();
      assertEquals(2, is1.getNumberOfKeys());
      assertEquals(100, is1.getNumberOfValues());
      
      IndexStatistics is2 = qs.getIndex(region, ""ID"").getStatistics();
      assertEquals(100, is2.getNumberOfKeys());
      assertEquals(100, is2.getNumberOfValues());
            
      //verify that a query on the creation time works as expected
      SelectResults results = (SelectResults)qs.newQuery(""<trace>SELECT * FROM /mainReportRegion.entrySet mr Where mr.value.createTime > 1L and mr.value.createTime < 3L"").execute();
      assertEquals(""OQL index results did not match"", 1, results.size());
      ds.disconnect();
      FileUtil.delete(file);
    }
  }
 
  @Test",False
"  public void testIndexCreationFromXML() throws Exception {
    InternalDistributedSystem.getAnyInstance().disconnect();
    File file = new File(""persistData0"");
    file.mkdir();
    
    {
      Properties props = new Properties();
      props.setProperty(DistributionConfig.NAME_NAME, ""test"");
      int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
      props.setProperty(""mcast-port"", ""0"");
      props.setProperty(""cache-xml-file"", IndexCreationJUnitTest.class.getResource(""index-creation-with-eviction.xml"").toURI().getPath());
      DistributedSystem ds = DistributedSystem.connect(props);

      // Create the cache which causes the cache-xml-file to be parsed
      Cache cache = CacheFactory.create(ds);
      QueryService qs = cache.getQueryService();
      Region region = cache.getRegion(""mainReportRegion"");
      for (int i = 0; i < 100; i++) {
        Portfolio pf = new Portfolio(i);
        pf.setCreateTime(i);
        region.put(""""+ i, pf);
      }
      
      //verify that a query on the creation time works as expected
      SelectResults results = (SelectResults)qs.newQuery(""<trace>SELECT * FROM /mainReportRegion.entrySet mr Where mr.value.createTime > 1L and mr.value.createTime < 3L"").execute();
      assertEquals(""OQL index results did not match"", 1, results.size());
      cache.close();
      ds.disconnect();
    }

    {
      Properties props = new Properties();
      props.setProperty(DistributionConfig.NAME_NAME, ""test"");
      props.setProperty(""mcast-port"", ""0"");
      //Using a different cache.xml that changes some region properties
      //That will force the disk code to copy the region entries.
      props.setProperty(""cache-xml-file"", IndexCreationJUnitTest.class.getResource(""index-creation-without-eviction.xml"").toURI().getPath());
      DistributedSystem ds = DistributedSystem.connect(props);
      Cache cache = CacheFactory.create(ds);
      QueryService qs = cache.getQueryService();
      Region region = cache.getRegion(""mainReportRegion"");

      //verify that a query on the creation time works as expected
      SelectResults results = (SelectResults)qs.newQuery(""<trace>SELECT * FROM /mainReportRegion.entrySet mr Where mr.value.createTime > 1L and mr.value.createTime < 3L"").execute();
      assertEquals(""OQL index results did not match"", 1, results.size());
      ds.disconnect();
      FileUtil.delete(file);
    }
  }",True
"  public void testIndexCreationFromXML() throws Exception {
    InternalDistributedSystem.getAnyInstance().disconnect();
    File file = new File(""persistData0"");
    file.mkdir();
    
    {
      Properties props = new Properties();
      props.setProperty(DistributionConfig.NAME_NAME, ""test"");
      props.setProperty(""mcast-port"", ""0"");
      props.setProperty(""cache-xml-file"", IndexCreationJUnitTest.class.getResource(""index-creation-with-eviction.xml"").toURI().getPath());
      DistributedSystem ds = DistributedSystem.connect(props);

      // Create the cache which causes the cache-xml-file to be parsed
      Cache cache = CacheFactory.create(ds);
      QueryService qs = cache.getQueryService();
      Region region = cache.getRegion(""mainReportRegion"");
      for (int i = 0; i < 100; i++) {
        Portfolio pf = new Portfolio(i);
        pf.setCreateTime(i);
        region.put(""""+ i, pf);
      }
      
      //verify that a query on the creation time works as expected
      SelectResults results = (SelectResults)qs.newQuery(""<trace>SELECT * FROM /mainReportRegion.entrySet mr Where mr.value.createTime > 1L and mr.value.createTime < 3L"").execute();
      assertEquals(""OQL index results did not match"", 1, results.size());
      cache.close();
      ds.disconnect();
    }

    {
      Properties props = new Properties();
      props.setProperty(DistributionConfig.NAME_NAME, ""test"");
      props.setProperty(""mcast-port"", ""0"");
      //Using a different cache.xml that changes some region properties
      //That will force the disk code to copy the region entries.
      props.setProperty(""cache-xml-file"", IndexCreationJUnitTest.class.getResource(""index-creation-without-eviction.xml"").toURI().getPath());
      DistributedSystem ds = DistributedSystem.connect(props);
      Cache cache = CacheFactory.create(ds);
      QueryService qs = cache.getQueryService();
      Region region = cache.getRegion(""mainReportRegion"");

      //verify that a query on the creation time works as expected
      SelectResults results = (SelectResults)qs.newQuery(""<trace>SELECT * FROM /mainReportRegion.entrySet mr Where mr.value.createTime > 1L and mr.value.createTime < 3L"").execute();
      assertEquals(""OQL index results did not match"", 1, results.size());
      ds.disconnect();
      FileUtil.delete(file);
    }
  }
 ",False
"  private void startCacheServer(VM server, final int port, final int mcastPort) throws Exception {
    server.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        getSystem(getServerProperties(mcastPort));
        
        GemFireCacheImpl cache = (GemFireCacheImpl)getCache();
        cache.setCopyOnRead(true);
        AttributesFactory factory = new AttributesFactory();        
        
        CacheServer cacheServer = getCache().addCacheServer();
        cacheServer.setPort(port);
        cacheServer.start();  
        
        QueryTestUtils.setCache(cache);
        return null;
      }
    });
  }",True
"  private void startCacheServer(VM server, final int port) throws Exception {
    server.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        disconnectFromDS();
        getSystem(getServerProperties());
        
        GemFireCacheImpl cache = (GemFireCacheImpl)getCache();
        cache.setCopyOnRead(true);
        AttributesFactory factory = new AttributesFactory();        
        
        CacheServer cacheServer = getCache().addCacheServer();
        cacheServer.setPort(port);
        cacheServer.start();  
        
        QueryTestUtils.setCache(cache);
        return null;
      }
    });
  }",False
"  public void helpTestPRQueryOnLocalNode(final String queryString, final int numPortfolios, final int numExpectedResults, final boolean hasIndex) throws Exception {
    
    final int[] port = AvailablePortHelper.getRandomAvailableTCPPorts(2);
    final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
    final int numPortfoliosPerVM = numPortfolios / 2;
    
    startCacheServer(vm0, port[0], mcastPort);
    startCacheServer(vm1, port[1], mcastPort);
    
    resetInstanceCount(vm0);
    resetInstanceCount(vm1);
    
    createPartitionRegion(vm0, ""portfolios"");
    if (hasIndex) {
      vm0.invoke(new SerializableCallable() {
        public Object call() throws Exception {
          QueryTestUtils utils = new QueryTestUtils();
          utils.createIndex(""idIndex"", ""p.ID"", ""/portfolios p"");
          return null;
        }
      });
    }
    
    createPartitionRegion(vm1, ""portfolios"");

    vm0.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        for (int i = 0 ; i < numPortfoliosPerVM; i++) {
          Portfolio p = new Portfolio(i);
          p.status = ""testStatus"";
          p.positions = new HashMap();
          p.positions.put("""" + i, new Position("""" + i, 20));
          region.put(""key "" + i, p);
        }
        
        if (hasIndex) {
          //operations we have done on this vm consist of:
          //numPortfoliosPerVM instances of Portfolio created for put operation
          //Due to index, we have deserialized all of the entries this vm currently host
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(),((PartitionedRegion)region).getLocalSize() + numPortfoliosPerVM , Portfolio.instanceCount.get());
        }
        else {
          //operations we have done on this vm consist of:
          //numPortfoliosPerVM instances of Portfolio created for put operation
          //We do not have an index, so we have not deserialized any values
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfoliosPerVM , Portfolio.instanceCount.get());
        }
        return null;
      }
    });
    
    vm1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        for (int i = numPortfoliosPerVM ; i < numPortfolios; i++) {
          Portfolio p = new Portfolio(i);
          p.status = ""testStatus"";
          p.positions = new HashMap();
          p.positions.put("""" + i, new Position("""" + i, 20));
          region.put(""key "" + i, p);
        }
        //PR indexes are created across nodes unlike Replicated Region Indexes
        if (hasIndex) {
          //operations we have done on this vm consist of:
          //numPortfoliosPerVM instances of Portfolio created for put operation
          //Due to index, we have deserialized all of the entries this vm currently host
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), ((PartitionedRegion)region).getLocalSize() + numPortfoliosPerVM, Portfolio.instanceCount.get());
        }
        else {
          //operations we have done on this vm consist of:
          //numPortfoliosPerVM instances of Portfolio created for put operation
          //We do not have an index, so we have not deserialized any values
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfoliosPerVM, Portfolio.instanceCount.get());
        }
        return null;
      }
    });
    
    vm0.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        QueryService qs = getCache().getQueryService();
        Query query = qs.newQuery(queryString);
        SelectResults results = (SelectResults) query.execute();
        assertEquals(numExpectedResults, results.size());
        for (Object o: results) {
          if (o instanceof Portfolio) {
            Portfolio p = (Portfolio) o;
            p.status = ""discardStatus"";
          }
          else {
            Struct struct = (Struct) o;
            Portfolio p = (Portfolio) struct.getFieldValues()[0];
            p.status = ""discardStatus"";
          }
        }
        if (hasIndex) {
          //operations we have done on this vm consist of:
          //50 instances of Portfolio created for put operation
          //Due to index, we have deserialized all of the entries this vm currently host
          //Since we have deserialized and cached these values, we just need to add the number of results we did a copy of due to copy on read
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), ((PartitionedRegion)region).getLocalSize() + numPortfoliosPerVM + numExpectedResults, Portfolio.instanceCount.get());
        }
        else {
          //operations we have done on this vm consist of:
          //50 instances of Portfolio created for put operation
          //Due to the query we deserialized the number of entries this vm currently hosts
          //We had to deserialized the results from the other data nodes when we iterated through the results as well as our own
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(),((PartitionedRegion)region).getLocalSize() + numExpectedResults + numPortfoliosPerVM , Portfolio.instanceCount.get());
        }
        return null;
      }
    });
    
    vm1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        if (hasIndex) {
          //After vm0 executed the query, we already had the values deserialized in our cache
          //So it's the same total as before
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), ((PartitionedRegion)region).getLocalSize() + numPortfoliosPerVM, Portfolio.instanceCount.get());
        }
        else {
          //After vm0 executed the query, we had to deserialize the values in our vm
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), ((PartitionedRegion)region).getLocalSize() + numPortfoliosPerVM, Portfolio.instanceCount.get());
        }
        return null;
      }
    });
    
    vm0.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        QueryService qs = getCache().getQueryService();
        Query query = qs.newQuery(queryString);
        SelectResults results = (SelectResults) query.execute();
        assertEquals(numExpectedResults, results.size());
        for (Object o: results) {
          if (o instanceof Portfolio) {
            Portfolio p = (Portfolio) o;
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
          }
          else {
            Struct struct = (Struct)o;
            Portfolio p = (Portfolio) struct.getFieldValues()[0];
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
          }
        }
        if (hasIndex) {
          //operations we have done on this vm consist of:
          //50 instances of Portfolio created for put operation
          //Due to index, we have deserialized all of the entries this vm currently host
          //This is the second query, because we have deserialized and cached these values, we just need to add the number of results a second time
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), ((PartitionedRegion)region).getLocalSize() + numExpectedResults + numExpectedResults + numPortfoliosPerVM, Portfolio.instanceCount.get());
        }
        else {
        //operations we have done on this vm consist of:
          //50 instances of Portfolio created for put operation
          //Due to index, we have deserialized all of the entries this vm currently host
          //This is the second query, because we have deserialized and cached these values, we just need to add the number of results a second time
          //Because we have no index, we have to again deserialize all the values that this vm is hosting
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(),((PartitionedRegion)region).getLocalSize() + ((PartitionedRegion)region).getLocalSize() + numExpectedResults + numExpectedResults + numPortfoliosPerVM, Portfolio.instanceCount.get());
        }
        return null;
      }
    });
  }",True
"  public void helpTestPRQueryOnLocalNode(final String queryString, final int numPortfolios, final int numExpectedResults, final boolean hasIndex) throws Exception {
    
    final int[] port = AvailablePortHelper.getRandomAvailableTCPPorts(2);
    final int numPortfoliosPerVM = numPortfolios / 2;
    
    startCacheServer(vm0, port[0]);
    startCacheServer(vm1, port[1]);
    
    resetInstanceCount(vm0);
    resetInstanceCount(vm1);
    
    createPartitionRegion(vm0, ""portfolios"");
    if (hasIndex) {
      vm0.invoke(new SerializableCallable() {
        public Object call() throws Exception {
          QueryTestUtils utils = new QueryTestUtils();
          utils.createIndex(""idIndex"", ""p.ID"", ""/portfolios p"");
          return null;
        }
      });
    }
    
    createPartitionRegion(vm1, ""portfolios"");

    vm0.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        for (int i = 0 ; i < numPortfoliosPerVM; i++) {
          Portfolio p = new Portfolio(i);
          p.status = ""testStatus"";
          p.positions = new HashMap();
          p.positions.put("""" + i, new Position("""" + i, 20));
          region.put(""key "" + i, p);
        }
        
        if (hasIndex) {
          //operations we have done on this vm consist of:
          //numPortfoliosPerVM instances of Portfolio created for put operation
          //Due to index, we have deserialized all of the entries this vm currently host
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(),((PartitionedRegion)region).getLocalSize() + numPortfoliosPerVM , Portfolio.instanceCount.get());
        }
        else {
          //operations we have done on this vm consist of:
          //numPortfoliosPerVM instances of Portfolio created for put operation
          //We do not have an index, so we have not deserialized any values
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfoliosPerVM , Portfolio.instanceCount.get());
        }
        return null;
      }
    });
    
    vm1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        for (int i = numPortfoliosPerVM ; i < numPortfolios; i++) {
          Portfolio p = new Portfolio(i);
          p.status = ""testStatus"";
          p.positions = new HashMap();
          p.positions.put("""" + i, new Position("""" + i, 20));
          region.put(""key "" + i, p);
        }
        //PR indexes are created across nodes unlike Replicated Region Indexes
        if (hasIndex) {
          //operations we have done on this vm consist of:
          //numPortfoliosPerVM instances of Portfolio created for put operation
          //Due to index, we have deserialized all of the entries this vm currently host
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), ((PartitionedRegion)region).getLocalSize() + numPortfoliosPerVM, Portfolio.instanceCount.get());
        }
        else {
          //operations we have done on this vm consist of:
          //numPortfoliosPerVM instances of Portfolio created for put operation
          //We do not have an index, so we have not deserialized any values
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfoliosPerVM, Portfolio.instanceCount.get());
        }
        return null;
      }
    });
    
    vm0.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        QueryService qs = getCache().getQueryService();
        Query query = qs.newQuery(queryString);
        SelectResults results = (SelectResults) query.execute();
        assertEquals(numExpectedResults, results.size());
        for (Object o: results) {
          if (o instanceof Portfolio) {
            Portfolio p = (Portfolio) o;
            p.status = ""discardStatus"";
          }
          else {
            Struct struct = (Struct) o;
            Portfolio p = (Portfolio) struct.getFieldValues()[0];
            p.status = ""discardStatus"";
          }
        }
        if (hasIndex) {
          //operations we have done on this vm consist of:
          //50 instances of Portfolio created for put operation
          //Due to index, we have deserialized all of the entries this vm currently host
          //Since we have deserialized and cached these values, we just need to add the number of results we did a copy of due to copy on read
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), ((PartitionedRegion)region).getLocalSize() + numPortfoliosPerVM + numExpectedResults, Portfolio.instanceCount.get());
        }
        else {
          //operations we have done on this vm consist of:
          //50 instances of Portfolio created for put operation
          //Due to the query we deserialized the number of entries this vm currently hosts
          //We had to deserialized the results from the other data nodes when we iterated through the results as well as our own
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(),((PartitionedRegion)region).getLocalSize() + numExpectedResults + numPortfoliosPerVM , Portfolio.instanceCount.get());
        }
        return null;
      }
    });
    
    vm1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        if (hasIndex) {
          //After vm0 executed the query, we already had the values deserialized in our cache
          //So it's the same total as before
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), ((PartitionedRegion)region).getLocalSize() + numPortfoliosPerVM, Portfolio.instanceCount.get());
        }
        else {
          //After vm0 executed the query, we had to deserialize the values in our vm
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), ((PartitionedRegion)region).getLocalSize() + numPortfoliosPerVM, Portfolio.instanceCount.get());
        }
        return null;
      }
    });
    
    vm0.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        QueryService qs = getCache().getQueryService();
        Query query = qs.newQuery(queryString);
        SelectResults results = (SelectResults) query.execute();
        assertEquals(numExpectedResults, results.size());
        for (Object o: results) {
          if (o instanceof Portfolio) {
            Portfolio p = (Portfolio) o;
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
          }
          else {
            Struct struct = (Struct)o;
            Portfolio p = (Portfolio) struct.getFieldValues()[0];
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
          }
        }
        if (hasIndex) {
          //operations we have done on this vm consist of:
          //50 instances of Portfolio created for put operation
          //Due to index, we have deserialized all of the entries this vm currently host
          //This is the second query, because we have deserialized and cached these values, we just need to add the number of results a second time
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), ((PartitionedRegion)region).getLocalSize() + numExpectedResults + numExpectedResults + numPortfoliosPerVM, Portfolio.instanceCount.get());
        }
        else {
        //operations we have done on this vm consist of:
          //50 instances of Portfolio created for put operation
          //Due to index, we have deserialized all of the entries this vm currently host
          //This is the second query, because we have deserialized and cached these values, we just need to add the number of results a second time
          //Because we have no index, we have to again deserialize all the values that this vm is hosting
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(),((PartitionedRegion)region).getLocalSize() + ((PartitionedRegion)region).getLocalSize() + numExpectedResults + numExpectedResults + numPortfoliosPerVM, Portfolio.instanceCount.get());
        }
        return null;
      }
    });
  }",False
"    Properties p = new Properties();
    p.setProperty(DistributionConfig.LOCATORS_NAME, ""localhost[""+getDUnitLocatorPort()+""]"");
    return p;
  }
  
  ",False
"      public Object call() throws Exception {
        disconnectFromDS();
        getSystem(getServerProperties());
        
        GemFireCacheImpl cache = (GemFireCacheImpl)getCache();
        cache.setCopyOnRead(true);
        AttributesFactory factory = new AttributesFactory();        
        
        CacheServer cacheServer = getCache().addCacheServer();
        cacheServer.setPort(port);
        cacheServer.start();  
        
        QueryTestUtils.setCache(cache);
        return null;
      }
    });
  }
  ",False
"  public void helpTestTransactionsOnReplicatedRegion(final String queryString, final int numPortfolios, final int numExpectedResults, final boolean hasIndex) throws Exception {
    final int[] port = AvailablePortHelper.getRandomAvailableTCPPorts(3);
    final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
    startCacheServer(vm0, port[0], mcastPort);
    startCacheServer(vm1, port[1], mcastPort);
    startCacheServer(vm2, port[2], mcastPort);
    resetInstanceCount(vm0);
    resetInstanceCount(vm1);
    resetInstanceCount(vm2);
    createReplicatedRegion(vm0, ""portfolios"");
    createReplicatedRegion(vm1, ""portfolios"");
    createReplicatedRegion(vm2, ""portfolios"");
    
    //In the case of replicated region hasPR really has no effect on serialization/deserialization counts
    if (hasIndex) {
      vm0.invoke(new SerializableCallable() {
        public Object call() throws Exception {
          QueryTestUtils utils = new QueryTestUtils();
          utils.createHashIndex(""idIndex"", ""p.ID"", ""/portfolios p"");
          return null;
        }
      });
      //let's not create index on vm1 to check different scenarios
      
      vm2.invoke(new SerializableCallable() {
        public Object call() throws Exception {
          QueryTestUtils utils = new QueryTestUtils();
          utils.createHashIndex(""idIndex"", ""p.ID"", ""/portfolios p"");
          return null;
        }
      });
    }
    

    vm0.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        for (int i = 0 ; i < numPortfolios; i++) {
          Portfolio p = new Portfolio(i);
          p.status = ""testStatus"";
          p.positions = new HashMap();
          p.positions.put("""" + i, new Position("""" + i, 20));
          region.put(""key "" + i, p);
        }
        
        //We should have the same number of portfolio objects that we created for the put
        assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfolios , Portfolio.instanceCount.get());
        return null;
      }
    });
    
    vm1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        //At this point, we should only have serialized values in this vm
        Region region = getCache().getRegion(""/portfolios"");
        assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), 0, Portfolio.instanceCount.get());
        return null;
      }
    });
    
    vm2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        //There is an index for vm2, so we should have deserialized values at this point,
        Region region = getCache().getRegion(""/portfolios"");
        if (hasIndex) {
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfolios, Portfolio.instanceCount.get());
        }
        else {
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), 0, Portfolio.instanceCount.get());
        }
        return null;
      }
    });
    
    //start transaction
    //execute query
    //modify results
    //check instance count
    vm0.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        CacheTransactionManager txManager =
            region.getCache().getCacheTransactionManager();
        try {
        txManager.begin();

        QueryService qs = getCache().getQueryService();
        Query query = qs.newQuery(queryString);
        SelectResults results = (SelectResults) query.execute();
        assertEquals(numExpectedResults, results.size());
        for (Object o: results) {
          if (o instanceof Portfolio) {
            Portfolio p = (Portfolio) o;
            p.status = ""discardStatus"";
          }
          else {
            Struct struct = (Struct) o;
            Portfolio p = (Portfolio) struct.getFieldValues()[0];
            p.status = ""discardStatus"";
          }
        }
        
        txManager.commit();
        }
        catch (CommitConflictException conflict) {
          fail(""commit conflict exception"", conflict);
        }
        
        //We have created puts from our previous callable
        //Now we have copied the results from the query 
        assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numExpectedResults + numPortfolios, Portfolio.instanceCount.get());
        return null;
      }
    });
    
    //Check objects in cache on vm1
    vm1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        QueryService qs = getCache().getQueryService();
        Query query = qs.newQuery(queryString);
        SelectResults results = (SelectResults) query.execute();
        assertEquals(numExpectedResults, results.size());
        for (Object o: results) {
          if (o instanceof Portfolio) {
            Portfolio p = (Portfolio) o;
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
            p.status = ""discardStatus"";
          }
          else {
            Struct struct = (Struct)o;
            Portfolio p = (Portfolio) struct.getFieldValues()[0];
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
            p.status = ""discardStatus"";
          }
        }
        //first it must deserialize the portfolios in the replicated region
        //then we do a copy on read of these deserialized objects for the final result set
        assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfolios + numExpectedResults, Portfolio.instanceCount.get());
        
        results = (SelectResults) query.execute();
        assertEquals(numExpectedResults, results.size());
        for (Object o: results) {
          if (o instanceof Portfolio) {
            Portfolio p = (Portfolio) o;
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
          }
          else {
            Struct struct = (Struct)o;
            Portfolio p = (Portfolio) struct.getFieldValues()[0];
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
          }
        }
      
        //we never created index on vm1
        //so in this case, we always have to deserialize the value from the region
        assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfolios * 2 + numExpectedResults * 2, Portfolio.instanceCount.get());

        return null;
      }
    });
    
    //Check objects in cache on vm2
    vm2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        QueryService qs = getCache().getQueryService();
        Query query = qs.newQuery(queryString);
        SelectResults results = (SelectResults) query.execute();
        assertEquals(numExpectedResults, results.size());
        for (Object o: results) {
          if (o instanceof Portfolio) {
            Portfolio p = (Portfolio) o;
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
            p.status = ""discardStatus"";
          }
          else {
            Struct struct = (Struct)o;
            Portfolio p = (Portfolio) struct.getFieldValues()[0];
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
            p.status = ""discardStatus"";
          }
        }
        //with or without index, the values had to have been deserialized at one point
        assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfolios + numExpectedResults, Portfolio.instanceCount.get());
        
        results = (SelectResults) query.execute();
        assertEquals(numExpectedResults, results.size());
        for (Object o: results) {
          if (o instanceof Portfolio) {
            Portfolio p = (Portfolio) o;
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
          }
          else {
            Struct struct = (Struct)o;
            Portfolio p = (Portfolio) struct.getFieldValues()[0];
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
          }
        }
      

        if (hasIndex) {
          //we have an index, so the values are already deserialized
          //total is now our original deserialization amount : numPortfolios
          //two query results copied.
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfolios + numExpectedResults * 2, Portfolio.instanceCount.get());
        }
        else {
          //we never created index on vm1
          //so in this case, we always have to deserialize the value from the region
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfolios * 2 + numExpectedResults * 2, Portfolio.instanceCount.get());
        }
        return null;
      }
    });
    
    //Check objects in cache on vm0
    vm0.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        QueryService qs = getCache().getQueryService();
        Query query = qs.newQuery(queryString);
        SelectResults results = (SelectResults) query.execute();
        assertEquals(numExpectedResults, results.size());
        for (Object o: results) {
          if (o instanceof Portfolio) {
            Portfolio p = (Portfolio) o;
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
          }
          else {
            Struct struct = (Struct)o;
            Portfolio p = (Portfolio) struct.getFieldValues()[0];
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
          }
        }
        
        //with or without index, the values we put in the region were already deserialized values
        assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(),numExpectedResults * 2 + numPortfolios, Portfolio.instanceCount.get());
        return null;
      }
    });
  }",True
"  public void helpTestTransactionsOnReplicatedRegion(final String queryString, final int numPortfolios, final int numExpectedResults, final boolean hasIndex) throws Exception {
    final int[] port = AvailablePortHelper.getRandomAvailableTCPPorts(3);
    startCacheServer(vm0, port[0]);
    startCacheServer(vm1, port[1]);
    startCacheServer(vm2, port[2]);
    resetInstanceCount(vm0);
    resetInstanceCount(vm1);
    resetInstanceCount(vm2);
    createReplicatedRegion(vm0, ""portfolios"");
    createReplicatedRegion(vm1, ""portfolios"");
    createReplicatedRegion(vm2, ""portfolios"");
    
    //In the case of replicated region hasPR really has no effect on serialization/deserialization counts
    if (hasIndex) {
      vm0.invoke(new SerializableCallable() {
        public Object call() throws Exception {
          QueryTestUtils utils = new QueryTestUtils();
          utils.createHashIndex(""idIndex"", ""p.ID"", ""/portfolios p"");
          return null;
        }
      });
      //let's not create index on vm1 to check different scenarios
      
      vm2.invoke(new SerializableCallable() {
        public Object call() throws Exception {
          QueryTestUtils utils = new QueryTestUtils();
          utils.createHashIndex(""idIndex"", ""p.ID"", ""/portfolios p"");
          return null;
        }
      });
    }
    

    vm0.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        for (int i = 0 ; i < numPortfolios; i++) {
          Portfolio p = new Portfolio(i);
          p.status = ""testStatus"";
          p.positions = new HashMap();
          p.positions.put("""" + i, new Position("""" + i, 20));
          region.put(""key "" + i, p);
        }
        
        //We should have the same number of portfolio objects that we created for the put
        assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfolios , Portfolio.instanceCount.get());
        return null;
      }
    });
    
    vm1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        //At this point, we should only have serialized values in this vm
        Region region = getCache().getRegion(""/portfolios"");
        assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), 0, Portfolio.instanceCount.get());
        return null;
      }
    });
    
    vm2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        //There is an index for vm2, so we should have deserialized values at this point,
        Region region = getCache().getRegion(""/portfolios"");
        if (hasIndex) {
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfolios, Portfolio.instanceCount.get());
        }
        else {
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), 0, Portfolio.instanceCount.get());
        }
        return null;
      }
    });
    
    //start transaction
    //execute query
    //modify results
    //check instance count
    vm0.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        CacheTransactionManager txManager =
            region.getCache().getCacheTransactionManager();
        try {
        txManager.begin();

        QueryService qs = getCache().getQueryService();
        Query query = qs.newQuery(queryString);
        SelectResults results = (SelectResults) query.execute();
        assertEquals(numExpectedResults, results.size());
        for (Object o: results) {
          if (o instanceof Portfolio) {
            Portfolio p = (Portfolio) o;
            p.status = ""discardStatus"";
          }
          else {
            Struct struct = (Struct) o;
            Portfolio p = (Portfolio) struct.getFieldValues()[0];
            p.status = ""discardStatus"";
          }
        }
        
        txManager.commit();
        }
        catch (CommitConflictException conflict) {
          fail(""commit conflict exception"", conflict);
        }
        
        //We have created puts from our previous callable
        //Now we have copied the results from the query 
        assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numExpectedResults + numPortfolios, Portfolio.instanceCount.get());
        return null;
      }
    });
    
    //Check objects in cache on vm1
    vm1.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        QueryService qs = getCache().getQueryService();
        Query query = qs.newQuery(queryString);
        SelectResults results = (SelectResults) query.execute();
        assertEquals(numExpectedResults, results.size());
        for (Object o: results) {
          if (o instanceof Portfolio) {
            Portfolio p = (Portfolio) o;
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
            p.status = ""discardStatus"";
          }
          else {
            Struct struct = (Struct)o;
            Portfolio p = (Portfolio) struct.getFieldValues()[0];
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
            p.status = ""discardStatus"";
          }
        }
        //first it must deserialize the portfolios in the replicated region
        //then we do a copy on read of these deserialized objects for the final result set
        assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfolios + numExpectedResults, Portfolio.instanceCount.get());
        
        results = (SelectResults) query.execute();
        assertEquals(numExpectedResults, results.size());
        for (Object o: results) {
          if (o instanceof Portfolio) {
            Portfolio p = (Portfolio) o;
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
          }
          else {
            Struct struct = (Struct)o;
            Portfolio p = (Portfolio) struct.getFieldValues()[0];
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
          }
        }
      
        //we never created index on vm1
        //so in this case, we always have to deserialize the value from the region
        assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfolios * 2 + numExpectedResults * 2, Portfolio.instanceCount.get());

        return null;
      }
    });
    
    //Check objects in cache on vm2
    vm2.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        QueryService qs = getCache().getQueryService();
        Query query = qs.newQuery(queryString);
        SelectResults results = (SelectResults) query.execute();
        assertEquals(numExpectedResults, results.size());
        for (Object o: results) {
          if (o instanceof Portfolio) {
            Portfolio p = (Portfolio) o;
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
            p.status = ""discardStatus"";
          }
          else {
            Struct struct = (Struct)o;
            Portfolio p = (Portfolio) struct.getFieldValues()[0];
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
            p.status = ""discardStatus"";
          }
        }
        //with or without index, the values had to have been deserialized at one point
        assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfolios + numExpectedResults, Portfolio.instanceCount.get());
        
        results = (SelectResults) query.execute();
        assertEquals(numExpectedResults, results.size());
        for (Object o: results) {
          if (o instanceof Portfolio) {
            Portfolio p = (Portfolio) o;
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
          }
          else {
            Struct struct = (Struct)o;
            Portfolio p = (Portfolio) struct.getFieldValues()[0];
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
          }
        }
      

        if (hasIndex) {
          //we have an index, so the values are already deserialized
          //total is now our original deserialization amount : numPortfolios
          //two query results copied.
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfolios + numExpectedResults * 2, Portfolio.instanceCount.get());
        }
        else {
          //we never created index on vm1
          //so in this case, we always have to deserialize the value from the region
          assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(), numPortfolios * 2 + numExpectedResults * 2, Portfolio.instanceCount.get());
        }
        return null;
      }
    });
    
    //Check objects in cache on vm0
    vm0.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        Region region = getCache().getRegion(""/portfolios"");
        QueryService qs = getCache().getQueryService();
        Query query = qs.newQuery(queryString);
        SelectResults results = (SelectResults) query.execute();
        assertEquals(numExpectedResults, results.size());
        for (Object o: results) {
          if (o instanceof Portfolio) {
            Portfolio p = (Portfolio) o;
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
          }
          else {
            Struct struct = (Struct)o;
            Portfolio p = (Portfolio) struct.getFieldValues()[0];
            assertEquals(""status should not have been changed"", ""testStatus"", p.status);
          }
        }
        
        //with or without index, the values we put in the region were already deserialized values
        assertEquals(""Incorrect number of portfolio instances""+ Portfolio.instanceCount.get(),numExpectedResults * 2 + numPortfolios, Portfolio.instanceCount.get());
        return null;
      }
    });
  }",False
"  public void testPutAllWithIndexes() {
    final String name = ""testRegion"";
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 10000;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
          config.setProperty(""mcast-port"", String.valueOf(unusedPort));
          Cache cache = new CacheFactory(config).create();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          cache.createRegionFactory(factory.create()).create(name);
          try {
            startBridgeServer(0, false);
          } catch (Exception ex) {
            fail(""While starting CacheServer"", ex);
          }
          //Create Index on empty region
          try {
            cache.getQueryService().createIndex(""idIndex"", ""ID"", ""/""+name);
          } catch (Exception e) {
            fail(""index creation failed"", e);
          }
        }
      });

    // Create client region
    final int port = vm0.invokeInt(PutAllWithIndexPerfDUnitDisabledTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          ClientCache cache = new ClientCacheFactory().addPoolServer(host0, port).create();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          cache.createClientRegionFactory(ClientRegionShortcut.PROXY).create(name);
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""putAll() test"") {
      
      @Override
      public void run2() throws CacheException {
        Region exampleRegion = ClientCacheFactory.getAnyInstance().getRegion(name);

        Map warmupMap = new HashMap();
        Map data =  new HashMap();
        for(int i=0; i<10000; i++){
          Object p = new PortfolioPdx(i);
          if (i < 1000) warmupMap.put(i, p);
          data.put(i, p);
        }
        
        for (int i=0; i<10; i++) {
          exampleRegion.putAll(warmupMap);
        }
        
        long start = System.currentTimeMillis();
        for (int i=0; i<10; i++) {
          exampleRegion.putAll(data);
        }
        long end = System.currentTimeMillis();
        timeWithoutStructTypeIndex = ((end-start)/10);
        System.out.println(""Total putall time for 10000 objects is: ""+ ((end-start)/10) + ""ms"");
 
      }
    });
    
    vm0.invoke(new CacheSerializableRunnable(""Remove Index and create new one"") {
      
      @Override
      public void run2() throws CacheException {
        try {
          Cache cache = CacheFactory.getAnyInstance();
          cache.getQueryService().removeIndexes();
          cache.getRegion(name).clear();
          cache.getQueryService().createIndex(""idIndex"", ""p.ID"", ""/""+name+"" p"");
        } catch (Exception e) {
          fail(""index creation failed"", e);
        }
      }
    });

    vm1.invoke(new CacheSerializableRunnable(""putAll() test"") {
      
      @Override
      public void run2() throws CacheException {
        Region exampleRegion = ClientCacheFactory.getAnyInstance().getRegion(name);
        exampleRegion.clear();
        Map warmupMap = new HashMap();
        Map data =  new HashMap();
        for(int i=0; i<10000; i++){
          Object p = new PortfolioPdx(i);
          if (i < 1000) warmupMap.put(i, p);
          data.put(i, p);
        }
        
        for (int i=0; i<10; i++) {
          exampleRegion.putAll(warmupMap);
        }
        
        long start = System.currentTimeMillis();
        for (int i=0; i<10; i++) {
          exampleRegion.putAll(data);
        }
        long end = System.currentTimeMillis();
        timeWithStructTypeIndex  = ((end-start)/10);
        System.out.println(""Total putall time for 10000 objects is: ""+ ((end-start)/10) + ""ms"");
 
      }
    });
    
    if (timeWithoutStructTypeIndex > timeWithStructTypeIndex) {
      fail(""putAll took more time without struct type index than simple index"");
    }
  }",True
"  public void testPutAllWithIndexes() {
    final String name = ""testRegion"";
    final Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int numberOfEntries = 10000;

    // Start server
    vm0.invoke(new CacheSerializableRunnable(""Create Bridge Server"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.put(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
          Cache cache = new CacheFactory(config).create();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          cache.createRegionFactory(factory.create()).create(name);
          try {
            startBridgeServer(0, false);
          } catch (Exception ex) {
            fail(""While starting CacheServer"", ex);
          }
          //Create Index on empty region
          try {
            cache.getQueryService().createIndex(""idIndex"", ""ID"", ""/""+name);
          } catch (Exception e) {
            fail(""index creation failed"", e);
          }
        }
      });

    // Create client region
    final int port = vm0.invokeInt(PutAllWithIndexPerfDUnitDisabledTest.class, ""getCacheServerPort"");
    final String host0 = getServerHostName(vm0.getHost());
    vm1.invoke(new CacheSerializableRunnable(""Create region"") {
        public void run2() throws CacheException {
          Properties config = new Properties();
          config.setProperty(""mcast-port"", ""0"");
          ClientCache cache = new ClientCacheFactory().addPoolServer(host0, port).create();
          AttributesFactory factory = new AttributesFactory();
          factory.setScope(Scope.LOCAL);
          cache.createClientRegionFactory(ClientRegionShortcut.PROXY).create(name);
        }
      });

    vm1.invoke(new CacheSerializableRunnable(""putAll() test"") {
      
      @Override
      public void run2() throws CacheException {
        Region exampleRegion = ClientCacheFactory.getAnyInstance().getRegion(name);

        Map warmupMap = new HashMap();
        Map data =  new HashMap();
        for(int i=0; i<10000; i++){
          Object p = new PortfolioPdx(i);
          if (i < 1000) warmupMap.put(i, p);
          data.put(i, p);
        }
        
        for (int i=0; i<10; i++) {
          exampleRegion.putAll(warmupMap);
        }
        
        long start = System.currentTimeMillis();
        for (int i=0; i<10; i++) {
          exampleRegion.putAll(data);
        }
        long end = System.currentTimeMillis();
        timeWithoutStructTypeIndex = ((end-start)/10);
        System.out.println(""Total putall time for 10000 objects is: ""+ ((end-start)/10) + ""ms"");
 
      }
    });
    
    vm0.invoke(new CacheSerializableRunnable(""Remove Index and create new one"") {
      
      @Override
      public void run2() throws CacheException {
        try {
          Cache cache = CacheFactory.getAnyInstance();
          cache.getQueryService().removeIndexes();
          cache.getRegion(name).clear();
          cache.getQueryService().createIndex(""idIndex"", ""p.ID"", ""/""+name+"" p"");
        } catch (Exception e) {
          fail(""index creation failed"", e);
        }
      }
    });

    vm1.invoke(new CacheSerializableRunnable(""putAll() test"") {
      
      @Override
      public void run2() throws CacheException {
        Region exampleRegion = ClientCacheFactory.getAnyInstance().getRegion(name);
        exampleRegion.clear();
        Map warmupMap = new HashMap();
        Map data =  new HashMap();
        for(int i=0; i<10000; i++){
          Object p = new PortfolioPdx(i);
          if (i < 1000) warmupMap.put(i, p);
          data.put(i, p);
        }
        
        for (int i=0; i<10; i++) {
          exampleRegion.putAll(warmupMap);
        }
        
        long start = System.currentTimeMillis();
        for (int i=0; i<10; i++) {
          exampleRegion.putAll(data);
        }
        long end = System.currentTimeMillis();
        timeWithStructTypeIndex  = ((end-start)/10);
        System.out.println(""Total putall time for 10000 objects is: ""+ ((end-start)/10) + ""ms"");
 
      }
    });
    
    if (timeWithoutStructTypeIndex > timeWithStructTypeIndex) {
      fail(""putAll took more time without struct type index than simple index"");
    }
  }",False
"  public Cache createMcastCache() {
    synchronized(CacheTestCase.class) {
      try {
        System.setProperty(""gemfire.DISABLE_DISCONNECT_DS_ON_CACHE_CLOSE"", ""true"");
        Cache c = CacheFactory.create(getMcastSystem()); 
        cache = c;
      } catch (CacheExistsException e) {
        fail(""the cache already exists"", e);

      } catch (RuntimeException ex) {
        throw ex;

      } catch (Exception ex) {
        fail(""Checked exception while initializing cache??"", ex);
      } finally {
        System.clearProperty(""gemfire.DISABLE_DISCONNECT_DS_ON_CACHE_CLOSE"");
      }
      return cache;
    }
  }",True
"   */
  public static synchronized void beginCacheXml() {
//    getLogWriter().info(""before closeCache"");
    closeCache();
//    getLogWriter().info(""before TestCacheCreation"");
    cache = new TestCacheCreation();
//    getLogWriter().info(""after TestCacheCreation"");
  }
  /**
   * Finish what beginCacheXml started. It does this be generating a cache.xml
   * file and then creating a real cache using that cache.xml.
   */
  public void finishCacheXml(String name) {
    synchronized(CacheTestCase.class) {
      File file = new File(name + ""-cache.xml"");
      try {
        PrintWriter pw = new PrintWriter(new FileWriter(file), true);
        CacheXmlGenerator.generate(cache, pw);
        pw.close();
      } catch (IOException ex) {",False
"      try {
        createCache();
      } finally {
        GemFireCacheImpl.testCacheXml = null;
      }
    }
  }
  
  /**
   * Finish what beginCacheXml started. It does this be generating a cache.xml
   * file and then creating a real cache using that cache.xml.
   */
  public void finishCacheXml(String name, boolean useSchema, String xmlVersion) {
    synchronized(CacheTestCase.class) {
      File dir = new File(""XML_"" + xmlVersion);
      dir.mkdirs();
      File file = new File(dir, name + "".xml"");
      try {
        PrintWriter pw = new PrintWriter(new FileWriter(file), true);
        CacheXmlGenerator.generate(cache, pw, useSchema, xmlVersion);",False
"  public void _testMembershipPortRangeWithExactThreeValues() throws Exception {
    Properties config = new Properties();
    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    config.setProperty(""mcast-port"", String.valueOf(mcastPort));
    config.setProperty(""locators"", """");
    config.setProperty(DistributionConfig.MEMBERSHIP_PORT_RANGE_NAME, """"
        + (DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[1] - 2) + ""-""
        + (DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[1]));
    system = (InternalDistributedSystem)DistributedSystem.connect(config);
    Cache cache = CacheFactory.create(system);
    cache.addCacheServer();
    DistributionManager dm = (DistributionManager) system.getDistributionManager();
    InternalDistributedMember idm = dm.getDistributionManagerId();
    system.disconnect();
    assertTrue(idm.getPort() <= DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[1]);
    assertTrue(idm.getPort() >= DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[0]);
    assertTrue(idm.getDirectChannelPort() <= DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[1]);
    assertTrue(idm.getDirectChannelPort() >= DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[0]);
  }",False
"  public void testConflictingUDPPort() throws Exception {
    final Properties config = new Properties();
    final int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    final int unicastPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    config.setProperty(""mcast-port"", String.valueOf(mcastPort));
    config.setProperty(""locators"", """");
    config.setProperty(DistributionConfig.MEMBERSHIP_PORT_RANGE_NAME, 
        """"+unicastPort+""-""+(unicastPort+2));
    system = (InternalDistributedSystem)DistributedSystem.connect(config);
    DistributionManager dm = (DistributionManager)system.getDistributionManager();
    InternalDistributedMember idm = dm.getDistributionManagerId();
    VM vm = Host.getHost(0).getVM(1);
    vm.invoke(new CacheSerializableRunnable(""start conflicting system"") {
      public void run2() {
        try {
          DistributedSystem system = DistributedSystem.connect(config);
          system.disconnect();
        } catch (SystemConnectException e) {
          return; // 
        }
        fail(""expected a SystemConnectException but didn't get one"");
      }
    });
    system.disconnect();
  }",True
"    final Properties config = new Properties();
    final int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    final int unicastPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    config.setProperty(""mcast-port"", String.valueOf(mcastPort));
    config.setProperty(""locators"", """");
    config.setProperty(DistributionConfig.MEMBERSHIP_PORT_RANGE_NAME, 
        """"+unicastPort+""-""+(unicastPort+2));
    system = (InternalDistributedSystem)DistributedSystem.connect(config);
    DistributionManager dm = (DistributionManager)system.getDistributionManager();
    InternalDistributedMember idm = dm.getDistributionManagerId();
    VM vm = Host.getHost(0).getVM(1);
    vm.invoke(new CacheSerializableRunnable(""start conflicting system"") {
      public void run2() {
        try {
          DistributedSystem system = DistributedSystem.connect(config);
          system.disconnect();
        } catch (SystemConnectException e) {
          return; // 
        }
        fail(""expected a SystemConnectException but didn't get one"");
      }
    });
    system.disconnect();
  }
",False
"  public void testSpecificTcpPort() throws Exception {
    Properties config = new Properties();
    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    int tcpPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    config.setProperty(""mcast-port"", String.valueOf(mcastPort));
    config.setProperty(""locators"", """");
    config.setProperty(""tcp-port"", String.valueOf(tcpPort));
    system = (InternalDistributedSystem)DistributedSystem.connect(config);
    DistributionManager dm = (DistributionManager)system.getDistributionManager();
    GMSMembershipManager mgr = (GMSMembershipManager)dm.getMembershipManager();
    int actualPort = mgr.getDirectChannelPort();
    system.disconnect();
    assertEquals(tcpPort, actualPort);
  }",True
"  public void testSpecificTcpPort() throws Exception {
    Properties config = new Properties();
    int tcpPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    config.put(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
    config.setProperty(""tcp-port"", String.valueOf(tcpPort));
    system = (InternalDistributedSystem)DistributedSystem.connect(config);
    DistributionManager dm = (DistributionManager)system.getDistributionManager();
    GMSMembershipManager mgr = (GMSMembershipManager)dm.getMembershipManager();
    int actualPort = mgr.getDirectChannelPort();
    system.disconnect();
    assertEquals(tcpPort, actualPort);
  }",False
"  public void _testMembershipPortRange() throws Exception {
    Properties config = new Properties();
    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    int unicastPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    config.setProperty(""mcast-port"", String.valueOf(mcastPort));
    config.setProperty(""locators"", """");
    config.setProperty(DistributionConfig.MEMBERSHIP_PORT_RANGE_NAME, 
        """"+unicastPort+""-""+(unicastPort+1));
    try {
      system = (InternalDistributedSystem)DistributedSystem.connect(config);
    } catch (Exception e) {
      assertTrue(""The exception must be IllegalArgumentException"", e instanceof IllegalArgumentException);
      return;
    }
    fail(""IllegalArgumentException must have been thrown by DistributedSystem.connect() as port-range: ""
        + config.getProperty(DistributionConfig.MEMBERSHIP_PORT_RANGE_NAME)
        + "" must have at least 3 values in range"");
  }",False
"  public void _testWaitForDeparture() throws Exception {
    disconnectAllFromDS();
    Properties p = getDistributedSystemProperties();
    p.put(DistributionConfig.LOCATORS_NAME, """");
    p.put(DistributionConfig.DISABLE_TCP_NAME, ""true"");
    InternalDistributedSystem ds = (InternalDistributedSystem)DistributedSystem.connect(p);
    try {
      // construct a member ID that will represent a departed member
      InternalDistributedMember mbr = new InternalDistributedMember(""localhost"", 12345, """", """");
      final DistributionManager mgr = (DistributionManager)ds.getDistributionManager();
      // schedule a message in order to create a queue for the fake member
      final FakeMessage msg = new FakeMessage(null);
      mgr.getExecutor(DistributionManager.SERIAL_EXECUTOR, mbr).execute(new SizeableRunnable(100) {
        public void run() {
          msg.doAction(mgr, false);
        }
        public String toString() {
          return ""Processing fake message"";
        }
      });
      try {
        assertTrue(""expected the serial queue to be flushed"", mgr.getMembershipManager().waitForDeparture(mbr));
      } catch (InterruptedException e) {
        fail(""interrupted"");
      } catch (TimeoutException e) {
        fail(""timed out - increase this test's member-timeout setting"");
      }
    } finally {
      ds.disconnect();
    }
  }",False
"  public void testWaitForDeparture() throws Exception {
    disconnectAllFromDS();
    Properties p = getDistributedSystemProperties();
    p.put(DistributionConfig.LOCATORS_NAME, """");
    p.put(DistributionConfig.MCAST_PORT_NAME, """"+AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS));
    p.put(DistributionConfig.DISABLE_TCP_NAME, ""true"");
    InternalDistributedSystem ds = (InternalDistributedSystem)DistributedSystem.connect(p);
    try {
      // construct a member ID that will represent a departed member
      InternalDistributedMember mbr = new InternalDistributedMember(""localhost"", 12345, """", """");
      final DistributionManager mgr = (DistributionManager)ds.getDistributionManager();
      // schedule a message in order to create a queue for the fake member
      final FakeMessage msg = new FakeMessage(null);
      mgr.getExecutor(DistributionManager.SERIAL_EXECUTOR, mbr).execute(new SizeableRunnable(100) {
        public void run() {
          msg.doAction(mgr, false);
        }
        public String toString() {
          return ""Processing fake message"";
        }
      });
      try {
        assertTrue(""expected the serial queue to be flushed"", mgr.getMembershipManager().waitForDeparture(mbr));
      } catch (InterruptedException e) {
        fail(""interrupted"");
      } catch (TimeoutException e) {
        fail(""timed out - increase this test's member-timeout setting"");
      }
    } finally {
      ds.disconnect();
    }
  }",True
"  // TODO this needs to use a locator
  public void _testWaitForDeparture() throws Exception {
    disconnectAllFromDS();
    Properties p = getDistributedSystemProperties();
    p.put(DistributionConfig.LOCATORS_NAME, """");
    p.put(DistributionConfig.DISABLE_TCP_NAME, ""true"");
    InternalDistributedSystem ds = (InternalDistributedSystem)DistributedSystem.connect(p);
    try {
      // construct a member ID that will represent a departed member
      InternalDistributedMember mbr = new InternalDistributedMember(""localhost"", 12345, """", """");
      final DistributionManager mgr = (DistributionManager)ds.getDistributionManager();
      // schedule a message in order to create a queue for the fake member
      final FakeMessage msg = new FakeMessage(null);
      mgr.getExecutor(DistributionManager.SERIAL_EXECUTOR, mbr).execute(new SizeableRunnable(100) {
        public void run() {
          msg.doAction(mgr, false);
        }
        public String toString() {
          return ""Processing fake message"";
        }
      });
      try {
        assertTrue(""expected the serial queue to be flushed"", mgr.getMembershipManager().waitForDeparture(mbr));
      } catch (InterruptedException e) {
        fail(""interrupted"");
      } catch (TimeoutException e) {
        fail(""timed out - increase this test's member-timeout setting"");
      }
    } finally {
      ds.disconnect();
    }
  }",False
"  public void testMembershipPortRangeWithExactThreeValues() throws Exception {
    Properties config = new Properties();
    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    config.setProperty(""mcast-port"", String.valueOf(mcastPort));
    config.setProperty(""locators"", """");
    config.setProperty(DistributionConfig.MEMBERSHIP_PORT_RANGE_NAME, """"
        + (DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[1] - 2) + ""-""
        + (DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[1]));
    system = (InternalDistributedSystem)DistributedSystem.connect(config);
    Cache cache = CacheFactory.create(system);
    cache.addCacheServer();
    DistributionManager dm = (DistributionManager) system.getDistributionManager();
    InternalDistributedMember idm = dm.getDistributionManagerId();
    system.disconnect();
    assertTrue(idm.getPort() <= DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[1]);
    assertTrue(idm.getPort() >= DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[0]);
    assertTrue(idm.getDirectChannelPort() <= DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[1]);
    assertTrue(idm.getDirectChannelPort() >= DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[0]);
  }",True
"    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    config.setProperty(""mcast-port"", String.valueOf(mcastPort));
    config.setProperty(""locators"", """");
    config.setProperty(DistributionConfig.MEMBERSHIP_PORT_RANGE_NAME, """"
        + (DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[1] - 2) + ""-""
        + (DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[1]));
    system = (InternalDistributedSystem)DistributedSystem.connect(config);
    Cache cache = CacheFactory.create(system);
    cache.addCacheServer();
    DistributionManager dm = (DistributionManager) system.getDistributionManager();
    InternalDistributedMember idm = dm.getDistributionManagerId();
    system.disconnect();
    assertTrue(idm.getPort() <= DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[1]);
    assertTrue(idm.getPort() >= DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[0]);
    assertTrue(idm.getDirectChannelPort() <= DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[1]);
    assertTrue(idm.getDirectChannelPort() >= DistributionConfig.DEFAULT_MEMBERSHIP_PORT_RANGE[0]);
  }

  // TODO this needs to use a locator",False
"  public void _testConflictingUDPPort() throws Exception {
    final Properties config = new Properties();
    final int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    final int unicastPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    config.setProperty(""mcast-port"", String.valueOf(mcastPort));
    config.setProperty(""locators"", """");
    config.setProperty(DistributionConfig.MEMBERSHIP_PORT_RANGE_NAME, 
        """"+unicastPort+""-""+(unicastPort+2));
    system = (InternalDistributedSystem)DistributedSystem.connect(config);
    DistributionManager dm = (DistributionManager)system.getDistributionManager();
    InternalDistributedMember idm = dm.getDistributionManagerId();
    VM vm = Host.getHost(0).getVM(1);
    vm.invoke(new CacheSerializableRunnable(""start conflicting system"") {
      public void run2() {
        try {
          DistributedSystem system = DistributedSystem.connect(config);
          system.disconnect();
        } catch (SystemConnectException e) {
          return; // 
        }
        fail(""expected a SystemConnectException but didn't get one"");
      }
    });
    system.disconnect();
  }",False
"  public void testMembershipPortRange() throws Exception {
    Properties config = new Properties();
    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    int unicastPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    config.setProperty(""mcast-port"", String.valueOf(mcastPort));
    config.setProperty(""locators"", """");
    config.setProperty(DistributionConfig.MEMBERSHIP_PORT_RANGE_NAME, 
        """"+unicastPort+""-""+(unicastPort+1));
    try {
      system = (InternalDistributedSystem)DistributedSystem.connect(config);
    } catch (Exception e) {
      assertTrue(""The exception must be IllegalArgumentException"", e instanceof IllegalArgumentException);
      return;
    }
    fail(""IllegalArgumentException must have been thrown by DistributedSystem.connect() as port-range: ""
        + config.getProperty(DistributionConfig.MEMBERSHIP_PORT_RANGE_NAME)
        + "" must have at least 3 values in range"");
  }",True
"    int unicastPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    config.setProperty(""mcast-port"", String.valueOf(mcastPort));
    config.setProperty(""locators"", """");
    config.setProperty(DistributionConfig.MEMBERSHIP_PORT_RANGE_NAME, 
        """"+unicastPort+""-""+(unicastPort+1));
    try {
      system = (InternalDistributedSystem)DistributedSystem.connect(config);
    } catch (Exception e) {
      assertTrue(""The exception must be IllegalArgumentException"", e instanceof IllegalArgumentException);
      return;
    }
    fail(""IllegalArgumentException must have been thrown by DistributedSystem.connect() as port-range: ""
        + config.getProperty(DistributionConfig.MEMBERSHIP_PORT_RANGE_NAME)
        + "" must have at least 3 values in range"");
  }

  // TODO this needs to use a locator
  public void _testMembershipPortRangeWithExactThreeValues() throws Exception {",False
"  public void testUDPPortRange() throws Exception {
    Properties config = new Properties();
    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    int unicastPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    config.setProperty(""mcast-port"", String.valueOf(mcastPort));
    config.setProperty(""locators"", """");
    // Minimum 3 ports required in range for UDP, FD_SOCK and TcpConduit.
    config.setProperty(DistributionConfig.MEMBERSHIP_PORT_RANGE_NAME, 
        """"+unicastPort+""-""+(unicastPort+2)); 
    system = (InternalDistributedSystem)DistributedSystem.connect(config);
    DistributionManager dm = (DistributionManager)system.getDistributionManager();
    InternalDistributedMember idm = dm.getDistributionManagerId();
    system.disconnect();
    assertTrue(unicastPort <= idm.getPort() && idm.getPort() <= unicastPort+2);
    assertTrue(unicastPort <= idm.getPort() && idm.getDirectChannelPort() <= unicastPort+2);
  }",True
"  public void testUDPPortRange() throws Exception {
    Properties config = new Properties();
    int unicastPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    config.put(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
    // Minimum 3 ports required in range for UDP, FD_SOCK and TcpConduit.
    config.setProperty(DistributionConfig.MEMBERSHIP_PORT_RANGE_NAME, 
        """"+unicastPort+""-""+(unicastPort+2)); 
    system = (InternalDistributedSystem)DistributedSystem.connect(config);
    DistributionManager dm = (DistributionManager)system.getDistributionManager();
    InternalDistributedMember idm = dm.getDistributionManagerId();
    system.disconnect();
    assertTrue(unicastPort <= idm.getPort() && idm.getPort() <= unicastPort+2);
    assertTrue(unicastPort <= idm.getPort() && idm.getDirectChannelPort() <= unicastPort+2);
  }",False
"  public void testNonDefaultConnectionName() {
    String name = ""BLAH"";
    Properties props = new Properties();
//     int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
//     props.setProperty(""mcast-port"", String.valueOf(unusedPort));
    // a loner is all this test needs
    //props.setProperty(""mcast-port"", ""0"");
    props.setProperty(""locators"", """");
    props.setProperty(DistributionConfig.NAME_NAME, name);
    int unusedPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    props.setProperty(DistributionConfig.MCAST_PORT_NAME, String.valueOf(unusedPort));
    createSystem(props);
  }",True
"  public void testNonDefaultConnectionName() {
    String name = ""BLAH"";
    Properties props = new Properties();
    // a loner is all this test needs
    props.setProperty(""mcast-port"", ""0"");
    props.setProperty(""locators"", """");
    props.setProperty(DistributionConfig.NAME_NAME, name);
    createSystem(props);
  }",False
"  public void testMembershipMonitoring() throws Exception {
    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);

    // use a locator so we will monitor server load and record member->server mappings
    int locatorPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    Properties p = new Properties();
    p.put(DistributionConfig.START_LOCATOR_NAME, ""localhost[""+locatorPort+""],peer=false"");
    p.put(DistributionConfig.USE_CLUSTER_CONFIGURATION_NAME, ""false"");
    InternalDistributedSystem system = getSystem(p);
    
    InternalLocator locator = (InternalLocator)Locator.getLocator();
    // server location is forced on for product use logging
    assertTrue(locator.isServerLocator());
    
    File logFile = new File(""locator""+locatorPort+""views.log"");
    // the locator should have already created this file
    assertTrue(logFile.exists());
    
    assertTrue(logFile.exists());
    vm0.invoke(new SerializableRunnable(""get system"") {
      public void run() {
        InternalDistributedSystem system = getSystem();
        Cache cache = CacheFactory.create(system);
        CacheServer server = cache.addCacheServer();
        try {
          server.start();
        } catch (IOException e) {
          fail(""failed to start server"", e);
        }
      }
    });

    // wait for the server info to be received and logged 
//    pause(2 * BridgeServerImpl.FORCE_LOAD_UPDATE_FREQUENCY * 1000);

    system.disconnect();

    String logContents = readFile(logFile);
    assertTrue(""expected "" + logFile + "" to contain a View"", logContents.contains(""View""));
    assertTrue(""expected "" + logFile + "" to contain 'server summary'"", logContents.contains(""server summary""));
  }",True
"  public void testMembershipMonitoring() throws Exception {
    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);

    // use a locator so we will monitor server load and record member->server mappings
    int locatorPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    Properties p = new Properties();
    p.put(DistributionConfig.START_LOCATOR_NAME, ""localhost[""+locatorPort+""],peer=false"");
    p.put(DistributionConfig.USE_CLUSTER_CONFIGURATION_NAME, ""false"");
    InternalDistributedSystem system = getSystem(p);
    
    InternalLocator locator = (InternalLocator)Locator.getLocator();
    // server location is forced on for product use logging
    assertTrue(locator.isServerLocator());
    
    File logFile = new File(""locator""+locatorPort+""views.log"");
    // the locator should have already created this file
    assertTrue(logFile.exists());
    
    assertTrue(logFile.exists());
    vm0.invoke(new SerializableRunnable(""get system"") {
      public void run() {
        InternalDistributedSystem system = getSystem();
        Cache cache = CacheFactory.create(system);
        CacheServer server = cache.addCacheServer();
        try {
          server.start();
        } catch (IOException e) {
          fail(""failed to start server"", e);
        }
      }
    });

    // wait for the server info to be received and logged 
//    pause(2 * BridgeServerImpl.FORCE_LOAD_UPDATE_FREQUENCY * 1000);

    system.disconnect();

    String logContents = readFile(logFile);
    assertTrue(""expected "" + logFile + "" to contain a View"", logContents.contains(""View""));
    assertTrue(""expected "" + logFile + "" to contain 'server summary'"", logContents.contains(""server summary""));
  }",False
"  public static int getRandomAvailableUDPPort() {
    return getRandomAvailableUDPPorts(1)[0];
  }",True
" public static int getRandomAvailableUDPPort() {
    return getRandomAvailableUDPPorts(1)[0];
  }",False
"  public BackwardCompatibilitySerializationDUnitTest(String name) {
    super(name);
  }",False
"  public void tearDown2() {
    resetFlags();
    // reset the class mapped to the dsfid
    DSFIDFactory.registerDSFID(DataSerializableFixedID.PUTALL_VERSIONS_LIST,
        EntryVersionsList.class);
    this.baos = null;
    this.bais = null;
  }",False
"  public BackwardCompatibilitySerializationJUnitTest() {
  }",True
"
  public BackwardCompatibilitySerializationDUnitTest(String name) {",False
"  public void testAllMessages() throws Exception {
    // list of msgs not created using reflection
    // taken from DSFIDFactory.create()
    ArrayList<Integer> constdsfids = new ArrayList<Integer>();
    constdsfids.add(new Byte(DataSerializableFixedID.REGION).intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.END_OF_STREAM_TOKEN)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.DLOCK_REMOTE_TOKEN)
        .intValue());
    constdsfids
        .add(new Byte(DataSerializableFixedID.TRANSACTION_ID).intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.INTEREST_RESULT_POLICY)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.UNDEFINED).intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.RESULTS_BAG).intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.GATEWAY_EVENT_IMPL_66)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.SQLF_TYPE).intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.SQLF_DVD_OBJECT)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.SQLF_GLOBAL_ROWLOC)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.SQLF_GEMFIRE_KEY)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.SQLF_FORMATIBLEBITSET)
        .intValue());
    constdsfids
        .add(new Short(DataSerializableFixedID.TOKEN_INVALID).intValue());
    constdsfids.add(new Short(DataSerializableFixedID.TOKEN_LOCAL_INVALID)
        .intValue());
    constdsfids.add(new Short(DataSerializableFixedID.TOKEN_DESTROYED)
        .intValue());
    constdsfids
        .add(new Short(DataSerializableFixedID.TOKEN_REMOVED).intValue());
    constdsfids.add(new Short(DataSerializableFixedID.TOKEN_REMOVED2)
        .intValue());
    constdsfids.add(new Short(DataSerializableFixedID.TOKEN_TOMBSTONE)
        .intValue());

    for (int i = 0; i < 256; i++) {
      Constructor<?> cons = DSFIDFactory.getDsfidmap()[i];
      if (!constdsfids.contains(i - Byte.MAX_VALUE - 1) && cons != null) {
        Object ds = cons.newInstance((Object[]) null);
        checkSupportForRollingUpgrade(ds);
      }
    }
    
    // some msgs require distributed system
    Cache c = new CacheFactory().set(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"").create();
    for (Object o : DSFIDFactory.getDsfidmap2().values()) {
      Constructor<?> cons = (Constructor<?>) o;
      if (cons != null) {
        DataSerializableFixedID ds = (DataSerializableFixedID) cons
            .newInstance((Object[]) null);
        checkSupportForRollingUpgrade(ds);
      }
    }
    c.close();
  }",False
"  public void testAllMessages() throws Exception {
    // list of msgs not created using reflection
    // taken from DSFIDFactory.create()
    ArrayList<Integer> constdsfids = new ArrayList<Integer>();
    constdsfids.add(new Byte(DataSerializableFixedID.REGION).intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.END_OF_STREAM_TOKEN)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.DLOCK_REMOTE_TOKEN)
        .intValue());
    constdsfids
        .add(new Byte(DataSerializableFixedID.TRANSACTION_ID).intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.INTEREST_RESULT_POLICY)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.UNDEFINED).intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.RESULTS_BAG).intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.GATEWAY_EVENT_IMPL_66)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.SQLF_TYPE).intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.SQLF_DVD_OBJECT)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.SQLF_GLOBAL_ROWLOC)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.SQLF_GEMFIRE_KEY)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.SQLF_FORMATIBLEBITSET)
        .intValue());
    constdsfids
        .add(new Short(DataSerializableFixedID.TOKEN_INVALID).intValue());
    constdsfids.add(new Short(DataSerializableFixedID.TOKEN_LOCAL_INVALID)
        .intValue());
    constdsfids.add(new Short(DataSerializableFixedID.TOKEN_DESTROYED)
        .intValue());
    constdsfids
        .add(new Short(DataSerializableFixedID.TOKEN_REMOVED).intValue());
    constdsfids.add(new Short(DataSerializableFixedID.TOKEN_REMOVED2)
        .intValue());
    constdsfids.add(new Short(DataSerializableFixedID.TOKEN_TOMBSTONE)
        .intValue());

    for (int i = 0; i < 256; i++) {
      Constructor<?> cons = DSFIDFactory.getDsfidmap()[i];
      if (!constdsfids.contains(i - Byte.MAX_VALUE - 1) && cons != null) {
        Object ds = cons.newInstance((Object[]) null);
        checkSupportForRollingUpgrade(ds);
      }
    }
    
    // some msgs require distributed system
    Cache c = new CacheFactory().set(""mcast-port"", """"+AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS)).create();
    for (Object o : DSFIDFactory.getDsfidmap2().values()) {
      Constructor<?> cons = (Constructor<?>) o;
      if (cons != null) {
        DataSerializableFixedID ds = (DataSerializableFixedID) cons
            .newInstance((Object[]) null);
        checkSupportForRollingUpgrade(ds);
      }
    }
    c.close();
  }",True
"   */
  @Test
  public void testAllMessages() throws Exception {
    // list of msgs not created using reflection
    // taken from DSFIDFactory.create()
    ArrayList<Integer> constdsfids = new ArrayList<Integer>();
    constdsfids.add(new Byte(DataSerializableFixedID.REGION).intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.END_OF_STREAM_TOKEN)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.DLOCK_REMOTE_TOKEN)
        .intValue());
    constdsfids
        .add(new Byte(DataSerializableFixedID.TRANSACTION_ID).intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.INTEREST_RESULT_POLICY)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.UNDEFINED).intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.RESULTS_BAG).intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.GATEWAY_EVENT_IMPL_66)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.SQLF_TYPE).intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.SQLF_DVD_OBJECT)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.SQLF_GLOBAL_ROWLOC)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.SQLF_GEMFIRE_KEY)
        .intValue());
    constdsfids.add(new Byte(DataSerializableFixedID.SQLF_FORMATIBLEBITSET)
        .intValue());
    constdsfids
        .add(new Short(DataSerializableFixedID.TOKEN_INVALID).intValue());
    constdsfids.add(new Short(DataSerializableFixedID.TOKEN_LOCAL_INVALID)
        .intValue());
    constdsfids.add(new Short(DataSerializableFixedID.TOKEN_DESTROYED)
        .intValue());
    constdsfids
        .add(new Short(DataSerializableFixedID.TOKEN_REMOVED).intValue());
    constdsfids.add(new Short(DataSerializableFixedID.TOKEN_REMOVED2)
        .intValue());
    constdsfids.add(new Short(DataSerializableFixedID.TOKEN_TOMBSTONE)
        .intValue());

    for (int i = 0; i < 256; i++) {
      Constructor<?> cons = DSFIDFactory.getDsfidmap()[i];
      if (!constdsfids.contains(i - Byte.MAX_VALUE - 1) && cons != null) {
        Object ds = cons.newInstance((Object[]) null);
        checkSupportForRollingUpgrade(ds);
      }
    }
    
    // some msgs require distributed system
    Cache c = new CacheFactory().set(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"").create();
    for (Object o : DSFIDFactory.getDsfidmap2().values()) {
      Constructor<?> cons = (Constructor<?>) o;
      if (cons != null) {
        DataSerializableFixedID ds = (DataSerializableFixedID) cons
            .newInstance((Object[]) null);
        checkSupportForRollingUpgrade(ds);
      }
    }",False
"  public void tearDown() {
    resetFlags();
    // reset the class mapped to the dsfid
    DSFIDFactory.registerDSFID(DataSerializableFixedID.PUTALL_VERSIONS_LIST,
        EntryVersionsList.class);
    this.baos = null;
    this.bais = null;
  }",True
"
  @After
  public void tearDown2() {
    resetFlags();
    // reset the class mapped to the dsfid
    DSFIDFactory.registerDSFID(DataSerializableFixedID.PUTALL_VERSIONS_LIST,
        EntryVersionsList.class);
    this.baos = null;",False
"  private void startCacheServer(VM server, final int port, final int mcastPort) throws Exception {
    server.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        //System.setProperty(""IDLE_THREAD_TIMEOUT"", ""50"");
        getSystem(getServerProperties(mcastPort));
        
        GemFireCacheImpl cache = (GemFireCacheImpl)getCache();
        
        CacheServer cacheServer = cache.addCacheServer();
        cacheServer.setPort(port);
        cacheServer.start();  
        return null;
      }
    });
  }",True
"  private void startCacheServer(VM server, final int port) throws Exception {
    server.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        //System.setProperty(""IDLE_THREAD_TIMEOUT"", ""50"");
        disconnectFromDS();
        
        getSystem(getServerProperties());
        
        GemFireCacheImpl cache = (GemFireCacheImpl)getCache();
        
        CacheServer cacheServer = cache.addCacheServer();
        cacheServer.setPort(port);
        cacheServer.start();  
        return null;
      }
    });
  }",False
"  protected Properties getServerProperties(int mcastPort) {
    Properties p = new Properties();
    p.setProperty(DistributionConfig.MCAST_PORT_NAME, mcastPort+"""");
    p.setProperty(DistributionConfig.LOCATORS_NAME, """");
    p.setProperty(DistributionConfig.CONSERVE_SOCKETS_NAME, ""false"");
    //p.setProperty(DistributionConfig.SOCKET_LEASE_TIME_NAME, ""120000"");
    return p;
  }",True
"
  protected Properties getServerProperties() {
    Properties p = new Properties();
    p.setProperty(DistributionConfig.LOCATORS_NAME, ""localhost[""+getDUnitLocatorPort()+""]"");
    p.setProperty(DistributionConfig.CONSERVE_SOCKETS_NAME, ""false"");
    //p.setProperty(DistributionConfig.SOCKET_LEASE_TIME_NAME, ""120000"");
    return p;
  }",False
"  public void testFDSocketFixOnlyServers() throws Exception {
    String os = System.getProperty(""os.name"");
    if (os != null) {
      if (os.indexOf(""Windows"") != -1) {
        System.out.println(""This test is disabled on Windows"");
        //we are running this test on windows.  fd stats are not available in windows so let's
        //just not run this test
        return;
      }
    }
    try {
      final int[] port = AvailablePortHelper.getRandomAvailableTCPPorts(3);
      final int mcastPort = AvailablePortHelper.getRandomAvailableUDPPort();
      int numThreads = 10;

      startCacheServer(vm0, port[0], mcastPort);
      startCacheServer(vm1, port[1], mcastPort);
      startCacheServer(vm2, port[2], mcastPort);

      createRegion(vm0, ""portfolios"", RegionShortcut.PARTITION_REDUNDANT);
      createRegion(vm1, ""portfolios"", RegionShortcut.PARTITION_REDUNDANT);
      createRegion(vm2, ""portfolios"", RegionShortcut.PARTITION_REDUNDANT);

      // run test without selector pooling
      setUseSelectorPooling(vm0, false);
      long startingFDs = checkFD(vm0);
      doPuts(vm0, numThreads, ""portfolios"");
      long endFDs = checkFD(vm0);
      long numFDs = endFDs - startingFDs;

      // run test with selector pooling
      setUseSelectorPooling(vm0, true);
      long startingFDsWithPooling = checkFD(vm0);
      doPuts(vm0, numThreads, ""portfolios"");
      long endFDsWithPooling = checkFD(vm0);
      long numFDsWithPooling = endFDsWithPooling - startingFDsWithPooling;
      assertTrue(numFDsWithPooling < numFDs);

      // run it again and see if the number still is below
      startingFDsWithPooling = checkFD(vm0);
      doPuts(vm0, numThreads, ""portfolios"");
      endFDsWithPooling = checkFD(vm0);
      numFDsWithPooling = endFDsWithPooling - startingFDsWithPooling;
      // if you see these asserts failing, it could be that we are not using the
      // selector pool
      assertTrue(numFDsWithPooling < numFDs);

    } finally {
      setUseSelectorPooling(vm0, true);
    }

  }",True
"  public void testFDSocketFixOnlyServers() throws Exception {
    String os = System.getProperty(""os.name"");
    if (os != null) {
      if (os.indexOf(""Windows"") != -1) {
        System.out.println(""This test is disabled on Windows"");
        //we are running this test on windows.  fd stats are not available in windows so let's
        //just not run this test
        return;
      }
    }
    try {
      final int[] port = AvailablePortHelper.getRandomAvailableTCPPorts(3);
      int numThreads = 10;

      startCacheServer(vm0, port[0]);
      startCacheServer(vm1, port[1]);
      startCacheServer(vm2, port[2]);

      createRegion(vm0, ""portfolios"", RegionShortcut.PARTITION_REDUNDANT);
      createRegion(vm1, ""portfolios"", RegionShortcut.PARTITION_REDUNDANT);
      createRegion(vm2, ""portfolios"", RegionShortcut.PARTITION_REDUNDANT);

      // run test without selector pooling
      setUseSelectorPooling(vm0, false);
      long startingFDs = checkFD(vm0);
      doPuts(vm0, numThreads, ""portfolios"");
      long endFDs = checkFD(vm0);
      long numFDs = endFDs - startingFDs;

      // run test with selector pooling
      setUseSelectorPooling(vm0, true);
      long startingFDsWithPooling = checkFD(vm0);
      doPuts(vm0, numThreads, ""portfolios"");
      long endFDsWithPooling = checkFD(vm0);
      long numFDsWithPooling = endFDsWithPooling - startingFDsWithPooling;
      assertTrue(numFDsWithPooling < numFDs);

      // run it again and see if the number still is below
      startingFDsWithPooling = checkFD(vm0);
      doPuts(vm0, numThreads, ""portfolios"");
      endFDsWithPooling = checkFD(vm0);
      numFDsWithPooling = endFDsWithPooling - startingFDsWithPooling;
      // if you see these asserts failing, it could be that we are not using the
      // selector pool
      assertTrue(numFDsWithPooling < numFDs);

    } finally {
      setUseSelectorPooling(vm0, true);
    }

  }",False
"  protected Properties getServerProperties() {
    Properties p = new Properties();
    p.setProperty(DistributionConfig.LOCATORS_NAME, ""localhost[""+getDUnitLocatorPort()+""]"");
    p.setProperty(DistributionConfig.CONSERVE_SOCKETS_NAME, ""false"");
    //p.setProperty(DistributionConfig.SOCKET_LEASE_TIME_NAME, ""120000"");
    return p;
  }",False
"    server.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        //System.setProperty(""IDLE_THREAD_TIMEOUT"", ""50"");
        disconnectFromDS();
        
        getSystem(getServerProperties());
        
        GemFireCacheImpl cache = (GemFireCacheImpl)getCache();
        
        CacheServer cacheServer = cache.addCacheServer();
        cacheServer.setPort(port);
        cacheServer.start();  
        return null;
      }
    });",False
"  private void createBridgeServer(VM server, final int mcastPort, final String regionName, final int serverPort, final boolean createPR) {
    server.invoke(new CacheSerializableRunnable(""Create server"") {
      public void run2() throws CacheException {
        // Create DS
        Properties config = new Properties();
        config.setProperty(DistributionConfig.MCAST_PORT_NAME, String.valueOf(mcastPort));
        config.setProperty(DistributionConfig.LOCATORS_NAME, """");
        getSystem(config);

        // Create Region
        AttributesFactory factory = new AttributesFactory();
        factory.setCacheLoader(new BridgeServerCacheLoader());
        if (createPR) {
          factory.setDataPolicy(DataPolicy.PARTITION);
          factory.setPartitionAttributes((new PartitionAttributesFactory()).create());
        } else {
          factory.setScope(Scope.DISTRIBUTED_ACK);
          factory.setDataPolicy(DataPolicy.REPLICATE);
        }
        Region region = createRootRegion(regionName, factory.create());
        if (createPR) {
          assertTrue(region instanceof PartitionedRegion);
        }
        int ENTRIES_ON_SERVER = 10;
        for (int i=1; i <= ENTRIES_ON_SERVER; i++) {
          region.create(""k""+i, ""v""+i);
        }
        try {
          startBridgeServer(serverPort);
        } catch (Exception e) {
          fail(""While starting CacheServer"", e);
        }
      }
    });
  }",True
"  private void createBridgeServer(VM server, final String regionName, final int serverPort, final boolean createPR) {
    server.invoke(new CacheSerializableRunnable(""Create server"") {
      public void run2() throws CacheException {
        // Create DS
        Properties config = new Properties();
        config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
        getSystem(config);

        // Create Region
        AttributesFactory factory = new AttributesFactory();
        factory.setCacheLoader(new BridgeServerCacheLoader());
        if (createPR) {
          factory.setDataPolicy(DataPolicy.PARTITION);
          factory.setPartitionAttributes((new PartitionAttributesFactory()).create());
        } else {
          factory.setScope(Scope.DISTRIBUTED_ACK);
          factory.setDataPolicy(DataPolicy.REPLICATE);
        }
        Region region = createRootRegion(regionName, factory.create());
        if (createPR) {
          assertTrue(region instanceof PartitionedRegion);
        }
        int ENTRIES_ON_SERVER = 10;
        for (int i=1; i <= ENTRIES_ON_SERVER; i++) {
          region.create(""k""+i, ""v""+i);
        }
        try {
          startBridgeServer(serverPort);
        } catch (Exception e) {
          fail(""While starting CacheServer"", e);
        }
      }
    });
  }",False
"  public void testBug41957() {
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final String regionName = getUniqueName();
    final int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    final int serverPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    final String serverHost = getServerHostName(server.getHost());

    createBridgeServer(server, mcastPort, regionName, serverPort, false);

    createBridgeClient(client, regionName, serverHost, new int[] {serverPort});

    client.invoke(new CacheSerializableRunnable(""register interest"") {
      public void run2() throws CacheException {
        Region region = getRootRegion(regionName);
        int ENTRIES_ON_SERVER = 10;
        for (int i=1; i <= ENTRIES_ON_SERVER; i++) {
          region.registerInterest(""k""+i, InterestResultPolicy.KEYS_VALUES);
        }
        assertEquals(2, region.size());
      }
    });

    stopBridgeServer(server);
  }",True
"  public void testBug41957() {
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final String regionName = getUniqueName();
    final int serverPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    final String serverHost = getServerHostName(server.getHost());

    createBridgeServer(server, regionName, serverPort, false);

    createBridgeClient(client, regionName, serverHost, new int[] {serverPort});

    client.invoke(new CacheSerializableRunnable(""register interest"") {
      public void run2() throws CacheException {
        Region region = getRootRegion(regionName);
        int ENTRIES_ON_SERVER = 10;
        for (int i=1; i <= ENTRIES_ON_SERVER; i++) {
          region.registerInterest(""k""+i, InterestResultPolicy.KEYS_VALUES);
        }
        assertEquals(2, region.size());
      }
    });

    stopBridgeServer(server);
  }",False
"    server.invoke(new CacheSerializableRunnable(""Create server"") {
      public void run2() throws CacheException {
        // Create DS
        Properties config = new Properties();
        config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
        getSystem(config);

        // Create Region
        AttributesFactory factory = new AttributesFactory();
        factory.setCacheLoader(new BridgeServerCacheLoader());
        if (createPR) {
          factory.setDataPolicy(DataPolicy.PARTITION);
          factory.setPartitionAttributes((new PartitionAttributesFactory()).create());
        } else {
          factory.setScope(Scope.DISTRIBUTED_ACK);
          factory.setDataPolicy(DataPolicy.REPLICATE);
        }
        Region region = createRootRegion(regionName, factory.create());
        if (createPR) {
          assertTrue(region instanceof PartitionedRegion);
        }
        int ENTRIES_ON_SERVER = 10;
        for (int i=1; i <= ENTRIES_ON_SERVER; i++) {
          region.create(""k""+i, ""v""+i);
        }
        try {
          startBridgeServer(serverPort);
        } catch (Exception e) {
          fail(""While starting CacheServer"", e);
        }
      }
    });
  }

  private void createBridgeClient(VM client, final String regionName, final String serverHost, final int[] serverPorts) {",False
"  private void createBridgeServer(VM server, final int mcastPort, final String regionName, final int serverPort, final boolean createPR, final boolean expectCallback) {
    createBridgeServer(server, mcastPort, regionName, serverPort, createPR, expectCallback, false);
  }",True
"  private void createBridgeServer(VM server, final String regionName, final int serverPort, final boolean createPR, final boolean expectCallback, final boolean offheap) {
    server.invoke(new CacheSerializableRunnable(""Create server"") {
      @Override
      public void run2() throws CacheException {
        // Create DS
        Properties config = new Properties();
        config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
        if (offheap) {
          config.setProperty(DistributionConfig.OFF_HEAP_MEMORY_SIZE_NAME, ""350m"");
        }
        getSystem(config);

        // Create Region
        AttributesFactory factory = new AttributesFactory();
        if (offheap) {
          factory.setOffHeap(true);
        }
        if (expectCallback) {
          factory.setCacheLoader(new CallbackBridgeServerCacheLoader());
        } else {
          factory.setCacheLoader(new BridgeServerCacheLoader());
        }
        if (createPR) {
          factory.setDataPolicy(DataPolicy.PARTITION);
          factory.setPartitionAttributes((new PartitionAttributesFactory()).create());
        } else {
          factory.setScope(Scope.DISTRIBUTED_ACK);
          factory.setDataPolicy(DataPolicy.REPLICATE);
        }
        Region region = createRootRegion(regionName, factory.create());
        if (createPR) {
          assertTrue(region instanceof PartitionedRegion);
        }
        try {
          Cache cache = getCache();
          BridgeServer bridge = cache.addBridgeServer();
          bridge.setPort(serverPort);
          // for off-heap I want the server to use a selector
          bridge.setMaxThreads(offheap ? 16 : getMaxThreads());
          bridge.start();
        } catch (Exception e) {
          fail(""While starting CacheServer"", e);
        }
      }
    });
  }",False
"  public void testGetAllWithExtraKeyFromServer() throws Exception {
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final String regionName = getUniqueName();
    final int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    final int serverPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    final String serverHost = getServerHostName(server.getHost());
    final int numLocalValues = 101;
    
    createBridgeServerWithoutLoader(server, mcastPort, regionName, serverPort, false);

    createBridgeClient(client, regionName, serverHost, new int[] {serverPort});

    // Put some entries from the client
    client.invoke(new CacheSerializableRunnable(""Put entries from client"") {
      public void run2() throws CacheException {
        Region region = getRootRegion(regionName);
        for (int i = 0; i < numLocalValues; i++) {
          region.put(""key-"" + i, ""value-from-client-"" + i);
        }
      }
    });
    
    server.invoke(new CacheSerializableRunnable(""Put entries from server"") {
      public void run2() throws CacheException {
        Region region = getRootRegion(regionName);
        for (int i = numLocalValues; i < numLocalValues*2; i++) {
          region.put(""key-"" + i, ""value-from-server-"" + i);
        }
        region.getCache().getLogger().fine(""The region entries in server "" + region.entrySet());
      }
    });
    
    
    // Run getAll
    client.invoke(new CacheSerializableRunnable(""Get all entries from server"") {
      public void run2() throws CacheException {
        // Build collection of keys
        Collection keys = new ArrayList();
        for (int i=0; i<numLocalValues*3; i++) {
          keys.add(""key-""+i);
        }

        // Invoke getAll
        Region region = getRootRegion(regionName);
        region.getCache().getLogger().fine(""The region entries in client before getAll "" + region.entrySet());
        assertEquals(region.entrySet().size(),numLocalValues);
        Map result = region.getAll(keys);
        assertEquals(region.entrySet().size(),2*numLocalValues);
        region.getCache().getLogger().fine(""The region entries in client after getAll "" + region.entrySet());
        
        // Verify result size is correct
        assertEquals(3*numLocalValues, result.size());

        // Verify the result contains each key,
        // and the value for each key is correct
        int i = 0;
        for (Iterator it = keys.iterator(); it.hasNext(); i++) {
          String key = (String) it.next();
          assertTrue(result.containsKey(key));
          Object value = result.get(key);
          if (i < numLocalValues) {
            assertEquals(""value-from-client-""+i, value);
          }else if(i < 2*numLocalValues) {
            assertEquals(""value-from-server-""+i, value);
          }
          else {
            assertEquals(null, value);
          }
        }
      }
    });

    stopBridgeServer(server);
  }",True
"  public void testGetAllWithExtraKeyFromServer() throws Exception {
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final String regionName = getUniqueName();
    final int serverPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    final String serverHost = getServerHostName(server.getHost());
    final int numLocalValues = 101;
    
    createBridgeServerWithoutLoader(server, regionName, serverPort, false);

    createBridgeClient(client, regionName, serverHost, new int[] {serverPort});

    // Put some entries from the client
    client.invoke(new CacheSerializableRunnable(""Put entries from client"") {
      public void run2() throws CacheException {
        Region region = getRootRegion(regionName);
        for (int i = 0; i < numLocalValues; i++) {
          region.put(""key-"" + i, ""value-from-client-"" + i);
        }
      }
    });
    
    server.invoke(new CacheSerializableRunnable(""Put entries from server"") {
      public void run2() throws CacheException {
        Region region = getRootRegion(regionName);
        for (int i = numLocalValues; i < numLocalValues*2; i++) {
          region.put(""key-"" + i, ""value-from-server-"" + i);
        }
        region.getCache().getLogger().fine(""The region entries in server "" + region.entrySet());
      }
    });
    
    
    // Run getAll
    client.invoke(new CacheSerializableRunnable(""Get all entries from server"") {
      public void run2() throws CacheException {
        // Build collection of keys
        Collection keys = new ArrayList();
        for (int i=0; i<numLocalValues*3; i++) {
          keys.add(""key-""+i);
        }

        // Invoke getAll
        Region region = getRootRegion(regionName);
        region.getCache().getLogger().fine(""The region entries in client before getAll "" + region.entrySet());
        assertEquals(region.entrySet().size(),numLocalValues);
        Map result = region.getAll(keys);
        assertEquals(region.entrySet().size(),2*numLocalValues);
        region.getCache().getLogger().fine(""The region entries in client after getAll "" + region.entrySet());
        
        // Verify result size is correct
        assertEquals(3*numLocalValues, result.size());

        // Verify the result contains each key,
        // and the value for each key is correct
        int i = 0;
        for (Iterator it = keys.iterator(); it.hasNext(); i++) {
          String key = (String) it.next();
          assertTrue(result.containsKey(key));
          Object value = result.get(key);
          if (i < numLocalValues) {
            assertEquals(""value-from-client-""+i, value);
          }else if(i < 2*numLocalValues) {
            assertEquals(""value-from-server-""+i, value);
          }
          else {
            assertEquals(null, value);
          }
        }
      }
    });

    stopBridgeServer(server);
  }",False
"        config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
        if (offheap) {
          config.setProperty(DistributionConfig.OFF_HEAP_MEMORY_SIZE_NAME, ""350m"");
        }
        getSystem(config);

        // Create Region
        AttributesFactory factory = new AttributesFactory();
        if (offheap) {
          factory.setOffHeap(true);
        }
        if (expectCallback) {
          factory.setCacheLoader(new CallbackBridgeServerCacheLoader());
        } else {
          factory.setCacheLoader(new BridgeServerCacheLoader());
        }
        if (createPR) {
          factory.setDataPolicy(DataPolicy.PARTITION);
          factory.setPartitionAttributes((new PartitionAttributesFactory()).create());
        } else {
          factory.setScope(Scope.DISTRIBUTED_ACK);
          factory.setDataPolicy(DataPolicy.REPLICATE);
        }
        Region region = createRootRegion(regionName, factory.create());
        if (createPR) {
          assertTrue(region instanceof PartitionedRegion);
        }
        try {
          Cache cache = getCache();
          BridgeServer bridge = cache.addBridgeServer();
          bridge.setPort(serverPort);
          // for off-heap I want the server to use a selector
          bridge.setMaxThreads(offheap ? 16 : getMaxThreads());
          bridge.start();
        } catch (Exception e) {
          fail(""While starting CacheServer"", e);
        }
      }
    });
  }
  
  private static final String CALLBACK_ARG = ""ClientServerGetAllDUnitTestCB"";

  private static class CallbackBridgeServerCacheLoader extends BridgeServerCacheLoader {
    @Override
    public Object load2(LoaderHelper helper) {
      if (helper.getArgument() instanceof String) {",False
"  public void testLargeOffHeapGetAllFromServer() throws Throwable {
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final String regionName = getUniqueName();
    final int mcastPort = 0; /* loner is ok for this test*/ //AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    final int serverPort = AvailablePortHelper.getRandomAvailableTCPPort();
    final String serverHost = getServerHostName(server.getHost());

    createBridgeServer(server, mcastPort, regionName, serverPort, false, false, true/*offheap*/);

    createBridgeClient(client, regionName, serverHost, new int[] {serverPort}, true);
    
    final int VALUE_SIZE = 1024 * 2/* *1024*/;

    final int VALUE_COUNT = 100;
    
    client.invoke(new CacheSerializableRunnable(""put entries on server"") {
      @Override
      public void run2() throws CacheException {
        final byte[] VALUE = new byte[VALUE_SIZE];
        for (int i=0; i < VALUE_SIZE; i++) {
          VALUE[i] = (byte)i;
        }
        Region region = getRootRegion(regionName);
        for (int i=0; i < VALUE_COUNT; i++) {
          region.put(""k""+i, new UnitTestValueHolder(VALUE));
        }
      }
    });

    CacheSerializableRunnable clientGetAll = new CacheSerializableRunnable(""Get all entries from server"") {
      @Override
      public void run2() throws CacheException {
        // Build collection of keys
        Collection keys = new ArrayList();
        for (int i=0; i<VALUE_COUNT; i++) {
          keys.add(""k""+i);
        }
        
        // Invoke getAll
        Region region = getRootRegion(regionName);
        final int GET_COUNT = 10/*0*/;
        long start = System.currentTimeMillis();
        Map result = null;
        for (int i=0; i < GET_COUNT; i++) {
          result = null; // allow gc to get rid of previous map before deserializing the next one
          result = region.getAll(keys);
        }
        long end = System.currentTimeMillis();
        long totalBytesRead = ((long)GET_COUNT * VALUE_COUNT * VALUE_SIZE);
        long elapsedMillis = (end-start);
        System.out.println(""PERF: read "" + totalBytesRead + "" bytes in "" + elapsedMillis + "" millis. bps="" + (((double)totalBytesRead / elapsedMillis) * 1000));

        // Verify result size is correct
        assertEquals(VALUE_COUNT, result.size());

        final byte[] EXPECTED = new byte[VALUE_SIZE];
        for (int i=0; i < VALUE_SIZE; i++) {
          EXPECTED[i] = (byte)i;
        }
        // Verify the result contains each key,
        // and the value for each key is correct
        // (the server has a loader that returns the key as the value)
        for (Iterator i = keys.iterator(); i.hasNext();) {
          String key = (String) i.next();
          assertTrue(result.containsKey(key));
          Object value = result.get(key);
          if (value instanceof UnitTestValueHolder) {
            Object v = ((UnitTestValueHolder) value).getValue();
            if (v instanceof byte[]) {
              byte[] bytes = (byte[]) v;
              if (bytes.length != VALUE_SIZE) {
                fail(""expected value for key "" + key + "" to be an array of size "" + (VALUE_SIZE) + "" but it was: "" + bytes.length);
              }
              if (!Arrays.equals(EXPECTED, bytes)) {
                fail(""expected bytes="" + Arrays.toString(bytes) + "" to be expected="" + Arrays.toString(EXPECTED));
              }
            } else {
              fail(""expected v for key "" + key + "" to be a byte array but it was: "" + v);
            }
          } else {
            fail(""expected value for key "" + key + "" to be a UnitTestValueHolder but it was: "" + value);
          }
        }
      }
    };
    // Run getAll
    {
      final int THREAD_COUNT = 4;
      AsyncInvocation[] ais = new AsyncInvocation[THREAD_COUNT];
      for (int i=0; i < THREAD_COUNT; i++) {
        ais[i] = client.invokeAsync(clientGetAll);
      }
      for (int i=0; i < THREAD_COUNT; i++) {
        ais[i].getResult();
      }
    }

    server.invoke(new CacheSerializableRunnable(""Dump OffHeap Stats"") {
      @Override
      public void run2() throws CacheException {
        SimpleMemoryAllocatorImpl ma = SimpleMemoryAllocatorImpl.getAllocator();
        System.out.println(""STATS: objects="" + ma.getStats().getObjects() + "" usedMemory="" + ma.getStats().getUsedMemory() + "" reads="" + ma.getStats().getReads());
      }
    });

    checkServerForOrphans(server, regionName);

    stopBridgeServer(server);
  }",True
"  public void testLargeOffHeapGetAllFromServer() throws Throwable {
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final String regionName = getUniqueName();
    final int serverPort = AvailablePortHelper.getRandomAvailableTCPPort();
    final String serverHost = getServerHostName(server.getHost());

    createBridgeServer(server, regionName, serverPort, false, false, true/*offheap*/);

    createBridgeClient(client, regionName, serverHost, new int[] {serverPort}, true);
    
    final int VALUE_SIZE = 1024 * 2/* *1024*/;

    final int VALUE_COUNT = 100;
    
    client.invoke(new CacheSerializableRunnable(""put entries on server"") {
      @Override
      public void run2() throws CacheException {
        final byte[] VALUE = new byte[VALUE_SIZE];
        for (int i=0; i < VALUE_SIZE; i++) {
          VALUE[i] = (byte)i;
        }
        Region region = getRootRegion(regionName);
        for (int i=0; i < VALUE_COUNT; i++) {
          region.put(""k""+i, new UnitTestValueHolder(VALUE));
        }
      }
    });

    CacheSerializableRunnable clientGetAll = new CacheSerializableRunnable(""Get all entries from server"") {
      @Override
      public void run2() throws CacheException {
        // Build collection of keys
        Collection keys = new ArrayList();
        for (int i=0; i<VALUE_COUNT; i++) {
          keys.add(""k""+i);
        }
        
        // Invoke getAll
        Region region = getRootRegion(regionName);
        final int GET_COUNT = 10/*0*/;
        long start = System.currentTimeMillis();
        Map result = null;
        for (int i=0; i < GET_COUNT; i++) {
          result = null; // allow gc to get rid of previous map before deserializing the next one
          result = region.getAll(keys);
        }
        long end = System.currentTimeMillis();
        long totalBytesRead = ((long)GET_COUNT * VALUE_COUNT * VALUE_SIZE);
        long elapsedMillis = (end-start);
        System.out.println(""PERF: read "" + totalBytesRead + "" bytes in "" + elapsedMillis + "" millis. bps="" + (((double)totalBytesRead / elapsedMillis) * 1000));

        // Verify result size is correct
        assertEquals(VALUE_COUNT, result.size());

        final byte[] EXPECTED = new byte[VALUE_SIZE];
        for (int i=0; i < VALUE_SIZE; i++) {
          EXPECTED[i] = (byte)i;
        }
        // Verify the result contains each key,
        // and the value for each key is correct
        // (the server has a loader that returns the key as the value)
        for (Iterator i = keys.iterator(); i.hasNext();) {
          String key = (String) i.next();
          assertTrue(result.containsKey(key));
          Object value = result.get(key);
          if (value instanceof UnitTestValueHolder) {
            Object v = ((UnitTestValueHolder) value).getValue();
            if (v instanceof byte[]) {
              byte[] bytes = (byte[]) v;
              if (bytes.length != VALUE_SIZE) {
                fail(""expected value for key "" + key + "" to be an array of size "" + (VALUE_SIZE) + "" but it was: "" + bytes.length);
              }
              if (!Arrays.equals(EXPECTED, bytes)) {
                fail(""expected bytes="" + Arrays.toString(bytes) + "" to be expected="" + Arrays.toString(EXPECTED));
              }
            } else {
              fail(""expected v for key "" + key + "" to be a byte array but it was: "" + v);
            }
          } else {
            fail(""expected value for key "" + key + "" to be a UnitTestValueHolder but it was: "" + value);
          }
        }
      }
    };
    // Run getAll
    {
      final int THREAD_COUNT = 4;
      AsyncInvocation[] ais = new AsyncInvocation[THREAD_COUNT];
      for (int i=0; i < THREAD_COUNT; i++) {
        ais[i] = client.invokeAsync(clientGetAll);
      }
      for (int i=0; i < THREAD_COUNT; i++) {
        ais[i].getResult();
      }
    }

    server.invoke(new CacheSerializableRunnable(""Dump OffHeap Stats"") {
      @Override
      public void run2() throws CacheException {
        SimpleMemoryAllocatorImpl ma = SimpleMemoryAllocatorImpl.getAllocator();
        System.out.println(""STATS: objects="" + ma.getStats().getObjects() + "" usedMemory="" + ma.getStats().getUsedMemory() + "" reads="" + ma.getStats().getReads());
      }
    });

    checkServerForOrphans(server, regionName);

    stopBridgeServer(server);
  }",False
"  public void testOffHeapGetAllFromServer() throws Exception {
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final String regionName = getUniqueName();
    final int mcastPort = 0; /* loner is ok for this test*/ //AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    final int serverPort = AvailablePortHelper.getRandomAvailableTCPPort();
    final String serverHost = getServerHostName(server.getHost());

    createBridgeServer(server, mcastPort, regionName, serverPort, false, false, true/*offheap*/);

    createBridgeClient(client, regionName, serverHost, new int[] {serverPort});

    // Run getAll
    client.invoke(new CacheSerializableRunnable(""Get all entries from server"") {
      @Override
      public void run2() throws CacheException {
        // Build collection of keys
        Collection keys = new ArrayList();
        for (int i=0; i<5; i++) {
          keys.add(""key-""+i);
        }
        
        keys.add(BridgeTestCase.NON_EXISTENT_KEY); // this will not be load CacheLoader
        
        // Invoke getAll
        Region region = getRootRegion(regionName);
        Map result = region.getAll(keys);

        // Verify result size is correct
        assertEquals(6, result.size());

        // Verify the result contains each key,
        // and the value for each key is correct
        // (the server has a loader that returns the key as the value)
        for (Iterator i = keys.iterator(); i.hasNext();) {
          String key = (String) i.next();
          assertTrue(result.containsKey(key));
          Object value = result.get(key);
          if(!key.equals(BridgeTestCase.NON_EXISTENT_KEY))
            assertEquals(key, value);
          else
            assertEquals(null, value);
        }
        
        assertEquals(null, region.get(BridgeTestCase.NON_EXISTENT_KEY));
      }
    });
    checkServerForOrphans(server, regionName);

    stopBridgeServer(server);
  }",True
"  public void testOffHeapGetAllFromServer() throws Exception {
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final String regionName = getUniqueName();
    final int serverPort = AvailablePortHelper.getRandomAvailableTCPPort();
    final String serverHost = getServerHostName(server.getHost());

    createBridgeServer(server, regionName, serverPort, false, false, true/*offheap*/);

    createBridgeClient(client, regionName, serverHost, new int[] {serverPort});

    // Run getAll
    client.invoke(new CacheSerializableRunnable(""Get all entries from server"") {
      @Override
      public void run2() throws CacheException {
        // Build collection of keys
        Collection keys = new ArrayList();
        for (int i=0; i<5; i++) {
          keys.add(""key-""+i);
        }
        
        keys.add(BridgeTestCase.NON_EXISTENT_KEY); // this will not be load CacheLoader
        
        // Invoke getAll
        Region region = getRootRegion(regionName);
        Map result = region.getAll(keys);

        // Verify result size is correct
        assertEquals(6, result.size());

        // Verify the result contains each key,
        // and the value for each key is correct
        // (the server has a loader that returns the key as the value)
        for (Iterator i = keys.iterator(); i.hasNext();) {
          String key = (String) i.next();
          assertTrue(result.containsKey(key));
          Object value = result.get(key);
          if(!key.equals(BridgeTestCase.NON_EXISTENT_KEY))
            assertEquals(key, value);
          else
            assertEquals(null, value);
        }
        
        assertEquals(null, region.get(BridgeTestCase.NON_EXISTENT_KEY));
      }
    });
    checkServerForOrphans(server, regionName);

    stopBridgeServer(server);
  }",False
"  private void createBridgeServerWithoutLoader(VM server, final int mcastPort, final String regionName, final int serverPort, final boolean createPR) {
    server.invoke(new CacheSerializableRunnable(""Create server"") {
      public void run2() throws CacheException {
        // Create DS
        Properties config = new Properties();
        config.setProperty(DistributionConfig.MCAST_PORT_NAME, String.valueOf(mcastPort));
        config.setProperty(DistributionConfig.LOCATORS_NAME, """");
        getSystem(config);

        // Create Region
        AttributesFactory factory = new AttributesFactory();
        if (createPR) {
          factory.setDataPolicy(DataPolicy.PARTITION);
          factory.setPartitionAttributes((new PartitionAttributesFactory()).create());
        } else {
          factory.setScope(Scope.DISTRIBUTED_ACK);
          factory.setDataPolicy(DataPolicy.REPLICATE);
        }
        Region region = createRootRegion(regionName, factory.create());
        if (createPR) {
          assertTrue(region instanceof PartitionedRegion);
        }
        try {
          startBridgeServer(serverPort);
          System.out.println(""Started bridger server "");
        } catch (Exception e) {
          fail(""While starting CacheServer"", e);
        }
      }
    });
  }",True
"  private void createBridgeServerWithoutLoader(VM server, final String regionName, final int serverPort, final boolean createPR) {
    server.invoke(new CacheSerializableRunnable(""Create server"") {
      public void run2() throws CacheException {
        // Create DS
        Properties config = new Properties();
        config.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
        getSystem(config);

        // Create Region
        AttributesFactory factory = new AttributesFactory();
        if (createPR) {
          factory.setDataPolicy(DataPolicy.PARTITION);
          factory.setPartitionAttributes((new PartitionAttributesFactory()).create());
        } else {
          factory.setScope(Scope.DISTRIBUTED_ACK);
          factory.setDataPolicy(DataPolicy.REPLICATE);
        }
        Region region = createRootRegion(regionName, factory.create());
        if (createPR) {
          assertTrue(region instanceof PartitionedRegion);
        }
        try {
          startBridgeServer(serverPort);
          System.out.println(""Started bridger server "");
        } catch (Exception e) {
          fail(""While starting CacheServer"", e);
        }
      }
    });
  }",False
"
        // Create Region
        AttributesFactory factory = new AttributesFactory();
        if (createPR) {
          factory.setDataPolicy(DataPolicy.PARTITION);
          factory.setPartitionAttributes((new PartitionAttributesFactory()).create());
        } else {
          factory.setScope(Scope.DISTRIBUTED_ACK);
          factory.setDataPolicy(DataPolicy.REPLICATE);
        }
        Region region = createRootRegion(regionName, factory.create());
        if (createPR) {
          assertTrue(region instanceof PartitionedRegion);
        }
        try {
          startBridgeServer(serverPort);
          System.out.println(""Started bridger server "");
        } catch (Exception e) {
          fail(""While starting CacheServer"", e);
        }
      }
    });
  }
  private void createBridgeClient(VM client, final String regionName, final String serverHost, final int[] serverPorts) {
    createBridgeClient(client, regionName, serverHost, serverPorts, false);
  }
  
  private void createBridgeClient(VM client, final String regionName, final String serverHost, final int[] serverPorts, final boolean proxy) {
    client.invoke(new CacheSerializableRunnable(""Create client"") {
      @Override
      public void run2() throws CacheException {",False
"  public void testGetAllFromServer() throws Exception {
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final String regionName = getUniqueName();
    final int mcastPort = 0; /* loner is ok for this test*/ //AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    final int serverPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    final String serverHost = getServerHostName(server.getHost());

    createBridgeServer(server, mcastPort, regionName, serverPort, false, false);

    createBridgeClient(client, regionName, serverHost, new int[] {serverPort});

    // Run getAll
    client.invoke(new CacheSerializableRunnable(""Get all entries from server"") {
      @Override
      public void run2() throws CacheException {
        // Build collection of keys
        Collection keys = new ArrayList();
        for (int i=0; i<5; i++) {
          keys.add(""key-""+i);
        }
        
        keys.add(BridgeTestCase.NON_EXISTENT_KEY); // this will not be load CacheLoader
        
        // Invoke getAll
        Region region = getRootRegion(regionName);
        Map result = region.getAll(keys);

        // Verify result size is correct
        assertEquals(6, result.size());

        // Verify the result contains each key,
        // and the value for each key is correct
        // (the server has a loader that returns the key as the value)
        for (Iterator i = keys.iterator(); i.hasNext();) {
          String key = (String) i.next();
          assertTrue(result.containsKey(key));
          Object value = result.get(key);
          if(!key.equals(BridgeTestCase.NON_EXISTENT_KEY))
            assertEquals(key, value);
          else
            assertEquals(null, value);
        }
        
        assertEquals(null, region.get(BridgeTestCase.NON_EXISTENT_KEY));
      }
    });

    stopBridgeServer(server);
  }",True
"  public void testGetAllFromServer() throws Exception {
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final String regionName = getUniqueName();
    final int mcastPort = 0; /* loner is ok for this test*/ //AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    final int serverPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    final String serverHost = getServerHostName(server.getHost());

    createBridgeServer(server, regionName, serverPort, false, false);

    createBridgeClient(client, regionName, serverHost, new int[] {serverPort});

    // Run getAll
    client.invoke(new CacheSerializableRunnable(""Get all entries from server"") {
      @Override
      public void run2() throws CacheException {
        // Build collection of keys
        Collection keys = new ArrayList();
        for (int i=0; i<5; i++) {
          keys.add(""key-""+i);
        }
        
        keys.add(BridgeTestCase.NON_EXISTENT_KEY); // this will not be load CacheLoader
        
        // Invoke getAll
        Region region = getRootRegion(regionName);
        Map result = region.getAll(keys);

        // Verify result size is correct
        assertEquals(6, result.size());

        // Verify the result contains each key,
        // and the value for each key is correct
        // (the server has a loader that returns the key as the value)
        for (Iterator i = keys.iterator(); i.hasNext();) {
          String key = (String) i.next();
          assertTrue(result.containsKey(key));
          Object value = result.get(key);
          if(!key.equals(BridgeTestCase.NON_EXISTENT_KEY))
            assertEquals(key, value);
          else
            assertEquals(null, value);
        }
        
        assertEquals(null, region.get(BridgeTestCase.NON_EXISTENT_KEY));
      }
    });

    stopBridgeServer(server);
  }",False
"  public void testLargeGetAllFromServer() throws Throwable {
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final String regionName = getUniqueName();
    final int mcastPort = 0; /* loner is ok for this test*/ //AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    final int serverPort = AvailablePortHelper.getRandomAvailableTCPPort();
    final String serverHost = getServerHostName(server.getHost());

    createBridgeServer(server, mcastPort, regionName, serverPort, false, false);

    createBridgeClient(client, regionName, serverHost, new int[] {serverPort}, true);
    
    final int VALUE_SIZE = 1024 * 2/* *1024*/;

    final int VALUE_COUNT = 100;
    
    client.invoke(new CacheSerializableRunnable(""put entries on server"") {
      @Override
      public void run2() throws CacheException {
        final byte[] VALUE = new byte[VALUE_SIZE];
        for (int i=0; i < VALUE_SIZE; i++) {
          VALUE[i] = (byte)i;
        }
        Region region = getRootRegion(regionName);
        for (int i=0; i < VALUE_COUNT; i++) {
          region.put(""k""+i, new UnitTestValueHolder(VALUE));
        }
      }
    });

    // force them to be deserialized on server
    server.invoke(new CacheSerializableRunnable(""deserialize entries on server"") {
      @Override
      public void run2() throws CacheException {
        Region region = getRootRegion(regionName);
        for (int i=0; i < VALUE_COUNT; i++) {
          region.get(""k""+i);
        }
      }
    });

    CacheSerializableRunnable clientGetAll = new CacheSerializableRunnable(""Get all entries from server"") {
      @Override
      public void run2() throws CacheException {
        // Build collection of keys
        Collection keys = new ArrayList();
        for (int i=0; i<VALUE_COUNT; i++) {
          keys.add(""k""+i);
        }
        
        // Invoke getAll
        Region region = getRootRegion(regionName);
        final int GET_COUNT = 10/*0*/;
        long start = System.currentTimeMillis();
        Map result = null;
        for (int i=0; i < GET_COUNT; i++) {
          result = null; // allow gc to get rid of previous map before deserializing the next one
          result = region.getAll(keys);
        }
        long end = System.currentTimeMillis();
        long totalBytesRead = ((long)GET_COUNT * VALUE_COUNT * VALUE_SIZE);
        long elapsedMillis = (end-start);
        System.out.println(""PERF: read "" + totalBytesRead + "" bytes in "" + elapsedMillis + "" millis. bps="" + (((double)totalBytesRead / elapsedMillis) * 1000));

        // Verify result size is correct
        assertEquals(VALUE_COUNT, result.size());

        final byte[] EXPECTED = new byte[VALUE_SIZE];
        for (int i=0; i < VALUE_SIZE; i++) {
          EXPECTED[i] = (byte)i;
        }
        // Verify the result contains each key,
        // and the value for each key is correct
        // (the server has a loader that returns the key as the value)
        for (Iterator i = keys.iterator(); i.hasNext();) {
          String key = (String) i.next();
          assertTrue(result.containsKey(key));
          Object value = result.get(key);
          if (value instanceof UnitTestValueHolder) {
            Object v = ((UnitTestValueHolder) value).getValue();
            if (v instanceof byte[]) {
              byte[] bytes = (byte[]) v;
              if (bytes.length != VALUE_SIZE) {
                fail(""expected value for key "" + key + "" to be an array of size "" + (VALUE_SIZE) + "" but it was: "" + bytes.length);
              }
              if (!Arrays.equals(EXPECTED, bytes)) {
                fail(""expected bytes="" + Arrays.toString(bytes) + "" to be expected="" + Arrays.toString(EXPECTED));
              }
            } else {
              fail(""expected v for key "" + key + "" to be a byte array but it was: "" + v);
            }
          } else {
            fail(""expected value for key "" + key + "" to be a UnitTestValueHolder but it was: "" + value);
          }
        }
      }
    };
    // Run getAll
    {
      final int THREAD_COUNT = 4;
      AsyncInvocation[] ais = new AsyncInvocation[THREAD_COUNT];
      for (int i=0; i < THREAD_COUNT; i++) {
        ais[i] = client.invokeAsync(clientGetAll);
      }
      for (int i=0; i < THREAD_COUNT; i++) {
        ais[i].getResult();
      }
    }
    stopBridgeServer(server);
  }",True
"  public void testLargeGetAllFromServer() throws Throwable {
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final String regionName = getUniqueName();
    final int mcastPort = 0; /* loner is ok for this test*/ //AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    final int serverPort = AvailablePortHelper.getRandomAvailableTCPPort();
    final String serverHost = getServerHostName(server.getHost());

    createBridgeServer(server, regionName, serverPort, false, false);

    createBridgeClient(client, regionName, serverHost, new int[] {serverPort}, true);
    
    final int VALUE_SIZE = 1024 * 2/* *1024*/;

    final int VALUE_COUNT = 100;
    
    client.invoke(new CacheSerializableRunnable(""put entries on server"") {
      @Override
      public void run2() throws CacheException {
        final byte[] VALUE = new byte[VALUE_SIZE];
        for (int i=0; i < VALUE_SIZE; i++) {
          VALUE[i] = (byte)i;
        }
        Region region = getRootRegion(regionName);
        for (int i=0; i < VALUE_COUNT; i++) {
          region.put(""k""+i, new UnitTestValueHolder(VALUE));
        }
      }
    });

    // force them to be deserialized on server
    server.invoke(new CacheSerializableRunnable(""deserialize entries on server"") {
      @Override
      public void run2() throws CacheException {
        Region region = getRootRegion(regionName);
        for (int i=0; i < VALUE_COUNT; i++) {
          region.get(""k""+i);
        }
      }
    });

    CacheSerializableRunnable clientGetAll = new CacheSerializableRunnable(""Get all entries from server"") {
      @Override
      public void run2() throws CacheException {
        // Build collection of keys
        Collection keys = new ArrayList();
        for (int i=0; i<VALUE_COUNT; i++) {
          keys.add(""k""+i);
        }
        
        // Invoke getAll
        Region region = getRootRegion(regionName);
        final int GET_COUNT = 10/*0*/;
        long start = System.currentTimeMillis();
        Map result = null;
        for (int i=0; i < GET_COUNT; i++) {
          result = null; // allow gc to get rid of previous map before deserializing the next one
          result = region.getAll(keys);
        }
        long end = System.currentTimeMillis();
        long totalBytesRead = ((long)GET_COUNT * VALUE_COUNT * VALUE_SIZE);
        long elapsedMillis = (end-start);
        System.out.println(""PERF: read "" + totalBytesRead + "" bytes in "" + elapsedMillis + "" millis. bps="" + (((double)totalBytesRead / elapsedMillis) * 1000));

        // Verify result size is correct
        assertEquals(VALUE_COUNT, result.size());

        final byte[] EXPECTED = new byte[VALUE_SIZE];
        for (int i=0; i < VALUE_SIZE; i++) {
          EXPECTED[i] = (byte)i;
        }
        // Verify the result contains each key,
        // and the value for each key is correct
        // (the server has a loader that returns the key as the value)
        for (Iterator i = keys.iterator(); i.hasNext();) {
          String key = (String) i.next();
          assertTrue(result.containsKey(key));
          Object value = result.get(key);
          if (value instanceof UnitTestValueHolder) {
            Object v = ((UnitTestValueHolder) value).getValue();
            if (v instanceof byte[]) {
              byte[] bytes = (byte[]) v;
              if (bytes.length != VALUE_SIZE) {
                fail(""expected value for key "" + key + "" to be an array of size "" + (VALUE_SIZE) + "" but it was: "" + bytes.length);
              }
              if (!Arrays.equals(EXPECTED, bytes)) {
                fail(""expected bytes="" + Arrays.toString(bytes) + "" to be expected="" + Arrays.toString(EXPECTED));
              }
            } else {
              fail(""expected v for key "" + key + "" to be a byte array but it was: "" + v);
            }
          } else {
            fail(""expected value for key "" + key + "" to be a UnitTestValueHolder but it was: "" + value);
          }
        }
      }
    };
    // Run getAll
    {
      final int THREAD_COUNT = 4;
      AsyncInvocation[] ais = new AsyncInvocation[THREAD_COUNT];
      for (int i=0; i < THREAD_COUNT; i++) {
        ais[i] = client.invokeAsync(clientGetAll);
      }
      for (int i=0; i < THREAD_COUNT; i++) {
        ais[i].getResult();
      }
    }
    stopBridgeServer(server);
  }",False
"  private void createBridgeServer(VM server, final String regionName, final int serverPort, final boolean createPR, final boolean expectCallback) {
    createBridgeServer(server, regionName, serverPort, createPR, expectCallback, false);
  }",False
"  private void testGetFromServer(final int numLocalValues) {
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final String regionName = getUniqueName();
    final int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    final int serverPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    final String serverHost = getServerHostName(server.getHost());

    createBridgeServer(server, mcastPort, regionName, serverPort, false, false);

    createBridgeClient(client, regionName, serverHost, new int[] {serverPort});

    // Put some entries from the client
    client.invoke(new CacheSerializableRunnable(""Put entries from client"") {
      @Override
      public void run2() throws CacheException {
        Region region = getRootRegion(regionName);
        for (int i=0; i<numLocalValues; i++) {
          region.put(""key-""+i, ""value-from-client-""+i);
        }
      }
    });

    // Run getAll
    client.invoke(new CacheSerializableRunnable(""Get all entries from server"") {
      @Override
      public void run2() throws CacheException {
        // Build collection of keys
        Collection keys = new ArrayList();
        for (int i=0; i<5; i++) {
          keys.add(""key-""+i);
        }

        // Invoke getAll
        Region region = getRootRegion(regionName);
        Map result = region.getAll(keys);

        // Verify result size is correct
        assertEquals(5, result.size());

        // Verify the result contains each key,
        // and the value for each key is correct
        // (the server has a loader that returns the key as the value)
        // (the local value contains the phrase 'from client')
        int i = 0;
        for (Iterator it = keys.iterator(); it.hasNext(); i++) {
          String key = (String) it.next();
          assertTrue(result.containsKey(key));
          Object value = result.get(key);
          if (i < numLocalValues) {
            assertEquals(""value-from-client-""+i, value);
          } else {
            assertEquals(key, value);
          }
        }
      }
    });

    // client may see ""server unreachable"" exceptions after this
    addExpectedException(""Server unreachable"", client);
    stopBridgeServer(server);
  }",True
"  private void testGetFromServer(final int numLocalValues) {
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final String regionName = getUniqueName();
    final int serverPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    final String serverHost = getServerHostName(server.getHost());

    createBridgeServer(server, regionName, serverPort, false, false);

    createBridgeClient(client, regionName, serverHost, new int[] {serverPort});

    // Put some entries from the client
    client.invoke(new CacheSerializableRunnable(""Put entries from client"") {
      @Override
      public void run2() throws CacheException {
        Region region = getRootRegion(regionName);
        for (int i=0; i<numLocalValues; i++) {
          region.put(""key-""+i, ""value-from-client-""+i);
        }
      }
    });

    // Run getAll
    client.invoke(new CacheSerializableRunnable(""Get all entries from server"") {
      @Override
      public void run2() throws CacheException {
        // Build collection of keys
        Collection keys = new ArrayList();
        for (int i=0; i<5; i++) {
          keys.add(""key-""+i);
        }

        // Invoke getAll
        Region region = getRootRegion(regionName);
        Map result = region.getAll(keys);

        // Verify result size is correct
        assertEquals(5, result.size());

        // Verify the result contains each key,
        // and the value for each key is correct
        // (the server has a loader that returns the key as the value)
        // (the local value contains the phrase 'from client')
        int i = 0;
        for (Iterator it = keys.iterator(); it.hasNext(); i++) {
          String key = (String) it.next();
          assertTrue(result.containsKey(key));
          Object value = result.get(key);
          if (i < numLocalValues) {
            assertEquals(""value-from-client-""+i, value);
          } else {
            assertEquals(key, value);
          }
        }
      }
    });

    // client may see ""server unreachable"" exceptions after this
    addExpectedException(""Server unreachable"", client);
    stopBridgeServer(server);
  }",False
"  public void testGetAllWithCallbackFromServer() throws Exception {
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final String regionName = getUniqueName();
    final int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    final int serverPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    final String serverHost = getServerHostName(server.getHost());

    createBridgeServer(server, mcastPort, regionName, serverPort, false, true);

    createBridgeClient(client, regionName, serverHost, new int[] {serverPort});

    // Run getAll
    client.invoke(new CacheSerializableRunnable(""Get all entries from server"") {
      @Override
      public void run2() throws CacheException {
        // Build collection of keys
        Collection keys = new ArrayList();
        for (int i=0; i<5; i++) {
          keys.add(""key-""+i);
        }
        
        keys.add(BridgeTestCase.NON_EXISTENT_KEY); // this will not be load CacheLoader
        
        // Invoke getAll
        Region region = getRootRegion(regionName);
        Map result = region.getAll(keys, CALLBACK_ARG);

        // Verify result size is correct
        assertEquals(6, result.size());

        // Verify the result contains each key,
        // and the value for each key is correct
        // (the server has a loader that returns the key as the value)
        for (Iterator i = keys.iterator(); i.hasNext();) {
          String key = (String) i.next();
          assertTrue(result.containsKey(key));
          Object value = result.get(key);
          if(!key.equals(BridgeTestCase.NON_EXISTENT_KEY))
            assertEquals(key, value);
          else
            assertEquals(null, value);
        }
        
        assertEquals(null, region.get(BridgeTestCase.NON_EXISTENT_KEY));
      }
    });

    stopBridgeServer(server);
  }",True
"  public void testGetAllWithCallbackFromServer() throws Exception {
    final Host host = Host.getHost(0);
    final VM server = host.getVM(0);
    final VM client = host.getVM(1);
    final String regionName = getUniqueName();
    final int serverPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    final String serverHost = getServerHostName(server.getHost());

    createBridgeServer(server, regionName, serverPort, false, true);

    createBridgeClient(client, regionName, serverHost, new int[] {serverPort});

    // Run getAll
    client.invoke(new CacheSerializableRunnable(""Get all entries from server"") {
      @Override
      public void run2() throws CacheException {
        // Build collection of keys
        Collection keys = new ArrayList();
        for (int i=0; i<5; i++) {
          keys.add(""key-""+i);
        }
        
        keys.add(BridgeTestCase.NON_EXISTENT_KEY); // this will not be load CacheLoader
        
        // Invoke getAll
        Region region = getRootRegion(regionName);
        Map result = region.getAll(keys, CALLBACK_ARG);

        // Verify result size is correct
        assertEquals(6, result.size());

        // Verify the result contains each key,
        // and the value for each key is correct
        // (the server has a loader that returns the key as the value)
        for (Iterator i = keys.iterator(); i.hasNext();) {
          String key = (String) i.next();
          assertTrue(result.containsKey(key));
          Object value = result.get(key);
          if(!key.equals(BridgeTestCase.NON_EXISTENT_KEY))
            assertEquals(key, value);
          else
            assertEquals(null, value);
        }
        
        assertEquals(null, region.get(BridgeTestCase.NON_EXISTENT_KEY));
      }
    });

    stopBridgeServer(server);
  }",False
"    server.invoke(new CacheSerializableRunnable(""Create server"") {
      @Override
      public void run2() throws CacheException {",False
"  public void testGetAllFromServerWithPR() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM client = host.getVM(2);
    final String regionName = getUniqueName();
    final int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    int[] ports = AvailablePortHelper.getRandomAvailableTCPPorts(2);
    final int server1Port = ports[0];
    final int server2Port = ports[1];
    final String serverHost = getServerHostName(server1.getHost());

    createBridgeServer(server1, mcastPort, regionName, server1Port, true, false);

    createBridgeServer(server2, mcastPort, regionName, server2Port, true, false);

    createBridgeClient(client, regionName, serverHost, new int[] {server1Port, server2Port});

    // Run getAll
    client.invoke(new CacheSerializableRunnable(""Get all entries from server"") {
      @Override
      public void run2() throws CacheException {
        Region region = getRootRegion(regionName);
        for (int i=0; i<200; i++) {
          region.put(i, i);
        }
        
        try {
          Thread.currentThread().sleep(1000);
        } catch (InterruptedException e) {
          // TODO Auto-generated catch block
          e.printStackTrace();          
        }
        // Build collection of keys
        Collection keys = new ArrayList();
        for (int i=0; i<5; i++) {
          keys.add(""key-""+i);
        }
        keys.add(BridgeTestCase.NON_EXISTENT_KEY); // this will not be load CacheLoader
        
        // Invoke getAll
        
        Map result = region.getAll(keys);
        

        // Verify result size is correct
        assertEquals(6, result.size());

        // Verify the result contains each key,
        // and the value for each key is correct
        // (the server has a loader that returns the key as the value)
        for (Iterator i = keys.iterator(); i.hasNext();) {
          String key = (String) i.next();
          assertTrue(result.containsKey(key));
          Object value = result.get(key);
          if(!key.equals(BridgeTestCase.NON_EXISTENT_KEY))
            assertEquals(key, value);
          else
            assertEquals(null, value);
        }
        assertEquals(null, region.get(BridgeTestCase.NON_EXISTENT_KEY));
      }
    });

    stopBridgeServer(server1);

    stopBridgeServer(server2);
  }",True
"  public void testGetAllFromServerWithPR() throws Exception {
    final Host host = Host.getHost(0);
    final VM server1 = host.getVM(0);
    final VM server2 = host.getVM(1);
    final VM client = host.getVM(2);
    final String regionName = getUniqueName();
    int[] ports = AvailablePortHelper.getRandomAvailableTCPPorts(2);
    final int server1Port = ports[0];
    final int server2Port = ports[1];
    final String serverHost = getServerHostName(server1.getHost());

    createBridgeServer(server1, regionName, server1Port, true, false);

    createBridgeServer(server2, regionName, server2Port, true, false);

    createBridgeClient(client, regionName, serverHost, new int[] {server1Port, server2Port});

    // Run getAll
    client.invoke(new CacheSerializableRunnable(""Get all entries from server"") {
      @Override
      public void run2() throws CacheException {
        Region region = getRootRegion(regionName);
        for (int i=0; i<200; i++) {
          region.put(i, i);
        }
        
        try {
          Thread.currentThread().sleep(1000);
        } catch (InterruptedException e) {
          // TODO Auto-generated catch block
          e.printStackTrace();          
        }
        // Build collection of keys
        Collection keys = new ArrayList();
        for (int i=0; i<5; i++) {
          keys.add(""key-""+i);
        }
        keys.add(BridgeTestCase.NON_EXISTENT_KEY); // this will not be load CacheLoader
        
        // Invoke getAll
        
        Map result = region.getAll(keys);
        

        // Verify result size is correct
        assertEquals(6, result.size());

        // Verify the result contains each key,
        // and the value for each key is correct
        // (the server has a loader that returns the key as the value)
        for (Iterator i = keys.iterator(); i.hasNext();) {
          String key = (String) i.next();
          assertTrue(result.containsKey(key));
          Object value = result.get(key);
          if(!key.equals(BridgeTestCase.NON_EXISTENT_KEY))
            assertEquals(key, value);
          else
            assertEquals(null, value);
        }
        assertEquals(null, region.get(BridgeTestCase.NON_EXISTENT_KEY));
      }
    });

    stopBridgeServer(server1);

    stopBridgeServer(server2);
  }",False
"  private Integer createRegionOnDisconnectedServer(VM vm, final boolean startServer) {
    return (Integer)vm.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        AttributesFactory af = new AttributesFactory();
        af.setScope(Scope.DISTRIBUTED_ACK);
        af.setDataPolicy(DataPolicy.REPLICATE);
        Properties props = getDistributedSystemProperties();
        props.put(""mcast-port"", """"+AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS));
        props.remove(""locators"");
        system = (InternalDistributedSystem)DistributedSystem.connect(props);
        Cache cache = CacheFactory.create(system);
        cache.createRegion(OTHER_REGION,af.create());
        if (startServer) {
          int port = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
          CacheServer s = cache.addCacheServer();
          s.setPort(port);
          ((BridgeServerImpl)s).setTransactionTimeToLive(10);
          s.start();
          return port;
        }
        return 0;
      }
    });
  }",True
"  private Integer createRegionOnDisconnectedServer(VM vm, final boolean startServer) {
    return (Integer)vm.invoke(new SerializableCallable() {
      public Object call() throws Exception {
        AttributesFactory af = new AttributesFactory();
        af.setScope(Scope.DISTRIBUTED_ACK);
        af.setDataPolicy(DataPolicy.REPLICATE);
        Properties props = getDistributedSystemProperties();
        props.put(""mcast-port"", ""0"");
        props.remove(""locators"");
        system = (InternalDistributedSystem)DistributedSystem.connect(props);
        Cache cache = CacheFactory.create(system);
        cache.createRegion(OTHER_REGION,af.create());
        if (startServer) {
          int port = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
          CacheServer s = cache.addCacheServer();
          s.setPort(port);
          ((BridgeServerImpl)s).setTransactionTimeToLive(10);
          s.start();
          return port;
        }
        return 0;
      }
    });
  }",False
"  public void doTest(boolean createPR, int timeout, String mode)
      throws Throwable {
    // start server
    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    int port = (Integer) server0.invoke(Bug51193DUnitTest.class,
        ""createServerCache"", new Object[] { mcastPort, createPR });
    // start client
    client0.invoke(Bug51193DUnitTest.class, ""createClientCache"", new Object[] {
        client0.getHost().getHostName(), port, timeout });
    // do puts and get
    server0
        .invoke(Bug51193DUnitTest.class, ""doPutsAndGet"", new Object[] { 10 });
    // execute function & verify timeout has been received at server.
    client0.invoke(Bug51193DUnitTest.class,
        ""executeFunction"", new Object[] { mode, timeout });
  }",True
"  public void doTest(boolean createPR, int timeout, String mode)
      throws Throwable {
    // start server
    int port = (Integer) server0.invoke(Bug51193DUnitTest.class,
        ""createServerCache"", new Object[] { createPR });
    // start client
    client0.invoke(Bug51193DUnitTest.class, ""createClientCache"", new Object[] {
        client0.getHost().getHostName(), port, timeout });
    // do puts and get
    server0
        .invoke(Bug51193DUnitTest.class, ""doPutsAndGet"", new Object[] { 10 });
    // execute function & verify timeout has been received at server.
    client0.invoke(Bug51193DUnitTest.class,
        ""executeFunction"", new Object[] { mode, timeout });
  }",False
"  public static Integer createServerCache(Integer mcastPort, Boolean createPR)
      throws Exception {
    Properties props = new Properties();
    props.setProperty(""locators"", """");
    props.setProperty(""mcast-port"", String.valueOf(mcastPort));

    Bug51193DUnitTest test = new Bug51193DUnitTest(""Bug51193DUnitTest"");
    DistributedSystem ds = test.getSystem(props);
    ds.disconnect();
    cache = (GemFireCacheImpl)CacheFactory.create(test.getSystem());

    RegionFactory<String, String> rf = null;
    if (createPR) {
      rf = cache.createRegionFactory(RegionShortcut.PARTITION);
      rf.setPartitionAttributes(
          new PartitionAttributesFactory<String, String>()
              .setRedundantCopies(1).setTotalNumBuckets(4).create());
    } else {
      rf = cache.createRegionFactory(RegionShortcut.REPLICATE);
    }

    rf.create(REGION_NAME);

    CacheServer server = cache.addCacheServer();
    server.setPort(AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
    server.start();
    return server.getPort();
  }",True
"  public static Integer createServerCache(Boolean createPR)
      throws Exception {
    Properties props = new Properties();
    props.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");

    Bug51193DUnitTest test = new Bug51193DUnitTest(""Bug51193DUnitTest"");
    DistributedSystem ds = test.getSystem(props);
    ds.disconnect();
    cache = (GemFireCacheImpl)CacheFactory.create(test.getSystem());

    RegionFactory<String, String> rf = null;
    if (createPR) {
      rf = cache.createRegionFactory(RegionShortcut.PARTITION);
      rf.setPartitionAttributes(
          new PartitionAttributesFactory<String, String>()
              .setRedundantCopies(1).setTotalNumBuckets(4).create());
    } else {
      rf = cache.createRegionFactory(RegionShortcut.REPLICATE);
    }

    rf.create(REGION_NAME);

    CacheServer server = cache.addCacheServer();
    server.setPort(AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
    server.start();
    return server.getPort();
  }",False
"  public static Integer createServerCache(Boolean createPR)
      throws Exception {
    Properties props = new Properties();
    props.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");

    Bug51193DUnitTest test = new Bug51193DUnitTest(""Bug51193DUnitTest"");
    DistributedSystem ds = test.getSystem(props);
    ds.disconnect();
    cache = (GemFireCacheImpl)CacheFactory.create(test.getSystem());

    RegionFactory<String, String> rf = null;
    if (createPR) {
      rf = cache.createRegionFactory(RegionShortcut.PARTITION);
      rf.setPartitionAttributes(
          new PartitionAttributesFactory<String, String>()
              .setRedundantCopies(1).setTotalNumBuckets(4).create());
    } else {
      rf = cache.createRegionFactory(RegionShortcut.REPLICATE);
    }

    rf.create(REGION_NAME);

    CacheServer server = cache.addCacheServer();
    server.setPort(AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
    server.start();
    return server.getPort();
  }
",False
"  public static int createServerCache() throws Exception {
    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    Properties props = new Properties();
    props.setProperty(DistributionConfig.MCAST_PORT_NAME, String.valueOf(mcastPort));
    props.setProperty(DistributionConfig.LOCATORS_NAME, """");
    props.setProperty(""log-file"", ""server_"" + OSProcess.getId() + "".log"");
    props.setProperty(""log-level"", ""info"");
    props.setProperty(""statistic-archive-file"", ""server_"" + OSProcess.getId()
        + "".gfs"");
    props.setProperty(""statistic-sampling-enabled"", ""true"");
    CacheFactory cf = new CacheFactory(props);

    DistributedSystem ds = new Bug48571DUnitTest(""Bug48571DUnitTest"").getSystem(props);
    ds.disconnect();

    cache = (GemFireCacheImpl)cf.create();

    RegionFactory<String, String> rf = cache.createRegionFactory(RegionShortcut.REPLICATE);
    rf.setConcurrencyChecksEnabled(false);
    rf.create(region);

    int port = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    CacheServer server1 = cache.addCacheServer();
    server1.setPort(port);
    server1.start();
    return server1.getPort();
  }",True
"  public static int createServerCache() throws Exception {
    Properties props = new Properties();
    props.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
    props.setProperty(""log-file"", ""server_"" + OSProcess.getId() + "".log"");
    props.setProperty(""log-level"", ""info"");
    props.setProperty(""statistic-archive-file"", ""server_"" + OSProcess.getId()
        + "".gfs"");
    props.setProperty(""statistic-sampling-enabled"", ""true"");
    CacheFactory cf = new CacheFactory(props);

    DistributedSystem ds = new Bug48571DUnitTest(""Bug48571DUnitTest"").getSystem(props);
    ds.disconnect();

    cache = (GemFireCacheImpl)cf.create();

    RegionFactory<String, String> rf = cache.createRegionFactory(RegionShortcut.REPLICATE);
    rf.setConcurrencyChecksEnabled(false);
    rf.create(region);

    int port = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    CacheServer server1 = cache.addCacheServer();
    server1.setPort(port);
    server1.start();
    return server1.getPort();
  }",False
"  public static Integer createCacheServer(Integer mcastPort)
      throws Exception {
    Bug48879DUnitTest test = new Bug48879DUnitTest(""Bug48879DUnitTest"");
    System.setProperty(""gemfire.MessageTimeToLive"", ""30"");
    cache = (GemFireCacheImpl)CacheFactory.create(test.getSystem());
    HARegionQueue.threadIdExpiryTime = (SLEEP_TIME/1000) - 10;
    cache.setMessageSyncInterval(SLEEP_TIME/500);

    RegionFactory<String, String> rf = cache
        .createRegionFactory(RegionShortcut.REPLICATE);

    Region<String, String> region = rf.create(REGION_NAME);

    CacheServer server = cache.addCacheServer();
    server.setPort(AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
    server.start();
    return server.getPort();
  }",True
"      throws Exception {
    Bug48879DUnitTest test = new Bug48879DUnitTest(""Bug48879DUnitTest"");
    System.setProperty(""gemfire.MessageTimeToLive"", ""30"");
    cache = (GemFireCacheImpl)CacheFactory.create(test.getSystem());
    HARegionQueue.threadIdExpiryTime = (SLEEP_TIME/1000) - 10;
    cache.setMessageSyncInterval(SLEEP_TIME/500);

    RegionFactory<String, String> rf = cache
        .createRegionFactory(RegionShortcut.REPLICATE);

    Region<String, String> region = rf.create(REGION_NAME);

    CacheServer server = cache.addCacheServer();
    server.setPort(AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
    server.start();
    return server.getPort();
  }
",False
"  public static Integer createCacheServer()
      throws Exception {
    Bug48879DUnitTest test = new Bug48879DUnitTest(""Bug48879DUnitTest"");
    System.setProperty(""gemfire.MessageTimeToLive"", ""30"");
    cache = (GemFireCacheImpl)CacheFactory.create(test.getSystem());
    HARegionQueue.threadIdExpiryTime = (SLEEP_TIME/1000) - 10;
    cache.setMessageSyncInterval(SLEEP_TIME/500);

    RegionFactory<String, String> rf = cache
        .createRegionFactory(RegionShortcut.REPLICATE);

    Region<String, String> region = rf.create(REGION_NAME);

    CacheServer server = cache.addCacheServer();
    server.setPort(AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
    server.start();
    return server.getPort();
  }",False
"  public void setUp() throws Exception {
    super.setUp();
    disconnectAllFromDS();
    Host host = Host.getHost(0);
    vm0 = host.getVM(0); // server1
    vm1 = host.getVM(1); // server2

    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    int port0 = (Integer) vm0.invoke(Bug48879DUnitTest.class,
        ""createCacheServer"", new Object[] { mcastPort });
    int port1 = (Integer) vm1.invoke(Bug48879DUnitTest.class,
        ""createCacheServer"", new Object[] { mcastPort });

    createClientCache(host, new Integer[] {port0, port1}, Boolean.TRUE);
  }",True
"  public void setUp() throws Exception {
    super.setUp();
    disconnectAllFromDS();
    Host host = Host.getHost(0);
    vm0 = host.getVM(0); // server1
    vm1 = host.getVM(1); // server2

    int port0 = (Integer) vm0.invoke(Bug48879DUnitTest.class,
        ""createCacheServer"", new Object[] { });
    int port1 = (Integer) vm1.invoke(Bug48879DUnitTest.class,
        ""createCacheServer"", new Object[] { });

    createClientCache(host, new Integer[] {port0, port1}, Boolean.TRUE);
  }",False
"  private void doRegisterInterest2(Object keys, Boolean isReplicated, Boolean isPrimaryEmpty) throws Exception {
    int mcast = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    int port1 = (Integer)server1.invoke(Bug43684DUnitTest.class, ""createServerCache"", new Object[]{mcast, isReplicated, isPrimaryEmpty});
    server2.invoke(Bug43684DUnitTest.class, ""createServerCache"", new Object[]{mcast, isReplicated, false});
    server3.invoke(Bug43684DUnitTest.class, ""createServerCache"", new Object[]{mcast, isReplicated, false});

    client1.invoke(Bug43684DUnitTest.class, ""createClientCache"", new Object[] {host, port1});
    createClientCache(host, port1);
    doOps();

    client1.invoke(Bug43684DUnitTest.class, ""registerInterest"", new Object[] {keys, null});
    client1.invoke(Bug43684DUnitTest.class, ""verifyResponse2"");
  }",True
"  private void doRegisterInterest2(Object keys, Boolean isReplicated, Boolean isPrimaryEmpty) throws Exception {
    int port1 = (Integer)server1.invoke(Bug43684DUnitTest.class, ""createServerCache"", new Object[]{isReplicated, isPrimaryEmpty});
    server2.invoke(Bug43684DUnitTest.class, ""createServerCache"", new Object[]{isReplicated, false});
    server3.invoke(Bug43684DUnitTest.class, ""createServerCache"", new Object[]{isReplicated, false});

    client1.invoke(Bug43684DUnitTest.class, ""createClientCache"", new Object[] {host, port1});
    createClientCache(host, port1);
    doOps();

    client1.invoke(Bug43684DUnitTest.class, ""registerInterest"", new Object[] {keys, null});
    client1.invoke(Bug43684DUnitTest.class, ""verifyResponse2"");
  }",False
"  public static Integer createServerCache(Integer mcastPort) throws Exception {
    return createServerCache(mcastPort, false, false);
  }",True
"  public static Integer createServerCache() throws Exception {
    return createServerCache(false, false);
  }",False
"    Properties props = new Properties();
    props.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
    props.setProperty(""log-file"", ""server_"" + OSProcess.getId() + "".log"");
    props.setProperty(""log-level"", ""fine"");
    props.setProperty(""statistic-archive-file"", ""server_"" + OSProcess.getId()
        + "".gfs"");
    props.setProperty(""statistic-sampling-enabled"", ""true"");
    CacheFactory cf = new CacheFactory(props);
    cache = (GemFireCacheImpl)cf.create();

    RegionFactory rf;
    if (isReplicated) {
      RegionShortcut rs = isPrimaryEmpty ? RegionShortcut.REPLICATE_PROXY : RegionShortcut.REPLICATE;
      rf = cache.createRegionFactory(rs);
    } else {
      RegionShortcut rs = isPrimaryEmpty ? RegionShortcut.PARTITION_PROXY : RegionShortcut.PARTITION;
      rf = cache.createRegionFactory(rs);
      rf.setPartitionAttributes(new PartitionAttributesFactory().setTotalNumBuckets(numBuckets).create());
    }
    rf.create(REGION_NAME);
    BridgeServerImpl server = (BridgeServerImpl)cache.addCacheServer();
    server.setPort(AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
    server.start();
    return server.getPort();
  }

  @SuppressWarnings({ ""unchecked"", ""rawtypes"" })
  public static void createClientCache(Host host, Integer port) {",False
"  }

  @SuppressWarnings(""rawtypes"")",False
"  public static Integer createServerCache(Boolean isReplicated, Boolean isPrimaryEmpty) throws Exception {
    DistributedTestCase.disconnectFromDS();
    Properties props = new Properties();
    props.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
    props.setProperty(""log-file"", ""server_"" + OSProcess.getId() + "".log"");
    props.setProperty(""log-level"", ""fine"");
    props.setProperty(""statistic-archive-file"", ""server_"" + OSProcess.getId()
        + "".gfs"");
    props.setProperty(""statistic-sampling-enabled"", ""true"");
    CacheFactory cf = new CacheFactory(props);
    cache = (GemFireCacheImpl)cf.create();

    RegionFactory rf;
    if (isReplicated) {
      RegionShortcut rs = isPrimaryEmpty ? RegionShortcut.REPLICATE_PROXY : RegionShortcut.REPLICATE;
      rf = cache.createRegionFactory(rs);
    } else {
      RegionShortcut rs = isPrimaryEmpty ? RegionShortcut.PARTITION_PROXY : RegionShortcut.PARTITION;
      rf = cache.createRegionFactory(rs);
      rf.setPartitionAttributes(new PartitionAttributesFactory().setTotalNumBuckets(numBuckets).create());
    }
    rf.create(REGION_NAME);
    BridgeServerImpl server = (BridgeServerImpl)cache.addCacheServer();
    server.setPort(AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
    server.start();
    return server.getPort();
  }",False
"  private void doRegisterInterest(Object keys, String regEx) throws Exception {
    doRegisterInterest(keys, regEx, numBuckets, false, false);
  }",True
"  private void doRegisterInterest(Object keys, String regEx, Integer numOfPuts, Boolean isReplicated, Boolean isPrimaryEmpty) throws Exception {
    int port1 = (Integer)server1.invoke(Bug43684DUnitTest.class, ""createServerCache"", new Object[]{isReplicated, isPrimaryEmpty});
    server2.invoke(Bug43684DUnitTest.class, ""createServerCache"", new Object[]{isReplicated, false});
    server3.invoke(Bug43684DUnitTest.class, ""createServerCache"", new Object[]{isReplicated, false});

    int regexNum = 20;
    server1.invoke(Bug43684DUnitTest.class, ""doPuts"", new Object[]{numOfPuts, regEx, regexNum});

    client1.invoke(Bug43684DUnitTest.class, ""createClientCache"", new Object[] {host, port1});
    client1.invoke(Bug43684DUnitTest.class, ""registerInterest"", new Object[] {keys, regEx});

    server1.invoke(Bug43684DUnitTest.class, ""closeCache"");
    int size = keys != null ? (keys instanceof List ? ((List)keys).size() : 1) : regEx == null ? numOfPuts : regexNum;
    client1.invoke(Bug43684DUnitTest.class, ""verifyResponse"", new Object[]{size});
  }",False
"  public static Integer createServerCache(Integer mcastPort,
      Integer maxMessageCount) throws Exception {
    Properties props = new Properties();
    props.setProperty(""locators"", """");
    props.setProperty(""mcast-port"", String.valueOf(mcastPort));
//    props.setProperty(""log-file"", ""server_"" + OSProcess.getId() + "".log"");
//    props.setProperty(""log-level"", ""fine"");
//    props.setProperty(""statistic-archive-file"", ""server_"" + OSProcess.getId()
//        + "".gfs"");
//    props.setProperty(""statistic-sampling-enabled"", ""true"");

    Bug51400DUnitTest test = new Bug51400DUnitTest(""Bug51400DUnitTest"");
    DistributedSystem ds = test.getSystem(props);
    ds.disconnect();
    cache = (GemFireCacheImpl)CacheFactory.create(test.getSystem());
//    cache = (GemFireCacheImpl) new CacheFactory(props).create();

    RegionFactory<String, String> rf = cache
        .createRegionFactory(RegionShortcut.REPLICATE);

    rf.setConcurrencyChecksEnabled(false);

    Region<String, String> region = rf.create(REGION_NAME);

    CacheServer server = cache.addCacheServer();
    server.setMaximumMessageCount(maxMessageCount);
    server.setPort(AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
    server.start();
    return server.getPort();
  }",True
"  public static Integer createServerCache(Integer mcastPort,
      Integer maxMessageCount) throws Exception {
    Properties props = new Properties();
    props.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
//    props.setProperty(""log-file"", ""server_"" + OSProcess.getId() + "".log"");
//    props.setProperty(""log-level"", ""fine"");
//    props.setProperty(""statistic-archive-file"", ""server_"" + OSProcess.getId()
//        + "".gfs"");
//    props.setProperty(""statistic-sampling-enabled"", ""true"");

    Bug51400DUnitTest test = new Bug51400DUnitTest(""Bug51400DUnitTest"");
    DistributedSystem ds = test.getSystem(props);
    ds.disconnect();
    cache = (GemFireCacheImpl)CacheFactory.create(test.getSystem());
//    cache = (GemFireCacheImpl) new CacheFactory(props).create();

    RegionFactory<String, String> rf = cache
        .createRegionFactory(RegionShortcut.REPLICATE);

    rf.setConcurrencyChecksEnabled(false);

    Region<String, String> region = rf.create(REGION_NAME);

    CacheServer server = cache.addCacheServer();
    server.setMaximumMessageCount(maxMessageCount);
    server.setPort(AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
    server.start();
    return server.getPort();
  }",False
"  public void ticket51932_testDeadlock() throws Throwable {
    int maxQSize = 5;
    // Set infinite ack interval so that the queue will not be drained.
    int ackInterval = Integer.MAX_VALUE;
    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);

    int port1 = (Integer) server0.invoke(Bug51400DUnitTest.class,
        ""createServerCache"", new Object[] { mcastPort, maxQSize });

    client1.invoke(Bug51400DUnitTest.class, ""createClientCache"",
        new Object[] { getServerHostName(Host.getHost(0)), new Integer[]{port1}, ackInterval});

    // Do puts from server as well as from client on the same key.
    AsyncInvocation ai1 = server0.invokeAsync(Bug51400DUnitTest.class,
        ""updateKey"", new Object[] { 2 * maxQSize });
    AsyncInvocation ai2 = client1.invokeAsync(Bug51400DUnitTest.class,
        ""updateKey"", new Object[] { 2 * maxQSize });
    ai1.getResult();
    ai2.getResult();
    // Verify that the queue has crossed its limit of maxQSize
    server0.invoke(Bug51400DUnitTest.class, ""verifyQueueSize"", new Object[] {
        true, 2 * maxQSize });
  }",True
"  public void ticket51932_testDeadlock() throws Throwable {
    int maxQSize = 5;
    // Set infinite ack interval so that the queue will not be drained.
    int ackInterval = Integer.MAX_VALUE;

    int port1 = (Integer) server0.invoke(Bug51400DUnitTest.class,
        ""createServerCache"", new Object[] { maxQSize });

    client1.invoke(Bug51400DUnitTest.class, ""createClientCache"",
        new Object[] { getServerHostName(Host.getHost(0)), new Integer[]{port1}, ackInterval});

    // Do puts from server as well as from client on the same key.
    AsyncInvocation ai1 = server0.invokeAsync(Bug51400DUnitTest.class,
        ""updateKey"", new Object[] { 2 * maxQSize });
    AsyncInvocation ai2 = client1.invokeAsync(Bug51400DUnitTest.class,
        ""updateKey"", new Object[] { 2 * maxQSize });
    ai1.getResult();
    ai2.getResult();
    // Verify that the queue has crossed its limit of maxQSize
    server0.invoke(Bug51400DUnitTest.class, ""verifyQueueSize"", new Object[] {
        true, 2 * maxQSize });
  }",False
"  public void testBug36829() {

    // Step 1: Starting the servers
    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    final String durableClientId = getName() + ""_client"";

    final int durableClientTimeout = 600; // keep the client alive for 600

    PORT = ((Integer)this.serverVM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { ""DUMMY_REGION"", new Boolean(true),
            new Integer(mcastPort) })).intValue();

    this.ClientVM.invoke(CacheServerTestUtil.class, ""createCacheClient"",
        new Object[] {
            getClientPool(getServerHostName(ClientVM.getHost()), PORT, true, 0),
            regionName,
            getClientDistributedSystemProperties(durableClientId,
                durableClientTimeout), Boolean.TRUE });

    // Send clientReady message
    this.ClientVM.invoke(new CacheSerializableRunnable(""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });

    // We expect in registerKey() that the RegionNotFoundException is thrown.
    // If exception is not thrown then the test fails.
    this.ClientVM.invoke(Bug36829DUnitTest.class, ""registerKey"",
        new Object[] { ""Key1"" });


    // creating REgion on the Server
/*    this.serverVM.invoke(CacheServerTestUtil.class, ""createRegion"",
        new Object[] { regionName });
     // should be successful.
    this.ClientVM.invoke(Bug36829DUnitTest.class, ""registerKeyAfterRegionCreation"",
        new Object[] { ""Key1"" });*/


    // Stop the durable client
    this.ClientVM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 1
    this.serverVM.invoke(CacheServerTestUtil.class, ""closeCache"");

  }",True
"  public void testBug36829() {

    // Step 1: Starting the servers
    final String durableClientId = getName() + ""_client"";

    final int durableClientTimeout = 600; // keep the client alive for 600

    PORT = ((Integer)this.serverVM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { ""DUMMY_REGION"", new Boolean(true)
          })).intValue();

    this.ClientVM.invoke(CacheServerTestUtil.class, ""createCacheClient"",
        new Object[] {
            getClientPool(getServerHostName(ClientVM.getHost()), PORT, true, 0),
            regionName,
            getClientDistributedSystemProperties(durableClientId,
                durableClientTimeout), Boolean.TRUE });

    // Send clientReady message
    this.ClientVM.invoke(new CacheSerializableRunnable(""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });

    // We expect in registerKey() that the RegionNotFoundException is thrown.
    // If exception is not thrown then the test fails.
    this.ClientVM.invoke(Bug36829DUnitTest.class, ""registerKey"",
        new Object[] { ""Key1"" });


    // creating REgion on the Server
/*    this.serverVM.invoke(CacheServerTestUtil.class, ""createRegion"",
        new Object[] { regionName });
     // should be successful.
    this.ClientVM.invoke(Bug36829DUnitTest.class, ""registerKeyAfterRegionCreation"",
        new Object[] { ""Key1"" });*/


    // Stop the durable client
    this.ClientVM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 1
    this.serverVM.invoke(CacheServerTestUtil.class, ""closeCache"");

  }",False
"  public void testFunctionality() {
 // Step 1: Starting the servers
    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);

    PORT1 = ((Integer)this.server1VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true),
            new Integer(mcastPort) })).intValue();
    final int durableClientTimeout = 600; 
    
    
    // Step 2: Starting Client and creating durableRegion
    final String durableClientId = getName() + ""_client"";

    this.durableClientVM.invoke(CacheServerTestUtil.class, ""createCacheClient"",
        new Object[] {
            getClientPool(getServerHostName(durableClientVM.getHost()), PORT1, true, 0),
            regionName,
            getDurableClientDistributedSystemProperties(durableClientId,
                durableClientTimeout), Boolean.TRUE });

    // Send clientReady message
    this.durableClientVM.invoke(new CacheSerializableRunnable(
        ""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });
    
    this.server1VM.invoke(Bug37805DUnitTest.class, ""checkRootRegions"");
    
    
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""closeCache"");
  }",True
"  public void testFunctionality() {
 // Step 1: Starting the servers

    PORT1 = ((Integer)this.server1VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true),
            })).intValue();
    final int durableClientTimeout = 600; 
    
    
    // Step 2: Starting Client and creating durableRegion
    final String durableClientId = getName() + ""_client"";

    this.durableClientVM.invoke(CacheServerTestUtil.class, ""createCacheClient"",
        new Object[] {
            getClientPool(getServerHostName(durableClientVM.getHost()), PORT1, true, 0),
            regionName,
            getDurableClientDistributedSystemProperties(durableClientId,
                durableClientTimeout), Boolean.TRUE });

    // Send clientReady message
    this.durableClientVM.invoke(new CacheSerializableRunnable(
        ""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });
    
    this.server1VM.invoke(Bug37805DUnitTest.class, ""checkRootRegions"");
    
    
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""closeCache"");
  }",False
"  public static Integer createCacheServer(String regionName,
      Boolean notifyBySubscription) throws Exception
  {
    Properties props = new Properties();
    props.setProperty(DistributionConfig.MCAST_PORT_NAME, ""0"");
    props.setProperty(DistributionConfig.LOCATORS_NAME, ""localhost[""+DistributedTestCase.getDUnitLocatorPort()+""]"");
    new CacheServerTestUtil(""temp"").createCache(props);
    AttributesFactory factory = new AttributesFactory();
    factory.setScope(Scope.DISTRIBUTED_ACK);
    factory.setEnableBridgeConflation(true);
    factory.setDataPolicy(DataPolicy.REPLICATE);
    RegionAttributes attrs = factory.create();
    cache.createRegion(regionName, attrs);
    BridgeServer server1 = cache.addBridgeServer();
    int port = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    server1.setPort(port);
    server1.setNotifyBySubscription(notifyBySubscription.booleanValue());
    server1.start();
    return new Integer(server1.getPort());
  }",True
"  public static void createCacheServer(String regionName,
      Boolean notifyBySubscription, Integer serverPort)
      throws Exception {
    Properties props = new Properties();
    props.setProperty(DistributionConfig.MCAST_PORT_NAME, ""0"");
    props.setProperty(DistributionConfig.LOCATORS_NAME, ""localhost[""+DistributedTestCase.getDUnitLocatorPort()+""]"");
    new CacheServerTestUtil(""temp"").createCache(props);",False
"  public static void createCacheServer(String regionName,
      Boolean notifyBySubscription, Integer serverPort)
      throws Exception {
    Properties props = new Properties();
    props.setProperty(DistributionConfig.MCAST_PORT_NAME, ""0"");
    props.setProperty(DistributionConfig.LOCATORS_NAME, ""localhost[""+DistributedTestCase.getDUnitLocatorPort()+""]"");
    new CacheServerTestUtil(""temp"").createCache(props);
    AttributesFactory factory = new AttributesFactory();
    factory.setScope(Scope.DISTRIBUTED_ACK);
    factory.setEnableBridgeConflation(true);
    factory.setDataPolicy(DataPolicy.REPLICATE);
    RegionAttributes attrs = factory.create();
    cache.createRegion(regionName, attrs);
    BridgeServer server = cache.addBridgeServer();
    server.setPort(serverPort.intValue());
    server.setNotifyBySubscription(notifyBySubscription.booleanValue());
    server.start();
  }",False
"    factory.setScope(Scope.DISTRIBUTED_ACK);
    factory.setEnableBridgeConflation(true);
    factory.setDataPolicy(DataPolicy.REPLICATE);
    RegionAttributes attrs = factory.create();
    cache.createRegion(regionName, attrs);
    BridgeServer server = cache.addBridgeServer();
    server.setPort(serverPort.intValue());
    server.setNotifyBySubscription(notifyBySubscription.booleanValue());
    server.start();
  }

  public static Integer createCacheServer(String regionName1,
      String regionName2, Boolean notifyBySubscription) throws Exception
  {
    new CacheServerTestUtil(""temp"").createCache(new Properties());
    AttributesFactory factory = new AttributesFactory();
    factory.setScope(Scope.DISTRIBUTED_ACK);
    factory.setEnableBridgeConflation(true);",False
"  public void setUp() throws Exception {
    super.setUp();
    vm0 = Host.getHost(0).getVM(0);
    vm1 = Host.getHost(0).getVM(1);
    vm2 = Host.getHost(0).getVM(2);
    vm3 = Host.getHost(0).getVM(3);

    mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    port0 = (Integer) vm0.invoke(DurableClientQueueSizeDUnitTest.class,
        ""createCacheServer"", new Object[] { mcastPort });
    port1 = (Integer) vm1.invoke(DurableClientQueueSizeDUnitTest.class,
        ""createCacheServer"", new Object[] { mcastPort });
    addExpectedException(""java.net.SocketException"");
    addExpectedException(""Unexpected IOException"");
  }",True
"  public void setUp() throws Exception {
    super.setUp();
    vm0 = Host.getHost(0).getVM(0);
    vm1 = Host.getHost(0).getVM(1);
    vm2 = Host.getHost(0).getVM(2);
    vm3 = Host.getHost(0).getVM(3);

    port0 = (Integer) vm0.invoke(DurableClientQueueSizeDUnitTest.class,
        ""createCacheServer"", new Object[] { });
    port1 = (Integer) vm1.invoke(DurableClientQueueSizeDUnitTest.class,
        ""createCacheServer"", new Object[] { });
    addExpectedException(""java.net.SocketException"");
    addExpectedException(""Unexpected IOException"");
  }",False
"  public static Integer createCacheServer(Integer mcastPort) throws Exception {
    return createCacheServer(mcastPort,
        AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
  }",True
"    props.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
//    props.setProperty(""log-level"", ""fine"");
//    props.setProperty(""log-file"", ""server_"" + OSProcess.getId() + "".log"");
//    props.setProperty(""statistic-archive-file"", ""server_"" + OSProcess.getId()
//        + "".gfs"");
//    props.setProperty(""statistic-sampling-enabled"", ""true"");

    DurableClientQueueSizeDUnitTest test = new DurableClientQueueSizeDUnitTest(
        ""DurableClientQueueSizeDUnitTest"");
    DistributedSystem ds = test.getSystem(props);
    ds.disconnect();
    cache = (GemFireCacheImpl)CacheFactory.create(test.getSystem());
//    cache = (GemFireCacheImpl) new CacheFactory(props).create();

    RegionFactory<String, String> rf = cache
        .createRegionFactory(RegionShortcut.REPLICATE);

    rf.create(REGION_NAME);
    rf.create(NEW_REGION);

    CacheServer server = cache.addCacheServer();
    server.setPort(serverPort);
    server.start();
    return server.getPort();
  }

  public static void createClientCache(Host host, Integer[] ports)
      throws Exception {
    createClientCache(host, ports, ""300"", Boolean.TRUE);",False
"  public static Integer createCacheServer(Integer serverPort)
      throws Exception {
    Properties props = new Properties();
    props.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
//    props.setProperty(""log-level"", ""fine"");
//    props.setProperty(""log-file"", ""server_"" + OSProcess.getId() + "".log"");
//    props.setProperty(""statistic-archive-file"", ""server_"" + OSProcess.getId()
//        + "".gfs"");
//    props.setProperty(""statistic-sampling-enabled"", ""true"");

    DurableClientQueueSizeDUnitTest test = new DurableClientQueueSizeDUnitTest(
        ""DurableClientQueueSizeDUnitTest"");
    DistributedSystem ds = test.getSystem(props);
    ds.disconnect();
    cache = (GemFireCacheImpl)CacheFactory.create(test.getSystem());
//    cache = (GemFireCacheImpl) new CacheFactory(props).create();

    RegionFactory<String, String> rf = cache
        .createRegionFactory(RegionShortcut.REPLICATE);

    rf.create(REGION_NAME);
    rf.create(NEW_REGION);

    CacheServer server = cache.addCacheServer();
    server.setPort(serverPort);
    server.start();
    return server.getPort();
  }",False
"  public static Integer createCacheServer() throws Exception {
    return createCacheServer(
        AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
  }",False
"  }

  @SuppressWarnings(""deprecation"")
  public static Integer createCacheServer(Integer serverPort)",False
"  public void testPrimaryServerRebootReturnsCorrectResponse() throws Exception {
    int num = 10;
    vm2.invoke(DurableClientQueueSizeDUnitTest.class, ""createClientCache"",
        new Object[] { vm2.getHost(), new Integer[] { port0, port1 } });
    vm2.invoke(DurableClientQueueSizeDUnitTest.class, ""doRI"");
    vm2.invoke(DurableClientQueueSizeDUnitTest.class, ""readyForEvents"");

    vm2.invoke(DurableClientQueueSizeDUnitTest.class, ""closeCache"",
        new Object[] { Boolean.TRUE });

    vm0.invoke(DurableClientQueueSizeDUnitTest.class, ""doPuts"",
        new Object[] { num });

    // Identify primary and restart it
    boolean isVM0Primary = (Boolean) vm0.invoke(
        DurableClientQueueSizeDUnitTest.class, ""isPrimary"");
    int port = 0;
    if (isVM0Primary) {
      vm0.invoke(DurableClientQueueSizeDUnitTest.class, ""closeCache"");
      vm0.invoke(DurableClientQueueSizeDUnitTest.class, ""createCacheServer"",
          new Object[] { mcastPort, port0 });
      port = port0;
    } else { // vm1 is primary
      vm1.invoke(DurableClientQueueSizeDUnitTest.class, ""closeCache"");
      vm1.invoke(DurableClientQueueSizeDUnitTest.class, ""createCacheServer"",
          new Object[] { mcastPort, port1 });
      port = port1;
    }

    vm2.invoke(DurableClientQueueSizeDUnitTest.class, ""createClientCache"",
        new Object[] { vm2.getHost(), new Integer[] { port } });

    vm2.invoke(DurableClientQueueSizeDUnitTest.class, ""verifyQueueSize"",
        new Object[] { PoolImpl.PRIMARY_QUEUE_NOT_AVAILABLE });
  }",True
"  public void testPrimaryServerRebootReturnsCorrectResponse() throws Exception {
    int num = 10;
    vm2.invoke(DurableClientQueueSizeDUnitTest.class, ""createClientCache"",
        new Object[] { vm2.getHost(), new Integer[] { port0, port1 } });
    vm2.invoke(DurableClientQueueSizeDUnitTest.class, ""doRI"");
    vm2.invoke(DurableClientQueueSizeDUnitTest.class, ""readyForEvents"");

    vm2.invoke(DurableClientQueueSizeDUnitTest.class, ""closeCache"",
        new Object[] { Boolean.TRUE });

    vm0.invoke(DurableClientQueueSizeDUnitTest.class, ""doPuts"",
        new Object[] { num });

    // Identify primary and restart it
    boolean isVM0Primary = (Boolean) vm0.invoke(
        DurableClientQueueSizeDUnitTest.class, ""isPrimary"");
    int port = 0;
    if (isVM0Primary) {
      vm0.invoke(DurableClientQueueSizeDUnitTest.class, ""closeCache"");
      vm0.invoke(DurableClientQueueSizeDUnitTest.class, ""createCacheServer"",
          new Object[] { port0 });
      port = port0;
    } else { // vm1 is primary
      vm1.invoke(DurableClientQueueSizeDUnitTest.class, ""closeCache"");
      vm1.invoke(DurableClientQueueSizeDUnitTest.class, ""createCacheServer"",
          new Object[] { port1 });
      port = port1;
    }

    vm2.invoke(DurableClientQueueSizeDUnitTest.class, ""createClientCache"",
        new Object[] { vm2.getHost(), new Integer[] { port } });

    vm2.invoke(DurableClientQueueSizeDUnitTest.class, ""verifyQueueSize"",
        new Object[] { PoolImpl.PRIMARY_QUEUE_NOT_AVAILABLE });
  }",False
"  public void testNonDurableClientStatistics() {


    // Step 1: Starting the servers
    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);

    PORT1 = ((Integer)this.server1VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true),
            new Integer(mcastPort) })).intValue();
    this.server1VM.invoke(DurableClientStatsDUnitTest.class, ""checkStatistics"");
    // Step 2: Bring Up the Client
    // Start a durable client that is not kept alive on the server when it
    // stops normally
    final int durableClientTimeout = 600; // keep the client alive for 600
    // seconds

    startAndCloseNonDurableClientCache(durableClientTimeout);
    startAndCloseNonDurableClientCache(1);      //////// -> Reconnection1
    pause(1400);        //////// -> Queue Dropped1
    startAndCloseNonDurableClientCache(1);
    pause(1400);        //////// -> Queue Dropped2
    
    startRegisterAndCloseNonDurableClientCache( durableClientTimeout);
    pause(500);

    this.server1VM.invoke(DurableClientStatsDUnitTest.class, ""putValue"",
        new Object[] { K1, ""Value1"" });         //////// -> Enqueue Message1

    pause(500);
    startAndCloseNonDurableClientCache(1);      //////// -> Reconnection2
    pause(1400);        //////// -> Queue Dropped3
    startAndCloseNonDurableClientCache(1);
    pause(1400);        //////// -> Queue Dropped4
    startRegisterAndCloseNonDurableClientCache( durableClientTimeout);
    pause(500);

    this.server1VM.invoke(DurableClientStatsDUnitTest.class, ""putValue"",
        new Object[] { K1, ""NewValue1"" });      //////// -> Enqueue Message2

    startAndCloseNonDurableClientCache(durableClientTimeout);   //////// -> Reconnection3

    this.server1VM.invoke(DurableClientStatsDUnitTest.class,
        ""checkStatisticsWithExpectedValues"", new Object[] { new Integer(0),
            new Integer(0), new Integer(0) });
  
    
  }",True
"  public void testNonDurableClientStatistics() {


    // Step 1: Starting the servers
    PORT1 = ((Integer)this.server1VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true)
             })).intValue();
    this.server1VM.invoke(DurableClientStatsDUnitTest.class, ""checkStatistics"");
    // Step 2: Bring Up the Client
    // Start a durable client that is not kept alive on the server when it
    // stops normally
    final int durableClientTimeout = 600; // keep the client alive for 600
    // seconds

    startAndCloseNonDurableClientCache(durableClientTimeout);
    startAndCloseNonDurableClientCache(1);      //////// -> Reconnection1
    pause(1400);        //////// -> Queue Dropped1
    startAndCloseNonDurableClientCache(1);
    pause(1400);        //////// -> Queue Dropped2
    
    startRegisterAndCloseNonDurableClientCache( durableClientTimeout);
    pause(500);

    this.server1VM.invoke(DurableClientStatsDUnitTest.class, ""putValue"",
        new Object[] { K1, ""Value1"" });         //////// -> Enqueue Message1

    pause(500);
    startAndCloseNonDurableClientCache(1);      //////// -> Reconnection2
    pause(1400);        //////// -> Queue Dropped3
    startAndCloseNonDurableClientCache(1);
    pause(1400);        //////// -> Queue Dropped4
    startRegisterAndCloseNonDurableClientCache( durableClientTimeout);
    pause(500);

    this.server1VM.invoke(DurableClientStatsDUnitTest.class, ""putValue"",
        new Object[] { K1, ""NewValue1"" });      //////// -> Enqueue Message2

    startAndCloseNonDurableClientCache(durableClientTimeout);   //////// -> Reconnection3

    this.server1VM.invoke(DurableClientStatsDUnitTest.class,
        ""checkStatisticsWithExpectedValues"", new Object[] { new Integer(0),
            new Integer(0), new Integer(0) });
  
    
  }",False
"  public void testDurableClientStatistics() {

    // Step 1: Starting the servers
    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);

    PORT1 = ((Integer)this.server1VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true),
            new Integer(mcastPort) })).intValue();
    this.server1VM.invoke(DurableClientStatsDUnitTest.class, ""checkStatistics"");
    // Step 2: Bring Up the Client
    // Start a durable client that is not kept alive on the server when it
    // stops normally
    final int durableClientTimeout = 600; // keep the client alive for 600
    // seconds

    startAndCloseDurableClientCache(durableClientTimeout);
    startAndCloseDurableClientCache(1);      //////// -> Reconnection1
    pause(1400);        //////// -> Queue Dropped1
    startAndCloseDurableClientCache(1);
    pause(1400);        //////// -> Queue Dropped2
    
    startRegisterAndCloseDurableClientCache( durableClientTimeout);
    pause(500);

    this.server1VM.invoke(DurableClientStatsDUnitTest.class, ""putValue"",
        new Object[] { K1, ""Value1"" });         //////// -> Enqueue Message1

    pause(500);
    startAndCloseDurableClientCache(1);      //////// -> Reconnection2
    pause(1400);        //////// -> Queue Dropped3
    startAndCloseDurableClientCache(1);
    pause(1400);        //////// -> Queue Dropped4
    startRegisterAndCloseDurableClientCache( durableClientTimeout);
    pause(500);

    this.server1VM.invoke(DurableClientStatsDUnitTest.class, ""putValue"",
        new Object[] { K1, ""NewValue1"" });      //////// -> Enqueue Message2

    startAndCloseDurableClientCache(durableClientTimeout);   //////// -> Reconnection3

    this.server1VM.invoke(DurableClientStatsDUnitTest.class,
        ""checkStatisticsWithExpectedValues"", new Object[] { new Integer(3),
            new Integer(4), new Integer(2) });
  }",True
"  public void testDurableClientStatistics() {

    // Step 1: Starting the servers
    PORT1 = ((Integer)this.server1VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true)
      })).intValue();
    this.server1VM.invoke(DurableClientStatsDUnitTest.class, ""checkStatistics"");
    // Step 2: Bring Up the Client
    // Start a durable client that is not kept alive on the server when it
    // stops normally
    final int durableClientTimeout = 600; // keep the client alive for 600
    // seconds

    startAndCloseDurableClientCache(durableClientTimeout);
    startAndCloseDurableClientCache(1);      //////// -> Reconnection1
    pause(1400);        //////// -> Queue Dropped1
    startAndCloseDurableClientCache(1);
    pause(1400);        //////// -> Queue Dropped2
    
    startRegisterAndCloseDurableClientCache( durableClientTimeout);
    pause(500);

    this.server1VM.invoke(DurableClientStatsDUnitTest.class, ""putValue"",
        new Object[] { K1, ""Value1"" });         //////// -> Enqueue Message1

    pause(500);
    startAndCloseDurableClientCache(1);      //////// -> Reconnection2
    pause(1400);        //////// -> Queue Dropped3
    startAndCloseDurableClientCache(1);
    pause(1400);        //////// -> Queue Dropped4
    startRegisterAndCloseDurableClientCache( durableClientTimeout);
    pause(500);

    this.server1VM.invoke(DurableClientStatsDUnitTest.class, ""putValue"",
        new Object[] { K1, ""NewValue1"" });      //////// -> Enqueue Message2

    startAndCloseDurableClientCache(durableClientTimeout);   //////// -> Reconnection3

    this.server1VM.invoke(DurableClientStatsDUnitTest.class,
        ""checkStatisticsWithExpectedValues"", new Object[] { new Integer(3),
            new Integer(4), new Integer(2) });
  }",False
"  public void testSimpleDurableClientWithRegistration() {
    // Step 1: Starting the servers
    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);

    PORT1 = ((Integer)this.server1VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true),
            new Integer(mcastPort) })).intValue();
    PORT2 = ((Integer)this.server2VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true),
            new Integer(mcastPort) })).intValue();

    // Step 2: Bring Up the Client
    // Start a durable client that is not kept alive on the server when it
    // stops normally
    final String durableClientId = getName() + ""_client"";
    // keep the client alive for 600 seconds
    final int durableClientTimeout = 600;
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""createCacheClient"",
        new Object[] {
            getClientPool(getServerHostName(durableClientVM.getHost()), PORT1, PORT2, true, 0),
            regionName,
            getClientDistributedSystemProperties(durableClientId,
                durableClientTimeout) });

    // Send clientReady message
    this.durableClientVM.invoke(new CacheSerializableRunnable(
        ""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });

    // Step 3: Client registers Interests
    // KEY_STONE1, KEY_STONE2 are registered as durableKeys & KEY_STONE3,
    // KEY_STONE4 as non-durableKeys

    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K1, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K2, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K3, new Boolean(true) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K4, new Boolean(true) });

    // Step 4: Update Values on the Server for KEY_STONE1, KEY_STONE2,
    // KEY_STONE3, KEY_STONE4

    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K1, ""Value1"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K2, ""Value2"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K3, ""Value3"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K4, ""Value4"" });

    pause(1000);
    // Step 5: Verify Updates on the Client

    assertEquals(""Value1"", this.server2VM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K1 }));
    assertEquals(""Value1"", this.server1VM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K1 }));

    assertEquals(""Value1"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K1 }));
    assertEquals(""Value2"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K2 }));
    assertEquals(""Value3"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K3 }));
    assertEquals(""Value4"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K4 }));

    // Step 6: Close Cache of the DurableClient
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""closeCache"");
    // pause(5000);
    // Step 7: Update KEY_STONE1,KEY_STONE2,KEY_STONE3,KEY_STONE4 on the
    // Server say with values PingPong1, PingPong2, PingPong3, PingPong4
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K1, ""PingPong1"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K2, ""PingPong2"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K3, ""PingPong3"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K4, ""PingPong4"" });

    // Step 8: Re-start the Client
    this.durableClientVM
        .invoke(CacheServerTestUtil.class, ""createCacheClient"",
            new Object[] { getClientPool(getServerHostName(durableClientVM.getHost()), PORT1, PORT2, true, 0),
                regionName,
                getClientDistributedSystemProperties(durableClientId),
                Boolean.TRUE });

    // Step 9: Send clientReady message
    this.durableClientVM.invoke(new CacheSerializableRunnable(
        ""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });

    // pause(1000);

    // Step 10: Register all Keys
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K3, new Boolean(true) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K4, new Boolean(true) });

    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K1, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K2, new Boolean(false) });

    // Step 11: Unregister Some Keys (Here K1, K3)
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""unregisterKey"", new Object[] { K1 });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""unregisterKey"", new Object[] { K3 });

    pause(5000);

    // Step 12: Modify values on the server for all the Keys
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K1, ""PingPong_updated_1"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K2, ""PingPong_updated_2"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K3, ""PingPong_updated_3"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K4, ""PingPong_updated_4"" });

    pause(5000);

    // Step 13: Check the values for the ones not unregistered and the
    // Unregistered Keys' Values should be null
    try {
      assertEquals(""PingPong_updated_2"", this.durableClientVM.invoke(
          DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K2 }));
    }
    catch (Exception e) {
      fail(""Prob in KEY_STONE2: ""
          + this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
              ""getValue"", new Object[] { K2 }));
    }

    try {
      assertEquals(""PingPong_updated_4"", this.durableClientVM.invoke(
          DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K4 }));
    }
    catch (Exception e) {
      fail(""Prob in KEY_STONE4: ""
          + this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
              ""getValue"", new Object[] { K4 }));

    }

    try {
      assertNull(this.durableClientVM.invoke(
          DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K1 }));
    }
    catch (Exception e) {
      fail(""Prob in KEY_STONE1: ""
          + this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
              ""getValue"", new Object[] { K1 }));

    }

    try {
      assertNull(this.durableClientVM.invoke(
          DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K3 }));
    }
    catch (Exception e) {
      fail(""Prob in KEY_STONE3: ""
          + this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
              ""getValue"", new Object[] { K3 }));

    }

    // Stop the durable client
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 2
    this.server2VM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 1
    this.server1VM.invoke(CacheServerTestUtil.class, ""closeCache"");

  }",True
"  public void testSimpleDurableClientWithRegistration() {
    // Step 1: Starting the servers
    PORT1 = ((Integer)this.server1VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true)
            })).intValue();
    PORT2 = ((Integer)this.server2VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true)
            })).intValue();

    // Step 2: Bring Up the Client
    // Start a durable client that is not kept alive on the server when it
    // stops normally
    final String durableClientId = getName() + ""_client"";
    // keep the client alive for 600 seconds
    final int durableClientTimeout = 600;
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""createCacheClient"",
        new Object[] {
            getClientPool(getServerHostName(durableClientVM.getHost()), PORT1, PORT2, true, 0),
            regionName,
            getClientDistributedSystemProperties(durableClientId,
                durableClientTimeout) });

    // Send clientReady message
    this.durableClientVM.invoke(new CacheSerializableRunnable(
        ""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });

    // Step 3: Client registers Interests
    // KEY_STONE1, KEY_STONE2 are registered as durableKeys & KEY_STONE3,
    // KEY_STONE4 as non-durableKeys

    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K1, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K2, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K3, new Boolean(true) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K4, new Boolean(true) });

    // Step 4: Update Values on the Server for KEY_STONE1, KEY_STONE2,
    // KEY_STONE3, KEY_STONE4

    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K1, ""Value1"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K2, ""Value2"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K3, ""Value3"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K4, ""Value4"" });

    pause(1000);
    // Step 5: Verify Updates on the Client

    assertEquals(""Value1"", this.server2VM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K1 }));
    assertEquals(""Value1"", this.server1VM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K1 }));

    assertEquals(""Value1"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K1 }));
    assertEquals(""Value2"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K2 }));
    assertEquals(""Value3"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K3 }));
    assertEquals(""Value4"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K4 }));

    // Step 6: Close Cache of the DurableClient
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""closeCache"");
    // pause(5000);
    // Step 7: Update KEY_STONE1,KEY_STONE2,KEY_STONE3,KEY_STONE4 on the
    // Server say with values PingPong1, PingPong2, PingPong3, PingPong4
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K1, ""PingPong1"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K2, ""PingPong2"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K3, ""PingPong3"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K4, ""PingPong4"" });

    // Step 8: Re-start the Client
    this.durableClientVM
        .invoke(CacheServerTestUtil.class, ""createCacheClient"",
            new Object[] { getClientPool(getServerHostName(durableClientVM.getHost()), PORT1, PORT2, true, 0),
                regionName,
                getClientDistributedSystemProperties(durableClientId),
                Boolean.TRUE });

    // Step 9: Send clientReady message
    this.durableClientVM.invoke(new CacheSerializableRunnable(
        ""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });

    // pause(1000);

    // Step 10: Register all Keys
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K3, new Boolean(true) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K4, new Boolean(true) });

    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K1, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K2, new Boolean(false) });

    // Step 11: Unregister Some Keys (Here K1, K3)
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""unregisterKey"", new Object[] { K1 });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""unregisterKey"", new Object[] { K3 });

    pause(5000);

    // Step 12: Modify values on the server for all the Keys
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K1, ""PingPong_updated_1"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K2, ""PingPong_updated_2"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K3, ""PingPong_updated_3"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K4, ""PingPong_updated_4"" });

    pause(5000);

    // Step 13: Check the values for the ones not unregistered and the
    // Unregistered Keys' Values should be null
    try {
      assertEquals(""PingPong_updated_2"", this.durableClientVM.invoke(
          DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K2 }));
    }
    catch (Exception e) {
      fail(""Prob in KEY_STONE2: ""
          + this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
              ""getValue"", new Object[] { K2 }));
    }

    try {
      assertEquals(""PingPong_updated_4"", this.durableClientVM.invoke(
          DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K4 }));
    }
    catch (Exception e) {
      fail(""Prob in KEY_STONE4: ""
          + this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
              ""getValue"", new Object[] { K4 }));

    }

    try {
      assertNull(this.durableClientVM.invoke(
          DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K1 }));
    }
    catch (Exception e) {
      fail(""Prob in KEY_STONE1: ""
          + this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
              ""getValue"", new Object[] { K1 }));

    }

    try {
      assertNull(this.durableClientVM.invoke(
          DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K3 }));
    }
    catch (Exception e) {
      fail(""Prob in KEY_STONE3: ""
          + this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
              ""getValue"", new Object[] { K3 }));

    }

    // Stop the durable client
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 2
    this.server2VM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 1
    this.server1VM.invoke(CacheServerTestUtil.class, ""closeCache"");

  }",False
"  public void testDurableClientDisConnectWithRegistrationHA() {
    
    // Step 1: Start server1
    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    
    PORT2 = new Integer(AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
    
    PORT1 = ((Integer)this.server1VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true),
            new Integer(mcastPort) })).intValue();
    

    // Step 2: Bring Up the Client
    final String durableClientId = getName() + ""_client"";
    // keep the client alive for 600 seconds
    final int durableClientTimeout = 600;
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""createCacheClient"",
        new Object[] {
            getClientPool(getServerHostName(durableClientVM.getHost()), PORT1, PORT2, true, 1),
            regionName,
            getClientDistributedSystemProperties(durableClientId,
                durableClientTimeout) });

    // Send clientReady message
    this.durableClientVM.invoke(new CacheSerializableRunnable(
        ""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });

    // Step 3: Client registers Interests
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K1, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K2, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K3, new Boolean(true) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K4, new Boolean(true) });

    // Close Cache of the DurableClient
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""closeCache"");

    pause(2000);

    //Re-start the Client
    this.durableClientVM
        .invoke(CacheServerTestUtil.class, ""createCacheClient"",
            new Object[] { getClientPool(getServerHostName(durableClientVM.getHost()), PORT1, PORT2, true, 1),
                regionName,
                getClientDistributedSystemProperties(durableClientId),
                Boolean.TRUE });

    //Send clientReady message
    this.durableClientVM.invoke(new CacheSerializableRunnable(
        ""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });

    // Step 4: Bring up the server2
    this.server2VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true),
            new Integer(mcastPort), PORT2 });

    pause(3000);

    // Check server2 got all the interests registered by the durable client.    
    server2VM.invoke(new CacheSerializableRunnable(""Verify Interests."") {
      public void run2() throws CacheException
      {
        getLogWriter().info(""### Verifying interests registered by DurableClient. ###"");
        CacheClientNotifier ccn = CacheClientNotifier.getInstance();
        CacheClientProxy p = null;
        
        // Get proxy for the client.        
        for (int i=0; i < 60; i++) {
          Iterator ps = ccn.getClientProxies().iterator();
          if (!ps.hasNext()) {
            pause(1000);
            continue;
          } else {
            p = (CacheClientProxy)ps.next();
            break;
          }
        }

        if (p == null) {
          fail(""Proxy initialization taking long time. Increase the wait time."");
        }
        
        Iterator rs = p.getInterestRegisteredRegions().iterator();
        String rName = (String)rs.next();
        assertNotNull(""Null region Name found."", rs);
        LocalRegion r = (LocalRegion)GemFireCacheImpl.getInstance().getRegion(rName);
        assertNotNull(""Null region found."", r);
        FilterProfile pf = r.getFilterProfile();
        Set intrests = Collections.EMPTY_SET;
        
        Set interestKeys = pf.getKeysOfInterest(p.getProxyID().getDurableId());
        assertNotNull(""durable Interests not found for the proxy"", interestKeys);
        assertEquals(""The number of durable keys registered during HARegion GII doesn't match."", interestKeys.size(), 2);
        interestKeys = pf.getKeysOfInterest(p.getProxyID());
        assertNull(""non-durable Interests found for the proxy"", interestKeys);
      }
    });


    // Stop the durable client
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 2
    this.server2VM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 1
    this.server1VM.invoke(CacheServerTestUtil.class, ""closeCache"");

  }",True
"  public void testDurableClientDisConnectWithRegistrationHA() {
    
    // Step 1: Start server1
    PORT2 = new Integer(AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
    
    PORT1 = ((Integer)this.server1VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true)
             })).intValue();
    

    // Step 2: Bring Up the Client
    final String durableClientId = getName() + ""_client"";
    // keep the client alive for 600 seconds
    final int durableClientTimeout = 600;
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""createCacheClient"",
        new Object[] {
            getClientPool(getServerHostName(durableClientVM.getHost()), PORT1, PORT2, true, 1),
            regionName,
            getClientDistributedSystemProperties(durableClientId,
                durableClientTimeout) });

    // Send clientReady message
    this.durableClientVM.invoke(new CacheSerializableRunnable(
        ""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });

    // Step 3: Client registers Interests
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K1, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K2, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K3, new Boolean(true) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K4, new Boolean(true) });

    // Close Cache of the DurableClient
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""closeCache"");

    pause(2000);

    //Re-start the Client
    this.durableClientVM
        .invoke(CacheServerTestUtil.class, ""createCacheClient"",
            new Object[] { getClientPool(getServerHostName(durableClientVM.getHost()), PORT1, PORT2, true, 1),
                regionName,
                getClientDistributedSystemProperties(durableClientId),
                Boolean.TRUE });

    //Send clientReady message
    this.durableClientVM.invoke(new CacheSerializableRunnable(
        ""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });

    // Step 4: Bring up the server2
    this.server2VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true),
             PORT2 });

    pause(3000);

    // Check server2 got all the interests registered by the durable client.    
    server2VM.invoke(new CacheSerializableRunnable(""Verify Interests."") {
      public void run2() throws CacheException
      {
        getLogWriter().info(""### Verifying interests registered by DurableClient. ###"");
        CacheClientNotifier ccn = CacheClientNotifier.getInstance();
        CacheClientProxy p = null;
        
        // Get proxy for the client.        
        for (int i=0; i < 60; i++) {
          Iterator ps = ccn.getClientProxies().iterator();
          if (!ps.hasNext()) {
            pause(1000);
            continue;
          } else {
            p = (CacheClientProxy)ps.next();
            break;
          }
        }

        if (p == null) {
          fail(""Proxy initialization taking long time. Increase the wait time."");
        }
        
        Iterator rs = p.getInterestRegisteredRegions().iterator();
        String rName = (String)rs.next();
        assertNotNull(""Null region Name found."", rs);
        LocalRegion r = (LocalRegion)GemFireCacheImpl.getInstance().getRegion(rName);
        assertNotNull(""Null region found."", r);
        FilterProfile pf = r.getFilterProfile();
        Set intrests = Collections.EMPTY_SET;
        
        Set interestKeys = pf.getKeysOfInterest(p.getProxyID().getDurableId());
        assertNotNull(""durable Interests not found for the proxy"", interestKeys);
        assertEquals(""The number of durable keys registered during HARegion GII doesn't match."", interestKeys.size(), 2);
        interestKeys = pf.getKeysOfInterest(p.getProxyID());
        assertNull(""non-durable Interests found for the proxy"", interestKeys);
      }
    });


    // Stop the durable client
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 2
    this.server2VM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 1
    this.server1VM.invoke(CacheServerTestUtil.class, ""closeCache"");

  }",False
"  public void testSimpleDurableClient() {

    // Step 1: Starting the servers
    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);

    PORT1 = ((Integer)this.server1VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true),
            new Integer(mcastPort) })).intValue();
    PORT2 = ((Integer)this.server2VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true),
            new Integer(mcastPort) })).intValue();

    // Step 2: Bring Up the Client
    // Start a durable client that is not kept alive on the server when it
    // stops normally
    final String durableClientId = getName() + ""_client"";

    final int durableClientTimeout = 600; // keep the client alive for 600
    // seconds
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""createCacheClient"",
        new Object[] {
            getClientPool(getServerHostName(durableClientVM.getHost()), PORT1, PORT2, true, 0),
            regionName,
            getClientDistributedSystemProperties(durableClientId,
                durableClientTimeout), Boolean.TRUE });

    // Send clientReady message
    this.durableClientVM.invoke(new CacheSerializableRunnable(
        ""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });

    // Step 3: Client registers Interests
    // KEY_STONE1, KEY_STONE2 are registered as durableKeys & KEY_STONE3,
    // KEY_STONE4 as non-durableKeys

    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K1, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K2, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K3, new Boolean(true) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K4, new Boolean(true) });

    // Step 4: Update Values on the Server for KEY_STONE1, KEY_STONE2,
    // KEY_STONE3, KEY_STONE4

    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K1, ""Value1"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K2, ""Value2"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K3, ""Value3"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K4, ""Value4"" });

    pause(1000);
    // Step 5: Verify Updates on the Client

    assertEquals(""Value1"", this.server2VM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K1 }));
    assertEquals(""Value1"", this.server1VM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K1 }));

    assertEquals(""Value1"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K1 }));
    assertEquals(""Value2"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K2 }));
    assertEquals(""Value3"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K3 }));
    assertEquals(""Value4"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K4 }));

    // Step 6: Close Cache of the DurableClient
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""closeCache"");
    // pause(5000);
    // Step 7: Update KEY_STONE1,KEY_STONE2,KEY_STONE3,KEY_STONE4 on the
    // Server say with values PingPong1, PingPong2, PingPong3, PingPong4
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K1, ""PingPong1"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K2, ""PingPong2"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K3, ""PingPong3"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K4, ""PingPong4"" });

    // Step 8: Re-start the Client
    this.durableClientVM
        .invoke(CacheServerTestUtil.class, ""createCacheClient"",
            new Object[] { getClientPool(getServerHostName(durableClientVM.getHost()), PORT1, PORT2, true, 0),
                regionName,
                getClientDistributedSystemProperties(durableClientId),
                Boolean.TRUE });

    // Send clientReady message
    this.durableClientVM.invoke(new CacheSerializableRunnable(
        ""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });

    pause(5000);

    assertNull(this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""getValue"", new Object[] { K1 }));
    assertNull(this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""getValue"", new Object[] { K2 }));

    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K1, new Boolean(false) });

    pause(5000);
    assertNull(this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""getValue"", new Object[] { K1 }));
    assertNull(this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""getValue"", new Object[] { K2 }));

    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K1, ""PingPong_updated_1"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K2, ""PingPong_updated_2"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K3, ""PingPong_updated_3"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K4, ""PingPong_updated_4"" });

    pause(5000);

    // Step 9: Verify Updates on the Client
    assertEquals(""PingPong_updated_1"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K1 }));
    assertNull(this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""getValue"", new Object[] { K2 }));
    assertEquals(""PingPong_updated_3"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K3 }));
    assertEquals(""PingPong_updated_4"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K4 }));

    // Step 10 : Stop all VMs
    // Stop the durable client
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 2
    this.server2VM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 1
    this.server1VM.invoke(CacheServerTestUtil.class, ""closeCache"");

  }",True
"  public void testSimpleDurableClient() {

    // Step 1: Starting the servers
    PORT1 = ((Integer)this.server1VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true)
            })).intValue();
    PORT2 = ((Integer)this.server2VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true),
            })).intValue();

    // Step 2: Bring Up the Client
    // Start a durable client that is not kept alive on the server when it
    // stops normally
    final String durableClientId = getName() + ""_client"";

    final int durableClientTimeout = 600; // keep the client alive for 600
    // seconds
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""createCacheClient"",
        new Object[] {
            getClientPool(getServerHostName(durableClientVM.getHost()), PORT1, PORT2, true, 0),
            regionName,
            getClientDistributedSystemProperties(durableClientId,
                durableClientTimeout), Boolean.TRUE });

    // Send clientReady message
    this.durableClientVM.invoke(new CacheSerializableRunnable(
        ""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });

    // Step 3: Client registers Interests
    // KEY_STONE1, KEY_STONE2 are registered as durableKeys & KEY_STONE3,
    // KEY_STONE4 as non-durableKeys

    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K1, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K2, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K3, new Boolean(true) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K4, new Boolean(true) });

    // Step 4: Update Values on the Server for KEY_STONE1, KEY_STONE2,
    // KEY_STONE3, KEY_STONE4

    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K1, ""Value1"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K2, ""Value2"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K3, ""Value3"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K4, ""Value4"" });

    pause(1000);
    // Step 5: Verify Updates on the Client

    assertEquals(""Value1"", this.server2VM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K1 }));
    assertEquals(""Value1"", this.server1VM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K1 }));

    assertEquals(""Value1"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K1 }));
    assertEquals(""Value2"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K2 }));
    assertEquals(""Value3"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K3 }));
    assertEquals(""Value4"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K4 }));

    // Step 6: Close Cache of the DurableClient
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""closeCache"");
    // pause(5000);
    // Step 7: Update KEY_STONE1,KEY_STONE2,KEY_STONE3,KEY_STONE4 on the
    // Server say with values PingPong1, PingPong2, PingPong3, PingPong4
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K1, ""PingPong1"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K2, ""PingPong2"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K3, ""PingPong3"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K4, ""PingPong4"" });

    // Step 8: Re-start the Client
    this.durableClientVM
        .invoke(CacheServerTestUtil.class, ""createCacheClient"",
            new Object[] { getClientPool(getServerHostName(durableClientVM.getHost()), PORT1, PORT2, true, 0),
                regionName,
                getClientDistributedSystemProperties(durableClientId),
                Boolean.TRUE });

    // Send clientReady message
    this.durableClientVM.invoke(new CacheSerializableRunnable(
        ""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });

    pause(5000);

    assertNull(this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""getValue"", new Object[] { K1 }));
    assertNull(this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""getValue"", new Object[] { K2 }));

    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K1, new Boolean(false) });

    pause(5000);
    assertNull(this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""getValue"", new Object[] { K1 }));
    assertNull(this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""getValue"", new Object[] { K2 }));

    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K1, ""PingPong_updated_1"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K2, ""PingPong_updated_2"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K3, ""PingPong_updated_3"" });
    this.server2VM.invoke(DurableRegistrationDUnitTest.class, ""putValue"",
        new Object[] { K4, ""PingPong_updated_4"" });

    pause(5000);

    // Step 9: Verify Updates on the Client
    assertEquals(""PingPong_updated_1"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K1 }));
    assertNull(this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""getValue"", new Object[] { K2 }));
    assertEquals(""PingPong_updated_3"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K3 }));
    assertEquals(""PingPong_updated_4"", this.durableClientVM.invoke(
        DurableRegistrationDUnitTest.class, ""getValue"", new Object[] { K4 }));

    // Step 10 : Stop all VMs
    // Stop the durable client
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 2
    this.server2VM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 1
    this.server1VM.invoke(CacheServerTestUtil.class, ""closeCache"");

  }",False
"  public void testDurableClientWithRegistrationHA() {
    
    // Step 1: Start server1
    int mcastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    
    PORT2 = new Integer(AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
    
    PORT1 = ((Integer)this.server1VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true),
            new Integer(mcastPort) })).intValue();
    

    // Step 2: Bring Up the Client
    final String durableClientId = getName() + ""_client"";
    // keep the client alive for 600 seconds
    final int durableClientTimeout = 600;
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""createCacheClient"",
        new Object[] {
            getClientPool(getServerHostName(durableClientVM.getHost()), PORT1, PORT2, true, 1),
            regionName,
            getClientDistributedSystemProperties(durableClientId,
                durableClientTimeout) });

    // Send clientReady message
    this.durableClientVM.invoke(new CacheSerializableRunnable(
        ""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });

    // Step 3: Client registers Interests
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K1, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K2, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K3, new Boolean(true) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K4, new Boolean(true) });

    // Step 4: Bring up the server2

    this.server2VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true),
            new Integer(mcastPort), PORT2 });

    pause(3000);

    // Check server2 got all the interests registered by the durable client.    
    server2VM.invoke(new CacheSerializableRunnable(""Verify Interests."") {
      public void run2() throws CacheException
      {
        getLogWriter().info(""### Verifying interests registered by DurableClient. ###"");
        CacheClientNotifier ccn = CacheClientNotifier.getInstance();
        CacheClientProxy p = null;
        
        // Get proxy for the client.        
        for (int i=0; i < 60; i++) {
          Iterator ps = ccn.getClientProxies().iterator();
          if (!ps.hasNext()) {
            pause(1000);
            continue;
          } else {
            p = (CacheClientProxy)ps.next();
            break;
          }
        }

        if (p == null) {
          fail(""Proxy initialization taking long time. Increase the wait time."");
        }
        
        Iterator rs = p.getInterestRegisteredRegions().iterator();
        String rName = (String)rs.next();
        assertNotNull(""Null region Name found."", rs);
        LocalRegion r = (LocalRegion)GemFireCacheImpl.getInstance().getRegion(rName);
        assertNotNull(""Null region found."", r);
        FilterProfile pf = r.getFilterProfile();
        Set intrests = Collections.EMPTY_SET;
        
        Set interestKeys = pf.getKeysOfInterest(p.getProxyID().getDurableId());
        assertNotNull(""durable Interests not found for the proxy"", interestKeys);
        assertEquals(""The number of durable keys registered during HARegion GII doesn't match."", interestKeys.size(), 2);
        interestKeys = pf.getKeysOfInterest(p.getProxyID());
        assertNotNull(""non-durable Interests not found for the proxy"", interestKeys);
        assertEquals(""The number of non-durable keys registered during HARegion GII doesn't match."", interestKeys.size(), 2);
      }
    });


    // Stop the durable client
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 2
    this.server2VM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 1
    this.server1VM.invoke(CacheServerTestUtil.class, ""closeCache"");

  }",True
"  public void testDurableClientWithRegistrationHA() {
    
    // Step 1: Start server1
    PORT2 = new Integer(AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
    
    PORT1 = ((Integer)this.server1VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true)
             })).intValue();
    

    // Step 2: Bring Up the Client
    final String durableClientId = getName() + ""_client"";
    // keep the client alive for 600 seconds
    final int durableClientTimeout = 600;
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""createCacheClient"",
        new Object[] {
            getClientPool(getServerHostName(durableClientVM.getHost()), PORT1, PORT2, true, 1),
            regionName,
            getClientDistributedSystemProperties(durableClientId,
                durableClientTimeout) });

    // Send clientReady message
    this.durableClientVM.invoke(new CacheSerializableRunnable(
        ""Send clientReady"") {
      public void run2() throws CacheException {
        CacheServerTestUtil.getCache().readyForEvents();
      }
    });

    // Step 3: Client registers Interests
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K1, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K2, new Boolean(false) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K3, new Boolean(true) });
    this.durableClientVM.invoke(DurableRegistrationDUnitTest.class,
        ""registerKey"", new Object[] { K4, new Boolean(true) });

    // Step 4: Bring up the server2

    this.server2VM.invoke(CacheServerTestUtil.class,
        ""createCacheServer"", new Object[] { regionName, new Boolean(true),
             PORT2 });

    pause(3000);

    // Check server2 got all the interests registered by the durable client.    
    server2VM.invoke(new CacheSerializableRunnable(""Verify Interests."") {
      public void run2() throws CacheException
      {
        getLogWriter().info(""### Verifying interests registered by DurableClient. ###"");
        CacheClientNotifier ccn = CacheClientNotifier.getInstance();
        CacheClientProxy p = null;
        
        // Get proxy for the client.        
        for (int i=0; i < 60; i++) {
          Iterator ps = ccn.getClientProxies().iterator();
          if (!ps.hasNext()) {
            pause(1000);
            continue;
          } else {
            p = (CacheClientProxy)ps.next();
            break;
          }
        }

        if (p == null) {
          fail(""Proxy initialization taking long time. Increase the wait time."");
        }
        
        Iterator rs = p.getInterestRegisteredRegions().iterator();
        String rName = (String)rs.next();
        assertNotNull(""Null region Name found."", rs);
        LocalRegion r = (LocalRegion)GemFireCacheImpl.getInstance().getRegion(rName);
        assertNotNull(""Null region found."", r);
        FilterProfile pf = r.getFilterProfile();
        Set intrests = Collections.EMPTY_SET;
        
        Set interestKeys = pf.getKeysOfInterest(p.getProxyID().getDurableId());
        assertNotNull(""durable Interests not found for the proxy"", interestKeys);
        assertEquals(""The number of durable keys registered during HARegion GII doesn't match."", interestKeys.size(), 2);
        interestKeys = pf.getKeysOfInterest(p.getProxyID());
        assertNotNull(""non-durable Interests not found for the proxy"", interestKeys);
        assertEquals(""The number of non-durable keys registered during HARegion GII doesn't match."", interestKeys.size(), 2);
      }
    });


    // Stop the durable client
    this.durableClientVM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 2
    this.server2VM.invoke(CacheServerTestUtil.class, ""closeCache"");

    // Stop server 1
    this.server1VM.invoke(CacheServerTestUtil.class, ""closeCache"");

  }",False
"  public void createServersAndClients(int redundancyLevel) {
    final Host host = Host.getHost(0);
    // start servers first
    final Integer mcastPort = new Integer(AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS));
    PORT1 = ((Integer)vm0.invoke(CacheServerTestUtil.class,
                                 ""createCacheServer"",
                                 new Object[] {REGION_NAME, new Boolean(true), mcastPort}))
        .intValue();

    PORT2 = ((Integer)vm3.invoke(CacheServerTestUtil.class,
                                 ""createCacheServer"",
                                 new Object[] {REGION_NAME, new Boolean(true), mcastPort}))
        .intValue();

    vm1.invoke(CacheServerTestUtil.class, ""disableShufflingOfEndpoints"");
    vm2.invoke(CacheServerTestUtil.class, ""disableShufflingOfEndpoints"");
    vm1.invoke(CacheServerTestUtil.class, ""createCacheClient"", new Object[] {
        getClientPool(getServerHostName(host),redundancyLevel), REGION_NAME });
    vm2.invoke(CacheServerTestUtil.class, ""createCacheClient"", new Object[] {
        getClientPool(getServerHostName(host),0), REGION_NAME });
  }",True
"  public void createServersAndClients(int redundancyLevel) {
    final Host host = Host.getHost(0);
    // start servers first
    PORT1 = ((Integer)vm0.invoke(CacheServerTestUtil.class,
                                 ""createCacheServer"",
                                 new Object[] {REGION_NAME, new Boolean(true)}))
        .intValue();

    PORT2 = ((Integer)vm3.invoke(CacheServerTestUtil.class,
                                 ""createCacheServer"",
                                 new Object[] {REGION_NAME, new Boolean(true)}))
        .intValue();

    vm1.invoke(CacheServerTestUtil.class, ""disableShufflingOfEndpoints"");
    vm2.invoke(CacheServerTestUtil.class, ""disableShufflingOfEndpoints"");
    vm1.invoke(CacheServerTestUtil.class, ""createCacheClient"", new Object[] {
        getClientPool(getServerHostName(host),redundancyLevel), REGION_NAME });
    vm2.invoke(CacheServerTestUtil.class, ""createCacheClient"", new Object[] {
        getClientPool(getServerHostName(host),0), REGION_NAME });
  }",False
"  public static Integer createCacheAndStartServer() throws Exception {
    DistributedSystem ds = new UnregisterInterestDUnitTest(""UnregisterInterestDUnitTest"").getSystem();
    ds.disconnect();
    Properties props = new Properties();
    props.setProperty(""locators"", """");
    props.setProperty(""mcast-port"", String.valueOf(AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS)));
    CacheFactory cf = new CacheFactory(props);
    cache = cf.create();
    RegionFactory rf = ((GemFireCacheImpl)cache).createRegionFactory(RegionShortcut.REPLICATE);
    rf.create(regionname);
    CacheServer server = ((GemFireCacheImpl)cache).addCacheServer();
    server.setPort(AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
    server.start();
    return server.getPort();
  }",True
"  public static Integer createCacheAndStartServer() throws Exception {
    DistributedSystem ds = new UnregisterInterestDUnitTest(""UnregisterInterestDUnitTest"").getSystem();
    ds.disconnect();
    Properties props = new Properties();
    props.setProperty(""locators"", ""localhost[""+getDUnitLocatorPort()+""]"");
    CacheFactory cf = new CacheFactory(props);
    cache = cf.create();
    RegionFactory rf = ((GemFireCacheImpl)cache).createRegionFactory(RegionShortcut.REPLICATE);
    rf.create(regionname);
    CacheServer server = ((GemFireCacheImpl)cache).addCacheServer();
    server.setPort(AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET));
    server.start();
    return server.getPort();
  }",False
"  public void setUp() throws Exception {
    super.setUp();
    locator = managedNode1;
    
    mCastPort = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
  }",True
"    locator = managedNode1;
  }

  public void tearDown2() throws Exception {
    stopLocator(locator);
    super.tearDown2();",False
"  protected final int getMcastPort() {
    return this.locatorPort;
  }",False
"  protected final Properties createProperties() {
    Properties properties = new Properties();
    properties.setProperty(""gemfire.start-locator"", ""localhost["" + String.valueOf(this.locatorPort) + ""]"");
    properties.setProperty(""gemfire.log-level"", ""warning"");
    properties.setProperty(""file.encoding"", ""UTF-8"");
    return editProperties(properties);
  }",False
"  public final InternalDistributedSystem getMcastSystem() {
    Properties props = this.getDistributedSystemProperties();
    int port = AvailablePort.getRandomAvailablePort(AvailablePort.JGROUPS);
    props.put(DistributionConfig.MCAST_PORT_NAME, """"+port);
    props.put(DistributionConfig.MCAST_TTL_NAME, ""0"");
    props.put(DistributionConfig.LOCATORS_NAME, """");
    return getSystem(props);
  }",True
"  public final boolean isConnectedToDS() {
    return system != null && system.isConnected();
  }

  /**
   * Returns a <code>Properties</code> object used to configure a
   * connection to a {@link
   * com.gemstone.gemfire.distributed.DistributedSystem}.",False
"  public Properties getDistributedSystemProperties() {
    return new Properties();
  }

  /**
   * Sets up the test (noop).
   */",False
"  public static final void pause(int ms) {
    LogWriter log = getLogWriter();
    if (ms >= 1000 || log.fineEnabled()) { // check for fine but log at info
      getLogWriter().info(""Pausing for "" + ms + "" ms...""/*, new Exception()*/);
    }
    final long target = System.currentTimeMillis() + ms;
    try {
      for (;;) {
        long msLeft = target - System.currentTimeMillis();
        if (msLeft <= 0) {
          break;
        }
        Thread.sleep(msLeft);
      }
    }
    catch (InterruptedException e) {
      fail(""interrupted"", e);
    }
  }",False
"  private static void startLocator(Registry registry) throws IOException, NotBoundException {
    RemoteDUnitVMIF remote = (RemoteDUnitVMIF) registry.lookup(""vm"" + LOCATOR_VM_NUM);
    final File locatorLogFile =
        LOCATOR_LOG_TO_DISK ? new File(""locator-"" + locatorPort + "".log"") : new File(""""); 
    MethExecutorResult result = remote.executeMethodOnObject(new SerializableCallable() {
      public Object call() throws IOException {
        Properties p = getDistributedSystemProperties();
        // I never want this locator to end up starting a jmx manager
        // since it is part of the unit test framework
        p.setProperty(""jmx-manager"", ""false"");
        //Disable the shared configuration on this locator.
        //Shared configuration tests create their own locator
        p.setProperty(""enable-cluster-configuration"", ""false"");
        Locator.startLocatorAndDS(locatorPort, locatorLogFile, p);
        return null;
      }
    }, ""call"");
    if(result.getException() != null) {
      RuntimeException ex = new RuntimeException(""Failed to start locator"", result.getException());
      ex.printStackTrace();
      throw ex;
    }
  }",True
"  private static void startLocator(Registry registry) throws IOException, NotBoundException {
    RemoteDUnitVMIF remote = (RemoteDUnitVMIF) registry.lookup(""vm"" + LOCATOR_VM_NUM);
    final File locatorLogFile =
        LOCATOR_LOG_TO_DISK ? new File(""locator-"" + locatorPort + "".log"") : new File(""""); 
    MethExecutorResult result = remote.executeMethodOnObject(new SerializableCallable() {
      public Object call() throws IOException {
        Properties p = getDistributedSystemProperties();
        // I never want this locator to end up starting a jmx manager
        // since it is part of the unit test framework
        p.setProperty(""jmx-manager"", ""false"");
        //Disable the shared configuration on this locator.
        //Shared configuration tests create their own locator
        p.setProperty(""enable-cluster-configuration"", ""false"");
        //Tell the locator it's the first in the system for
        //faster boot-up
        System.setProperty(""gemfire.first-member"", ""true"");
        
        Locator.startLocatorAndDS(locatorPort, locatorLogFile, p);
        return null;
      }
    }, ""call"");
    if(result.getException() != null) {
      RuntimeException ex = new RuntimeException(""Failed to start locator"", result.getException());
      ex.printStackTrace();
      throw ex;
    }
  }",False
"  private String[] buildJavaCommand(int vmNum, int namingPort) {
    String cmd = System.getProperty( ""java.home"" ) + File.separator + ""bin"" + File.separator + ""java"";
    String classPath = System.getProperty(""java.class.path"");
    //String tmpDir = System.getProperty(""java.io.tmpdir"");
    String agent = getAgentString();
    return new String[] {
      cmd, ""-classpath"", classPath,
      ""-D"" + DUnitLauncher.RMI_PORT_PARAM + ""="" + namingPort,
      ""-D"" + DUnitLauncher.VM_NUM_PARAM + ""="" + vmNum,
      ""-D"" + DUnitLauncher.WORKSPACE_DIR_PARAM + ""="" + new File(""."").getAbsolutePath(),
      ""-DlogLevel="" + DUnitLauncher.LOG_LEVEL,
      ""-Djava.library.path="" + System.getProperty(""java.library.path""),
      ""-Xrunjdwp:transport=dt_socket,server=y,suspend=n"",
      ""-XX:+HeapDumpOnOutOfMemoryError"",
      ""-Xmx512m"",
      ""-XX:MaxPermSize=256M"",
      ""-Dgemfire.DEFAULT_MAX_OPLOG_SIZE=10"",
      ""-Dgemfire.disallowMcastDefaults=true"",
      ""-XX:MaxPermSize=256M"",
      ""-ea"",
      agent,
      ""dunit.standalone.ChildVM""
    };
  }",True
"  private String[] buildJavaCommand(int vmNum, int namingPort) {
    String cmd = System.getProperty( ""java.home"" ) + File.separator + ""bin"" + File.separator + ""java"";
    String classPath = System.getProperty(""java.class.path"");
    //String tmpDir = System.getProperty(""java.io.tmpdir"");
    String agent = getAgentString();
    return new String[] {
      cmd, ""-classpath"", classPath,
      ""-D"" + DUnitLauncher.RMI_PORT_PARAM + ""="" + namingPort,
      ""-D"" + DUnitLauncher.VM_NUM_PARAM + ""="" + vmNum,
      ""-D"" + DUnitLauncher.WORKSPACE_DIR_PARAM + ""="" + new File(""."").getAbsolutePath(),
      ""-DlogLevel="" + DUnitLauncher.LOG_LEVEL,
      ""-Djava.library.path="" + System.getProperty(""java.library.path""),
      ""-Xrunjdwp:transport=dt_socket,server=y,suspend=n"",
      ""-XX:+HeapDumpOnOutOfMemoryError"",
      ""-Xmx512m"",
      ""-XX:MaxPermSize=256M"",
      ""-Dgemfire.DEFAULT_MAX_OPLOG_SIZE=10"",
      ""-Dgemfire.disallowMcastDefaults=true"",
      ""-XX:MaxPermSize=256M"",
      ""-ea"",
      // use IPv4 on Windows
      // see https://github.com/belaban/JGroups/wiki/FAQ
//      (IS_WINDOWS?""-Djava.net.preferIPv4Stack=true"":""""),
      agent,
      ""dunit.standalone.ChildVM""
    };
  }",False
"  public String startGatewaySender(@RequestParam(CliStrings.START_GATEWAYSENDER__ID) final String gatewaySenderId,
                                   @RequestParam(value = CliStrings.START_GATEWAYSENDER__GROUP, required = false) final String[] groups,
                                   @RequestParam(value = CliStrings.START_GATEWAYSENDER__MEMBER, required = false) final String[] members)
  {
    CommandStringBuilder command = new CommandStringBuilder(CliStrings.START_GATEWAYRECEIVER);

    command.addOption(CliStrings.START_GATEWAYSENDER__ID, gatewaySenderId);

    if (hasValue(groups)) {
      command.addOption(CliStrings.START_GATEWAYSENDER__GROUP, StringUtils.concat(groups, StringUtils.COMMA_DELIMITER));
    }

    if (hasValue(members)) {
      command.addOption(CliStrings.START_GATEWAYSENDER__MEMBER, StringUtils.concat(members, StringUtils.COMMA_DELIMITER));
    }

    return processCommand(command.toString());
  }",True
"  public String startGatewaySender(@RequestParam(CliStrings.START_GATEWAYSENDER__ID) final String gatewaySenderId,
                                   @RequestParam(value = CliStrings.START_GATEWAYSENDER__GROUP, required = false) final String[] groups,
                                   @RequestParam(value = CliStrings.START_GATEWAYSENDER__MEMBER, required = false) final String[] members)
  {
    CommandStringBuilder command = new CommandStringBuilder(CliStrings.START_GATEWAYSENDER);

    command.addOption(CliStrings.START_GATEWAYSENDER__ID, gatewaySenderId);

    if (hasValue(groups)) {
      command.addOption(CliStrings.START_GATEWAYSENDER__GROUP, StringUtils.concat(groups, StringUtils.COMMA_DELIMITER));
    }

    if (hasValue(members)) {
      command.addOption(CliStrings.START_GATEWAYSENDER__MEMBER, StringUtils.concat(members, StringUtils.COMMA_DELIMITER));
    }

    return processCommand(command.toString());
  }",False
"  public static LuceneService get(Cache cache) {
    synchronized(LuceneService.class) {
      Extensible<Cache> extensible = (Extensible<Cache>) cache;
      LuceneServiceImpl service = (LuceneServiceImpl) extensible.getExtensionPoint().getExtension(LuceneService.class);
      if(service == null) {
        service = new LuceneServiceImpl(cache);
        extensible.getExtensionPoint().addExtension(LuceneService.class, service);
      }
      
      return service;
    }
    
  }",True
"  /**
   * Create a lucene index using default analyzer.
   * 
   * @param indexName
   * @param regionName
   * @param fields
   * @return LuceneIndex object
   */
  public LuceneIndex createIndex(String indexName, String regionName, String... fields);
  
  /**
   * Create a lucene index using specified analyzer per field
   * ",False
"  private LuceneServiceProvider() {
    
  }",False
"  public static LuceneService get(Cache cache) {
    synchronized(LuceneService.class) {
      Extensible<Cache> extensible = (Extensible<Cache>) cache;
      LuceneServiceImpl service = (LuceneServiceImpl) extensible.getExtensionPoint().getExtension(LuceneService.class);
      if(service == null) {
        service = new LuceneServiceImpl(cache);
        extensible.getExtensionPoint().addExtension(LuceneService.class, service);
      }
      
      return service;
    }
  }",False
"  public boolean authorizeOperation(String regionName, OperationContext context) {
    this.logger.info("" JASON Authorizing request "" + context.getOperationCode() + "" class:"" + context.getClass().getName());
    new Exception(""JASON authz stack"").printStackTrace();
    if (context instanceof ExecuteCQOperationContext) {
      cache.close();
      //return false;
      throw new CacheClosedException(""cache is closed"");
    }
    return true;
  }",True
"  public boolean authorizeOperation(String regionName, OperationContext context) {
    if (context instanceof ExecuteCQOperationContext) {
      cache.close();
      //return false;
      throw new CacheClosedException(""cache is closed"");
    }
    return true;
  }
}
",False
"  private GfManagerAgentConfig buildAgentConfig(InternalLogWriter logWriter) {
    RemoteTransportConfig conf = new RemoteTransportConfig(
        isMcastEnabled(), getDisableTcp(),
        getDisableAutoReconnect(),
        getBindAddress(), buildSSLConfig(), parseLocators(), 
        getMembershipPortRange(), getTcpPort());
    return new GfManagerAgentConfig(
        getSystemName(), conf, logWriter, this.alertLevel.getSeverity(), this, this);
  }",True
"  private GfManagerAgentConfig buildAgentConfig(InternalLogWriter logWriter) {
    RemoteTransportConfig conf = new RemoteTransportConfig(
        isMcastEnabled(), getDisableTcp(),
        getDisableAutoReconnect(),
        getBindAddress(), buildSSLConfig(), parseLocators(), 
        getMembershipPortRange(), getTcpPort(), DistributionManager.ADMIN_ONLY_DM_TYPE);
    return new GfManagerAgentConfig(
        getSystemName(), conf, logWriter, this.alertLevel.getSeverity(), this, this);
  }",False
"    protected void sendMessage(Connection cnx) throws Exception {
      HeapDataOutputStream hdos = new HeapDataOutputStream(Version.CURRENT);
      byte[] secureBytes = null;
      hdos.writeLong(cnx.getConnectionID());
      if (this.securityProperties != null) {
        byte[] credentialBytes = null;
        DistributedMember server = new InternalDistributedMember(cnx
            .getSocket().getInetAddress(), cnx.getSocket().getPort(), false);
        DistributedSystem sys = InternalDistributedSystem
            .getConnectedInstance();
        String authInitMethod = sys.getProperties().getProperty(
            DistributionConfig.SECURITY_CLIENT_AUTH_INIT_NAME);

        Properties credentials = HandShake.getCredentials(authInitMethod,
            this.securityProperties, server, false, (InternalLogWriter)sys.getLogWriter(), (InternalLogWriter)sys
                .getSecurityLogWriter());
        HeapDataOutputStream heapdos = new HeapDataOutputStream(Version.CURRENT);
        try {
          DataSerializer.writeProperties(credentials, heapdos);
          credentialBytes = ((ConnectionImpl)cnx).getHandShake().encryptBytes(
              heapdos.toByteArray());
        } finally {
          heapdos.close();
        }
        getMessage().addBytesPart(credentialBytes);
      }
      try {
        secureBytes = ((ConnectionImpl)cnx).getHandShake().encryptBytes(
            hdos.toByteArray());
      } finally {
        hdos.close();
      }
      getMessage().setSecurePart(secureBytes);
      getMessage().send(false);
    }",True
"    protected void sendMessage(Connection cnx) throws Exception {
      HeapDataOutputStream hdos = new HeapDataOutputStream(Version.CURRENT);
      byte[] secureBytes = null;
      hdos.writeLong(cnx.getConnectionID());
      if (this.securityProperties != null) {
        byte[] credentialBytes = null;
        // TODO this is not a valid way to create a member ID
        DistributedMember server = new InternalDistributedMember(cnx
            .getSocket().getInetAddress(), cnx.getSocket().getPort(), false);
        DistributedSystem sys = InternalDistributedSystem
            .getConnectedInstance();
        String authInitMethod = sys.getProperties().getProperty(
            DistributionConfig.SECURITY_CLIENT_AUTH_INIT_NAME);

        Properties credentials = HandShake.getCredentials(authInitMethod,
            this.securityProperties, server, false, (InternalLogWriter)sys.getLogWriter(), (InternalLogWriter)sys
                .getSecurityLogWriter());
        HeapDataOutputStream heapdos = new HeapDataOutputStream(Version.CURRENT);
        try {
          DataSerializer.writeProperties(credentials, heapdos);
          credentialBytes = ((ConnectionImpl)cnx).getHandShake().encryptBytes(
              heapdos.toByteArray());
        } finally {
          heapdos.close();
        }
        getMessage().addBytesPart(credentialBytes);
      }
      try {
        secureBytes = ((ConnectionImpl)cnx).getHandShake().encryptBytes(
            hdos.toByteArray());
      } finally {
        hdos.close();
      }
      getMessage().setSecurePart(secureBytes);
      getMessage().send(false);
    }",False
"    public AuthenticateUserOpImpl(Connection con, ExecutablePool pool) {
      super(MessageType.USER_CREDENTIAL_MESSAGE, 1);
      byte[] credentialBytes = null;
      DistributedMember server = new InternalDistributedMember(con.getSocket()
          .getInetAddress(), con.getSocket().getPort(), false);
      DistributedSystem sys = InternalDistributedSystem.getConnectedInstance();
      String authInitMethod = sys.getProperties().getProperty(
          DistributionConfig.SECURITY_CLIENT_AUTH_INIT_NAME);
      Properties tmpSecurityProperties = sys.getSecurityProperties();

      // LOG: following passes the DS API LogWriters into the security API
      Properties credentials = HandShake.getCredentials(authInitMethod,
          tmpSecurityProperties, server, false, (InternalLogWriter)sys.getLogWriter(), (InternalLogWriter)sys
              .getSecurityLogWriter());
      
      getMessage().setEarlyAck(Message.MESSAGE_HAS_SECURE_PART);
      HeapDataOutputStream heapdos = new HeapDataOutputStream(Version.CURRENT);
      try {
        DataSerializer.writeProperties(credentials, heapdos);
        credentialBytes = ((ConnectionImpl)con).getHandShake()
            .encryptBytes(heapdos.toByteArray());
      } catch (Exception e) {
        throw new ServerOperationException(e);
      } finally {
        heapdos.close();
      }
      getMessage().addBytesPart(credentialBytes);
    }",True
"    public AuthenticateUserOpImpl(Connection con, ExecutablePool pool) {
      super(MessageType.USER_CREDENTIAL_MESSAGE, 1);
      byte[] credentialBytes = null;
      // TODO this is not a valid way to create a member ID
      DistributedMember server = new InternalDistributedMember(con.getSocket()
          .getInetAddress(), con.getSocket().getPort(), false);
      DistributedSystem sys = InternalDistributedSystem.getConnectedInstance();
      String authInitMethod = sys.getProperties().getProperty(
          DistributionConfig.SECURITY_CLIENT_AUTH_INIT_NAME);
      Properties tmpSecurityProperties = sys.getSecurityProperties();

      // LOG: following passes the DS API LogWriters into the security API
      Properties credentials = HandShake.getCredentials(authInitMethod,
          tmpSecurityProperties, server, false, (InternalLogWriter)sys.getLogWriter(), (InternalLogWriter)sys
              .getSecurityLogWriter());
      
      getMessage().setEarlyAck(Message.MESSAGE_HAS_SECURE_PART);
      HeapDataOutputStream heapdos = new HeapDataOutputStream(Version.CURRENT);
      try {
        DataSerializer.writeProperties(credentials, heapdos);
        credentialBytes = ((ConnectionImpl)con).getHandShake()
            .encryptBytes(heapdos.toByteArray());
      } catch (Exception e) {
        throw new ServerOperationException(e);
      } finally {
        heapdos.close();
      }
      getMessage().addBytesPart(credentialBytes);
    }",False
"  public static DistributionManager create(InternalDistributedSystem system)
  {

    DistributionManager dm = null;
    
    try {

      if (Boolean.getBoolean(InternalLocator.FORCE_LOCATOR_DM_TYPE)) {
        // if this DM is starting for a locator, set it to be a locator DM
        setDistributionManagerType(LOCATOR_DM_TYPE);

      } else if (isDedicatedAdminVM) {
        setDistributionManagerType(ADMIN_ONLY_DM_TYPE);

      } else {
        setDistributionManagerType(NORMAL_DM_TYPE);
      }
    
      RemoteTransportConfig transport = new RemoteTransportConfig(system.getConfig());
      transport.setIsReconnectingDS(system.isReconnectingDS());
      transport.setOldDSMembershipInfo(system.oldDSMembershipInfo());
      
      long start = System.currentTimeMillis();

      dm = new DistributionManager(system, transport);
      dm.assertDistributionManagerType();

      {
        InternalDistributedMember id = dm.getDistributionManagerId();
        if (!"""".equals(id.getName())) {
          for (InternalDistributedMember m: (List<InternalDistributedMember>)dm.getViewMembers()) {
            if (m.equals(id)) {
              // I'm counting on the members returned by getViewMembers being ordered such that
              // members that joined before us will precede us AND members that join after us
              // will succeed us.
              // SO once we find ourself break out of this loop.
              break;
            }
            if (id.getName().equals(m.getName())) {
              if (dm.getMembershipManager().verifyMember(m, ""member is using the name of "" + id)) {
                throw new IncompatibleSystemException(""Member "" + id + "" could not join this distributed system because the existing member "" + m + "" used the same name. Set the \""name\"" gemfire property to a unique value."");
              }
            }
          }
        }
        dm.addNewMember(id, null); // add ourselves
        dm.selectElder(); // ShutdownException could be thrown here
      }

      // Send out a StartupMessage to the other members.
      StartupOperation op = new StartupOperation(dm, transport);

      try {
        if (!dm.sendStartupMessage(op, true)) {
          // We'll we didn't hear back from anyone else.  We assume that
          // we're the first one.
          if (dm.getOtherDistributionManagerIds().size() == 0) {
            logger.info(LocalizedMessage.create(LocalizedStrings.DistributionManager_DIDNT_HEAR_BACK_FROM_ANY_OTHER_SYSTEM_I_AM_THE_FIRST_ONE));
          } else if (transport.isMcastEnabled()) {
            // perform a multicast ping test
            if (!dm.testMulticast()) {
              logger.warn(LocalizedMessage.create(
                  LocalizedStrings.DistributionManager_RECEIVED_NO_STARTUP_RESPONSES_BUT_OTHER_MEMBERS_EXIST_MULTICAST_IS_NOT_RESPONSIVE));
            }
          }
        }
      } catch (InterruptedException ex) {
        Thread.currentThread().interrupt();
        // This is ALWAYS bad; don't consult a CancelCriterion.
        throw new InternalGemFireException(LocalizedStrings.DistributionManager_INTERRUPTED_WHILE_WAITING_FOR_FIRST_STARTUPRESPONSEMESSAGE.toLocalizedString(), ex);
      } catch (IncompatibleSystemException ex) {
        logger.fatal(ex.getMessage(), ex);
        throw ex;
      } finally {
        dm.readyToSendMsgs();
      }

      if (logger.isInfoEnabled()) {
        long delta = System.currentTimeMillis() - start;
        Object[] logArgs = new Object[] {
            dm.getDistributionManagerId(),
            transport,
            Integer.valueOf(dm.getOtherDistributionManagerIds().size()),
            dm.getOtherDistributionManagerIds(), 
            (logger.isInfoEnabled(LogMarker.DM) ? "" (VERBOSE, took "" + delta + "" ms)"" : """"),
            ((dm.getDMType() == ADMIN_ONLY_DM_TYPE) ? "" (admin only)"" : (dm.getDMType() == LOCATOR_DM_TYPE) ? "" (locator)"" : """")
        };
        logger.info(LogMarker.DM, LocalizedMessage.create(
            LocalizedStrings.DistributionManager_DISTRIBUTIONMANAGER_0_STARTED_ON_1_THERE_WERE_2_OTHER_DMS_3_4_5, logArgs));
        MembershipLogger.logStartup(dm.getDistributionManagerId());
      }
      return dm;
    }
    catch (RuntimeException r) {
      if (dm != null) {
        if (logger.isDebugEnabled()) {
          logger.debug(""cleaning up incompletely started DistributionManager due to exception"", r); 
        }
        dm.uncleanShutdown(true);
      }
      throw r;
    }
  }",True
"  public static DistributionManager create(InternalDistributedSystem system)
  {

    DistributionManager dm = null;
    
    try {

      int vmKind;
      
      if (Boolean.getBoolean(InternalLocator.FORCE_LOCATOR_DM_TYPE)) {
        // if this DM is starting for a locator, set it to be a locator DM
        vmKind = LOCATOR_DM_TYPE;

      } else if (isDedicatedAdminVM) {
        vmKind = ADMIN_ONLY_DM_TYPE;

      } else {
        vmKind = NORMAL_DM_TYPE;
      }
    
      RemoteTransportConfig transport = new RemoteTransportConfig(system.getConfig(), vmKind);
      transport.setIsReconnectingDS(system.isReconnectingDS());
      transport.setOldDSMembershipInfo(system.oldDSMembershipInfo());
      
      long start = System.currentTimeMillis();

      dm = new DistributionManager(system, transport);
      dm.assertDistributionManagerType();

      {
        InternalDistributedMember id = dm.getDistributionManagerId();
        if (!"""".equals(id.getName())) {
          for (InternalDistributedMember m: (List<InternalDistributedMember>)dm.getViewMembers()) {
            if (m.equals(id)) {
              // I'm counting on the members returned by getViewMembers being ordered such that
              // members that joined before us will precede us AND members that join after us
              // will succeed us.
              // SO once we find ourself break out of this loop.
              break;
            }
            if (id.getName().equals(m.getName())) {
              if (dm.getMembershipManager().verifyMember(m, ""member is using the name of "" + id)) {
                throw new IncompatibleSystemException(""Member "" + id + "" could not join this distributed system because the existing member "" + m + "" used the same name. Set the \""name\"" gemfire property to a unique value."");
              }
            }
          }
        }
        dm.addNewMember(id, null); // add ourselves
        dm.selectElder(); // ShutdownException could be thrown here
      }

      // Send out a StartupMessage to the other members.
      StartupOperation op = new StartupOperation(dm, transport);

      try {
        if (!dm.sendStartupMessage(op, true)) {
          // We'll we didn't hear back from anyone else.  We assume that
          // we're the first one.
          if (dm.getOtherDistributionManagerIds().size() == 0) {
            logger.info(LocalizedMessage.create(LocalizedStrings.DistributionManager_DIDNT_HEAR_BACK_FROM_ANY_OTHER_SYSTEM_I_AM_THE_FIRST_ONE));
          } else if (transport.isMcastEnabled()) {
            // perform a multicast ping test
            if (!dm.testMulticast()) {
              logger.warn(LocalizedMessage.create(
                  LocalizedStrings.DistributionManager_RECEIVED_NO_STARTUP_RESPONSES_BUT_OTHER_MEMBERS_EXIST_MULTICAST_IS_NOT_RESPONSIVE));
            }
          }
        }
      } catch (InterruptedException ex) {
        Thread.currentThread().interrupt();
        // This is ALWAYS bad; don't consult a CancelCriterion.
        throw new InternalGemFireException(LocalizedStrings.DistributionManager_INTERRUPTED_WHILE_WAITING_FOR_FIRST_STARTUPRESPONSEMESSAGE.toLocalizedString(), ex);
      } catch (IncompatibleSystemException ex) {
        logger.fatal(ex.getMessage(), ex);
        throw ex;
      } finally {
        dm.readyToSendMsgs();
      }

      if (logger.isInfoEnabled()) {
        long delta = System.currentTimeMillis() - start;
        Object[] logArgs = new Object[] {
            dm.getDistributionManagerId(),
            transport,
            Integer.valueOf(dm.getOtherDistributionManagerIds().size()),
            dm.getOtherDistributionManagerIds(), 
            (logger.isInfoEnabled(LogMarker.DM) ? "" (VERBOSE, took "" + delta + "" ms)"" : """"),
            ((dm.getDMType() == ADMIN_ONLY_DM_TYPE) ? "" (admin only)"" : (dm.getDMType() == LOCATOR_DM_TYPE) ? "" (locator)"" : """")
        };
        logger.info(LogMarker.DM, LocalizedMessage.create(
            LocalizedStrings.DistributionManager_DISTRIBUTIONMANAGER_0_STARTED_ON_1_THERE_WERE_2_OTHER_DMS_3_4_5, logArgs));
        MembershipLogger.logStartup(dm.getDistributionManagerId());
      }
      return dm;
    }
    catch (RuntimeException r) {
      if (dm != null) {
        if (logger.isDebugEnabled()) {
          logger.debug(""cleaning up incompletely started DistributionManager due to exception"", r); 
        }
        dm.uncleanShutdown(true);
      }
      throw r;
    }
  }",False
"  public static int getDistributionManagerType() {
    Integer vmType = (Integer) distributionManagerType.get();
    if (vmType == null) return 0;
    return vmType.intValue();
  }",True
"        vmKind = NORMAL_DM_TYPE;
      }
    
      RemoteTransportConfig transport = new RemoteTransportConfig(system.getConfig(), vmKind);
      transport.setIsReconnectingDS(system.isReconnectingDS());",False
"  protected static void setDistributionManagerType(int vmType) {
    switch (vmType) {
    case NORMAL_DM_TYPE:
    case LONER_DM_TYPE:
    case ADMIN_ONLY_DM_TYPE:
    case LOCATOR_DM_TYPE:
       distributionManagerType.set(Integer.valueOf(vmType));
        break;
    default:
      throw new IllegalArgumentException(LocalizedStrings.DistributionManager_UNKNOWN_DISTRIBUTIONMANAGERTYPE_0.toLocalizedString(Integer.valueOf(vmType)));
    }
  }",True
"  // @todo davidw Modify JGroups so that we do not have to send out a
  // {@link StartupMessage}
  /**
   * Creates a new distribution manager and discovers the other members of the
   * distributed system. Note that it does not check to see whether or not this
   * VM already has a distribution manager.
   * 
   * @param system
   *                The distributed system to which this distribution manager
   *                will send messages.
   */
  public static DistributionManager create(InternalDistributedSystem system)",False
"  public DistributionManager() {
    this.elderLock = null;
    this.membershipListeners = null;
    this.myid = null;
    this.description = null;
    this.dmType = 0;
    throw new IllegalAccessError(""this constructor should never be invoked"");
  }",True
"  private DistributionManager(RemoteTransportConfig transport,
                              InternalDistributedSystem system) {

    this.dmType = transport.getVmKind();
    this.system = system;
    this.elderLock = new StoppableReentrantLock(stopper);
    this.transport = transport;

    this.membershipListeners = new ConcurrentHashMap();
    this.distributedSystemId = system.getConfig().getDistributedSystemId();
    {
      long statId = OSProcess.getId();
      /* deadcoded since we don't know the channel id yet.
        if (statId == 0 || statId == -1) {
        statId = getChannelId();
        }
      */
      this.stats = new DistributionStats(system, statId);
      DistributionStats.enableClockStats = system.getConfig().getEnableTimeStatistics();
    }

    this.exceptionInThreads = false;
    
    // Start the processing threads
    final LoggingThreadGroup group =
      LoggingThreadGroup.createThreadGroup(""DistributionManager Threads"", logger);
    this.threadGroup = group;
    
    boolean finishedConstructor = false;
    try {

    if (MULTI_SERIAL_EXECUTORS) {
      if (logger.isInfoEnabled(LogMarker.DM)) {
        logger.info(LogMarker.DM,
            ""Serial Queue info :"" + 
            "" THROTTLE_PERCENT: "" + THROTTLE_PERCENT +
            "" SERIAL_QUEUE_BYTE_LIMIT :"" + SERIAL_QUEUE_BYTE_LIMIT +   
            "" SERIAL_QUEUE_THROTTLE :"" + SERIAL_QUEUE_THROTTLE + 
            "" TOTAL_SERIAL_QUEUE_BYTE_LIMIT :"" + TOTAL_SERIAL_QUEUE_BYTE_LIMIT +  
            "" TOTAL_SERIAL_QUEUE_THROTTLE :"" + TOTAL_SERIAL_QUEUE_THROTTLE + 
            "" SERIAL_QUEUE_SIZE_LIMIT :"" + SERIAL_QUEUE_SIZE_LIMIT +
            "" SERIAL_QUEUE_SIZE_THROTTLE :"" + SERIAL_QUEUE_SIZE_THROTTLE
        ); 
      }
      this.serialQueuedExecutorPool = new SerialQueuedExecutorPool(this.threadGroup, this.stats);
    }
      
    {
      BlockingQueue poolQueue;
      if (SERIAL_QUEUE_BYTE_LIMIT == 0) {
        poolQueue = new OverflowQueueWithDMStats(this.stats.getSerialQueueHelper());
      } else {
        this.serialQueue = new ThrottlingMemLinkedQueueWithDMStats(TOTAL_SERIAL_QUEUE_BYTE_LIMIT, 
            TOTAL_SERIAL_QUEUE_THROTTLE, SERIAL_QUEUE_SIZE_LIMIT, SERIAL_QUEUE_SIZE_THROTTLE, 
            this.stats.getSerialQueueHelper());
        poolQueue = this.serialQueue;
     } 
      ThreadFactory tf = new ThreadFactory() {
        public Thread newThread(final Runnable command) {
          DistributionManager.this.stats.incSerialThreadStarts();
          final Runnable r = new Runnable() {
            public void run() {
              DistributionManager.this.stats.incNumSerialThreads(1);
              try {
              ConnectionTable.threadWantsSharedResources();
              Connection.makeReaderThread();
              runUntilShutdown(command);
              // command.run();
              } finally {
                ConnectionTable.releaseThreadsSockets();
                DistributionManager.this.stats.incNumSerialThreads(-1);
              }
            }
          };
          Thread thread = new Thread(group, r, LocalizedStrings.DistributionManager_SERIAL_MESSAGE_PROCESSOR.toLocalizedString());
          thread.setDaemon(true);
          return thread;
        }
      };
      SerialQueuedExecutorWithDMStats executor = new SerialQueuedExecutorWithDMStats(poolQueue, 
          this.stats.getSerialProcessorHelper(), tf);
      this.serialThread = executor;
    }
    {
      BlockingQueue q = new LinkedBlockingQueue();
      ThreadFactory tf = new ThreadFactory() {
          public Thread newThread(final Runnable command) {
            DistributionManager.this.stats.incViewThreadStarts();
            final Runnable r = new Runnable() {
                public void run() {
                  DistributionManager.this.stats.incNumViewThreads(1);
                  try {
                    ConnectionTable.threadWantsSharedResources();
                    Connection.makeReaderThread();
                    runUntilShutdown(command);
                  } finally {
                    ConnectionTable.releaseThreadsSockets();
                    DistributionManager.this.stats.incNumViewThreads(-1);
                  }
                }
              };
            Thread thread = new Thread(group, r, LocalizedStrings.DistributionManager_VIEW_MESSAGE_PROCESSOR.toLocalizedString());
            thread.setDaemon(true);
            return thread;
          }
        };
      this.viewThread = new SerialQueuedExecutorWithDMStats(q, 
          this.stats.getViewProcessorHelper(), tf);
    }

    {
      BlockingQueue poolQueue;
      if (INCOMING_QUEUE_LIMIT == 0) {
        poolQueue = new OverflowQueueWithDMStats(this.stats.getOverflowQueueHelper());
      } else {
        poolQueue = new OverflowQueueWithDMStats(INCOMING_QUEUE_LIMIT, this.stats.getOverflowQueueHelper());
      }
      ThreadFactory tf = new ThreadFactory() {
          private int next = 0;

          public Thread newThread(final Runnable command) {
            DistributionManager.this.stats.incProcessingThreadStarts();
            final Runnable r = new Runnable() {
                public void run() {
                  DistributionManager.this.stats.incNumProcessingThreads(1);
                  try {
                  ConnectionTable.threadWantsSharedResources();
                  Connection.makeReaderThread();
                  runUntilShutdown(command);
                  } finally {
                    ConnectionTable.releaseThreadsSockets();
                    DistributionManager.this.stats.incNumProcessingThreads(-1);
                  }
                }
              };
            Thread thread = new Thread(group, r, 
               LocalizedStrings.DistributionManager_POOLED_MESSAGE_PROCESSOR.toLocalizedString() + (next++));
            thread.setDaemon(true);
            return thread;
          }
        };
      ThreadPoolExecutor pool =
        new PooledExecutorWithDMStats(poolQueue, MAX_THREADS, this.stats.getNormalPoolHelper(), tf);
      this.threadPool = pool;
    }


    {
      BlockingQueue poolQueue;
      if (INCOMING_QUEUE_LIMIT == 0) {
        poolQueue = new OverflowQueueWithDMStats(this.stats.getHighPriorityQueueHelper());
      } else {
        poolQueue = new OverflowQueueWithDMStats(INCOMING_QUEUE_LIMIT, this.stats.getHighPriorityQueueHelper());
      }
      ThreadFactory tf = new ThreadFactory() {
          private int next = 0;

          public Thread newThread(final Runnable command) {
            DistributionManager.this.stats.incHighPriorityThreadStarts();
            final Runnable r = new Runnable() {
                public void run() {
                  DistributionManager.this.stats.incHighPriorityThreads(1);
                  try {
                    ConnectionTable.threadWantsSharedResources();
                    Connection.makeReaderThread();
                    runUntilShutdown(command);
                  } finally {
                    ConnectionTable.releaseThreadsSockets();
                    DistributionManager.this.stats.incHighPriorityThreads(-1);
                  }
                }
              };
            Thread thread = new Thread(group, r, 
                LocalizedStrings.DistributionManager_POOLED_HIGH_PRIORITY_MESSAGE_PROCESSOR.toLocalizedString() + (next++));
            thread.setDaemon(true);
            return thread;
          }
        };
      this.highPriorityPool = new PooledExecutorWithDMStats(poolQueue, MAX_THREADS, this.stats.getHighPriorityPoolHelper(), tf);
    }


    {
      ThreadFactory tf = new ThreadFactory() {
          private int next = 0;

          public Thread newThread(final Runnable command) {
            DistributionManager.this.stats.incWaitingThreadStarts();
            final Runnable r = new Runnable() {
                public void run() {
                  DistributionManager.this.stats.incWaitingThreads(1);
                  try {
                  ConnectionTable.threadWantsSharedResources();
                  Connection.makeReaderThread();
                  runUntilShutdown(command);
                  } finally {
                   ConnectionTable.releaseThreadsSockets();
                   DistributionManager.this.stats.incWaitingThreads(-1);
                  }
                }
              };
            Thread thread = new Thread(group, r, 
                                       LocalizedStrings.DistributionManager_POOLED_WAITING_MESSAGE_PROCESSOR.toLocalizedString() + (next++));
            thread.setDaemon(true);
            return thread;
          }
        };
      BlockingQueue poolQueue;
      if (MAX_WAITING_THREADS == Integer.MAX_VALUE) {
        // no need for a queue since we have infinite threads
        poolQueue = new SynchronousQueue();
      } else {
        poolQueue = new OverflowQueueWithDMStats(this.stats.getWaitingQueueHelper());
      }
      this.waitingPool = new PooledExecutorWithDMStats(poolQueue,
                                                       MAX_WAITING_THREADS,
                                                       this.stats.getWaitingPoolHelper(),
                                                       tf);
    }
    
    {
      ThreadFactory tf = new ThreadFactory() {
          private int next = 0;

          public Thread newThread(final Runnable command) {
            DistributionManager.this.stats.incWaitingThreadStarts();//will it be ok?
            final Runnable r = new Runnable() {
                public void run() {
                  DistributionManager.this.stats.incWaitingThreads(1);//will it be ok
                  try {
                  ConnectionTable.threadWantsSharedResources();
                  Connection.makeReaderThread();
                  runUntilShutdown(command);
                  } finally {
                   ConnectionTable.releaseThreadsSockets();
                   DistributionManager.this.stats.incWaitingThreads(-1);
                  }
                }
              };
            Thread thread = new Thread(group, r, 
                                       LocalizedStrings.DistributionManager_PR_META_DATA_CLEANUP_MESSAGE_PROCESSOR.toLocalizedString() + (next++));
            thread.setDaemon(true);
            return thread;
          }
        };
      BlockingQueue poolQueue;
      poolQueue = new OverflowQueueWithDMStats(this.stats.getWaitingQueueHelper());
      this.prMetaDataCleanupThreadPool = new PooledExecutorWithDMStats(poolQueue,
                                                        MAX_PR_META_DATA_CLEANUP_THREADS,
                                                       this.stats.getWaitingPoolHelper(),
                                                       tf);
    }

    {
      BlockingQueue poolQueue;
      if (INCOMING_QUEUE_LIMIT == 0) {
        poolQueue = new OverflowQueueWithDMStats(this.stats.getPartitionedRegionQueueHelper());
      } else {
        poolQueue = new OverflowQueueWithDMStats(INCOMING_QUEUE_LIMIT, this.stats.getPartitionedRegionQueueHelper());
      }
      ThreadFactory tf = new ThreadFactory() {
        private int next = 0;

        public Thread newThread(final Runnable command) {
          DistributionManager.this.stats.incPartitionedRegionThreadStarts();
          final Runnable r = new Runnable() {
              public void run() {
                stats.incPartitionedRegionThreads(1);
                try {
                  ConnectionTable.threadWantsSharedResources();
                  Connection.makeReaderThread();
                  runUntilShutdown(command);
                } finally {
                  ConnectionTable.releaseThreadsSockets();
                  stats.incPartitionedRegionThreads(-1);
                }
              }
            };
          Thread thread = new Thread(group, r, 
                                     ""PartitionedRegion Message Processor"" + (next++));
          thread.setDaemon(true);
          return thread;
        }
      };
      if (MAX_PR_THREADS > 1) {
        this.partitionedRegionPool = new PooledExecutorWithDMStats(poolQueue, 
            MAX_PR_THREADS, this.stats.getPartitionedRegionPoolHelper(), tf);
      } else {
        SerialQueuedExecutorWithDMStats executor = new SerialQueuedExecutorWithDMStats(poolQueue, 
            this.stats.getPartitionedRegionPoolHelper(), tf);
        this.partitionedRegionThread = executor;
      }
      
    }

    {
      BlockingQueue poolQueue;
      if (INCOMING_QUEUE_LIMIT == 0) {
        poolQueue = new OverflowQueueWithDMStats(this.stats.getFunctionExecutionQueueHelper());
      } else {
        poolQueue = new OverflowQueueWithDMStats(INCOMING_QUEUE_LIMIT, this.stats.getFunctionExecutionQueueHelper());
      }
      ThreadFactory tf = new ThreadFactory() {
        private int next = 0;

        public Thread newThread(final Runnable command) {
          DistributionManager.this.stats.incFunctionExecutionThreadStarts();
          final Runnable r = new Runnable() {
              public void run() {
                stats.incFunctionExecutionThreads(1);
                isFunctionExecutionThread.set(Boolean.TRUE);
                try {
                  ConnectionTable.threadWantsSharedResources();
                  Connection.makeReaderThread();
                  runUntilShutdown(command);
                } finally {
                  ConnectionTable.releaseThreadsSockets();
                  stats.incFunctionExecutionThreads(-1);
                }
              }
            };
          Thread thread = new Thread(group, r, 
                                     ""Function Execution Processor"" + (next++));
          thread.setDaemon(true);
          return thread;
        }
      };
      
      if(MAX_FE_THREADS > 1){
        this.functionExecutionPool = new FunctionExecutionPooledExecutor(poolQueue, 
            MAX_FE_THREADS, this.stats.getFunctionExecutionPoolHelper(), tf,true /*for fn exec*/);
      } else {
        SerialQueuedExecutorWithDMStats executor = new SerialQueuedExecutorWithDMStats(poolQueue, 
            this.stats.getFunctionExecutionPoolHelper(), tf);
        this.functionExecutionThread = executor;
      }
    
    }
    
    if (!SYNC_EVENTS) {
      this.memberEventThread = new Thread(group, new MemberEventInvoker(), 
          ""DM-MemberEventInvoker"");
      this.memberEventThread.setDaemon(true);
    }

    StringBuffer sb = new StringBuffer("" (took "");

   long start = System.currentTimeMillis();
    
    // Create direct channel first
//    DirectChannel dc = new DirectChannel(new MyListener(this), system.getConfig(), logger, null);
//    setDirectChannelPort(dc.getPort()); // store in a thread local

    // connect to JGroups
    start = System.currentTimeMillis();
    
    MyListener l = new MyListener(this);
    membershipManager = MemberFactory.newMembershipManager(l, system.getConfig(), transport, stats);

    sb.append(System.currentTimeMillis() - start);
    sb.append(""/"");
    this.myid = membershipManager.getLocalMember();

//    dc.patchUpAddress(this.myid);
//    id.setDirectChannelPort(dc.getPort());

    // create the distribution channel
    this.channel = new DistributionChannel(membershipManager);

    membershipManager.postConnect();
    
    //Assert.assertTrue(this.getChannelMap().size() >= 1);
    //       System.out.println(""Channel Map:"");
    //       for (Iterator iter = this.getChannelMap().entrySet().iterator();
    //            iter.hasNext(); ) {
    //         Map.Entry entry = (Map.Entry) iter.next();
    //         Object key = entry.getKey();
    //         System.out.println(""  "" + key + "" a "" +
    //                            key.getClass().getName() + "" -> "" +
    //                            entry.getValue());
    //       }

    sb.append("" ms)"");

    logger.info(LocalizedMessage.create(LocalizedStrings.DistributionManager_STARTING_DISTRIBUTIONMANAGER_0_1,
        new Object[] { this.myid, (logger.isInfoEnabled(LogMarker.DM) ? sb.toString() : """")}));

    this.description = NAME + "" on "" + this.myid + "" started at ""
      + (new Date(System.currentTimeMillis())).toString();

    finishedConstructor = true;
    } finally {
      if (!finishedConstructor) {
        askThreadsToStop(); // fix for bug 42039
      }
    }
  }",False
"  public void updateLonerPort(int newPort) {
    this.logger.config(LocalizedStrings.LonerDistributionmanager_CHANGING_PORT_FROM_TO,
        new Object[]{this.lonerPort, newPort});
    this.lonerPort = newPort;
    MemberAttributes.setDefaults(lonerPort,
        MemberAttributes.DEFAULT.getVmPid(),
        DistributionManager.LONER_DM_TYPE,
        -1,
        MemberAttributes.DEFAULT.getName(),
        MemberAttributes.DEFAULT.getGroups(), MemberAttributes.DEFAULT.getDurableClientAttributes());
    this.getId().setPort(this.lonerPort);
  }",True
"    this.getId().setPort(this.lonerPort);
  }
  public boolean isCurrentMember(InternalDistributedMember p_id) {
    return getId().equals(p_id);
  }

  public Set putOutgoing(DistributionMessage msg)
  {
    return null;
  }

  public boolean shutdownInProgress() {",False
"  private InternalDistributedMember generateMemberId() {
    InternalDistributedMember result = null;
    String host;
    try {
      // create string of the current millisecond clock time
      StringBuffer sb = new StringBuffer();
      // use low four bytes for backward compatibility
      long time = System.currentTimeMillis() & 0xffffffffL;
      for (int i = 0; i < 4; i++) {
        String hex = Integer.toHexString((int)(time & 0xff));
        if (hex.length() < 2) {
          sb.append('0');
        }
        sb.append(hex);
        time = time / 0x100;
      }
      String uniqueString = sb.toString();

      String name = this.system.getName();

      host = SocketCreator.getLocalHost().getCanonicalHostName();
      DistributionConfig config = system.getConfig();
      DurableClientAttributes dac = null;
      if (config.getDurableClientId() != null) {
        dac = new DurableClientAttributes(config.getDurableClientId(), config
            .getDurableClientTimeout());
      }
      MemberAttributes.setDefaults(lonerPort,
              com.gemstone.gemfire.internal.OSProcess.getId(),
              DistributionManager.LONER_DM_TYPE, -1,
              name,
              MemberAttributes.parseGroups(config.getRoles(), config.getGroups()), dac);
      result = new InternalDistributedMember(host, lonerPort, name, uniqueString);

    } catch (UnknownHostException ex) {
      throw new InternalGemFireError(LocalizedStrings.LonerDistributionManager_CANNOT_RESOLVE_LOCAL_HOST_NAME_TO_AN_IP_ADDRESS.toLocalizedString());
    }
    return result;
  }",True
"  private InternalDistributedMember generateMemberId() {
    InternalDistributedMember result = null;
    String host;
    try {
      // create string of the current millisecond clock time
      StringBuffer sb = new StringBuffer();
      // use low four bytes for backward compatibility
      long time = System.currentTimeMillis() & 0xffffffffL;
      for (int i = 0; i < 4; i++) {
        String hex = Integer.toHexString((int)(time & 0xff));
        if (hex.length() < 2) {
          sb.append('0');
        }
        sb.append(hex);
        time = time / 0x100;
      }
      String uniqueString = sb.toString();

      String name = this.system.getName();

      host = SocketCreator.getLocalHost().getCanonicalHostName();
      DistributionConfig config = system.getConfig();
      DurableClientAttributes dac = null;
      if (config.getDurableClientId() != null) {
        dac = new DurableClientAttributes(config.getDurableClientId(), config
            .getDurableClientTimeout());
      }
      result = new InternalDistributedMember(host, lonerPort, name, uniqueString, DistributionManager.LONER_DM_TYPE,
          MemberAttributes.parseGroups(config.getRoles(), config.getGroups()), dac);

    } catch (UnknownHostException ex) {
      throw new InternalGemFireError(LocalizedStrings.LonerDistributionManager_CANNOT_RESOLVE_LOCAL_HOST_NAME_TO_AN_IP_ADDRESS.toLocalizedString());
    }
    return result;
  }",False
"  public InternalDistributedMember() {
    this.groups = new String[0];
  }",True
"  public InternalDistributedMember(String host, int p, String n, String u,
      int vmKind, String[] groups, DurableClientAttributes attr) throws UnknownHostException {
    MemberAttributes mattr = new MemberAttributes(p,
        com.gemstone.gemfire.internal.OSProcess.getId(),
        vmKind, -1,
        n,
        groups, attr);
    InetAddress addr = SocketCreator.toInetAddress(host);
    netMbr = MemberFactory.newNetMember(addr, p, false, true, Version.CURRENT_ORDINAL, mattr);
    defaultToCurrentHost();
    this.name = n;
    this.uniqueTag = u;
    this.vmKind = vmKind;
    this.dcPort = p;
    this.durableClientAttributes = attr;
    this.hostName = host;
    this.vmPid = OSProcess.getId();
  }",False
"    this.dcPort = p;
    this.durableClientAttributes = attr;
    this.hostName = host;
    this.vmPid = OSProcess.getId();
  }
",False
"  public Set<Role> getRoles() {
    Set<Role> tmpRolesSet = this.rolesSet;
    if (tmpRolesSet != null) {
      return tmpRolesSet;
    }
    assert !this.isPartial;
    synchronized (this.rolesLock) {
      tmpRolesSet = this.rolesSet;
      if (tmpRolesSet == null) {
        final String[] tmpRoles = this.groups;
        // convert array of string role names to array of Roles...
        if (tmpRoles.length == 0) {
          tmpRolesSet = Collections.emptySet();
        }
        else {
          tmpRolesSet = new HashSet<Role>(tmpRoles.length);
          for (int i = 0; i < tmpRoles.length; i++) {
            tmpRolesSet.add(InternalRole.getRole(tmpRoles[i]));
          }
          tmpRolesSet = Collections.unmodifiableSet(tmpRolesSet);
        }
        this.rolesSet = tmpRolesSet;
      }
    }
    Assert.assertTrue(tmpRolesSet != null);
    return tmpRolesSet;
  }",True
"  public Set<Role> getRoles() {
    Set<Role> tmpRolesSet = this.rolesSet;
    if (tmpRolesSet != null) {
      return tmpRolesSet;
    }
    assert !this.isPartial;
    synchronized (this.rolesLock) {
      tmpRolesSet = this.rolesSet;
      if (tmpRolesSet == null) {
        final String[] tmpRoles = this.groups;
        // convert array of string role names to array of Roles...
        if (tmpRoles == null  ||  tmpRoles.length == 0) {
          tmpRolesSet = Collections.emptySet();
        }
        else {
          tmpRolesSet = new HashSet<Role>(tmpRoles.length);
          for (int i = 0; i < tmpRoles.length; i++) {
            tmpRolesSet.add(InternalRole.getRole(tmpRoles[i]));
          }
          tmpRolesSet = Collections.unmodifiableSet(tmpRolesSet);
        }
        this.rolesSet = tmpRolesSet;
      }
    }
    Assert.assertTrue(tmpRolesSet != null);
    return tmpRolesSet;
  }",False
"  private void defaultToCurrentHost() {
    int defaultDcPort = MemberAttributes.DEFAULT.getPort();
    this.dcPort = defaultDcPort;;
    this.vmKind = MemberAttributes.DEFAULT.getVmKind();
    this.vmPid = MemberAttributes.DEFAULT.getVmPid();
    this.name = MemberAttributes.DEFAULT.getName();
    this.groups = MemberAttributes.DEFAULT.getGroups();
    this.vmViewId = MemberAttributes.DEFAULT.getVmViewId();
    this.durableClientAttributes = MemberAttributes.DEFAULT.getDurableClientAttributes();
    try {
      if (SocketCreator.resolve_dns) {
        this.hostName = SocketCreator.getHostName(SocketCreator.getLocalHost());
      }
      else {
        this.hostName = SocketCreator.getLocalHost().getHostAddress();
      }
    }
    catch(UnknownHostException ee){
      throw new InternalGemFireError(ee);
    }
    synchPayload();
  }",True
"  private void defaultToCurrentHost() {
    this.vmPid = OSProcess.getId();
    try {
      if (SocketCreator.resolve_dns) {
        this.hostName = SocketCreator.getHostName(SocketCreator.getLocalHost());
      }
      else {
        this.hostName = SocketCreator.getLocalHost().getHostAddress();
      }
    }
    catch(UnknownHostException ee){
      throw new InternalGemFireError(ee);
    }
    synchPayload();
  }",False
"  public static void setDefaults(int dcPort, int vmPid, int vmKind, int vmViewId, String name, String[] groups, DurableClientAttributes durableClientAttributes) {
    DEFAULT = new MemberAttributes(dcPort, vmPid, vmKind, vmViewId, name, groups, durableClientAttributes);
  }",True
"  private int vmPid;
  private int vmKind;
  private int vmViewId;",False
"  public MemberAttributes(int dcPort, int vmPid, int vmKind, int vmViewId,
      String p_name, String[] p_groups, 
      DurableClientAttributes durableClientAttributes) {
    String[] l_groups = p_groups;
    this.dcPort = dcPort;
    this.vmPid = vmPid;
    this.vmKind = vmKind;
    this.vmViewId = vmViewId;
    if (l_groups == null) {
      l_groups = new String[0];
    }
    if (p_name == null) {
      this.name = """";
    } else {
      this.name = p_name;
    }
    this.groups = l_groups;
    this.durableClientAttributes = durableClientAttributes;
  }",True
"  public MemberAttributes(int dcPort, int vmPid, int vmKind, int vmViewId,
      String p_name, String[] p_groups, 
      DurableClientAttributes durableClientAttributes) {
    String[] l_groups = p_groups;
    this.dcPort = dcPort;
    this.vmPid = vmPid;
    this.vmKind = vmKind;
    this.vmViewId = vmViewId;
    if (l_groups == null) {
      l_groups = new String[0];
    }
    this.groups = l_groups;
    if (p_name == null) {
      this.name = """";
    } else {
      this.name = p_name;
    }
    this.durableClientAttributes = durableClientAttributes;
  }",False
"  public GMSMember() {
  }",True
"   */
  public GMSMember(String i, int p) {
    udpPort=p;
    try {
      inetAddr=InetAddress.getByName(i);
    } catch (UnknownHostException e) {
      // oops
    }
  }",False
"  public GMSMember(MemberAttributes attr, InetAddress i, int p, boolean splitBrainEnabled, boolean preferredForCoordinator,
      short version,
      long msbs, long lsbs) {
    setAttributes(attr);
    this.inetAddr = i;
    this.udpPort=p;
    this.splitBrainEnabled = splitBrainEnabled;
    this.preferredForCoordinator = preferredForCoordinator;
    this.versionOrdinal = version;
    this.uuidMSBs = msbs;
    this.uuidLSBs = lsbs;
  }",False
"  private MemberAttributes getDefaultAttributes() {
    // TODO can we get rid of this??
    if (MemberAttributes.DEFAULT.getVmPid() == -1 ||
        MemberAttributes.DEFAULT.getVmKind() == -1) {
      MemberAttributes.setDefaults(
          -1, 
          OSProcess.getId(), 
          -1,
          DistributionManager.getDistributionManagerType(), 
          null,
          null, null);
    }
    return MemberAttributes.DEFAULT;
  }",True
"   * @param p the membership port being used
   * @return the new NetMember
   */
  public NetMember newNetMember(InetAddress i, int p) {
    return new GMSMember(MemberAttributes.INVALID, i, p, false, true, Version.CURRENT_ORDINAL, 0, 0);
  }

  /**
   * Return a new NetMember representing current host
   * 
   * @param s a String referring to the current host
   * @param p the membership port being used
   * @return the new member
   */",False
"  public NetMember newNetMember(InetAddress i, int p, boolean splitBrainEnabled,
      boolean canBeCoordinator, MemberAttributes attr, short version) {
    GMSMember result = new GMSMember(i, p, splitBrainEnabled, canBeCoordinator, version, 0, 0);
    result.setAttributes(attr);
    return result;
  }",True
"  public NetMember newNetMember(String s, int p) {
    InetAddress inetAddr = null;
    try {
      inetAddr=InetAddress.getByName(s);
    } catch (UnknownHostException e) {
      throw new RuntimeException(""Unable to create an identifier for testing for "" + s, e);
    }
    return newNetMember(inetAddr, p);
  }",False
"  public NetMember newNetMember(InetAddress i, int p, boolean splitBrainEnabled,
      boolean canBeCoordinator, MemberAttributes attr, short version) {
    GMSMember result = new GMSMember(attr, i, p, splitBrainEnabled, canBeCoordinator, version, 0, 0);
    return result;
  }",False
"  public NetMember newNetMember(InetAddress i, int p) {
    return new GMSMember(MemberAttributes.INVALID, i, p, false, true, Version.CURRENT_ORDINAL, 0, 0);
  }",False
"  public static void insertDefaultGemFireAttributes(GMSMember addr) {
    MemberAttributes attr = com.gemstone.gemfire.distributed.internal.membership.MemberAttributes.DEFAULT;
    insertGemFireAttributes(addr, attr);
  }",True
"  public static void insertGemFireAttributes(GMSMember addr, MemberAttributes attr) {
    addr.setProcessId(attr.getVmPid());
    addr.setVmKind(attr.getVmKind());
    addr.setDirectPort(attr.getPort());
    addr.setBirthViewId(attr.getVmViewId());
    addr.setName(attr.getName());
    addr.setGroups(attr.getGroups());
    addr.setDurableClientAttributes(attr.getDurableClientAttributes());
  }",True
"  private void establishLocalAddress() {
    UUID logicalAddress = (UUID)myChannel.getAddress();
    
    IpAddress ipaddr = (IpAddress)myChannel.down(new Event(Event.GET_PHYSICAL_ADDRESS));
    
    if (ipaddr != null) {
      this.jgAddress = new JGAddress(logicalAddress, ipaddr);
    }
    else {
      UDP udp = (UDP)myChannel.getProtocolStack().getTransport();

      try {
        Method getAddress = UDP.class.getDeclaredMethod(""getPhysicalAddress"");
        getAddress.setAccessible(true);
        ipaddr = (IpAddress)getAddress.invoke(udp, new Object[0]);
        this.jgAddress = new JGAddress(logicalAddress, ipaddr);
      } catch (NoSuchMethodException | InvocationTargetException | IllegalAccessException e) {
        logger.info(""Unable to find getPhysicallAddress method in UDP - parsing its address instead"");
      }
      
      if (this.jgAddress == null) {
        String addr = udp.getLocalPhysicalAddress();
        int cidx = addr.lastIndexOf(':');  // IPv6 literals might have colons
        String host = addr.substring(0, cidx);
        int jgport = Integer.parseInt(addr.substring(cidx+1, addr.length()));
        try {
          this.jgAddress = new JGAddress(logicalAddress, new IpAddress(InetAddress.getByName(host), jgport));
        } catch (UnknownHostException e) {
          myChannel.disconnect();
          throw new SystemConnectException(""unable to initialize jgroups address"", e);
        }
      }
    }
  
    // install the address in the JGroups channel protocols
    myChannel.down(new Event(Event.SET_LOCAL_ADDRESS, this.jgAddress));

    DistributionConfig config = services.getConfig().getDistributionConfig();
    boolean isLocator = (MemberAttributes.DEFAULT.getVmKind() == DistributionManager.LOCATOR_DM_TYPE); 
    
    // establish the DistributedSystem's address
    localAddress = new InternalDistributedMember(jgAddress.getInetAddress(),
        jgAddress.getPort(), config.getEnableNetworkPartitionDetection(),
        isLocator, MemberAttributes.DEFAULT);

    // add the JGroups logical address to the GMSMember
    UUID uuid = this.jgAddress;
    ((GMSMember)localAddress.getNetMember()).setUUID(uuid);
  }",True
"  private void establishLocalAddress() {
    UUID logicalAddress = (UUID)myChannel.getAddress();
    
    IpAddress ipaddr = (IpAddress)myChannel.down(new Event(Event.GET_PHYSICAL_ADDRESS));
    
    if (ipaddr != null) {
      this.jgAddress = new JGAddress(logicalAddress, ipaddr);
    }
    else {
      UDP udp = (UDP)myChannel.getProtocolStack().getTransport();

      try {
        Method getAddress = UDP.class.getDeclaredMethod(""getPhysicalAddress"");
        getAddress.setAccessible(true);
        ipaddr = (IpAddress)getAddress.invoke(udp, new Object[0]);
        this.jgAddress = new JGAddress(logicalAddress, ipaddr);
      } catch (NoSuchMethodException | InvocationTargetException | IllegalAccessException e) {
        logger.info(""Unable to find getPhysicallAddress method in UDP - parsing its address instead"");
      }
      
      if (this.jgAddress == null) {
        String addr = udp.getLocalPhysicalAddress();
        int cidx = addr.lastIndexOf(':');  // IPv6 literals might have colons
        String host = addr.substring(0, cidx);
        int jgport = Integer.parseInt(addr.substring(cidx+1, addr.length()));
        try {
          this.jgAddress = new JGAddress(logicalAddress, new IpAddress(InetAddress.getByName(host), jgport));
        } catch (UnknownHostException e) {
          myChannel.disconnect();
          throw new SystemConnectException(""unable to initialize jgroups address"", e);
        }
      }
    }
  
    // install the address in the JGroups channel protocols
    myChannel.down(new Event(Event.SET_LOCAL_ADDRESS, this.jgAddress));

    DistributionConfig config = services.getConfig().getDistributionConfig();
    boolean isLocator = (services.getConfig().getTransport().getVmKind() == DistributionManager.LOCATOR_DM_TYPE); 
    
    // establish the DistributedSystem's address
    DurableClientAttributes dca = null;
    if (config.getDurableClientId() != null) {
      dca = new DurableClientAttributes(config.getDurableClientId(), config
          .getDurableClientTimeout());
    }
    MemberAttributes attr = new MemberAttributes(
        -1/*dcPort - not known at this time*/,
        OSProcess.getId(),
        services.getConfig().getTransport().getVmKind(),
        -1/*view id - not known at this time*/,
        config.getName(),
        MemberAttributes.parseGroups(config.getRoles(), config.getGroups()),
        dca);
    localAddress = new InternalDistributedMember(jgAddress.getInetAddress(),
        jgAddress.getPort(), config.getEnableNetworkPartitionDetection(),
        isLocator, attr);

    // add the JGroups logical address to the GMSMember
    UUID uuid = this.jgAddress;
    ((GMSMember)localAddress.getNetMember()).setUUID(uuid);
  }",False
"  public void start() {
    // create the configuration XML string for JGroups
    String properties = this.jgStackConfig;
    
    logger.debug(""JGroups configuration: {}"", properties);
    
    long start = System.currentTimeMillis();
    
    // start the jgroups channel and establish the membership ID
    try {
      InputStream is = new ByteArrayInputStream(properties.getBytes(""UTF-8""));
      myChannel = new JChannel(is);
      
    } catch (Exception e) {
      throw new GemFireConfigException(""unable to create jgroups channel"", e);
    }

    try {
      
      myChannel.setReceiver(new JGroupsReceiver());
      myChannel.connect(""AG""); // apache g***** (whatever we end up calling it)
      
    } catch (Exception e) {
      throw new SystemConnectException(""unable to create jgroups channel"", e);
    }
    
    establishLocalAddress();
    
    logger.info(""JGroups channel created (took {}ms)"", System.currentTimeMillis()-start);
    
  }",True
"  public void start() {
    // create the configuration XML string for JGroups
    String properties = this.jgStackConfig;
    
    logger.debug(""JGroups configuration: {}"", properties);
    
    long start = System.currentTimeMillis();
    
    // start the jgroups channel and establish the membership ID
    boolean reconnecting = false;
    try {
      Object oldChannel = services.getConfig().getTransport().getOldDSMembershipInfo();
      if (oldChannel != null) {
        myChannel = (JChannel)oldChannel;
        reconnecting = true;
      }
      else {
        InputStream is = new ByteArrayInputStream(properties.getBytes(""UTF-8""));
        myChannel = new JChannel(is);
      }
    } catch (Exception e) {
      throw new GemFireConfigException(""unable to create jgroups channel"", e);
    }

    try {
      
      myChannel.setReceiver(new JGroupsReceiver());
      if (!reconnecting) {
        myChannel.connect(""AG""); // apache g***** (whatever we end up calling it)
      }
    } catch (Exception e) {
      throw new SystemConnectException(""unable to create jgroups channel"", e);
    }
    
    establishLocalAddress();
    
    logger.info(""JGroups channel created (took {}ms)"", System.currentTimeMillis()-start);
    
  }",False
"    public void receive(Message jgmsg) {
      if (services.getManager().shutdownInProgress())
        return;

      if (logger.isDebugEnabled()) {
        logger.debug(""JGroupsMessenger received {} headers: {}"", jgmsg, jgmsg.getHeaders());
      }
      
      Object o = readJGMessage(jgmsg);
      if (o == null) {
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_GEMFIRE_RECEIVED_NULL_MESSAGE_FROM__0, String.valueOf(jgmsg)));
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_MESSAGE_HEADERS__0, jgmsg.printObjectHeaders()));
        return;
      } else if ( !(o instanceof DistributionMessage) ) {
        logger.warn(""Received something other than a message from "" + jgmsg.getSrc() + "": "" + o);
        return;
      }

      DistributionMessage msg = (DistributionMessage)o;
      
      // admin-only VMs don't have caches, so we ignore cache operations
      // multicast to them, avoiding deserialization cost and classpath
      // problems
      if ( (MemberAttributes.DEFAULT.getVmKind() == DistributionManager.ADMIN_ONLY_DM_TYPE)
           && (msg instanceof DistributedCacheOperation.CacheOperationMessage)) {
        if (logger.isTraceEnabled())
          logger.trace(""Membership: admin VM discarding cache operation message {}"", jgmsg.getObject());
        return;
      }

      msg.resetTimestamp();
      msg.setBytesRead(jgmsg.getLength());
            
      if (msg.getSender() == null) {
        Exception e = new Exception(LocalizedStrings.GroupMembershipService_NULL_SENDER.toLocalizedString());
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_GEMFIRE_RECEIVED_A_MESSAGE_WITH_NO_SENDER_ADDRESS), e);
      }
      
      try {
        filterIncomingMessage(msg);
        MessageHandler h = getMessageHandler(msg);
        logger.trace(""Handler for this message is {}"", h);
        h.processMessage(msg);
      }
      catch (MemberShunnedException e) {
        // message from non-member - ignore
      }
    }",True
"    public void receive(Message jgmsg) {
      if (services.getManager().shutdownInProgress())
        return;

      if (logger.isDebugEnabled()) {
        logger.debug(""JGroupsMessenger received {} headers: {}"", jgmsg, jgmsg.getHeaders());
      }
      
      Object o = readJGMessage(jgmsg);
      if (o == null) {
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_GEMFIRE_RECEIVED_NULL_MESSAGE_FROM__0, String.valueOf(jgmsg)));
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_MESSAGE_HEADERS__0, jgmsg.printObjectHeaders()));
        return;
      } else if ( !(o instanceof DistributionMessage) ) {
        logger.warn(""Received something other than a message from "" + jgmsg.getSrc() + "": "" + o);
        return;
      }

      DistributionMessage msg = (DistributionMessage)o;
      
      // admin-only VMs don't have caches, so we ignore cache operations
      // multicast to them, avoiding deserialization cost and classpath
      // problems
      if ( (services.getConfig().getTransport().getVmKind() == DistributionManager.ADMIN_ONLY_DM_TYPE)
           && (msg instanceof DistributedCacheOperation.CacheOperationMessage)) {
        if (logger.isTraceEnabled())
          logger.trace(""Membership: admin VM discarding cache operation message {}"", jgmsg.getObject());
        return;
      }

      msg.resetTimestamp();
      msg.setBytesRead(jgmsg.getLength());
            
      if (msg.getSender() == null) {
        Exception e = new Exception(LocalizedStrings.GroupMembershipService_NULL_SENDER.toLocalizedString());
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_GEMFIRE_RECEIVED_A_MESSAGE_WITH_NO_SENDER_ADDRESS), e);
      }
      
      try {
        filterIncomingMessage(msg);
        MessageHandler h = getMessageHandler(msg);
        logger.trace(""Handler for this message is {}"", h);
        h.processMessage(msg);
      }
      catch (MemberShunnedException e) {
        // message from non-member - ignore
      }
    }",False
"  public String getJGroupsStackConfig() {
    return this.jgStackConfig;
  }",False
"  public synchronized boolean checkForQuorum(long timeout)
    throws InterruptedException {
    
    if (this.quorumAchieved) {
      return true;
    }
    
    final boolean isDebugEnabled = logger.isDebugEnabled();
    if (this.sock == null || this.sock.isClosed()) {
      if (isDebugEnabled) {
        logger.debug(""quorum check: UDP socket is closed.  Unable to perform a quorum check"");
      }
      return false;
    }
    
    boolean wasSuspended = this.suspended;
    if (this.suspended) {
      this.suspended = false;
    }
    
    
    byte[] buffer = new byte[] { 'p', 'i', 'n', 'g' };
    
    
    if (isDebugEnabled) {
      logger.debug(""beginning quorum check with {}"", this);
    }
    try {
      // send a ping message to each member and read pong responses
      List<InternalDistributedMember> members = this.lastView.getMembers();
      for (InternalDistributedMember addr: members) {
        if (!receivedAcks.contains(addr)) {
          SocketAddress sockaddr = new InetSocketAddress(addr.getNetMember().getInetAddress(), addr.getPort());
          if (isDebugEnabled) {
            logger.debug(""quorum check: sending request to {}"", addr);
          }
          try {
            DatagramPacket packet = new DatagramPacket(buffer, 0, buffer.length, sockaddr);
            this.sock.send(packet);
          } catch (IOException io) {
            // continue to the next member
          }
        }
      }
      
      
      long endTime = System.currentTimeMillis() + timeout;
      for ( ;; ) {
        long time = System.currentTimeMillis();
        long remaining = (endTime - time);
        if (remaining <= 0) {
          if (isDebugEnabled) {
            logger.debug(""quorum check: timeout waiting for responses.  {} responses received"", receivedAcks.size());
          }
          break;
        }
        if (isDebugEnabled) {
          logger.debug(""quorum check: waiting up to {}ms to receive a quorum of responses"", remaining);
        }
        Thread.sleep(500);
        if (receivedAcks.size() == members.size()) {
          // we've heard from everyone now so we've got a quorum
          if (isDebugEnabled) {
            logger.debug(""quorum check: received responses from all members that were in the old distributed system"");
          }
          this.quorumAchieved = true;
          return true;
        }
      }
      
      // quorum check
      int weight = getWeight(this.lastView.getMembers(), this.lastView.getLeadMember());
      int ackedWeight = getWeight(receivedAcks, this.lastView.getLeadMember());
      int lossThreshold = (int)Math.round((weight * this.partitionThreshold) / 100.0); 
      if (isDebugEnabled) {
        logger.debug(""quorum check: contacted {} processes with {} member weight units.  Threshold for a quorum is {}"", receivedAcks.size(), ackedWeight, lossThreshold);
      }
      this.quorumAchieved = (ackedWeight >= lossThreshold);
      return this.quorumAchieved;

    } finally {
      if (wasSuspended) {
        this.suspended = true;
      }
    }
  }",True
"  public synchronized boolean checkForQuorum(long timeout)
    throws InterruptedException {
    
    if (this.quorumAchieved) {
      return true;
    }
    
    final boolean isDebugEnabled = logger.isDebugEnabled();
    if (this.sock == null || this.sock.isClosed()) {
      if (isDebugEnabled) {
        logger.debug(""quorum check: UDP socket is closed.  Unable to perform a quorum check"");
      }
      return false;
    }
    
    boolean wasSuspended = this.suspended;
    if (this.suspended) {
      this.suspended = false;
    }
    
    
    byte[] buffer = new byte[] { 'p', 'i', 'n', 'g' };
    
    
    if (isDebugEnabled) {
      logger.debug(""beginning quorum check with {}"", this);
    }
    try {
      // send a ping message to each member and read pong responses
      List<InternalDistributedMember> members = this.lastView.getMembers();
      for (InternalDistributedMember addr: members) {
        if (!receivedAcks.contains(addr)) {
          SocketAddress sockaddr = new InetSocketAddress(addr.getNetMember().getInetAddress(), addr.getPort());
          if (isDebugEnabled) {
            logger.debug(""quorum check: sending request to {}"", addr);
          }
          try {
            Message msg = new Message();
//            msg.setDest(new JGAddress((GMSMember)addr.getNetMember()));
//            msg.setObject(obj)
            DatagramPacket packet = new DatagramPacket(buffer, 0, buffer.length, sockaddr);
            this.sock.send(packet);
          } catch (IOException io) {
            // continue to the next member
          }
        }
      }
      
      
      long endTime = System.currentTimeMillis() + timeout;
      for ( ;; ) {
        long time = System.currentTimeMillis();
        long remaining = (endTime - time);
        if (remaining <= 0) {
          if (isDebugEnabled) {
            logger.debug(""quorum check: timeout waiting for responses.  {} responses received"", receivedAcks.size());
          }
          break;
        }
        if (isDebugEnabled) {
          logger.debug(""quorum check: waiting up to {}ms to receive a quorum of responses"", remaining);
        }
        Thread.sleep(500);
        if (receivedAcks.size() == members.size()) {
          // we've heard from everyone now so we've got a quorum
          if (isDebugEnabled) {
            logger.debug(""quorum check: received responses from all members that were in the old distributed system"");
          }
          this.quorumAchieved = true;
          return true;
        }
      }
      
      // quorum check
      int weight = getWeight(this.lastView.getMembers(), this.lastView.getLeadMember());
      int ackedWeight = getWeight(receivedAcks, this.lastView.getLeadMember());
      int lossThreshold = (int)Math.round((weight * this.partitionThreshold) / 100.0); 
      if (isDebugEnabled) {
        logger.debug(""quorum check: contacted {} processes with {} member weight units.  Threshold for a quorum is {}"", receivedAcks.size(), ackedWeight, lossThreshold);
      }
      this.quorumAchieved = (ackedWeight >= lossThreshold);
      return this.quorumAchieved;

    } finally {
      if (wasSuspended) {
        this.suspended = true;
      }
    }
  }",False
"  public QuorumChecker getQuorumCheckerImpl() {
    return this.quorumChecker;
  }",True
"      DatagramSocket sock = new DatagramSocket(this.address.getPort(),
                               this.address.getNetMember().getInetAddress());
      JGroupsQuorumChecker impl = new JGroupsQuorumChecker(",False
"  public void uncleanShutdown(String reason, final Exception e) {
    inhibitForcedDisconnectLogging(false);
    
    if (this.directChannel != null) {
      this.directChannel.disconnect(e);
    }
    
    // first shut down communication so we don't do any more harm to other
    // members
    services.emergencyClose();
    
    // we have to clear the view before notifying the membership listener,
    // so that it won't try sending disconnect messages to members that
    // aren't there.  Otherwise, it sends the disconnect messages to other
    // members, they ignore the ""surprise"" connections, and we hang.
    //GroupMembershipService.this.clearView();
    if (e != null) {
      try {
        if (membershipTestHooks != null) {
          List l = membershipTestHooks;
          for (Iterator it=l.iterator(); it.hasNext(); ) {
            MembershipTestHook dml = (MembershipTestHook)it.next();
            dml.beforeMembershipFailure(reason, e);
          }
        }
        listener.membershipFailure(reason, e);
        if (membershipTestHooks != null) {
          List l = membershipTestHooks;
          for (Iterator it=l.iterator(); it.hasNext(); ) {
            MembershipTestHook dml = (MembershipTestHook)it.next();
            dml.afterMembershipFailure(reason, e);
          }
        }
      }
      catch (RuntimeException re) {
        logger.warn(LocalizedMessage.create(LocalizedStrings.GroupMembershipService_EXCEPTION_CAUGHT_WHILE_SHUTTING_DOWN), re);
      }
    }
  }",True
"      try {
        if (membershipTestHooks != null) {
          List l = membershipTestHooks;
          for (Iterator it=l.iterator(); it.hasNext(); ) {
            MembershipTestHook dml = (MembershipTestHook)it.next();
            dml.beforeMembershipFailure(reason, e);
          }
        }
        listener.membershipFailure(reason, e);
        if (membershipTestHooks != null) {
          List l = membershipTestHooks;
          for (Iterator it=l.iterator(); it.hasNext(); ) {
            MembershipTestHook dml = (MembershipTestHook)it.next();
            dml.afterMembershipFailure(reason, e);
          }
        }
      }
      catch (RuntimeException re) {
        logger.warn(LocalizedMessage.create(LocalizedStrings.GroupMembershipService_EXCEPTION_CAUGHT_WHILE_SHUTTING_DOWN), re);
      }
    }
  }
  
  /** generate XML for the cache before shutting down due to forced disconnect */
  public void saveCacheXmlForReconnect() {
    // there are two versions of this method so it can be unit-tested
    boolean sharedConfigEnabled = services.getConfig().getDistributionConfig().getUseSharedConfiguration();
    saveCacheXmlForReconnect(sharedConfigEnabled);
  }
  
  /** generate XML from the cache before shutting down due to forced disconnect */
  public void saveCacheXmlForReconnect(boolean sharedConfigEnabled) {
    // first save the current cache description so reconnect can rebuild the cache
    GemFireCacheImpl cache = GemFireCacheImpl.getInstance();
    if (cache != null && (cache instanceof Cache)) {
      if (!Boolean.getBoolean(""gemfire.autoReconnect-useCacheXMLFile"")
          && !cache.isSqlfSystem() && !sharedConfigEnabled) {
        try {
          logger.info(""generating XML to rebuild the cache after reconnect completes"");",False
"  public boolean shutdownInProgress() {
    // Impossible condition (bug36329): make sure that we check DM's
    // view of shutdown here
    return shutdownInProgress || listener.getDM().shutdownInProgress();
  }",True
"  public boolean shutdownInProgress() {
    // Impossible condition (bug36329): make sure that we check DM's
    // view of shutdown here
    DistributionManager dm = listener.getDM();
    return shutdownInProgress || (dm != null && dm.shutdownInProgress());
  }",False
"  public void shutdown()
  {
    setShutdown(); // for safety
    services.stop();
  }",True
"  public void shutdown() {
    if (!shutdownInProgress) {
      setShutdown();
      services.stop();
    }
  }",False
"  public void start() {
    DistributionConfig config = services.getConfig().getDistributionConfig();
    RemoteTransportConfig transport = services.getConfig().getTransport();

    int dcPort = 0;
    if (!tcpDisabled) {
      directChannel = new DirectChannel(this, dcReceiver, config, null);
      dcPort = directChannel.getPort();
    }

    
    services.getMessenger().getMemberID().setDirectChannelPort(dcPort);

    MemberAttributes.setDefaults(dcPort,
        MemberAttributes.DEFAULT.getVmPid(),
        MemberAttributes.DEFAULT.getVmKind(),
        MemberAttributes.DEFAULT.getVmViewId(),
        MemberAttributes.DEFAULT.getName(),
        MemberAttributes.DEFAULT.getGroups(), MemberAttributes.DEFAULT.getDurableClientAttributes());
  }",True
"  public void start() {
    DistributionConfig config = services.getConfig().getDistributionConfig();
    RemoteTransportConfig transport = services.getConfig().getTransport();

    int dcPort = 0;
    if (!tcpDisabled) {
      directChannel = new DirectChannel(this, dcReceiver, config, null);
      dcPort = directChannel.getPort();
    }

    
    services.getMessenger().getMemberID().setDirectChannelPort(dcPort);

  }
  
  
  @Override
  public void joinDistributedSystem() {
    long startTime = System.currentTimeMillis();
    ",False
"  public void joinDistributedSystem() {
    long startTime = System.currentTimeMillis();
    
    try {
      join();
    }
    catch (RuntimeException e) {
      if (directChannel != null) {
        directChannel.disconnect(e);
      }
      throw e;
    }
    
    this.address = services.getMessenger().getMemberID();

    int dcPort = 0;
    if (directChannel != null) {
      dcPort = directChannel.getPort();
    }
    
    MemberAttributes.setDefaults(dcPort,
        MemberAttributes.DEFAULT.getVmPid(),
        MemberAttributes.DEFAULT.getVmKind(),
        address.getVmViewId(),
        MemberAttributes.DEFAULT.getName(),
        MemberAttributes.DEFAULT.getGroups(), MemberAttributes.DEFAULT.getDurableClientAttributes());
    
    if (directChannel != null) {
      directChannel.setLocalAddr(address);
      Stub stub = directChannel.getLocalStub();
      memberToStubMap.put(address, stub);
      stubToMemberMap.put(stub, address);
    }

    this.hasConnected = true;

    // in order to debug startup issues we need to announce the membership
    // ID as soon as we know it
    logger.info(LocalizedMessage.create(LocalizedStrings.GroupMembershipService_entered_into_membership_in_group_0_with_id_1,
        new Object[]{""""+(System.currentTimeMillis()-startTime)}));

  }",True
"    catch (RuntimeException e) {
      if (directChannel != null) {
        directChannel.disconnect(e);
      }
      throw e;
    }
    
    this.address = services.getMessenger().getMemberID();

    int dcPort = 0;
    if (directChannel != null) {
      dcPort = directChannel.getPort();
    }
    
    if (directChannel != null) {
      directChannel.setLocalAddr(address);
      Stub stub = directChannel.getLocalStub();
      memberToStubMap.put(address, stub);
      stubToMemberMap.put(stub, address);
    }

    this.hasConnected = true;

    // in order to debug startup issues we need to announce the membership
    // ID as soon as we know it
    logger.info(LocalizedMessage.create(LocalizedStrings.GroupMembershipService_entered_into_membership_in_group_0_with_id_1,
        new Object[]{""""+(System.currentTimeMillis()-startTime)}));

  }
  
  @Override
  public void started() {
  }
  

  /** this is invoked by JoinLeave when there is a loss of quorum in the membership system */
  public void quorumLost(Collection<InternalDistributedMember> failures, NetView view) {
    // notify of quorum loss if split-brain detection is enabled (meaning we'll shut down) or
    // if the loss is more than one member
    
    boolean notify = failures.size() > 1;
    if (!notify) {",False
"  public RemoteTransportConfig(DistributionConfig config) {
    if (config.getBindAddress() == null) {
      this.bindAddress = DistributionConfig.DEFAULT_BIND_ADDRESS;
    } else {
      this.bindAddress = config.getBindAddress();
    }
    this.tcpPort = config.getTcpPort();
    this.membershipPortRange = 
            getMembershipPortRangeString(config.getMembershipPortRange());
    this.sslConfig = new SSLConfig();
    
    String initialHosts = config.getLocators();
    if (initialHosts == null)
      initialHosts = """";
    initialHosts = initialHosts.trim();
    
    if (config.getMcastPort() > 0) {
      this.mcastId = new DistributionLocatorId(config.getMcastAddress(), 
                                               config.getMcastPort(), 
                                               config.getBindAddress(),
                                               this.sslConfig);
      this.mcastEnabled = true;
    }
    else {
      this.mcastEnabled = false;
      this.mcastId = null;
    }
    
    this.tcpDisabled = config.getDisableTcp();
    this.disableAutoReconnect = config.getDisableAutoReconnect();

    // See what type of discovery is being used
    if (initialHosts.length() == 0) {
      // loner system
      this.ids = Collections.EMPTY_SET;
      return;
    }
    else {
      HashSet locators = new HashSet();
      int startIdx = 0;
      int endIdx = -1;
      do {
        String locator;
        endIdx = initialHosts.indexOf(',', startIdx);
        if (endIdx == -1) {
          locator = initialHosts.substring(startIdx);
        } else {
          locator = initialHosts.substring(startIdx, endIdx);
          startIdx = endIdx+1;
        }
        locators.add(new DistributionLocatorId(locator));

      } while (endIdx != -1);
    
      if (this.mcastEnabled) {
        locators.add(this.mcastId);
      }
      this.ids = Collections.unmodifiableSet(locators);
      if (this.mcastEnabled) {
        Assert.assertTrue(this.mcastId != null);
      }
    }
  }",True
"   * configuration information in a <code>DistributionConfig</code>.
   * We assume that <code>config</code> already been checked for
   * errors.
   *
   * @since 3.0
   */
  public RemoteTransportConfig(DistributionConfig config, int vmKind) {
    if (config.getBindAddress() == null) {
      this.bindAddress = DistributionConfig.DEFAULT_BIND_ADDRESS;
    } else {
      this.bindAddress = config.getBindAddress();
    }
    this.vmKind = vmKind;
    this.tcpPort = config.getTcpPort();
    this.membershipPortRange = 
            getMembershipPortRangeString(config.getMembershipPortRange());
    this.sslConfig = new SSLConfig();
    
    String initialHosts = config.getLocators();
    if (initialHosts == null)
      initialHosts = """";
    initialHosts = initialHosts.trim();
    
    if (config.getMcastPort() > 0) {
      this.mcastId = new DistributionLocatorId(config.getMcastAddress(), 
                                               config.getMcastPort(), 
                                               config.getBindAddress(),
                                               this.sslConfig);
      this.mcastEnabled = true;
    }
    else {
      this.mcastEnabled = false;
      this.mcastId = null;
    }
    
    this.tcpDisabled = config.getDisableTcp();
    this.disableAutoReconnect = config.getDisableAutoReconnect();

    // See what type of discovery is being used
    if (initialHosts.length() == 0) {
      // loner system
      this.ids = Collections.EMPTY_SET;
      return;
    }
    else {
      HashSet locators = new HashSet();
      int startIdx = 0;
      int endIdx = -1;
      do {
        String locator;
        endIdx = initialHosts.indexOf(',', startIdx);
        if (endIdx == -1) {
          locator = initialHosts.substring(startIdx);
        } else {
          locator = initialHosts.substring(startIdx, endIdx);
          startIdx = endIdx+1;
        }
        locators.add(new DistributionLocatorId(locator));

      } while (endIdx != -1);
    
      if (this.mcastEnabled) {
        locators.add(this.mcastId);",False
"  public int getVmKind() {
    return this.vmKind;
  }",False
"  public RemoteTransportConfig(DistributionConfig config, int vmKind) {
    if (config.getBindAddress() == null) {
      this.bindAddress = DistributionConfig.DEFAULT_BIND_ADDRESS;
    } else {
      this.bindAddress = config.getBindAddress();
    }
    this.vmKind = vmKind;
    this.tcpPort = config.getTcpPort();
    this.membershipPortRange = 
            getMembershipPortRangeString(config.getMembershipPortRange());
    this.sslConfig = new SSLConfig();
    
    String initialHosts = config.getLocators();
    if (initialHosts == null)
      initialHosts = """";
    initialHosts = initialHosts.trim();
    
    if (config.getMcastPort() > 0) {
      this.mcastId = new DistributionLocatorId(config.getMcastAddress(), 
                                               config.getMcastPort(), 
                                               config.getBindAddress(),
                                               this.sslConfig);
      this.mcastEnabled = true;
    }
    else {
      this.mcastEnabled = false;
      this.mcastId = null;
    }
    
    this.tcpDisabled = config.getDisableTcp();
    this.disableAutoReconnect = config.getDisableAutoReconnect();

    // See what type of discovery is being used
    if (initialHosts.length() == 0) {
      // loner system
      this.ids = Collections.EMPTY_SET;
      return;
    }
    else {
      HashSet locators = new HashSet();
      int startIdx = 0;
      int endIdx = -1;
      do {
        String locator;
        endIdx = initialHosts.indexOf(',', startIdx);
        if (endIdx == -1) {
          locator = initialHosts.substring(startIdx);
        } else {
          locator = initialHosts.substring(startIdx, endIdx);
          startIdx = endIdx+1;
        }
        locators.add(new DistributionLocatorId(locator));

      } while (endIdx != -1);
    
      if (this.mcastEnabled) {
        locators.add(this.mcastId);
      }
      this.ids = Collections.unmodifiableSet(locators);
      if (this.mcastEnabled) {
        Assert.assertTrue(this.mcastId != null);
      }
    }
  }",False
"  public RemoteTransportConfig(
    boolean isMcastEnabled,
    boolean isTcpDisabled,
    boolean isAutoReconnectDisabled,
    String bindAddress, 
    SSLConfig sslConfig,
    Collection ids, String membershipPortRange,
    int tcpPort, int vmKind)
  {
    DistributionLocatorId mid = null;
    
    if (bindAddress == null) {
      this.bindAddress = DistributionConfig.DEFAULT_BIND_ADDRESS;
    } else {
      this.bindAddress = bindAddress;
    }
    
    this.sslConfig = sslConfig;
    
    this.mcastEnabled = isMcastEnabled;
    this.tcpDisabled = isTcpDisabled;
    this.disableAutoReconnect = isAutoReconnectDisabled;
    if (isMcastEnabled) {
      if (ids.size() < 1) {
        throw new IllegalArgumentException(LocalizedStrings.RemoteTransportConfig_EXPECTED_AT_LEAST_ONE_HOSTPORT_ID.toLocalizedString());
      }
      Iterator it = ids.iterator();
      while (it.hasNext() && mid == null) {
        DistributionLocatorId id = (DistributionLocatorId)it.next();
        if (id.isMcastId()) {
          mid = id;
          //System.out.println(""mcast id: "" + id);
        }
        else {
          //System.out.println(""non-mcast id: "" + id);
        }
      }
    }
    this.ids = Collections.unmodifiableSet(new HashSet(ids));
    this.mcastId = mid;
    if (this.mcastEnabled) {
      Assert.assertTrue(this.mcastId != null);
    }
    this.membershipPortRange = membershipPortRange;
    this.tcpPort = tcpPort;
    this.vmKind = vmKind;
 }",False
"    }
  }

  /**
   * Constructs a transport config given a collection of {@link
   * DistributionLocatorId} instances.
   */
  public RemoteTransportConfig(
    boolean isMcastEnabled,
    boolean isTcpDisabled,
    boolean isAutoReconnectDisabled,
    String bindAddress, 
    SSLConfig sslConfig,
    Collection ids, String membershipPortRange,
    int tcpPort, int vmKind)
  {
    DistributionLocatorId mid = null;
    
    if (bindAddress == null) {
      this.bindAddress = DistributionConfig.DEFAULT_BIND_ADDRESS;
    } else {
      this.bindAddress = bindAddress;
    }
    
    this.sslConfig = sslConfig;
    
    this.mcastEnabled = isMcastEnabled;
    this.tcpDisabled = isTcpDisabled;
    this.disableAutoReconnect = isAutoReconnectDisabled;
    if (isMcastEnabled) {
      if (ids.size() < 1) {
        throw new IllegalArgumentException(LocalizedStrings.RemoteTransportConfig_EXPECTED_AT_LEAST_ONE_HOSTPORT_ID.toLocalizedString());
      }
      Iterator it = ids.iterator();
      while (it.hasNext() && mid == null) {
        DistributionLocatorId id = (DistributionLocatorId)it.next();
        if (id.isMcastId()) {
          mid = id;
          //System.out.println(""mcast id: "" + id);
        }
        else {
          //System.out.println(""non-mcast id: "" + id);
        }
      }
    }
    this.ids = Collections.unmodifiableSet(new HashSet(ids));",False
"  public void testConcurrentOpWithGII() {
    if (this.getClass() != DistributedAckRegionCCEDUnitTest.class) {
      return; // not really a scope-related thing
    }
    final String name = this.getUniqueName() + ""-CC"";
    final String key = ""mykey"";
    VM vm1 = Host.getHost(0).getVM(1);
    VM vm2 = Host.getHost(0).getVM(2);
    
    // create some destroyed entries so the GC service is populated
    SerializableCallable create = new SerializableCallable(""create region"") {
      public Object call() {
        RegionFactory f = getCache().createRegionFactory(getRegionAttributes());
        CCRegion = (LocalRegion)f.create(name);
        return CCRegion.getDistributionManager().getDistributionManagerId();
      }
    };
    // do conflicting update() and destroy() on the region.  We want the update() to
    // be sent with a message and the destroy() to be transferred in the initial image
    // and be the value that we want to keep
    InternalDistributedMember vm1ID = (InternalDistributedMember)vm1.invoke(create);
    
    AsyncInvocation partialCreate = vm2.invokeAsync(new SerializableCallable(""create region with stall"") {
      public Object call() throws Exception {
        final GemFireCacheImpl cache = (GemFireCacheImpl)getCache();
        RegionFactory f = cache.createRegionFactory(getRegionAttributes());
        InitialImageOperation.VMOTION_DURING_GII = true;
        // this will stall region creation at the point of asking for an initial image
        VMotionObserverHolder.setInstance(new VMotionObserver() {
          @Override
          public void vMotionBeforeCQRegistration() {
          }
          @Override
          public void vMotionBeforeRegisterInterest() {
          }
          @Override
          public void vMotionDuringGII(Set recipientSet, LocalRegion region) {
            InitialImageOperation.VMOTION_DURING_GII = false;
            int oldLevel = LocalRegion.setThreadInitLevelRequirement(
                LocalRegion.BEFORE_INITIAL_IMAGE);
            LocalRegion ccregion = cache.getRegionByPath(""/""+name);
            try {
              // wait for the update op (sent below from vm1) to arrive, then allow the GII to happen
              while (!ccregion.isDestroyed() && ccregion.getRegionEntry(key) == null) {
                try {
                  Thread.sleep(1000);
                } catch (InterruptedException e) {
                  return;
                }
              }
            } finally {
              LocalRegion.setThreadInitLevelRequirement(oldLevel);
            }
          }
        });
        try {
          CCRegion = (LocalRegion)f.create(name);
          // at this point we should have received the update op and then the GII, which should overwrite
          // the conflicting update op
          assertFalse(""expected initial image transfer to destroy entry"", CCRegion.containsKey(key));
        } finally {
          InitialImageOperation.VMOTION_DURING_GII = false;
        }
        return null;
      }
    });
    vm1.invoke(new SerializableRunnable(""create conflicting events"") {
      public void run() {
        // wait for the other to come on line
        long waitEnd = System.currentTimeMillis() + 45000;
        DistributionAdvisor adv = ((DistributedRegion)CCRegion).getCacheDistributionAdvisor();
        while (System.currentTimeMillis() < waitEnd && adv.adviseGeneric().isEmpty()) {
          try {Thread.sleep(1000);} catch (InterruptedException e) { return; }
        }
        if (adv.adviseGeneric().isEmpty()) {
          fail(""other member never came on line"");
        }
        DistributedCacheOperation.LOSS_SIMULATION_RATIO = 200.0; // inhibit all messaging
        try {
          CCRegion.put(""mykey"", ""initialValue"");
          CCRegion.destroy(""mykey"");
        } finally {
          DistributedCacheOperation.LOSS_SIMULATION_RATIO = 0.0;
        }
        
        // generate a fake version tag for the message
        VersionTag tag = CCRegion.getRegionEntry(key).getVersionStamp().asVersionTag();
        // create a fake member ID that will be < mine and lose a concurrency check
        NetMember nm = CCRegion.getDistributionManager().getDistributionManagerId().getNetMember();
        InternalDistributedMember mbr = null;
        try {
          mbr = new InternalDistributedMember(nm.getInetAddress().getCanonicalHostName(), nm.getPort()-1, ""fake_id"", ""fake_id_ustring"");
          tag.setMemberID(mbr);
        } catch (UnknownHostException e) {
          fail(""could not create member id"", e);
        }
        
        // generate an event to distribute that contains the fake version tag
        EntryEventImpl event = EntryEventImpl.create(CCRegion, Operation.UPDATE, key, false, mbr, true, false);
        event.setNewValue(""newValue"");
        event.setVersionTag(tag);

        // this should update the controller's cache with the updated value but leave this cache alone
        DistributedCacheOperation op = new UpdateOperation(event, tag.getVersionTimeStamp());
        op.distribute();
        event.release();
      }
    });
    try {
      partialCreate.getResult();
    } catch (Throwable e) {
      fail(""async invocation in vm2 failed"", e);
    }
  }  ",True
"  public void testConcurrentOpWithGII() {
    if (this.getClass() != DistributedAckRegionCCEDUnitTest.class) {
      return; // not really a scope-related thing
    }
    final String name = this.getUniqueName() + ""-CC"";
    final String key = ""mykey"";
    VM vm1 = Host.getHost(0).getVM(1);
    VM vm2 = Host.getHost(0).getVM(2);
    
    // create some destroyed entries so the GC service is populated
    SerializableCallable create = new SerializableCallable(""create region"") {
      public Object call() {
        RegionFactory f = getCache().createRegionFactory(getRegionAttributes());
        CCRegion = (LocalRegion)f.create(name);
        return CCRegion.getDistributionManager().getDistributionManagerId();
      }
    };
    // do conflicting update() and destroy() on the region.  We want the update() to
    // be sent with a message and the destroy() to be transferred in the initial image
    // and be the value that we want to keep
    InternalDistributedMember vm1ID = (InternalDistributedMember)vm1.invoke(create);
    
    AsyncInvocation partialCreate = vm2.invokeAsync(new SerializableCallable(""create region with stall"") {
      public Object call() throws Exception {
        final GemFireCacheImpl cache = (GemFireCacheImpl)getCache();
        RegionFactory f = cache.createRegionFactory(getRegionAttributes());
        InitialImageOperation.VMOTION_DURING_GII = true;
        // this will stall region creation at the point of asking for an initial image
        VMotionObserverHolder.setInstance(new VMotionObserver() {
          @Override
          public void vMotionBeforeCQRegistration() {
          }
          @Override
          public void vMotionBeforeRegisterInterest() {
          }
          @Override
          public void vMotionDuringGII(Set recipientSet, LocalRegion region) {
            InitialImageOperation.VMOTION_DURING_GII = false;
            int oldLevel = LocalRegion.setThreadInitLevelRequirement(
                LocalRegion.BEFORE_INITIAL_IMAGE);
            LocalRegion ccregion = cache.getRegionByPath(""/""+name);
            try {
              // wait for the update op (sent below from vm1) to arrive, then allow the GII to happen
              while (!ccregion.isDestroyed() && ccregion.getRegionEntry(key) == null) {
                try {
                  Thread.sleep(1000);
                } catch (InterruptedException e) {
                  return;
                }
              }
            } finally {
              LocalRegion.setThreadInitLevelRequirement(oldLevel);
            }
          }
        });
        try {
          CCRegion = (LocalRegion)f.create(name);
          // at this point we should have received the update op and then the GII, which should overwrite
          // the conflicting update op
          assertFalse(""expected initial image transfer to destroy entry"", CCRegion.containsKey(key));
        } finally {
          InitialImageOperation.VMOTION_DURING_GII = false;
        }
        return null;
      }
    });
    vm1.invoke(new SerializableRunnable(""create conflicting events"") {
      public void run() {
        // wait for the other to come on line
        long waitEnd = System.currentTimeMillis() + 45000;
        DistributionAdvisor adv = ((DistributedRegion)CCRegion).getCacheDistributionAdvisor();
        while (System.currentTimeMillis() < waitEnd && adv.adviseGeneric().isEmpty()) {
          try {Thread.sleep(1000);} catch (InterruptedException e) { return; }
        }
        if (adv.adviseGeneric().isEmpty()) {
          fail(""other member never came on line"");
        }
        DistributedCacheOperation.LOSS_SIMULATION_RATIO = 200.0; // inhibit all messaging
        try {
          CCRegion.put(""mykey"", ""initialValue"");
          CCRegion.destroy(""mykey"");
        } finally {
          DistributedCacheOperation.LOSS_SIMULATION_RATIO = 0.0;
        }
        
        // generate a fake version tag for the message
        VersionTag tag = CCRegion.getRegionEntry(key).getVersionStamp().asVersionTag();
        // create a fake member ID that will be < mine and lose a concurrency check
        NetMember nm = CCRegion.getDistributionManager().getDistributionManagerId().getNetMember();
        InternalDistributedMember mbr = null;
        try {
          mbr = new InternalDistributedMember(nm.getInetAddress().getCanonicalHostName(), nm.getPort()-1,
              ""fake_id"", ""fake_id_ustring"", DistributionManager.NORMAL_DM_TYPE, null, null);
          tag.setMemberID(mbr);
        } catch (UnknownHostException e) {
          fail(""could not create member id"", e);
        }
        
        // generate an event to distribute that contains the fake version tag
        EntryEventImpl event = EntryEventImpl.create(CCRegion, Operation.UPDATE, key, false, mbr, true, false);
        event.setNewValue(""newValue"");
        event.setVersionTag(tag);

        // this should update the controller's cache with the updated value but leave this cache alone
        DistributedCacheOperation op = new UpdateOperation(event, tag.getVersionTimeStamp());
        op.distribute();
        event.release();
      }
    });
    try {
      partialCreate.getResult();
    } catch (Throwable e) {
      fail(""async invocation in vm2 failed"", e);
    }
  }  ",False
"  public void _testWaitForDeparture() throws Exception {
    disconnectAllFromDS();
    Properties p = getDistributedSystemProperties();
    p.put(DistributionConfig.LOCATORS_NAME, """");
    p.put(DistributionConfig.DISABLE_TCP_NAME, ""true"");
    InternalDistributedSystem ds = (InternalDistributedSystem)DistributedSystem.connect(p);
    try {
      // construct a member ID that will represent a departed member
      InternalDistributedMember mbr = new InternalDistributedMember(""localhost"", 12345, """", """");
      final DistributionManager mgr = (DistributionManager)ds.getDistributionManager();
      // schedule a message in order to create a queue for the fake member
      final FakeMessage msg = new FakeMessage(null);
      mgr.getExecutor(DistributionManager.SERIAL_EXECUTOR, mbr).execute(new SizeableRunnable(100) {
        public void run() {
          msg.doAction(mgr, false);
        }
        public String toString() {
          return ""Processing fake message"";
        }
      });
      try {
        assertTrue(""expected the serial queue to be flushed"", mgr.getMembershipManager().waitForDeparture(mbr));
      } catch (InterruptedException e) {
        fail(""interrupted"");
      } catch (TimeoutException e) {
        fail(""timed out - increase this test's member-timeout setting"");
      }
    } finally {
      ds.disconnect();
    }
  }",True
"  public void _testWaitForDeparture() throws Exception {
    disconnectAllFromDS();
    Properties p = getDistributedSystemProperties();
    p.put(DistributionConfig.LOCATORS_NAME, """");
    p.put(DistributionConfig.DISABLE_TCP_NAME, ""true"");
    InternalDistributedSystem ds = (InternalDistributedSystem)DistributedSystem.connect(p);
    try {
      // construct a member ID that will represent a departed member
      InternalDistributedMember mbr = new InternalDistributedMember(""localhost"", 12345, """", """",
          DistributionManager.NORMAL_DM_TYPE, null, null);
      final DistributionManager mgr = (DistributionManager)ds.getDistributionManager();
      // schedule a message in order to create a queue for the fake member
      final FakeMessage msg = new FakeMessage(null);
      mgr.getExecutor(DistributionManager.SERIAL_EXECUTOR, mbr).execute(new SizeableRunnable(100) {
        public void run() {
          msg.doAction(mgr, false);
        }
        public String toString() {
          return ""Processing fake message"";
        }
      });
      try {
        assertTrue(""expected the serial queue to be flushed"", mgr.getMembershipManager().waitForDeparture(mbr));
      } catch (InterruptedException e) {
        fail(""interrupted"");
      } catch (TimeoutException e) {
        fail(""timed out - increase this test's member-timeout setting"");
      }
    } finally {
      ds.disconnect();
    }
  }",False
"  public void setUp() throws Exception {
    boolean finishedSetup = false;
    addExpectedException(""Error occurred while reading system log"");
    try {
      if (firstTime) {
        disconnectFromDS(); //make sure there's no ldm lying around
        try { Thread.sleep(5 * 1000); } catch (InterruptedException ie) { fail(""interrupted"");}
        firstTime = false;
      }

      DistributionManager.isDedicatedAdminVM = true;

      super.setUp();
      populateCache();

      RemoteTransportConfig transport = null;
      {
        boolean created = !isConnectedToDS();
        InternalDistributedSystem ds = getSystem();
        transport = new RemoteTransportConfig(ds.getConfig());
        if (created) {
          disconnectFromDS();
        }
      }
      // create a GfManagerAgent in the master vm.
      this.agent = GfManagerAgentFactory.
        getManagerAgent(new GfManagerAgentConfig(null, transport, getLogWriter(), Alert.SEVERE, this, null));
      if (!agent.isConnected()) {
        WaitCriterion ev = new WaitCriterion() {
          public boolean done() {
            return agent.isConnected();
          }
          public String description() {
            return null;
          }
        };
        DistributedTestCase.waitForCriterion(ev, 60 * 1000, 200, true);
      }
      finishedSetup = true;
    } finally {
      if (!finishedSetup) {
        try {
          this.agent.disconnect();
        } 
        catch (VirtualMachineError e) {
          SystemFailure.initiateFailure(e);
          throw e;
        }
        catch (Throwable ignore) {
        }
        try {
          super.tearDown2();
        } 
        catch (VirtualMachineError e) {
          SystemFailure.initiateFailure(e);
          throw e;
        }
        catch (Throwable ignore) {
        }
        try {
          disconnectFromDS();
        } 
        catch (VirtualMachineError e) {
          SystemFailure.initiateFailure(e);
          throw e;
        }
        catch (Throwable ignore) {
        }
        DistributionManager.isDedicatedAdminVM = false;
      }
    }
  }",True
"  public void setUp() throws Exception {
    boolean finishedSetup = false;
    addExpectedException(""Error occurred while reading system log"");
    try {
      if (firstTime) {
        disconnectFromDS(); //make sure there's no ldm lying around
        try { Thread.sleep(5 * 1000); } catch (InterruptedException ie) { fail(""interrupted"");}
        firstTime = false;
      }

      DistributionManager.isDedicatedAdminVM = true;

      super.setUp();
      populateCache();

      RemoteTransportConfig transport = null;
      {
        boolean created = !isConnectedToDS();
        InternalDistributedSystem ds = getSystem();
        transport = new RemoteTransportConfig(ds.getConfig(), DistributionManager.ADMIN_ONLY_DM_TYPE);
        if (created) {
          disconnectFromDS();
        }
      }
      // create a GfManagerAgent in the master vm.
      this.agent = GfManagerAgentFactory.
        getManagerAgent(new GfManagerAgentConfig(null, transport, getLogWriter(), Alert.SEVERE, this, null));
      if (!agent.isConnected()) {
        WaitCriterion ev = new WaitCriterion() {
          public boolean done() {
            return agent.isConnected();
          }
          public String description() {
            return null;
          }
        };
        DistributedTestCase.waitForCriterion(ev, 60 * 1000, 200, true);
      }
      finishedSetup = true;
    } finally {
      if (!finishedSetup) {
        try {
          this.agent.disconnect();
        } 
        catch (VirtualMachineError e) {
          SystemFailure.initiateFailure(e);
          throw e;
        }
        catch (Throwable ignore) {
        }
        try {
          super.tearDown2();
        } 
        catch (VirtualMachineError e) {
          SystemFailure.initiateFailure(e);
          throw e;
        }
        catch (Throwable ignore) {
        }
        try {
          disconnectFromDS();
        } 
        catch (VirtualMachineError e) {
          SystemFailure.initiateFailure(e);
          throw e;
        }
        catch (Throwable ignore) {
        }
        DistributionManager.isDedicatedAdminVM = false;
      }
    }
  }",False
"  public void testCountDMs() {
    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);
    final int systemCount = 2;

    createSystem(vm0);
    vm0.invoke(new SerializableRunnable(""Count DMs"") {
        public void run() {
          DM dm = getSystem().getDistributionManager();
          assertEquals(systemCount + 1,
                       dm.getNormalDistributionManagerIds().size());
        }
      });
    createSystem(vm1);
    vm1.invoke(new SerializableRunnable(""Count DMs Again"") {
        public void run() {
          DM dm = getSystem().getDistributionManager();
          assertEquals(systemCount + 2,
                       dm.getNormalDistributionManagerIds().size());
        }
      });
  }",True
"    public void memberJoined(InternalDistributedMember id) {
      this.joined = true;
    }",True
    public FirstMessage() { }   // For Externalizable,True
"    public void quorumLost(Set<InternalDistributedMember> failures, List<InternalDistributedMember> remaining) {
    }",True
"    public void process(DistributionManager dm) {
      Response response = new Response();
      response.processorId = this.processorId;
      response.setRecipient(this.getSender());
      dm.putOutgoing(response);
    }",True
"  public void testMemberJoinedAndDeparted()
    throws InterruptedException {

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    createSystem(vm0);
    vm0.invoke(new SerializableRunnable(""Install listener"") {
        public void run() {
          DM dm = getSystem().getDistributionManager();
          listener = new TestMembershipListener();
          dm.addMembershipListener(listener);
        }
      });
    createSystem(vm1);

    vm0.invoke(new SerializableRunnable(""Verify member joining"") {
        public void run() {
          WaitCriterion ev = new WaitCriterion() {
            public boolean done() {
              return listener.memberJoined();
            }
            public String description() {
              return null;
            }
          };
          DistributedTestCase.waitForCriterion(ev, 3 * 1000, 200, true);
        }
      });
    vm1.invoke(new SerializableRunnable(""Disconnect from system"") {
        public void run() {
          getSystem().disconnect();
        }
      });

    vm0.invoke(new SerializableRunnable(""Verify member departing"") {
        public void run() {
          WaitCriterion ev = new WaitCriterion() {
            public boolean done() {
              return listener.memberDeparted();
            }
            public String description() {
              return null;
            }
          };
          DistributedTestCase.waitForCriterion(ev, 3 * 1000, 200, true);
        }
      });
  }",True
"  public void testSendMessage() throws InterruptedException {
    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    createSystem(vm0);
    createSystem(vm1);

    Thread.sleep(5 * 1000);

    vm0.invoke(new SerializableRunnable(""Send message"") {
        public void run() {
          DM dm = getSystem().getDistributionManager();
          assertEquals(""For DM "" + dm.getId(),
                       3, dm.getOtherNormalDistributionManagerIds().size());
          FirstMessage message = new FirstMessage();
          dm.putOutgoing(message);
        }
      });

    Thread.sleep(3 * 1000);

    vm1.invoke(new SerializableRunnable(""Was message received?"") {
        public void run() {
          WaitCriterion ev = new WaitCriterion() {
            public boolean done() {
              return FirstMessage.received;
            }
            public String description() {
              return null;
            }
          };
          DistributedTestCase.waitForCriterion(ev, 3 * 1000, 200, true);
          FirstMessage.received = false;
        }
      });
  }",True
"    public void process(DistributionManager dm) {
    }",True
"    public void memberDeparted(InternalDistributedMember id, boolean crashed) {
      this.departed = true;
    }",True
"    public void process(DistributionManager dm) {
      received = true;
    }",True
"  protected void createSystem(VM vm) {
    vm.invoke(new SerializableRunnable(""Connect to distributed system"") {
        public void run() {
          // @todo davidw Remove reliance on shared memory for
          // configuration
          Properties props = new Properties();
          // props.setProperty(DistributionConfig.ENABLE_SHARED_MEMORY_NAME, ""true"");
//           File sysDir =
//             GemFireConnectionFactory.getInstance().getSystemDirectory();
//           props.setProperty(DistributionConfig.SYSTEM_DIRECTORY_NAME, sysDir.getPath());
          getSystem(props); 
        }
      });
  }",True
"    public String toString() {
      return ""Only GFDM replies with processor "" + this.processorId;
    }",True
"    public int getProcessorId() {
      return this.processorId;
    }",True
"  public LocalDistributionManagerTest(String name) {
    super(name);
  }",True
"    public void memberSuspect(InternalDistributedMember id,
        InternalDistributedMember whoSuspected) {
    }",True
"    public void toData(DataOutput out) throws IOException {
      super.toData(out);
      out.writeInt(this.processorId);
    }",True
    public OnlyGFDMReply() { }  // For Externalizable,True
    public Request() { }        // For Externizable,True
"    public void process(DistributionManager dm) {
      // Look up the processor
      ReplyProcessor21 processor =
        ReplyProcessor21.getProcessor(this.processorId);
      assertNotNull(""Null processor!"", processor);
      synchronized (Response.class) {
        totalResponses++;
      }
      processor.process(this);
    }",True
"    public void fromData(DataInput in)
      throws ClassNotFoundException, IOException {
      super.fromData(in);
      this.processorId = in.readInt();
    }",True
"    public int getDSFID() {
      return NO_FIXED_ID;
    }",True
"  public void testReplyProcessor() throws InterruptedException {
    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    createSystem(vm0);
    createSystem(vm1);

    Thread.sleep(2 * 1000);

    vm0.invoke(new SerializableRunnable(""Send request"") {
        public void run() {
          // Send a request, wait for a response
          DM dm = getSystem().getDistributionManager();
          int expected = dm.getOtherNormalDistributionManagerIds().size();
          assertEquals(""For DM "" + dm.getId(), 3, expected);

          Response.totalResponses = 0;

          Request request = new Request();
          ReplyProcessor21 processor = new ReplyProcessor21(getSystem(),
               dm.getOtherNormalDistributionManagerIds()); 
          request.processorId = processor.getProcessorId();
          dm.putOutgoing(request);
          try {
            processor.waitForReplies();

          } catch (Exception ex) {
            fail(""While waiting for replies"", ex);
          }

          assertEquals(expected, Response.totalResponses);
        }
      });
    
  }",True
    public Response() { }       // For Externalizable,True
"  public void testMembersDepartWhileWaiting()
    throws InterruptedException {

    Host host = Host.getHost(0);
    VM vm0 = host.getVM(0);
    VM vm1 = host.getVM(1);

    createSystem(vm0);
    createSystem(vm1);

    Thread.sleep(3 * 1000);
    
    AsyncInvocation ai0 =
      vm0.invokeAsync(new SerializableRunnable(""Send message and wait"") {
          public void run() {
            DM dm = getSystem().getDistributionManager();
            OnlyGFDMReply message = new OnlyGFDMReply();
            ReplyProcessor21 processor = new ReplyProcessor21(getSystem(),
              dm.getOtherNormalDistributionManagerIds());
            message.processorId = processor.getProcessorId();
            dm.putOutgoing(message);

            try {
              processor.waitForReplies();
              
            } catch (Exception ex) {
              fail(""While waiting for replies"", ex);
            }
          }
        });

    Thread.sleep(3 * 1000);
    vm1.invoke(new SerializableRunnable(""Disconnect from system"") {
        public void run() {
          getSystem().disconnect();
        }
      });

    DistributedTestCase.join(ai0, 30 * 1000, getLogWriter());
    if (ai0.exceptionOccurred()) {
      fail(""got exception"", ai0.getException());
    }
  }",True
"    public String toString() {
      return ""Response with processor "" + this.processorId;
    }",True
"    public String toString() {
      return ""Request with processor "" + this.processorId;
    }",True
"  public static void setupClass() {
    baseLogLevel = LogService.getBaseLogLevel();
    LogService.setBaseLogLevel(Level.DEBUG);
  }",False
"    public void quorumLost(Set<InternalDistributedMember> failures,
        List<InternalDistributedMember> remainingMembers) {
    }",False
"    public boolean isShutdownMsgSent() {
      return false;
    }",False
"    public void messageReceived(DistributionMessage o) {
    }",False
"    public void membershipFailure(String reason, Throwable t) {
    }",False
"    public DistributionManager getDM() {
      return null;
    }",False
"  protected void setUp() throws Exception {
    baseLogLevel = LogService.getBaseLogLevel();
//    LogService.setBaseLogLevel(Level.DEBUG);
    super.setUp();
  }",True
"import com.gemstone.gemfire.distributed.internal.DistributionMessage;
import com.gemstone.gemfire.distributed.internal.LonerDistributionManager.DummyDMStats;
import com.gemstone.gemfire.distributed.internal.MembershipListener;
import com.gemstone.gemfire.distributed.internal.PoolStatHelper;
import com.gemstone.gemfire.internal.AvailablePortHelper;",False
"    public void memberSuspect(InternalDistributedMember suspect,
        InternalDistributedMember whoSuspected) {
    }",False
"  public void testJoinLeave() throws Exception {
    
    MembershipManager m1=null, m2=null;
    Locator l = null;
    
    try {
      
      // boot up a locator
      int port = AvailablePortHelper.getRandomAvailableTCPPort();
      InetAddress localHost = SocketCreator.getLocalHost();
      
      // this locator will hook itself up with the first MembershipManager
      // to be created
      l = Locator.startLocator(port, new File(""""), localHost);

      // create configuration objects
      Properties nonDefault = new Properties();
      nonDefault.put(DistributionConfig.DISABLE_TCP_NAME, ""true"");
      nonDefault.put(DistributionConfig.MCAST_PORT_NAME, ""0"");
      nonDefault.put(DistributionConfig.LOG_FILE_NAME, """");
      nonDefault.put(DistributionConfig.LOG_LEVEL_NAME, ""fine"");
      nonDefault.put(DistributionConfig.LOCATORS_NAME, localHost.getHostName()+'['+port+']');
      DistributionConfigImpl config = new DistributionConfigImpl(nonDefault);
      RemoteTransportConfig transport = new RemoteTransportConfig(config,
          DistributionManager.NORMAL_DM_TYPE);

      // start the first membership manager
      MembershipListener listener1 = new MembershipListener();
      DMStats stats1 = new MyStats();
      m1 = MemberFactory.newMembershipManager(listener1, config, transport, stats1);

      // start the second membership manager
      MembershipListener listener2 = new MembershipListener();
      DMStats stats2 = new MyStats();
      m2 = MemberFactory.newMembershipManager(listener2, config, transport, stats2);
      
      assert m2.getView().size() == 2;
      assert m1.getView().size() == 2;
      assert m1.getView().getViewId() == m2.getView().getViewId();
      
      m2.shutdown();
      assert !m2.isConnected();
      
      assert m1.getView().size() == 1;
    }
    finally {
      System.getProperties().remove(ConfigurationFactory.CONFIGURATION_FILE_PROPERTY);
      LogService.reconfigure();
      
      if (m2 != null) {
        m2.shutdown();
      }
      if (m1 != null) {
        m1.shutdown();
      }
      if (l != null) {
        l.stop();
      }
    }
    
  }",False
"    public void viewInstalled(NetView view) {
    }",False
"    public void memberDeparted(InternalDistributedMember id, boolean crashed,
        String reason) {
    }",False
"  protected void tearDown() throws Exception {
//    LogService.setBaseLogLevel(baseLogLevel);
    super.tearDown();
  }",True
"  protected void tearDown() throws Exception {
    LogService.setBaseLogLevel(baseLogLevel);
  }",False
    public void endJob(){},False
    public void startJob() {},False
"    public void newMemberConnected(InternalDistributedMember m, Stub stub) {
    }",False
"  public static void beforeClass() {
    //bogus initialization to be able to create InternalDistributedMembers
    MemberAttributes.setDefaults(1, 1, 1, -1, null, null, null);
  }",True
"  public void setUp() {
    this.bucketOperator = new MyBucketOperator();
  }
  ",False
"  public void testDurableReconnect_DifferentPrimary() throws Exception
  {
   //create client cache and Send clientReady message
    createCacheClient();
    HashSet redundantServers = new HashSet(pool.getRedundantNames());
    String primaryBefore = pool.getPrimaryName() ;
    redundantServers.add(primaryBefore);  
    instance.determineAndVerfiyRedundantServers(redundantServers);
    instance.determineAndVerfiyNonRedundantServers(redundantServers);    
    
    // Stop the durable client
    closeCache(true);
    
    //Wait for server to cleanup client resources
    //temporary fix for bug 38345.
    pause(2000);
    
    createCacheClient();
    
    HashSet redundantServersAfterReconnect = new HashSet(pool.getRedundantNames());
    String primaryAfter = pool.getPrimaryName() ;
    redundantServersAfterReconnect.add(primaryAfter);
    instance.determineAndVerfiyRedundantServers(redundantServersAfterReconnect);
    instance.determineAndVerfiyNonRedundantServers(redundantServersAfterReconnect);
    
    assertTrue(redundantServers.equals(redundantServersAfterReconnect));
    assertFalse(primaryBefore.equals(primaryAfter));
    
  }",False
"  public void testDurableReconnect_DiffernetPrimary() throws Exception
  {
   //create client cache and Send clientReady message
    createCacheClient();
    HashSet redundantServers = new HashSet(pool.getRedundantNames());
    String primaryBefore = pool.getPrimaryName() ;
    redundantServers.add(primaryBefore);  
    instance.determineAndVerfiyRedundantServers(redundantServers);
    instance.determineAndVerfiyNonRedundantServers(redundantServers);    
    
    // Stop the durable client
    closeCache(true);
    
    //Wait for server to cleanup client resources
    //temporary fix for bug 38345.
    pause(2000);
    
    createCacheClient();
    
    HashSet redundantServersAfterReconnect = new HashSet(pool.getRedundantNames());
    String primaryAfter = pool.getPrimaryName() ;
    redundantServersAfterReconnect.add(primaryAfter);
    instance.determineAndVerfiyRedundantServers(redundantServersAfterReconnect);
    instance.determineAndVerfiyNonRedundantServers(redundantServersAfterReconnect);
    
    assertTrue(redundantServers.equals(redundantServersAfterReconnect));
    assertFalse(primaryBefore.equals(primaryAfter));
    
  }",True
"    if (sunbits == 64) {
      is64Bit = true;
    } else if (sunbits == 32) {",True
"      if (SystemUtils.isAzulJVM()) {
        tmpObjectHeaderSize = 8;
        tmpReferenceSize = 8;
      } else {",False
"      if (scaleIndex == 0) {
        // If our heap is > 32G (64G on java 8) then assume large oops. Otherwise assume compressed oops.
        long SMALL_OOP_BOUNDARY = 32L;
        if (SystemUtils.isJavaVersionAtLeast(""1.8"")) {
          SMALL_OOP_BOUNDARY = 64L;
        }
        if (Runtime.getRuntime().maxMemory() > (SMALL_OOP_BOUNDARY*1024*1024*1024)) {
          tmpReferenceSize = 8;
          tmpObjectHeaderSize = 16;
        } else {
          tmpReferenceSize = 4;
          tmpObjectHeaderSize = 12;
        }
      }",False
"      if (unsafe != null) {
        // Use unsafe to figure out the size of an object reference since we might
        // be using compressed oops.
        // Note: as of java 8 compressed oops do not imply a compressed object header.
        // The object header is determined by UseCompressedClassPointers.
        // UseCompressedClassPointers requires UseCompressedOops
        // but UseCompressedOops does not require UseCompressedClassPointers.
        // But it seems unlikely that someone would compress their oops
        // not their class pointers. 
        scaleIndex = unsafe.arrayScaleIndex(Object[].class);
        if (scaleIndex == 4) {
          // compressed oops
          tmpReferenceSize = 4;
          tmpObjectHeaderSize = 12;
        } else if (scaleIndex == 8) {
          tmpReferenceSize = 8;
          tmpObjectHeaderSize = 16;
        } else {
          System.out.println(""Unexpected arrayScaleIndex "" + scaleIndex + "". Using max heap size to estimate reference size."");
          scaleIndex = 0;
        }
      }",False
"  public static boolean checkAndLog() {
    boolean minimumSystemRequirementsMet = true;

    minimumSystemRequirementsMet &= checkJavaVersion();

    if (!minimumSystemRequirementsMet) {
      logger.fatal(LocalizedMessage.create(LocalizedStrings.MinimumSystemRequirements_NOT_MET));
    }

    return minimumSystemRequirementsMet;
  }",True
"  public static boolean checkAndLog() {
    boolean minimumSystemRequirementsMet = true;

    minimumSystemRequirementsMet &= checkJavaVersion();

    if (!minimumSystemRequirementsMet) {
      logger.warn(LocalizedMessage.create(LocalizedStrings.MinimumSystemRequirements_NOT_MET));
    }

    return minimumSystemRequirementsMet;
  }",False
"  private static boolean checkJavaVersion() {
    if (SystemUtils.isJavaVersionAtLeast(JAVA_VERSION)) {
      return true;
    }

    logger.fatal(LocalizedMessage.create(LocalizedStrings.MinimumSystemRequirements_JAVA_VERSION, JAVA_VERSION));
    return false;
  }",True
"  private static boolean checkJavaVersion() {
    if (SystemUtils.isJavaVersionAtLeast(JAVA_VERSION)) {
      return true;
    }

    logger.warn(LocalizedMessage.create(LocalizedStrings.MinimumSystemRequirements_JAVA_VERSION, JAVA_VERSION));
    return false;
  }",False
"  static boolean isTenured(MemoryPoolMXBean memoryPoolMXBean) {
    if (memoryPoolMXBean.getType() != MemoryType.HEAP) {
      return false;
    }
    
    String name = memoryPoolMXBean.getName();
    
    return name.equals(""CMS Old Gen"")     // Sun Concurrent Mark Sweep GC
        || name.equals(""PS Old Gen"")      // Sun Parallel GC
        || name.equals(""G1 Old Gen"")      // Sun G1 GC
        || name.equals(""Old Space"")       // BEA JRockit 1.5, 1.6 GC
        || name.equals(""Tenured Gen"")     // Hitachi 1.5 GC
        || name.equals(""Java heap"")       // IBM 1.5, 1.6 GC
        
        // Allow an unknown pool name to monitor
        || (HEAP_POOL != null && name.equals(HEAP_POOL));
  }",True
"  static boolean isTenured(MemoryPoolMXBean memoryPoolMXBean) {
    if (memoryPoolMXBean.getType() != MemoryType.HEAP) {
      return false;
    }
    
    String name = memoryPoolMXBean.getName();
    
    return name.equals(""CMS Old Gen"")     // Sun Concurrent Mark Sweep GC
        || name.equals(""PS Old Gen"")      // Sun Parallel GC
        || name.equals(""G1 Old Gen"")      // Sun G1 GC
        || name.equals(""Old Space"")       // BEA JRockit 1.5, 1.6 GC
        || name.equals(""Tenured Gen"")     // Hitachi 1.5 GC
        || name.equals(""Java heap"")       // IBM 1.5, 1.6 GC
        || name.equals(""GenPauseless Old Gen"") // azul C4/GPGC collector
        
        // Allow an unknown pool name to monitor
        || (HEAP_POOL != null && name.equals(HEAP_POOL));
  }",False
"  public static boolean isAzulJVM() {
    return isJvmVendor(AZUL_JVM_VENDOR_NAME);
  }",False
"  public static boolean isJavaVersionAtLeast(final String expectedVersion) {
    String actualVersionDigits = StringUtils.getDigitsOnly(System.getProperty(""java.version""));

    String expectedVersionDigits = StringUtils.padEnding(StringUtils.getDigitsOnly(expectedVersion), '0',
      actualVersionDigits.length());

    try {
      return (Long.parseLong(actualVersionDigits) >= Long.parseLong(expectedVersionDigits));
    }
    catch (NumberFormatException ignore) {
      return false;
    }
  }",True
"  public static boolean isJavaVersionAtLeast(String expectedVersion) {
    String actualVersionDigits;
    if (isAzulJVM()) {
      actualVersionDigits = StringUtils.getDigitsOnly(System.getProperty(""java.specification.version""));
      int dotIdx = expectedVersion.indexOf('.');
      if (dotIdx != -1) {
        dotIdx = expectedVersion.indexOf('.', dotIdx+1);
        if (dotIdx != -1) {
          // strip off everything after the second dot.
          expectedVersion = expectedVersion.substring(0, dotIdx);
        }
      }
    } else {
      actualVersionDigits = StringUtils.getDigitsOnly(System.getProperty(""java.version""));
    }

    String expectedVersionDigits = StringUtils.padEnding(StringUtils.getDigitsOnly(expectedVersion), '0',
      actualVersionDigits.length());

    try {
      return (Long.parseLong(actualVersionDigits) >= Long.parseLong(expectedVersionDigits));
    }
    catch (NumberFormatException ignore) {
      return false;
    }
  }",False
"   * 
   * @param expectedVersion an string value specifying the minimum expected version of the Java Runtime.
   * @return a boolean value indicating if the Java Runtime meets the expected version requirement.
   * @see java.lang.System#getProperty(String) with ""java.version"".
   */
  public static boolean isJavaVersionAtLeast(String expectedVersion) {
    String actualVersionDigits;
    if (isAzulJVM()) {
      actualVersionDigits = StringUtils.getDigitsOnly(System.getProperty(""java.specification.version""));
      int dotIdx = expectedVersion.indexOf('.');
      if (dotIdx != -1) {
        dotIdx = expectedVersion.indexOf('.', dotIdx+1);
        if (dotIdx != -1) {",False
"  public long sizeof(Object object) {
    return sizeof(object, true);
  }",True
"  public static long sizeof(Class clazz, boolean roundResult) {
    Assert.assertTrue(!clazz.isArray());
    long size;
    if (unsafe != null) {
      Field lastField = null;
      long lastFieldOffset = 0;
      do {
        Field[] fields = clazz.getDeclaredFields();
        for(Field field: fields) {
          if(!Modifier.isStatic(field.getModifiers())) {
            long offset = unsafe.fieldOffset(field);
            if (offset >= lastFieldOffset) {
              lastFieldOffset = offset;
              lastField = field;
            }
          }
        }
        if (lastField != null) {
          // if we have found a field in a subclass then one of them will be the last field
          // so just break without looking at super class fields.
          break;
        }
        clazz = clazz.getSuperclass();
      } while (clazz != null);

      if (lastField != null) {
        size = lastFieldOffset + sizeType(lastField.getType());
      } else {
        // class with no fields
        size = OBJECT_SIZE;
      }
    } else {
      // This code is not as accurate as unsafe but gives an estimate of memory used.
      // If it is wrong it will always under estimate because it does not account
      // for any of the field alignment that the jvm does.
      size = OBJECT_SIZE;
      do {
        Field[] fields = clazz.getDeclaredFields();
        for(Field field: fields) {
          if(!Modifier.isStatic(field.getModifiers())) {
            size += sizeType(field.getType());
          }
        }
        clazz = clazz.getSuperclass();
      } while (clazz != null);
    }
    if (roundResult) {
      size = roundUpSize(size);
    }
    return size;
  }",False
"  public void testStatusUsingPid() throws Throwable {
    final List<String> jvmArguments = new ArrayList<String>();
    jvmArguments.add(""-D"" + getUniqueName() + ""=true"");
    jvmArguments.add(""-Dgemfire.log-level=config"");
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    // wait for locator to start
    int pid = 0;
    LocatorLauncher pidLauncher = null; 
    final LocatorLauncher dirLauncher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(dirLauncher);

      // validate the pid file and its contents
      final File pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
      assertTrue(pidFile.exists());
      pid = readPid(pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());

      // use launcher with pid
      pidLauncher = new Builder()
          .setPid(pid)
          .build();

      assertNotNull(pidLauncher);
      assertFalse(pidLauncher.isRunning());

      // status with pid only should throw AttachAPINotFoundException
      try {
        pidLauncher.status();
        fail(""FileProcessController should have thrown AttachAPINotFoundException"");
      } catch (AttachAPINotFoundException e) {
        // passed
      }
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the locator
    try {
      assertEquals(Status.STOPPED, dirLauncher.stop().getStatus());
      waitForPidToStop(pid, true);
      waitForFileToDelete(this.pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    } finally {
      new File(ProcessType.LOCATOR.getStatusRequestFileName()).delete(); // TODO: delete?
    }
  }",True
"  public void testStatusUsingPid() throws Throwable {
    final List<String> jvmArguments = getJvmArguments();
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    // wait for locator to start
    int pid = 0;
    LocatorLauncher pidLauncher = null; 
    final LocatorLauncher dirLauncher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(dirLauncher);

      // validate the pid file and its contents
      final File pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
      assertTrue(pidFile.exists());
      pid = readPid(pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());

      // use launcher with pid
      pidLauncher = new Builder()
          .setPid(pid)
          .build();

      assertNotNull(pidLauncher);
      assertFalse(pidLauncher.isRunning());

      // status with pid only should throw AttachAPINotFoundException
      try {
        pidLauncher.status();
        fail(""FileProcessController should have thrown AttachAPINotFoundException"");
      } catch (AttachAPINotFoundException e) {
        // passed
      }
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the locator
    try {
      assertEquals(Status.STOPPED, dirLauncher.stop().getStatus());
      waitForPidToStop(pid, true);
      waitForFileToDelete(this.pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    } finally {
      new File(ProcessType.LOCATOR.getStatusRequestFileName()).delete(); // TODO: delete?
    }
  }",False
"  public void testStopUsingPid() throws Throwable {
    final List<String> jvmArguments = new ArrayList<String>();
    jvmArguments.add(""-D"" + getUniqueName() + ""=true"");
    jvmArguments.add(""-Dgemfire.log-level=config"");
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).inputListener(createLoggingListener(""sysout"", getUniqueName() + ""#sysout"")).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).inputListener(createLoggingListener(""syserr"", getUniqueName() + ""#syserr"")).build().start();

    // wait for locator to start
    int pid = 0;
    File pidFile = null;
    LocatorLauncher pidLauncher = null; 
    final LocatorLauncher dirLauncher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(dirLauncher);

      // validate the pid file and its contents
      pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
      assertTrue(pidFile.exists());
      pid = readPid(pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());

      // use launcher with pid
      pidLauncher = new Builder()
          .setPid(pid)
          .build();

      assertNotNull(pidLauncher);
      assertFalse(pidLauncher.isRunning());

      // stop with pid only should throw AttachAPINotFoundException
      try {
        pidLauncher.stop();
        fail(""FileProcessController should have thrown AttachAPINotFoundException"");
      } catch (AttachAPINotFoundException e) {
        // passed
      }

    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      // stop the locator
      assertEquals(Status.STOPPED, dirLauncher.stop().getStatus());
      waitForPidToStop(pid);
      waitForFileToDelete(pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    } finally {
      new File(ProcessType.LOCATOR.getStopRequestFileName()).delete(); // TODO: delete?
    }
  }",True
"  public void testStopUsingPid() throws Throwable {
    final List<String> jvmArguments = getJvmArguments();
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).inputListener(createLoggingListener(""sysout"", getUniqueName() + ""#sysout"")).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).inputListener(createLoggingListener(""syserr"", getUniqueName() + ""#syserr"")).build().start();

    // wait for locator to start
    int pid = 0;
    File pidFile = null;
    LocatorLauncher pidLauncher = null; 
    final LocatorLauncher dirLauncher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(dirLauncher);

      // validate the pid file and its contents
      pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
      assertTrue(pidFile.exists());
      pid = readPid(pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());

      // use launcher with pid
      pidLauncher = new Builder()
          .setPid(pid)
          .build();

      assertNotNull(pidLauncher);
      assertFalse(pidLauncher.isRunning());

      // stop with pid only should throw AttachAPINotFoundException
      try {
        pidLauncher.stop();
        fail(""FileProcessController should have thrown AttachAPINotFoundException"");
      } catch (AttachAPINotFoundException e) {
        // passed
      }

    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      // stop the locator
      assertEquals(Status.STOPPED, dirLauncher.stop().getStatus());
      waitForPidToStop(pid);
      waitForFileToDelete(pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    } finally {
      new File(ProcessType.LOCATOR.getStopRequestFileName()).delete(); // TODO: delete?
    }
  }",False
"  public void testStopUsingPid() throws Throwable {
    final List<String> jvmArguments = new ArrayList<String>();
    jvmArguments.add(""-D"" + getUniqueName() + ""=true"");
    jvmArguments.add(""-Dgemfire.log-level=config"");
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).inputListener(createLoggingListener(""sysout"", getUniqueName() + ""#sysout"")).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).inputListener(createLoggingListener(""syserr"", getUniqueName() + ""#syserr"")).build().start();

    // wait for locator to start
    int pid = 0;
    LocatorLauncher pidLauncher = null; 
    final LocatorLauncher dirLauncher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(dirLauncher);

      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());

      // use launcher with pid
      pidLauncher = new Builder()
          .setPid(pid)
          .build();

      assertNotNull(pidLauncher);
      assertFalse(pidLauncher.isRunning());

      // validate the status
      final LocatorState status = pidLauncher.status();
      assertNotNull(status);
      assertEquals(Status.ONLINE, status.getStatus());
      assertEquals(pid, status.getPid().intValue());

    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the locator
    try {
      if (pidLauncher == null) {
        assertEquals(Status.STOPPED, dirLauncher.stop().getStatus());
      } else {
        assertEquals(Status.STOPPED, pidLauncher.stop().getStatus());
      }          
      waitForPidToStop(pid);
      waitForFileToDelete(pidFile);
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStopUsingPid() throws Throwable {
    final List<String> jvmArguments = getJvmArguments();
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).inputListener(createLoggingListener(""sysout"", getUniqueName() + ""#sysout"")).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).inputListener(createLoggingListener(""syserr"", getUniqueName() + ""#syserr"")).build().start();

    // wait for locator to start
    int pid = 0;
    LocatorLauncher pidLauncher = null; 
    final LocatorLauncher dirLauncher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(dirLauncher);

      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());

      // use launcher with pid
      pidLauncher = new Builder()
          .setPid(pid)
          .build();

      assertNotNull(pidLauncher);
      assertFalse(pidLauncher.isRunning());

      // validate the status
      final LocatorState status = pidLauncher.status();
      assertNotNull(status);
      assertEquals(Status.ONLINE, status.getStatus());
      assertEquals(pid, status.getPid().intValue());

    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the locator
    try {
      if (pidLauncher == null) {
        assertEquals(Status.STOPPED, dirLauncher.stop().getStatus());
      } else {
        assertEquals(Status.STOPPED, pidLauncher.stop().getStatus());
      }          
      waitForPidToStop(pid);
      waitForFileToDelete(pidFile);
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public static List<String> getJvmArguments() {
    final List<String> jvmArguments = new ArrayList<String>();
    jvmArguments.add(""-Dgemfire.log-level=config"");
    return jvmArguments;
  }",False
"  public void testStartUsingForceOverwritesExistingPidFile() throws Throwable {
    // create existing pid file
    this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
    final int otherPid = getPid();
    assertTrue(""Pid "" + otherPid + "" should be alive"", ProcessUtils.isProcessAlive(otherPid));
    writePid(this.pidFile, otherPid);

    // build and start the locator
    final List<String> jvmArguments = new ArrayList<String>();
    jvmArguments.add(""-D"" + getUniqueName() + ""=true"");
    jvmArguments.add(""-Dgemfire.log-level=config"");
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");
    command.add(""--force"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    // wait for locator to start
    int pid = 0;
    this.launcher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(this.launcher);

      // validate the pid file and its contents
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertTrue(pid != otherPid);

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the locator
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForPidToStop(pid);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStartUsingForceOverwritesExistingPidFile() throws Throwable {
    // create existing pid file
    this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
    final int otherPid = getPid();
    assertTrue(""Pid "" + otherPid + "" should be alive"", ProcessUtils.isProcessAlive(otherPid));
    writePid(this.pidFile, otherPid);

    // build and start the locator
    final List<String> jvmArguments = getJvmArguments();
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");
    command.add(""--force"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    // wait for locator to start
    int pid = 0;
    this.launcher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(this.launcher);

      // validate the pid file and its contents
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertTrue(pid != otherPid);

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the locator
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForPidToStop(pid);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void testStartOverwritesStalePidFile() throws Throwable {
    // create existing pid file
    this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
    writePid(this.pidFile, Integer.MAX_VALUE);

    // build and start the locator
    final List<String> jvmArguments = new ArrayList<String>();
    jvmArguments.add(""-D"" + getUniqueName() + ""=true"");
    jvmArguments.add(""-Dgemfire.log-level=config"");
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    int pid = 0;
    this.launcher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(this.launcher);

      // validate the pid file and its contents
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertFalse(pid == Integer.MAX_VALUE);

      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the locator
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForPidToStop(pid);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStartOverwritesStalePidFile() throws Throwable {
    // create existing pid file
    this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
    writePid(this.pidFile, Integer.MAX_VALUE);

    // build and start the locator
    final List<String> jvmArguments = getJvmArguments();
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    int pid = 0;
    this.launcher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(this.launcher);

      // validate the pid file and its contents
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertFalse(pid == Integer.MAX_VALUE);

      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the locator
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForPidToStop(pid);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void testStopUsingWorkingDirectory() throws Throwable {
    final List<String> jvmArguments = new ArrayList<String>();
    jvmArguments.add(""-D"" + getUniqueName() + ""=true"");
    jvmArguments.add(""-Dgemfire.log-level=config"");
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    // wait for locator to start
    int pid = 0;
    final LocatorLauncher dirLauncher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(dirLauncher);

      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());

    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      // stop the locator
      assertEquals(Status.STOPPED, dirLauncher.stop().getStatus());
      waitForPidToStop(pid);
      assertFalse(""PID file still exists!"", this.pidFile.exists());
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStopUsingWorkingDirectory() throws Throwable {
    final List<String> jvmArguments = getJvmArguments();
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    // wait for locator to start
    int pid = 0;
    final LocatorLauncher dirLauncher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(dirLauncher);

      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());

    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      // stop the locator
      assertEquals(Status.STOPPED, dirLauncher.stop().getStatus());
      waitForPidToStop(pid);
      assertFalse(""PID file still exists!"", this.pidFile.exists());
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void testStartUsingPortInUseFails() throws Throwable {
    this.socket = SocketCreator.getDefaultInstance().createServerSocket(this.locatorPort, 50, null, -1);
    
    final List<String> jvmArguments = new ArrayList<String>();
    jvmArguments.add(""-D"" + getUniqueName() + ""=true"");
    jvmArguments.add(""-Dgemfire.log-level=config"");
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--redirect-output"");
    command.add(""--port="" + this.locatorPort);

    String expectedString = ""java.net.BindException"";
    AtomicBoolean outputContainedExpectedString = new AtomicBoolean();
    
    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).inputListener(createExpectedListener(""sysout"", getUniqueName() + ""#sysout"", expectedString, outputContainedExpectedString)).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).inputListener(createExpectedListener(""syserr"", getUniqueName() + ""#syserr"", expectedString, outputContainedExpectedString)).build().start();

    // wait for locator to start and fail
    final LocatorLauncher dirLauncher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      int code = process.waitFor();
      assertEquals(""Expected exit code 1 but was "" + code, 1, code);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
      
    try {
      // check the status
      final LocatorState locatorState = dirLauncher.status();
      assertNotNull(locatorState);
      assertEquals(Status.NOT_RESPONDING, locatorState.getStatus());
      
      final String logFileName = getUniqueName()+"".log"";
      assertFalse(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    // if the following fails, then the SHORTER_TIMEOUT is too short for slow machines
    // or this test needs to use MainLauncher in ProcessWrapper
    
    // validate that output contained BindException 
    this.errorCollector.checkThat(outputContainedExpectedString.get(), is(equalTo(true)));

    // just in case the launcher started...
    LocatorState status = null;
    try {
      status = dirLauncher.stop();
    } catch (Throwable t) { 
      // ignore
    }
    
    this.errorCollector.checkThat(status.getStatus(), is(equalTo(getExpectedStopStatusForNotRunning())));
  }",True
"  public void testStartUsingPortInUseFails() throws Throwable {
    this.socket = SocketCreator.getDefaultInstance().createServerSocket(this.locatorPort, 50, null, -1);
    
    final List<String> jvmArguments = getJvmArguments();
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--redirect-output"");
    command.add(""--port="" + this.locatorPort);

    String expectedString = ""java.net.BindException"";
    AtomicBoolean outputContainedExpectedString = new AtomicBoolean();
    
    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).inputListener(createExpectedListener(""sysout"", getUniqueName() + ""#sysout"", expectedString, outputContainedExpectedString)).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).inputListener(createExpectedListener(""syserr"", getUniqueName() + ""#syserr"", expectedString, outputContainedExpectedString)).build().start();

    // wait for locator to start and fail
    final LocatorLauncher dirLauncher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      int code = process.waitFor();
      assertEquals(""Expected exit code 1 but was "" + code, 1, code);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
      
    try {
      // check the status
      final LocatorState locatorState = dirLauncher.status();
      assertNotNull(locatorState);
      assertEquals(Status.NOT_RESPONDING, locatorState.getStatus());
      
      final String logFileName = getUniqueName()+"".log"";
      assertFalse(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    // if the following fails, then the SHORTER_TIMEOUT is too short for slow machines
    // or this test needs to use MainLauncher in ProcessWrapper
    
    // validate that output contained BindException 
    this.errorCollector.checkThat(outputContainedExpectedString.get(), is(equalTo(true)));

    // just in case the launcher started...
    LocatorState status = null;
    try {
      status = dirLauncher.stop();
    } catch (Throwable t) { 
      // ignore
    }
    
    this.errorCollector.checkThat(status.getStatus(), is(equalTo(getExpectedStopStatusForNotRunning())));
  }",False
"  public void testStatusUsingPid() throws Throwable {
    final List<String> jvmArguments = new ArrayList<String>();
    jvmArguments.add(""-D"" + getUniqueName() + ""=true"");
    jvmArguments.add(""-Dgemfire.log-level=config"");
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    // wait for locator to start
    int pid = 0;
    LocatorLauncher pidLauncher = null; 
    final LocatorLauncher dirLauncher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(dirLauncher);

      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());

      // use launcher with pid
      pidLauncher = new Builder()
          .setPid(pid)
          .build();

      assertNotNull(pidLauncher);
      assertFalse(pidLauncher.isRunning());

      // validate the status
      final LocatorState actualStatus = pidLauncher.status();
      assertNotNull(actualStatus);
      assertEquals(Status.ONLINE, actualStatus.getStatus());
      assertEquals(pid, actualStatus.getPid().intValue());
      assertTrue(actualStatus.getUptime() > 0);
      assertEquals(this.temporaryFolder.getRoot().getCanonicalPath(), actualStatus.getWorkingDirectory());
      assertEquals(jvmArguments, actualStatus.getJvmArguments());
      assertEquals(ManagementFactory.getRuntimeMXBean().getClassPath(), actualStatus.getClasspath());
      assertEquals(GemFireVersion.getGemFireVersion(), actualStatus.getGemFireVersion());
      assertEquals(System.getProperty(""java.version""),  actualStatus.getJavaVersion());
      assertEquals(this.temporaryFolder.getRoot().getCanonicalPath() + File.separator + getUniqueName() + "".log"", actualStatus.getLogFile());
      assertEquals(InetAddress.getLocalHost().getCanonicalHostName(), actualStatus.getHost());
      assertEquals(getUniqueName(), actualStatus.getMemberName());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the locator
    try {
      if (pidLauncher == null) {
        assertEquals(Status.STOPPED, dirLauncher.stop().getStatus());
      } else {
        assertEquals(Status.STOPPED, pidLauncher.stop().getStatus());
      }          
      waitForPidToStop(pid);
      waitForFileToDelete(this.pidFile);
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStatusUsingPid() throws Throwable {
    final List<String> jvmArguments = getJvmArguments();
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    // wait for locator to start
    int pid = 0;
    LocatorLauncher pidLauncher = null; 
    final LocatorLauncher dirLauncher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(dirLauncher);

      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());

      // use launcher with pid
      pidLauncher = new Builder()
          .setPid(pid)
          .build();

      assertNotNull(pidLauncher);
      assertFalse(pidLauncher.isRunning());

      // validate the status
      final LocatorState actualStatus = pidLauncher.status();
      assertNotNull(actualStatus);
      assertEquals(Status.ONLINE, actualStatus.getStatus());
      assertEquals(pid, actualStatus.getPid().intValue());
      assertTrue(actualStatus.getUptime() > 0);
      assertEquals(this.temporaryFolder.getRoot().getCanonicalPath(), actualStatus.getWorkingDirectory());
      assertEquals(jvmArguments, actualStatus.getJvmArguments());
      assertEquals(ManagementFactory.getRuntimeMXBean().getClassPath(), actualStatus.getClasspath());
      assertEquals(GemFireVersion.getGemFireVersion(), actualStatus.getGemFireVersion());
      assertEquals(System.getProperty(""java.version""),  actualStatus.getJavaVersion());
      assertEquals(this.temporaryFolder.getRoot().getCanonicalPath() + File.separator + getUniqueName() + "".log"", actualStatus.getLogFile());
      assertEquals(InetAddress.getLocalHost().getCanonicalHostName(), actualStatus.getHost());
      assertEquals(getUniqueName(), actualStatus.getMemberName());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the locator
    try {
      if (pidLauncher == null) {
        assertEquals(Status.STOPPED, dirLauncher.stop().getStatus());
      } else {
        assertEquals(Status.STOPPED, pidLauncher.stop().getStatus());
      }          
      waitForPidToStop(pid);
      waitForFileToDelete(this.pidFile);
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void testStartCreatesPidFile() throws Throwable {
    // build and start the locator
    final List<String> jvmArguments = new ArrayList<String>();
    jvmArguments.add(""-D"" + getUniqueName() + ""=true"");
    jvmArguments.add(""-Dgemfire.log-level=config"");
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    int pid = 0;
    this.launcher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(this.launcher);
    
      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());
      
      // check the status
      final LocatorState locatorState = this.launcher.status();
      assertNotNull(locatorState);
      assertEquals(Status.ONLINE, locatorState.getStatus());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
      
    // stop the locator
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForPidToStop(pid);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStartCreatesPidFile() throws Throwable {
    // build and start the locator
    final List<String> jvmArguments = getJvmArguments();
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    int pid = 0;
    this.launcher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(this.launcher);
    
      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());
      
      // check the status
      final LocatorState locatorState = this.launcher.status();
      assertNotNull(locatorState);
      assertEquals(Status.ONLINE, locatorState.getStatus());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
      
    // stop the locator
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForPidToStop(pid);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void testStartDeletesStaleControlFiles() throws Throwable {
    // create existing control files
    this.stopRequestFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getStopRequestFileName());
    this.stopRequestFile.createNewFile();
    assertTrue(this.stopRequestFile.exists());

    this.statusRequestFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getStatusRequestFileName());
    this.statusRequestFile.createNewFile();
    assertTrue(this.statusRequestFile.exists());

    this.statusFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getStatusFileName());
    this.statusFile.createNewFile();
    assertTrue(this.statusFile.exists());
    
    // build and start the locator
    final List<String> jvmArguments = new ArrayList<String>();
    jvmArguments.add(""-D"" + getUniqueName() + ""=true"");
    jvmArguments.add(""-Dgemfire.log-level=config"");
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    // wait for locator to start
    int pid = 0;
    this.launcher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(this.launcher);

      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate stale control files were deleted
      waitForFileToDelete(this.stopRequestFile);
      waitForFileToDelete(this.statusRequestFile);
      waitForFileToDelete(this.statusFile);
      
      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the locator
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForPidToStop(pid);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStartDeletesStaleControlFiles() throws Throwable {
    // create existing control files
    this.stopRequestFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getStopRequestFileName());
    this.stopRequestFile.createNewFile();
    assertTrue(this.stopRequestFile.exists());

    this.statusRequestFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getStatusRequestFileName());
    this.statusRequestFile.createNewFile();
    assertTrue(this.statusRequestFile.exists());

    this.statusFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getStatusFileName());
    this.statusFile.createNewFile();
    assertTrue(this.statusFile.exists());
    
    // build and start the locator
    final List<String> jvmArguments = getJvmArguments();
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    // wait for locator to start
    int pid = 0;
    this.launcher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(this.launcher);

      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate stale control files were deleted
      waitForFileToDelete(this.stopRequestFile);
      waitForFileToDelete(this.statusRequestFile);
      waitForFileToDelete(this.statusFile);
      
      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the locator
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForPidToStop(pid);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void testStartWithDefaultPortInUseFails() throws Throwable {
    String expectedString = ""java.net.BindException"";
    AtomicBoolean outputContainedExpectedString = new AtomicBoolean();

    this.socket = SocketCreator.getDefaultInstance().createServerSocket(this.locatorPort, 50, null, -1);
    
    assertFalse(AvailablePort.isPortAvailable(this.locatorPort, AvailablePort.SOCKET));
    assertTrue(this.socket.isBound());
    assertFalse(this.socket.isClosed());
    
    // launch locator
    final List<String> jvmArguments = new ArrayList<String>();
    jvmArguments.add(""-D"" + DistributionLocator.TEST_OVERRIDE_DEFAULT_PORT_PROPERTY + ""="" + this.locatorPort);
    jvmArguments.add(""-D"" + getUniqueName() + ""=true"");
    jvmArguments.add(""-Dgemfire.log-level=config"");
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--redirect-output"");
    
    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).inputListener(createExpectedListener(""sysout"", getUniqueName() + ""#sysout"", expectedString, outputContainedExpectedString)).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).inputListener(createExpectedListener(""syserr"", getUniqueName() + ""#syserr"", expectedString, outputContainedExpectedString)).build().start();
    
    // wait for locator to start up
    final LocatorLauncher dirLauncher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      int code = process.waitFor(); // TODO: create flavor with timeout in ProcessUtils
      assertEquals(""Expected exit code 1 but was "" + code, 1, code);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
      
    try {
      // check the status
      final LocatorState locatorState = dirLauncher.status();
      assertNotNull(locatorState);
      assertEquals(Status.NOT_RESPONDING, locatorState.getStatus());
      
      // creation of log file seems to be random -- look into why sometime
      final String logFileName = getUniqueName()+"".log"";
      assertFalse(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    // if the following fails, then the SHORTER_TIMEOUT might be too short for slow machines
    // or this test needs to use MainLauncher in ProcessWrapper
    
    // validate that output contained BindException 
    this.errorCollector.checkThat(outputContainedExpectedString.get(), is(equalTo(true)));

    // just in case the launcher started...
    LocatorState status = null;
    try {
      status = dirLauncher.stop();
    } catch (Throwable t) { 
      // ignore
    }
    
    this.errorCollector.checkThat(status.getStatus(), is(equalTo(getExpectedStopStatusForNotRunning())));
  }",True
"  public void testStartWithDefaultPortInUseFails() throws Throwable {
    String expectedString = ""java.net.BindException"";
    AtomicBoolean outputContainedExpectedString = new AtomicBoolean();

    this.socket = SocketCreator.getDefaultInstance().createServerSocket(this.locatorPort, 50, null, -1);
    
    assertFalse(AvailablePort.isPortAvailable(this.locatorPort, AvailablePort.SOCKET));
    assertTrue(this.socket.isBound());
    assertFalse(this.socket.isClosed());
    
    // launch locator
    final List<String> jvmArguments = getJvmArguments();
    jvmArguments.add(""-D"" + DistributionLocator.TEST_OVERRIDE_DEFAULT_PORT_PROPERTY + ""="" + this.locatorPort);
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--redirect-output"");
    
    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).inputListener(createExpectedListener(""sysout"", getUniqueName() + ""#sysout"", expectedString, outputContainedExpectedString)).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).inputListener(createExpectedListener(""syserr"", getUniqueName() + ""#syserr"", expectedString, outputContainedExpectedString)).build().start();
    
    // wait for locator to start up
    final LocatorLauncher dirLauncher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      int code = process.waitFor(); // TODO: create flavor with timeout in ProcessUtils
      assertEquals(""Expected exit code 1 but was "" + code, 1, code);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
      
    try {
      // check the status
      final LocatorState locatorState = dirLauncher.status();
      assertNotNull(locatorState);
      assertEquals(Status.NOT_RESPONDING, locatorState.getStatus());
      
      // creation of log file seems to be random -- look into why sometime
      final String logFileName = getUniqueName()+"".log"";
      assertFalse(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    // if the following fails, then the SHORTER_TIMEOUT might be too short for slow machines
    // or this test needs to use MainLauncher in ProcessWrapper
    
    // validate that output contained BindException 
    this.errorCollector.checkThat(outputContainedExpectedString.get(), is(equalTo(true)));

    // just in case the launcher started...
    LocatorState status = null;
    try {
      status = dirLauncher.stop();
    } catch (Throwable t) { 
      // ignore
    }
    
    this.errorCollector.checkThat(status.getStatus(), is(equalTo(getExpectedStopStatusForNotRunning())));
  }",False
"  public void testStatusUsingWorkingDirectory() throws Throwable {
    final List<String> jvmArguments = new ArrayList<String>();
    jvmArguments.add(""-D"" + getUniqueName() + ""=true"");
    jvmArguments.add(""-Dgemfire.log-level=config"");
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    // wait for locator to start
    int pid = 0;
    final LocatorLauncher dirLauncher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(dirLauncher);

      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());

      assertNotNull(dirLauncher);
      assertFalse(dirLauncher.isRunning());

      // validate the status
      final LocatorState actualStatus = dirLauncher.status();
      assertNotNull(actualStatus);
      assertEquals(Status.ONLINE, actualStatus.getStatus());
      assertEquals(pid, actualStatus.getPid().intValue());
      assertTrue(actualStatus.getUptime() > 0);
      assertEquals(this.temporaryFolder.getRoot().getCanonicalPath(), actualStatus.getWorkingDirectory());
      assertEquals(jvmArguments, actualStatus.getJvmArguments());
      assertEquals(ManagementFactory.getRuntimeMXBean().getClassPath(), actualStatus.getClasspath());
      assertEquals(GemFireVersion.getGemFireVersion(), actualStatus.getGemFireVersion());
      assertEquals(System.getProperty(""java.version""),  actualStatus.getJavaVersion());
      assertEquals(this.temporaryFolder.getRoot().getCanonicalPath() + File.separator + getUniqueName() + "".log"", actualStatus.getLogFile());
      assertEquals(InetAddress.getLocalHost().getCanonicalHostName(), actualStatus.getHost());
      assertEquals(getUniqueName(), actualStatus.getMemberName());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the locator
    try {
      assertEquals(Status.STOPPED, dirLauncher.stop().getStatus());
      waitForPidToStop(pid);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStatusUsingWorkingDirectory() throws Throwable {
    final List<String> jvmArguments = getJvmArguments();
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(LocatorLauncher.class.getName());
    command.add(LocatorLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--port="" + this.locatorPort);
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    // wait for locator to start
    int pid = 0;
    final LocatorLauncher dirLauncher = new LocatorLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForLocatorToStart(dirLauncher);

      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.LOCATOR.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());

      assertNotNull(dirLauncher);
      assertFalse(dirLauncher.isRunning());

      // validate the status
      final LocatorState actualStatus = dirLauncher.status();
      assertNotNull(actualStatus);
      assertEquals(Status.ONLINE, actualStatus.getStatus());
      assertEquals(pid, actualStatus.getPid().intValue());
      assertTrue(actualStatus.getUptime() > 0);
      assertEquals(this.temporaryFolder.getRoot().getCanonicalPath(), actualStatus.getWorkingDirectory());
      assertEquals(jvmArguments, actualStatus.getJvmArguments());
      assertEquals(ManagementFactory.getRuntimeMXBean().getClassPath(), actualStatus.getClasspath());
      assertEquals(GemFireVersion.getGemFireVersion(), actualStatus.getGemFireVersion());
      assertEquals(System.getProperty(""java.version""),  actualStatus.getJavaVersion());
      assertEquals(this.temporaryFolder.getRoot().getCanonicalPath() + File.separator + getUniqueName() + "".log"", actualStatus.getLogFile());
      assertEquals(InetAddress.getLocalHost().getCanonicalHostName(), actualStatus.getHost());
      assertEquals(getUniqueName(), actualStatus.getMemberName());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the locator
    try {
      assertEquals(Status.STOPPED, dirLauncher.stop().getStatus());
      waitForPidToStop(pid);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void testStartUsingDisableDefaultServerSkipsPortCheck() throws Throwable {
    // generate one free port and then use TEST_OVERRIDE_DEFAULT_PORT_PROPERTY
    this.socket = SocketCreator.getDefaultInstance().createServerSocket(this.serverPort, 50, null, -1);
    assertFalse(AvailablePort.isPortAvailable(this.serverPort, AvailablePort.SOCKET));
    
    // build and start the server
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"");
    this.launcher = builder.build();

    // wait for server to start
    try {
      // if start succeeds without throwing exception then #47778 is fixed
      this.launcher.start();
      waitForServerToStart(this.launcher);

      // validate the pid file and its contents
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertEquals(getPid(), pid);

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(logFileName).exists());
      
      final ServerState status = this.launcher.status();
      final String portString = status.getPort();
      assertEquals(""Port should be \""\"" instead of "" + portString, """", portString);
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    // stop the server
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForFileToDelete(this.pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  
    // verify port is still in use
    this.errorCollector.checkThat(AvailablePort.isPortAvailable(this.serverPort, AvailablePort.SOCKET), is(equalTo(false)));
  }",True
"  public void testStartUsingDisableDefaultServerSkipsPortCheck() throws Throwable {
    // generate one free port and then use TEST_OVERRIDE_DEFAULT_PORT_PROPERTY
    this.socket = SocketCreator.getDefaultInstance().createServerSocket(this.serverPort, 50, null, -1);
    assertFalse(AvailablePort.isPortAvailable(this.serverPort, AvailablePort.SOCKET));
    
    // build and start the server
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"")
        .set(DistributionConfig.MCAST_PORT_NAME, ""0"");

    this.launcher = builder.build();

    // wait for server to start
    try {
      // if start succeeds without throwing exception then #47778 is fixed
      this.launcher.start();
      waitForServerToStart(this.launcher);

      // validate the pid file and its contents
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertEquals(getPid(), pid);

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(logFileName).exists());
      
      final ServerState status = this.launcher.status();
      final String portString = status.getPort();
      assertEquals(""Port should be \""\"" instead of "" + portString, """", portString);
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    // stop the server
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForFileToDelete(this.pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  
    // verify port is still in use
    this.errorCollector.checkThat(AvailablePort.isPortAvailable(this.serverPort, AvailablePort.SOCKET), is(equalTo(false)));
  }",False
"  public void testStartUsingServerPortUsedInsteadOfDefaultCacheXml() throws Throwable {
    // write out cache.xml with one port
    final CacheCreation creation = new CacheCreation();
    final RegionAttributesCreation attrs = new RegionAttributesCreation(creation);
    attrs.setScope(Scope.DISTRIBUTED_ACK);
    attrs.setDataPolicy(DataPolicy.REPLICATE);
    creation.createRegion(getUniqueName(), attrs);
    creation.addCacheServer();
    
    File cacheXmlFile = this.temporaryFolder.newFile(getUniqueName() + "".xml"");
    final PrintWriter pw = new PrintWriter(new FileWriter(cacheXmlFile), true);
    CacheXmlGenerator.generate(creation, pw);
    pw.close();
    
    System.setProperty(DistributionConfig.CACHE_XML_FILE_NAME, cacheXmlFile.getCanonicalPath());
      
    // start server
    final Builder builder = new Builder()
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .setServerPort(this.serverPort)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"");

    this.launcher = builder.build();
    this.launcher.start();
  
    // wait for server to start up
    try {
      waitForServerToStart(this.launcher);
  
      // validate the pid file and its contents
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertEquals(getPid(), pid);

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(logFileName).exists());

      // verify server used --server-port instead of default
      assertFalse(AvailablePort.isPortAvailable(this.serverPort, AvailablePort.SOCKET));
      
      final int port = Integer.valueOf( this.launcher.status().getPort());
      assertEquals(""Port should be "" + this.serverPort + "" instead of "" + port, this.serverPort, port);
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
      
    // stop the server
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForFileToDelete(this.pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStartUsingServerPortUsedInsteadOfDefaultCacheXml() throws Throwable {
    // write out cache.xml with one port
    final CacheCreation creation = new CacheCreation();
    final RegionAttributesCreation attrs = new RegionAttributesCreation(creation);
    attrs.setScope(Scope.DISTRIBUTED_ACK);
    attrs.setDataPolicy(DataPolicy.REPLICATE);
    creation.createRegion(getUniqueName(), attrs);
    creation.addCacheServer();
    
    File cacheXmlFile = this.temporaryFolder.newFile(getUniqueName() + "".xml"");
    final PrintWriter pw = new PrintWriter(new FileWriter(cacheXmlFile), true);
    CacheXmlGenerator.generate(creation, pw);
    pw.close();
    
    System.setProperty(DistributionConfig.CACHE_XML_FILE_NAME, cacheXmlFile.getCanonicalPath());
      
    // start server
    final Builder builder = new Builder()
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .setServerPort(this.serverPort)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"")
        .set(DistributionConfig.MCAST_PORT_NAME, ""0"");

    this.launcher = builder.build();
    this.launcher.start();
  
    // wait for server to start up
    try {
      waitForServerToStart(this.launcher);
  
      // validate the pid file and its contents
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertEquals(getPid(), pid);

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(logFileName).exists());

      // verify server used --server-port instead of default
      assertFalse(AvailablePort.isPortAvailable(this.serverPort, AvailablePort.SOCKET));
      
      final int port = Integer.valueOf( this.launcher.status().getPort());
      assertEquals(""Port should be "" + this.serverPort + "" instead of "" + port, this.serverPort, port);
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
      
    // stop the server
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForFileToDelete(this.pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void testStopUsingWorkingDirectory() throws Throwable {
    // build and start the server
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"");

    assertFalse(builder.getForce());
    this.launcher = builder.build();
    assertFalse(this.launcher.isForcing());

    ServerLauncher dirLauncher = null;
    try {
      this.launcher.start();
      waitForServerToStart(this.launcher);
    
      // validate the pid file and its contents
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      final int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertEquals(ProcessUtils.identifyPid(), pid);

      final String workingDir = new File(System.getProperty(""user.dir"")).getCanonicalPath();
      dirLauncher = new Builder().setWorkingDirectory(workingDir).build();
      assertNotNull(dirLauncher);
      assertFalse(dirLauncher.isRunning());
      
      // stop the server
      final ServerState serverState = dirLauncher.stop();
      assertNotNull(serverState);
      assertEquals(Status.STOPPED, serverState.getStatus());
    
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      this.launcher.stop();
    } catch (Throwable e) {
      // ignore
    }

    try {
      // verify the PID file was deleted
      waitForFileToDelete(this.pidFile); // TODO
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStopUsingWorkingDirectory() throws Throwable {
    // build and start the server
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"")
        .set(DistributionConfig.MCAST_PORT_NAME, ""0"");

    assertFalse(builder.getForce());
    this.launcher = builder.build();
    assertFalse(this.launcher.isForcing());

    ServerLauncher dirLauncher = null;
    try {
      this.launcher.start();
      waitForServerToStart(this.launcher);
    
      // validate the pid file and its contents
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      final int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertEquals(ProcessUtils.identifyPid(), pid);

      final String workingDir = new File(System.getProperty(""user.dir"")).getCanonicalPath();
      dirLauncher = new Builder().setWorkingDirectory(workingDir).build();
      assertNotNull(dirLauncher);
      assertFalse(dirLauncher.isRunning());
      
      // stop the server
      final ServerState serverState = dirLauncher.stop();
      assertNotNull(serverState);
      assertEquals(Status.STOPPED, serverState.getStatus());
    
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      this.launcher.stop();
    } catch (Throwable e) {
      // ignore
    }

    try {
      // verify the PID file was deleted
      waitForFileToDelete(this.pidFile); // TODO
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void testStopUsingPid() throws Throwable {
    // build and start the server
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"");

    assertFalse(builder.getForce());
    this.launcher = builder.build();
    assertFalse(this.launcher.isForcing());

    ServerLauncher pidLauncher = null;
    
    try {
      this.launcher.start();
      waitForServerToStart(this.launcher);
  
      // validate the pid file and its contents
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      final int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertEquals(ProcessUtils.identifyPid(), pid);

      pidLauncher = new Builder().setPid(pid).build();
      assertNotNull(pidLauncher);
      assertFalse(pidLauncher.isRunning());
      
      // stop the server
      final ServerState serverState = pidLauncher.stop();
      assertNotNull(serverState);
      assertEquals(Status.STOPPED, serverState.getStatus());
    
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      this.launcher.stop();
    } catch (Throwable e) {
      // ignore
    }

    try {
      // verify the PID file was deleted
      waitForFileToDelete(this.pidFile); // TODO
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStopUsingPid() throws Throwable {
    // build and start the server
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"")
        .set(DistributionConfig.MCAST_PORT_NAME, ""0"");

    assertFalse(builder.getForce());
    this.launcher = builder.build();
    assertFalse(this.launcher.isForcing());

    ServerLauncher pidLauncher = null;
    
    try {
      this.launcher.start();
      waitForServerToStart(this.launcher);
  
      // validate the pid file and its contents
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      final int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertEquals(ProcessUtils.identifyPid(), pid);

      pidLauncher = new Builder().setPid(pid).build();
      assertNotNull(pidLauncher);
      assertFalse(pidLauncher.isRunning());
      
      // stop the server
      final ServerState serverState = pidLauncher.stop();
      assertNotNull(serverState);
      assertEquals(Status.STOPPED, serverState.getStatus());
    
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      this.launcher.stop();
    } catch (Throwable e) {
      // ignore
    }

    try {
      // verify the PID file was deleted
      waitForFileToDelete(this.pidFile); // TODO
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void testStatusUsingPid() throws Throwable {
    // build and start the server
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"");
    
    assertFalse(builder.getForce());
    this.launcher = builder.build();
    assertFalse(this.launcher.isForcing());
    
    ServerLauncher pidLauncher = null;
    try {
      this.launcher.start();
      waitForServerToStart(this.launcher);
      
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      final int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertEquals(ProcessUtils.identifyPid(), pid);
  
      pidLauncher = new Builder().setPid(pid).build();
      assertNotNull(pidLauncher);
      assertFalse(pidLauncher.isRunning());

      final ServerState actualStatus = pidLauncher.status();
      assertNotNull(actualStatus);
      assertEquals(Status.ONLINE, actualStatus.getStatus());
      assertEquals(pid, actualStatus.getPid().intValue());
      assertTrue(actualStatus.getUptime() > 0);
      assertEquals(new File(System.getProperty(""user.dir"")).getCanonicalPath(), actualStatus.getWorkingDirectory());
      //assertEquals(???, actualStatus.getJvmArguments());
      assertEquals(ManagementFactory.getRuntimeMXBean().getClassPath(), actualStatus.getClasspath());
      assertEquals(GemFireVersion.getGemFireVersion(), actualStatus.getGemFireVersion());
      assertEquals(System.getProperty(""java.version""),  actualStatus.getJavaVersion());
      assertEquals(new File(System.getProperty(""user.dir"")).getCanonicalPath() + File.separator + getUniqueName() + "".log"", actualStatus.getLogFile());
      assertEquals(InetAddress.getLocalHost().getCanonicalHostName(), actualStatus.getHost());
      assertEquals(getUniqueName(), actualStatus.getMemberName());
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    if (pidLauncher == null) {
      try {
        assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
        waitForFileToDelete(this.pidFile);
      } catch (Throwable e) {
        this.errorCollector.addError(e);
      }
      
    } else {
      try {
        assertEquals(Status.STOPPED, pidLauncher.stop().getStatus());
        waitForFileToDelete(this.pidFile);
      } catch (Throwable e) {
        this.errorCollector.addError(e);
      }
    }
  }",True
"  public void testStatusUsingPid() throws Throwable {
    // build and start the server
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"")
        .set(DistributionConfig.MCAST_PORT_NAME, ""0"");
    
    assertFalse(builder.getForce());
    this.launcher = builder.build();
    assertFalse(this.launcher.isForcing());
    
    ServerLauncher pidLauncher = null;
    try {
      this.launcher.start();
      waitForServerToStart(this.launcher);
      
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      final int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertEquals(ProcessUtils.identifyPid(), pid);
  
      pidLauncher = new Builder().setPid(pid).build();
      assertNotNull(pidLauncher);
      assertFalse(pidLauncher.isRunning());

      final ServerState actualStatus = pidLauncher.status();
      assertNotNull(actualStatus);
      assertEquals(Status.ONLINE, actualStatus.getStatus());
      assertEquals(pid, actualStatus.getPid().intValue());
      assertTrue(actualStatus.getUptime() > 0);
      assertEquals(new File(System.getProperty(""user.dir"")).getCanonicalPath(), actualStatus.getWorkingDirectory());
      //assertEquals(???, actualStatus.getJvmArguments());
      assertEquals(ManagementFactory.getRuntimeMXBean().getClassPath(), actualStatus.getClasspath());
      assertEquals(GemFireVersion.getGemFireVersion(), actualStatus.getGemFireVersion());
      assertEquals(System.getProperty(""java.version""),  actualStatus.getJavaVersion());
      assertEquals(new File(System.getProperty(""user.dir"")).getCanonicalPath() + File.separator + getUniqueName() + "".log"", actualStatus.getLogFile());
      assertEquals(InetAddress.getLocalHost().getCanonicalHostName(), actualStatus.getHost());
      assertEquals(getUniqueName(), actualStatus.getMemberName());
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    if (pidLauncher == null) {
      try {
        assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
        waitForFileToDelete(this.pidFile);
      } catch (Throwable e) {
        this.errorCollector.addError(e);
      }
      
    } else {
      try {
        assertEquals(Status.STOPPED, pidLauncher.stop().getStatus());
        waitForFileToDelete(this.pidFile);
      } catch (Throwable e) {
        this.errorCollector.addError(e);
      }
    }
  }",False
"  public void testStartUsingDisableDefaultServerLeavesPortFree() throws Throwable {
    // build and start the server
    assertTrue(AvailablePort.isPortAvailable(this.serverPort, AvailablePort.SOCKET));
    
    // build and start the server
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"");
    this.launcher = builder.build();

    // wait for server to start
    try {
      // if start succeeds without throwing exception then #47778 is fixed
      this.launcher.start();
      waitForServerToStart(this.launcher);

      // validate the pid file and its contents
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertEquals(getPid(), pid);

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(logFileName).exists());

      // verify server did not a port
      assertTrue(AvailablePort.isPortAvailable(this.serverPort, AvailablePort.SOCKET));
      
      final ServerState status = this.launcher.status();
      final String portString = status.getPort();
      assertEquals(""Port should be \""\"" instead of "" + portString, """", portString);
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the server
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForFileToDelete(this.pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStartUsingDisableDefaultServerLeavesPortFree() throws Throwable {
    // build and start the server
    assertTrue(AvailablePort.isPortAvailable(this.serverPort, AvailablePort.SOCKET));
    
    // build and start the server
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"")
        .set(DistributionConfig.MCAST_PORT_NAME, ""0"");
    
    this.launcher = builder.build();

    // wait for server to start
    try {
      // if start succeeds without throwing exception then #47778 is fixed
      this.launcher.start();
      waitForServerToStart(this.launcher);

      // validate the pid file and its contents
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertEquals(getPid(), pid);

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(logFileName).exists());

      // verify server did not a port
      assertTrue(AvailablePort.isPortAvailable(this.serverPort, AvailablePort.SOCKET));
      
      final ServerState status = this.launcher.status();
      final String portString = status.getPort();
      assertEquals(""Port should be \""\"" instead of "" + portString, """", portString);
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the server
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForFileToDelete(this.pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void testStartUsingServerPortInUseFails() throws Throwable {
    // generate one free port and then use TEST_OVERRIDE_DEFAULT_PORT_PROPERTY
    final int freeTCPPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    this.socket = SocketCreator.getDefaultInstance().createServerSocket(freeTCPPort, 50, null, -1);
    
    // build and start the server
    final Builder builder = new Builder()
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .setServerPort(freeTCPPort)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"");

    this.launcher = builder.build();
    
    RuntimeException expected = null;
    try {
      this.launcher.start();
      fail(""ServerLauncher start should have thrown RuntimeException caused by BindException"");
    } catch (RuntimeException e) {
      expected = e;
      assertNotNull(expected.getMessage());
      // BindException string varies by platform
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    try {
      assertNotNull(expected);
      final Throwable cause = expected.getCause();
      assertNotNull(cause);
      assertTrue(cause instanceof BindException);
      // BindException string varies by platform
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      this.pidFile = new File (ProcessType.SERVER.getPidFileName());
      assertFalse(""Pid file should not exist: "" + this.pidFile, this.pidFile.exists());
      
      // creation of log file seems to be random -- look into why sometime
      final String logFileName = getUniqueName()+"".log"";
      assertFalse(""Log file should not exist: "" + logFileName, new File(logFileName).exists());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    // just in case the launcher started...
    ServerState status = null; // TODO: this could result in NPE later
    try {
      status = this.launcher.stop();
    } catch (Throwable t) { 
      // ignore
    }
    
    try {
      waitForFileToDelete(this.pidFile);
      assertEquals(getExpectedStopStatusForNotRunning(), status.getStatus());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStartUsingServerPortInUseFails() throws Throwable {
    // generate one free port and then use TEST_OVERRIDE_DEFAULT_PORT_PROPERTY
    final int freeTCPPort = AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET);
    this.socket = SocketCreator.getDefaultInstance().createServerSocket(freeTCPPort, 50, null, -1);
    
    // build and start the server
    final Builder builder = new Builder()
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .setServerPort(freeTCPPort)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"")
        .set(DistributionConfig.MCAST_PORT_NAME, ""0"");

    this.launcher = builder.build();
    
    RuntimeException expected = null;
    try {
      this.launcher.start();
      fail(""ServerLauncher start should have thrown RuntimeException caused by BindException"");
    } catch (RuntimeException e) {
      expected = e;
      assertNotNull(expected.getMessage());
      // BindException string varies by platform
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    try {
      assertNotNull(expected);
      final Throwable cause = expected.getCause();
      assertNotNull(cause);
      assertTrue(cause instanceof BindException);
      // BindException string varies by platform
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      this.pidFile = new File (ProcessType.SERVER.getPidFileName());
      assertFalse(""Pid file should not exist: "" + this.pidFile, this.pidFile.exists());
      
      // creation of log file seems to be random -- look into why sometime
      final String logFileName = getUniqueName()+"".log"";
      assertFalse(""Log file should not exist: "" + logFileName, new File(logFileName).exists());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    // just in case the launcher started...
    ServerState status = null; // TODO: this could result in NPE later
    try {
      status = this.launcher.stop();
    } catch (Throwable t) { 
      // ignore
    }
    
    try {
      waitForFileToDelete(this.pidFile);
      assertEquals(getExpectedStopStatusForNotRunning(), status.getStatus());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void testStartOverwritesStalePidFile() throws Throwable {
    // create existing pid file
    this.pidFile = new File(ProcessType.SERVER.getPidFileName());
    assertFalse(""Integer.MAX_VALUE shouldn't be the same as local pid "" + Integer.MAX_VALUE, Integer.MAX_VALUE == ProcessUtils.identifyPid());
    writePid(this.pidFile, Integer.MAX_VALUE);

    // build and start the server
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"");

    assertFalse(builder.getForce());
    this.launcher = builder.build();
    assertFalse(this.launcher.isForcing());
    this.launcher.start();
    
    try {
      waitForServerToStart(this.launcher);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    try {
      // validate the pid file and its contents
      assertTrue(this.pidFile.exists());
      final int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertEquals(getPid(), pid);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForFileToDelete(this.pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStartOverwritesStalePidFile() throws Throwable {
    // create existing pid file
    this.pidFile = new File(ProcessType.SERVER.getPidFileName());
    assertFalse(""Integer.MAX_VALUE shouldn't be the same as local pid "" + Integer.MAX_VALUE, Integer.MAX_VALUE == ProcessUtils.identifyPid());
    writePid(this.pidFile, Integer.MAX_VALUE);

    // build and start the server
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"")
        .set(DistributionConfig.MCAST_PORT_NAME, ""0"");

    assertFalse(builder.getForce());
    this.launcher = builder.build();
    assertFalse(this.launcher.isForcing());
    this.launcher.start();
    
    try {
      waitForServerToStart(this.launcher);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    try {
      // validate the pid file and its contents
      assertTrue(this.pidFile.exists());
      final int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertEquals(getPid(), pid);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForFileToDelete(this.pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void testStartDeletesStaleControlFiles() throws Throwable {
    // create existing control files
    this.stopRequestFile = new File(ProcessType.SERVER.getStopRequestFileName());
    this.stopRequestFile.createNewFile();
    assertTrue(this.stopRequestFile.exists());

    this.statusRequestFile = new File(ProcessType.SERVER.getStatusRequestFileName());
    this.statusRequestFile.createNewFile();
    assertTrue(this.statusRequestFile.exists());

    this.statusFile = new File(ProcessType.SERVER.getStatusFileName());
    this.statusFile.createNewFile();
    assertTrue(this.statusFile.exists());
    
    // build and start the server
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"");

    assertFalse(builder.getForce());
    this.launcher = builder.build();
    assertFalse(this.launcher.isForcing());
    this.launcher.start();
    
    try {
      waitForServerToStart(this.launcher);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    try {
      // validate the pid file and its contents
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      final int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertEquals(getPid(), pid);
      
      // validate stale control files were deleted
      assertFalse(this.stopRequestFile.exists());
      assertFalse(this.statusRequestFile.exists());
      assertFalse(this.statusFile.exists());
      
      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(logFileName).exists());
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForFileToDelete(this.pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStartDeletesStaleControlFiles() throws Throwable {
    // create existing control files
    this.stopRequestFile = new File(ProcessType.SERVER.getStopRequestFileName());
    this.stopRequestFile.createNewFile();
    assertTrue(this.stopRequestFile.exists());

    this.statusRequestFile = new File(ProcessType.SERVER.getStatusRequestFileName());
    this.statusRequestFile.createNewFile();
    assertTrue(this.statusRequestFile.exists());

    this.statusFile = new File(ProcessType.SERVER.getStatusFileName());
    this.statusFile.createNewFile();
    assertTrue(this.statusFile.exists());
    
    // build and start the server
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"")
        .set(DistributionConfig.MCAST_PORT_NAME, ""0"");

    assertFalse(builder.getForce());
    this.launcher = builder.build();
    assertFalse(this.launcher.isForcing());
    this.launcher.start();
    
    try {
      waitForServerToStart(this.launcher);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    try {
      // validate the pid file and its contents
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      final int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertEquals(getPid(), pid);
      
      // validate stale control files were deleted
      assertFalse(this.stopRequestFile.exists());
      assertFalse(this.statusRequestFile.exists());
      assertFalse(this.statusFile.exists());
      
      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(logFileName).exists());
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForFileToDelete(this.pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void testStatusUsingWorkingDirectory() throws Throwable {
    // build and start the server
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"");
    
    assertFalse(builder.getForce());
    this.launcher = builder.build();
    assertFalse(this.launcher.isForcing());
    
    ServerLauncher dirLauncher = null;
    try {
      this.launcher.start();
      waitForServerToStart(this.launcher);
      
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      final int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertEquals(ProcessUtils.identifyPid(), pid);
  
      final String workingDir = new File(System.getProperty(""user.dir"")).getCanonicalPath();
      dirLauncher = new Builder().setWorkingDirectory(workingDir).build();
      assertNotNull(dirLauncher);
      assertFalse(dirLauncher.isRunning());

      final ServerState actualStatus = dirLauncher.status();
      assertNotNull(actualStatus);
      assertEquals(Status.ONLINE, actualStatus.getStatus());
      assertEquals(pid, actualStatus.getPid().intValue());
      assertTrue(actualStatus.getUptime() > 0);
      assertEquals(new File(System.getProperty(""user.dir"")).getCanonicalPath(), actualStatus.getWorkingDirectory());
      //assertEquals(???, actualStatus.getJvmArguments());
      assertEquals(ManagementFactory.getRuntimeMXBean().getClassPath(), actualStatus.getClasspath());
      assertEquals(GemFireVersion.getGemFireVersion(), actualStatus.getGemFireVersion());
      assertEquals(System.getProperty(""java.version""),  actualStatus.getJavaVersion());
      assertEquals(new File(System.getProperty(""user.dir"")).getCanonicalPath() + File.separator + getUniqueName() + "".log"", actualStatus.getLogFile());
      assertEquals(InetAddress.getLocalHost().getCanonicalHostName(), actualStatus.getHost());
      assertEquals(getUniqueName(), actualStatus.getMemberName());
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    if (dirLauncher == null) {
      try {
        assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
        waitForFileToDelete(this.pidFile);
      } catch (Throwable e) {
        this.errorCollector.addError(e);
      }
      
    } else {
      try {
        assertEquals(Status.STOPPED, dirLauncher.stop().getStatus());
        waitForFileToDelete(this.pidFile);
      } catch (Throwable e) {
        this.errorCollector.addError(e);
      }
    }
  }",True
"  public void testStatusUsingWorkingDirectory() throws Throwable {
    // build and start the server
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"")
        .set(DistributionConfig.MCAST_PORT_NAME, ""0"");
    
    assertFalse(builder.getForce());
    this.launcher = builder.build();
    assertFalse(this.launcher.isForcing());
    
    ServerLauncher dirLauncher = null;
    try {
      this.launcher.start();
      waitForServerToStart(this.launcher);
      
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      final int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertEquals(ProcessUtils.identifyPid(), pid);
  
      final String workingDir = new File(System.getProperty(""user.dir"")).getCanonicalPath();
      dirLauncher = new Builder().setWorkingDirectory(workingDir).build();
      assertNotNull(dirLauncher);
      assertFalse(dirLauncher.isRunning());

      final ServerState actualStatus = dirLauncher.status();
      assertNotNull(actualStatus);
      assertEquals(Status.ONLINE, actualStatus.getStatus());
      assertEquals(pid, actualStatus.getPid().intValue());
      assertTrue(actualStatus.getUptime() > 0);
      assertEquals(new File(System.getProperty(""user.dir"")).getCanonicalPath(), actualStatus.getWorkingDirectory());
      //assertEquals(???, actualStatus.getJvmArguments());
      assertEquals(ManagementFactory.getRuntimeMXBean().getClassPath(), actualStatus.getClasspath());
      assertEquals(GemFireVersion.getGemFireVersion(), actualStatus.getGemFireVersion());
      assertEquals(System.getProperty(""java.version""),  actualStatus.getJavaVersion());
      assertEquals(new File(System.getProperty(""user.dir"")).getCanonicalPath() + File.separator + getUniqueName() + "".log"", actualStatus.getLogFile());
      assertEquals(InetAddress.getLocalHost().getCanonicalHostName(), actualStatus.getHost());
      assertEquals(getUniqueName(), actualStatus.getMemberName());
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    if (dirLauncher == null) {
      try {
        assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
        waitForFileToDelete(this.pidFile);
      } catch (Throwable e) {
        this.errorCollector.addError(e);
      }
      
    } else {
      try {
        assertEquals(Status.STOPPED, dirLauncher.stop().getStatus());
        waitForFileToDelete(this.pidFile);
      } catch (Throwable e) {
        this.errorCollector.addError(e);
      }
    }
  }",False
"  public void testStartUsingServerPortOverridesCacheXml() throws Throwable {
    // verifies part of the fix for #47664
    
    // generate two free ports
    final int[] freeTCPPorts = AvailablePortHelper.getRandomAvailableTCPPorts(2);
    assertTrue(AvailablePort.isPortAvailable(freeTCPPorts[0], AvailablePort.SOCKET));
    assertTrue(AvailablePort.isPortAvailable(freeTCPPorts[1], AvailablePort.SOCKET));
    
    // write out cache.xml with one port
    final CacheCreation creation = new CacheCreation();
    final RegionAttributesCreation attrs = new RegionAttributesCreation(creation);
    attrs.setScope(Scope.DISTRIBUTED_ACK);
    attrs.setDataPolicy(DataPolicy.REPLICATE);
    creation.createRegion(getUniqueName(), attrs);
    creation.addCacheServer().setPort(freeTCPPorts[0]);
    
    File cacheXmlFile = this.temporaryFolder.newFile(getUniqueName() + "".xml"");
    final PrintWriter pw = new PrintWriter(new FileWriter(cacheXmlFile), true);
    CacheXmlGenerator.generate(creation, pw);
    pw.close();
    
    System.setProperty(DistributionConfig.CACHE_XML_FILE_NAME, cacheXmlFile.getCanonicalPath());
    
    // start server
    final Builder builder = new Builder()
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .setServerPort(freeTCPPorts[1])
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"");

    this.launcher = builder.build();
    this.launcher.start();
  
    // wait for server to start up
    try {
      waitForServerToStart(this.launcher);
  
      // validate the pid file and its contents
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertEquals(getPid(), pid);

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(logFileName).exists());

      // verify server used --server-port instead of default or port in cache.xml
      assertTrue(AvailablePort.isPortAvailable(freeTCPPorts[0], AvailablePort.SOCKET));
      assertFalse(AvailablePort.isPortAvailable(freeTCPPorts[1], AvailablePort.SOCKET));
      
      final ServerState status = this.launcher.status();
      final String portString = status.getPort();
      final int port = Integer.valueOf(portString);
      assertEquals(""Port should be "" + freeTCPPorts[1] + "" instead of "" + port, freeTCPPorts[1], port);
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
      
    // stop the server
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForFileToDelete(this.pidFile);
      assertFalse(""PID file still exists!"", pidFile.exists());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStartUsingServerPortOverridesCacheXml() throws Throwable {
    // verifies part of the fix for #47664
    
    // generate two free ports
    final int[] freeTCPPorts = AvailablePortHelper.getRandomAvailableTCPPorts(2);
    assertTrue(AvailablePort.isPortAvailable(freeTCPPorts[0], AvailablePort.SOCKET));
    assertTrue(AvailablePort.isPortAvailable(freeTCPPorts[1], AvailablePort.SOCKET));
    
    // write out cache.xml with one port
    final CacheCreation creation = new CacheCreation();
    final RegionAttributesCreation attrs = new RegionAttributesCreation(creation);
    attrs.setScope(Scope.DISTRIBUTED_ACK);
    attrs.setDataPolicy(DataPolicy.REPLICATE);
    creation.createRegion(getUniqueName(), attrs);
    creation.addCacheServer().setPort(freeTCPPorts[0]);
    
    File cacheXmlFile = this.temporaryFolder.newFile(getUniqueName() + "".xml"");
    final PrintWriter pw = new PrintWriter(new FileWriter(cacheXmlFile), true);
    CacheXmlGenerator.generate(creation, pw);
    pw.close();
    
    System.setProperty(DistributionConfig.CACHE_XML_FILE_NAME, cacheXmlFile.getCanonicalPath());
    
    // start server
    final Builder builder = new Builder()
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .setServerPort(freeTCPPorts[1])
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"")
        .set(DistributionConfig.MCAST_PORT_NAME, ""0"");

    this.launcher = builder.build();
    this.launcher.start();
  
    // wait for server to start up
    try {
      waitForServerToStart(this.launcher);
  
      // validate the pid file and its contents
      this.pidFile = new File(ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertEquals(getPid(), pid);

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(logFileName).exists());

      // verify server used --server-port instead of default or port in cache.xml
      assertTrue(AvailablePort.isPortAvailable(freeTCPPorts[0], AvailablePort.SOCKET));
      assertFalse(AvailablePort.isPortAvailable(freeTCPPorts[1], AvailablePort.SOCKET));
      
      final ServerState status = this.launcher.status();
      final String portString = status.getPort();
      final int port = Integer.valueOf(portString);
      assertEquals(""Port should be "" + freeTCPPorts[1] + "" instead of "" + port, freeTCPPorts[1], port);
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
      
    // stop the server
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForFileToDelete(this.pidFile);
      assertFalse(""PID file still exists!"", pidFile.exists());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void testStartWithDefaultPortInUseFails() throws Throwable {
    // generate one free port and then use TEST_OVERRIDE_DEFAULT_PORT_PROPERTY
    this.socket = SocketCreator.getDefaultInstance().createServerSocket(this.serverPort, 50, null, -1);
    assertFalse(AvailablePort.isPortAvailable(this.serverPort, AvailablePort.SOCKET));
    
    // build and start the server
    final Builder builder = new Builder()
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"");

    this.launcher = builder.build();
    
    RuntimeException expected = null;
    try {
      this.launcher.start();
     
      // why did it not fail like it's supposed to?
      final String property = System.getProperty(AbstractBridgeServer.TEST_OVERRIDE_DEFAULT_PORT_PROPERTY);
      assertNotNull(property);
      assertEquals(this.serverPort, Integer.valueOf(property).intValue());
      assertFalse(AvailablePort.isPortAvailable(this.serverPort, AvailablePort.SOCKET));
      
      fail(""Server port is "" + this.launcher.getCache().getCacheServers().get(0).getPort());
      fail(""ServerLauncher start should have thrown RuntimeException caused by BindException"");
    } catch (RuntimeException e) {
      expected = e;
      assertNotNull(expected.getMessage());
      // BindException text varies by platform
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    try {
      assertNotNull(expected);
      final Throwable cause = expected.getCause();
      assertNotNull(cause);
      assertTrue(cause instanceof BindException);
      // BindException string varies by platform
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      this.pidFile = new File (ProcessType.SERVER.getPidFileName());
      assertFalse(""Pid file should not exist: "" + this.pidFile, this.pidFile.exists());
      
      // creation of log file seems to be random -- look into why sometime
      final String logFileName = getUniqueName()+"".log"";
      assertFalse(""Log file should not exist: "" + logFileName, new File(logFileName).exists());
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    // just in case the launcher started...
    ServerState status = null;
    try {
      status = this.launcher.stop();
    } catch (Throwable t) { 
      // ignore
    }
    
    try {
      waitForFileToDelete(this.pidFile);
      assertEquals(getExpectedStopStatusForNotRunning(), status.getStatus());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStartWithDefaultPortInUseFails() throws Throwable {
    // generate one free port and then use TEST_OVERRIDE_DEFAULT_PORT_PROPERTY
    this.socket = SocketCreator.getDefaultInstance().createServerSocket(this.serverPort, 50, null, -1);
    assertFalse(AvailablePort.isPortAvailable(this.serverPort, AvailablePort.SOCKET));
    
    // build and start the server
    final Builder builder = new Builder()
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"")
        .set(DistributionConfig.MCAST_PORT_NAME, ""0"");

    this.launcher = builder.build();
    
    RuntimeException expected = null;
    try {
      this.launcher.start();
     
      // why did it not fail like it's supposed to?
      final String property = System.getProperty(AbstractBridgeServer.TEST_OVERRIDE_DEFAULT_PORT_PROPERTY);
      assertNotNull(property);
      assertEquals(this.serverPort, Integer.valueOf(property).intValue());
      assertFalse(AvailablePort.isPortAvailable(this.serverPort, AvailablePort.SOCKET));
      
      fail(""Server port is "" + this.launcher.getCache().getCacheServers().get(0).getPort());
      fail(""ServerLauncher start should have thrown RuntimeException caused by BindException"");
    } catch (RuntimeException e) {
      expected = e;
      assertNotNull(expected.getMessage());
      // BindException text varies by platform
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    try {
      assertNotNull(expected);
      final Throwable cause = expected.getCause();
      assertNotNull(cause);
      assertTrue(cause instanceof BindException);
      // BindException string varies by platform
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      this.pidFile = new File (ProcessType.SERVER.getPidFileName());
      assertFalse(""Pid file should not exist: "" + this.pidFile, this.pidFile.exists());
      
      // creation of log file seems to be random -- look into why sometime
      final String logFileName = getUniqueName()+"".log"";
      assertFalse(""Log file should not exist: "" + logFileName, new File(logFileName).exists());
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
    
    // just in case the launcher started...
    ServerState status = null;
    try {
      status = this.launcher.stop();
    } catch (Throwable t) { 
      // ignore
    }
    
    try {
      waitForFileToDelete(this.pidFile);
      assertEquals(getExpectedStopStatusForNotRunning(), status.getStatus());
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void testStartCreatesPidFile() throws Throwable {
    // build and start the Server locally
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"");

    this.launcher = builder.build();
    assertNotNull(this.launcher);

    try {
      this.launcher.start();
      waitForServerToStart(this.launcher);
      assertEquals(Status.ONLINE, this.launcher.status().getStatus());

      // validate the pid file and its contents
      this.pidFile = new File(builder.getWorkingDirectory(), ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      final int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertEquals(getPid(), pid);

      assertEquals(Status.ONLINE, this.launcher.status().getStatus());
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
      
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForFileToDelete(this.pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testStartCreatesPidFile() throws Throwable {
    // build and start the Server locally
    final Builder builder = new Builder()
        .setDisableDefaultServer(true)
        .setMemberName(getUniqueName())
        .setRedirectOutput(true)
        .set(DistributionConfig.LOG_LEVEL_NAME, ""config"")
        .set(DistributionConfig.MCAST_PORT_NAME, ""0"");

    this.launcher = builder.build();
    assertNotNull(this.launcher);

    try {
      this.launcher.start();
      waitForServerToStart(this.launcher);
      assertEquals(Status.ONLINE, this.launcher.status().getStatus());

      // validate the pid file and its contents
      this.pidFile = new File(builder.getWorkingDirectory(), ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      final int pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));
      assertEquals(getPid(), pid);

      assertEquals(Status.ONLINE, this.launcher.status().getStatus());
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
      
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForFileToDelete(this.pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void testStopUsingPid() throws Throwable {
    final List<String> jvmArguments = getJvmArguments();
    jvmArguments.add(""-D"" + getUniqueName() + ""=true"");
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(ServerLauncher.class.getName());
    command.add(ServerLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--disable-default-server"");
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).inputListener(createLoggingListener(""sysout"", getUniqueName() + ""#sysout"")).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).inputListener(createLoggingListener(""syserr"", getUniqueName() + ""#syserr"")).build().start();

    // wait for server to start
    int pid = 0;
    ServerLauncher pidLauncher = null; 
    this.launcher = new ServerLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForServerToStart();

      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());

      // use launcher with pid
      pidLauncher = new Builder()
          .setPid(pid)
          .build();

      assertNotNull(pidLauncher);
      assertFalse(pidLauncher.isRunning());

      // stop with pid only should throw AttachAPINotFoundException
      try {
        pidLauncher.stop();
        fail(""FileProcessController should have thrown AttachAPINotFoundException"");
      } catch (AttachAPINotFoundException e) {
        // passed
      }

    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      // stop the server
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForPidToStop(pid);
      waitForFileToDelete(this.pidFile);
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    } finally {
      new File(ProcessType.SERVER.getStopRequestFileName()).delete(); // TODO: delete
    }
  }",True
"    final List<String> jvmArguments = getJvmArguments();
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(ServerLauncher.class.getName());
    command.add(ServerLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--disable-default-server"");
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).inputListener(createLoggingListener(""sysout"", getUniqueName() + ""#sysout"")).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).inputListener(createLoggingListener(""syserr"", getUniqueName() + ""#syserr"")).build().start();

    // wait for server to start
    int pid = 0;
    ServerLauncher pidLauncher = null; 
    this.launcher = new ServerLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForServerToStart();

      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());

      // use launcher with pid
      pidLauncher = new Builder()
          .setPid(pid)
          .build();

      assertNotNull(pidLauncher);
      assertFalse(pidLauncher.isRunning());

      // stop with pid only should throw AttachAPINotFoundException
      try {
        pidLauncher.stop();
        fail(""FileProcessController should have thrown AttachAPINotFoundException"");
      } catch (AttachAPINotFoundException e) {
        // passed
      }

    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      // stop the server
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForPidToStop(pid);
      waitForFileToDelete(this.pidFile);
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    } finally {
      new File(ProcessType.SERVER.getStopRequestFileName()).delete(); // TODO: delete
    }
  }
}
",False
"  public void testStatusUsingPid() throws Throwable {
    final List<String> jvmArguments = getJvmArguments();
    jvmArguments.add(""-D"" + getUniqueName() + ""=true"");
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(ServerLauncher.class.getName());
    command.add(ServerLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--disable-default-server"");
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    // wait for server to start
    int pid = 0;
    ServerLauncher pidLauncher = null; 
    this.launcher = new ServerLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForServerToStart();

      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());

      // use launcher with pid
      pidLauncher = new Builder()
          .setPid(pid)
          .build();

      assertNotNull(pidLauncher);
      assertFalse(pidLauncher.isRunning());

      // status with pid only should throw AttachAPINotFoundException
      try {
        pidLauncher.status();
        fail(""FileProcessController should have thrown AttachAPINotFoundException"");
      } catch (AttachAPINotFoundException e) {
        // passed
      }
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the server
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForPidToStop(pid, true);
      waitForFileToDelete(this.pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    } finally {
      new File(ProcessType.SERVER.getStatusRequestFileName()).delete(); // TODO: delete
    }
  }",True
"  public void testStatusUsingPid() throws Throwable {
    final List<String> jvmArguments = getJvmArguments();
    
    final List<String> command = new ArrayList<String>();
    command.add(new File(new File(System.getProperty(""java.home""), ""bin""), ""java"").getCanonicalPath());
    for (String jvmArgument : jvmArguments) {
      command.add(jvmArgument);
    }
    command.add(""-cp"");
    command.add(System.getProperty(""java.class.path""));
    command.add(ServerLauncher.class.getName());
    command.add(ServerLauncher.Command.START.getName());
    command.add(getUniqueName());
    command.add(""--disable-default-server"");
    command.add(""--redirect-output"");

    this.process = new ProcessBuilder(command).directory(this.temporaryFolder.getRoot()).start();
    this.processOutReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getInputStream()).build().start();
    this.processErrReader = new ProcessStreamReader.Builder(this.process).inputStream(this.process.getErrorStream()).build().start();

    // wait for server to start
    int pid = 0;
    ServerLauncher pidLauncher = null; 
    this.launcher = new ServerLauncher.Builder()
        .setWorkingDirectory(this.temporaryFolder.getRoot().getCanonicalPath())
        .build();
    try {
      waitForServerToStart();

      // validate the pid file and its contents
      this.pidFile = new File(this.temporaryFolder.getRoot(), ProcessType.SERVER.getPidFileName());
      assertTrue(this.pidFile.exists());
      pid = readPid(this.pidFile);
      assertTrue(pid > 0);
      assertTrue(ProcessUtils.isProcessAlive(pid));

      // validate log file was created
      final String logFileName = getUniqueName()+"".log"";
      assertTrue(""Log file should exist: "" + logFileName, new File(this.temporaryFolder.getRoot(), logFileName).exists());

      // use launcher with pid
      pidLauncher = new Builder()
          .setPid(pid)
          .build();

      assertNotNull(pidLauncher);
      assertFalse(pidLauncher.isRunning());

      // status with pid only should throw AttachAPINotFoundException
      try {
        pidLauncher.status();
        fail(""FileProcessController should have thrown AttachAPINotFoundException"");
      } catch (AttachAPINotFoundException e) {
        // passed
      }
      
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    // stop the server
    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      waitForPidToStop(pid, true);
      waitForFileToDelete(this.pidFile);
    } catch (Throwable e) {
      this.errorCollector.addError(e);
    } finally {
      new File(ProcessType.SERVER.getStatusRequestFileName()).delete(); // TODO: delete
    }
  }
  ",False
"  public void testBootstrapGemFireServerWithSpring() throws Throwable {
    this.launcher = new Builder()
      .setDisableDefaultServer(true)
      .setForce(true)
      .setMemberName(getUniqueName())
      .setSpringXmlLocation(""spring/spring-gemfire-context.xml"")
      .build();

    assertNotNull(this.launcher);

    try {
      assertEquals(Status.ONLINE, this.launcher.start().getStatus());

      waitForServerToStart(this.launcher);

      Cache cache = this.launcher.getCache();

      assertNotNull(cache);
      assertTrue(cache.getCopyOnRead());
      assertEquals(0.95f, cache.getResourceManager().getCriticalHeapPercentage(), 0);
      assertEquals(0.85f, cache.getResourceManager().getEvictionHeapPercentage(), 0);
      assertFalse(cache.getPdxIgnoreUnreadFields());
      assertTrue(cache.getPdxPersistent());
      assertTrue(cache.getPdxReadSerialized());
    }
    catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      assertNull(this.launcher.getCache());
    }
    catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",True
"  public void testBootstrapGemFireServerWithSpring() throws Throwable {
    this.launcher = new Builder()
      .setDisableDefaultServer(true)
      .setForce(true)
      .setMemberName(getUniqueName())
      .setSpringXmlLocation(""spring/spring-gemfire-context.xml"")
      .set(DistributionConfig.MCAST_PORT_NAME, ""0"")
      .build();

    assertNotNull(this.launcher);

    try {
      assertEquals(Status.ONLINE, this.launcher.start().getStatus());

      waitForServerToStart(this.launcher);

      Cache cache = this.launcher.getCache();

      assertNotNull(cache);
      assertTrue(cache.getCopyOnRead());
      assertEquals(0.95f, cache.getResourceManager().getCriticalHeapPercentage(), 0);
      assertEquals(0.85f, cache.getResourceManager().getEvictionHeapPercentage(), 0);
      assertFalse(cache.getPdxIgnoreUnreadFields());
      assertTrue(cache.getPdxPersistent());
      assertTrue(cache.getPdxReadSerialized());
    }
    catch (Throwable e) {
      this.errorCollector.addError(e);
    }

    try {
      assertEquals(Status.STOPPED, this.launcher.stop().getStatus());
      assertNull(this.launcher.getCache());
    }
    catch (Throwable e) {
      this.errorCollector.addError(e);
    }
  }",False
"  public void test() throws IllegalArgumentException, IllegalAccessException {
    long size = ObjectGraphSizer.size(new Object());
    assertEquals(OBJECT_SIZE, 8, size);
    
    assertEquals(roundup(OBJECT_SIZE + 4), ObjectGraphSizer.size(new TestObject1()));
    assertEquals(roundup(OBJECT_SIZE + 4), ObjectGraphSizer.size(new TestObject2()));
    assertEquals(roundup(OBJECT_SIZE), ObjectGraphSizer.size(new TestObject3()));
    assertEquals(roundup(OBJECT_SIZE * 2 + REFERENCE_SIZE), ObjectGraphSizer.size(new TestObject3(), true));
    assertEquals(roundup(OBJECT_SIZE + REFERENCE_SIZE), ObjectGraphSizer.size(new TestObject4()));
    assertEquals(roundup(OBJECT_SIZE + REFERENCE_SIZE) + roundup(OBJECT_SIZE + 4), ObjectGraphSizer.size(new TestObject5()));
    assertEquals(roundup(OBJECT_SIZE + REFERENCE_SIZE) + roundup(OBJECT_SIZE + REFERENCE_SIZE * 4 + 4) + roundup(OBJECT_SIZE + 4), ObjectGraphSizer.size(new TestObject6()));
  }",True
"  public void test() throws IllegalArgumentException, IllegalAccessException {
    assertEquals(roundup(OBJECT_SIZE), ObjectGraphSizer.size(new Object()));
    
    assertEquals(roundup(OBJECT_SIZE + 4), ObjectGraphSizer.size(new TestObject1()));
    assertEquals(roundup(OBJECT_SIZE + 4), ObjectGraphSizer.size(new TestObject2()));
    assertEquals(roundup(OBJECT_SIZE), ObjectGraphSizer.size(new TestObject3()));
    assertEquals(roundup(OBJECT_SIZE * 2 + REFERENCE_SIZE), ObjectGraphSizer.size(new TestObject3(), true));
    assertEquals(roundup(OBJECT_SIZE + REFERENCE_SIZE), ObjectGraphSizer.size(new TestObject4()));
    assertEquals(roundup(OBJECT_SIZE + REFERENCE_SIZE) + roundup(OBJECT_SIZE + 4), ObjectGraphSizer.size(new TestObject5()));
    assertEquals(roundup(OBJECT_SIZE + REFERENCE_SIZE) + roundup(OBJECT_SIZE + REFERENCE_SIZE * 4 + 4) + roundup(OBJECT_SIZE + 4), ObjectGraphSizer.size(new TestObject6()));
    assertEquals(roundup(OBJECT_SIZE + 7), ObjectGraphSizer.size(new TestObject7()));
  }",False
"  public static DistributionManager create(InternalDistributedSystem system)
  {

    DistributionManager dm = null;
    
    try {

      int vmKind;
      
      if (Boolean.getBoolean(InternalLocator.FORCE_LOCATOR_DM_TYPE)) {
        // if this DM is starting for a locator, set it to be a locator DM
        vmKind = LOCATOR_DM_TYPE;

      } else if (isDedicatedAdminVM) {
        vmKind = ADMIN_ONLY_DM_TYPE;

      } else {
        vmKind = NORMAL_DM_TYPE;
      }
    
      RemoteTransportConfig transport = new RemoteTransportConfig(system.getConfig(), vmKind);
      transport.setIsReconnectingDS(system.isReconnectingDS());
      transport.setOldDSMembershipInfo(system.oldDSMembershipInfo());
      
      long start = System.currentTimeMillis();

      dm = new DistributionManager(system, transport);
      dm.assertDistributionManagerType();

      {
        InternalDistributedMember id = dm.getDistributionManagerId();
        if (!"""".equals(id.getName())) {
          for (InternalDistributedMember m: (List<InternalDistributedMember>)dm.getViewMembers()) {
            if (m.equals(id)) {
              // I'm counting on the members returned by getViewMembers being ordered such that
              // members that joined before us will precede us AND members that join after us
              // will succeed us.
              // SO once we find ourself break out of this loop.
              break;
            }
            if (id.getName().equals(m.getName())) {
              if (dm.getMembershipManager().verifyMember(m, ""member is using the name of "" + id)) {
                throw new IncompatibleSystemException(""Member "" + id + "" could not join this distributed system because the existing member "" + m + "" used the same name. Set the \""name\"" gemfire property to a unique value."");
              }
            }
          }
        }
        dm.addNewMember(id, null); // add ourselves
        dm.selectElder(); // ShutdownException could be thrown here
      }

      // Send out a StartupMessage to the other members.
      StartupOperation op = new StartupOperation(dm, transport);

      try {
        if (!dm.sendStartupMessage(op, true)) {
          // We'll we didn't hear back from anyone else.  We assume that
          // we're the first one.
          if (dm.getOtherDistributionManagerIds().size() == 0) {
            logger.info(LocalizedMessage.create(LocalizedStrings.DistributionManager_DIDNT_HEAR_BACK_FROM_ANY_OTHER_SYSTEM_I_AM_THE_FIRST_ONE));
          } else if (transport.isMcastEnabled()) {
            // perform a multicast ping test
            if (!dm.testMulticast()) {
              logger.warn(LocalizedMessage.create(
                  LocalizedStrings.DistributionManager_RECEIVED_NO_STARTUP_RESPONSES_BUT_OTHER_MEMBERS_EXIST_MULTICAST_IS_NOT_RESPONSIVE));
            }
          }
        }
      } catch (InterruptedException ex) {
        Thread.currentThread().interrupt();
        // This is ALWAYS bad; don't consult a CancelCriterion.
        throw new InternalGemFireException(LocalizedStrings.DistributionManager_INTERRUPTED_WHILE_WAITING_FOR_FIRST_STARTUPRESPONSEMESSAGE.toLocalizedString(), ex);
      } catch (IncompatibleSystemException ex) {
        logger.fatal(ex.getMessage(), ex);
        throw ex;
      } finally {
        dm.readyToSendMsgs();
      }

      if (logger.isInfoEnabled()) {
        long delta = System.currentTimeMillis() - start;
        Object[] logArgs = new Object[] {
            dm.getDistributionManagerId(),
            transport,
            Integer.valueOf(dm.getOtherDistributionManagerIds().size()),
            dm.getOtherDistributionManagerIds(), 
            (logger.isInfoEnabled(LogMarker.DM) ? "" (VERBOSE, took "" + delta + "" ms)"" : """"),
            ((dm.getDMType() == ADMIN_ONLY_DM_TYPE) ? "" (admin only)"" : (dm.getDMType() == LOCATOR_DM_TYPE) ? "" (locator)"" : """")
        };
        logger.info(LogMarker.DM, LocalizedMessage.create(
            LocalizedStrings.DistributionManager_DISTRIBUTIONMANAGER_0_STARTED_ON_1_THERE_WERE_2_OTHER_DMS_3_4_5, logArgs));
        MembershipLogger.logStartup(dm.getDistributionManagerId());
      }
      return dm;
    }
    catch (RuntimeException r) {
      if (dm != null) {
        if (logger.isDebugEnabled()) {
          logger.debug(""cleaning up incompletely started DistributionManager due to exception"", r); 
        }
        dm.uncleanShutdown(true);
      }
      throw r;
    }
  }",True
"  public static DistributionManager create(InternalDistributedSystem system)
  {

    DistributionManager dm = null;
    
    try {

      int vmKind;
      
      if (Boolean.getBoolean(InternalLocator.FORCE_LOCATOR_DM_TYPE)) {
        // if this DM is starting for a locator, set it to be a locator DM
        vmKind = LOCATOR_DM_TYPE;

      } else if (isDedicatedAdminVM) {
        vmKind = ADMIN_ONLY_DM_TYPE;

      } else {
        vmKind = NORMAL_DM_TYPE;
      }
    
      RemoteTransportConfig transport = new RemoteTransportConfig(system.getConfig(), vmKind);
      transport.setIsReconnectingDS(system.isReconnectingDS());
      transport.setOldDSMembershipInfo(system.oldDSMembershipInfo());
      
      long start = System.currentTimeMillis();

      dm = new DistributionManager(system, transport);
      dm.assertDistributionManagerType();

      {
        InternalDistributedMember id = dm.getDistributionManagerId();
        if (!"""".equals(id.getName())) {
          for (InternalDistributedMember m: (List<InternalDistributedMember>)dm.getViewMembers()) {
            if (m.equals(id)) {
              // I'm counting on the members returned by getViewMembers being ordered such that
              // members that joined before us will precede us AND members that join after us
              // will succeed us.
              // SO once we find ourself break out of this loop.
              break;
            }
            if (id.getName().equals(m.getName())) {
              if (dm.getMembershipManager().verifyMember(m, ""member is using the name of "" + id)) {
                throw new IncompatibleSystemException(""Member "" + id + "" could not join this distributed system because the existing member "" + m + "" used the same name. Set the \""name\"" gemfire property to a unique value."");
              }
            }
          }
        }
        dm.addNewMember(id, null); // add ourselves
        dm.selectElder(); // ShutdownException could be thrown here
      }

      // Send out a StartupMessage to the other members.
      StartupOperation op = new StartupOperation(dm, transport);

      try {
        if (!dm.sendStartupMessage(op, true)) {
          // We'll we didn't hear back from anyone else.  We assume that
          // we're the first one.
          if (dm.getOtherDistributionManagerIds().size() == 0) {
            logger.info(LocalizedMessage.create(LocalizedStrings.DistributionManager_DIDNT_HEAR_BACK_FROM_ANY_OTHER_SYSTEM_I_AM_THE_FIRST_ONE));
          } else if (transport.isMcastEnabled()) {
            // perform a multicast ping test
            if (!dm.testMulticast()) {
              logger.warn(LocalizedMessage.create(
                  LocalizedStrings.DistributionManager_RECEIVED_NO_STARTUP_RESPONSES_BUT_OTHER_MEMBERS_EXIST_MULTICAST_IS_NOT_RESPONSIVE));
            }
          }
        }
      } catch (InterruptedException ex) {
        Thread.currentThread().interrupt();
        // This is ALWAYS bad; don't consult a CancelCriterion.
        throw new InternalGemFireException(LocalizedStrings.DistributionManager_INTERRUPTED_WHILE_WAITING_FOR_FIRST_STARTUPRESPONSEMESSAGE.toLocalizedString(), ex);
      } catch (IncompatibleSystemException ex) {
        logger.fatal(ex.getMessage(), ex);
        throw ex;
      } finally {
        dm.readyToSendMsgs();
      }

      if (logger.isInfoEnabled()) {
        long delta = System.currentTimeMillis() - start;
        Object[] logArgs = new Object[] {
            dm.getDistributionManagerId(),
            transport,
            Integer.valueOf(dm.getOtherDistributionManagerIds().size()),
            dm.getOtherDistributionManagerIds(), 
            (logger.isInfoEnabled(LogMarker.DM) ? "" (VERBOSE, took "" + delta + "" ms)"" : """"),
            ((dm.getDMType() == ADMIN_ONLY_DM_TYPE) ? "" (admin only)"" : (dm.getDMType() == LOCATOR_DM_TYPE) ? "" (locator)"" : """")
        };
        logger.info(LogMarker.DM, LocalizedMessage.create(
            LocalizedStrings.DistributionManager_DISTRIBUTIONMANAGER_0_STARTED_ON_1_THERE_WERE_2_OTHER_DMS_3_4_5, logArgs));

logger.info(""My ID is {}"", Integer.toHexString(System.identityHashCode(dm.getDistributionManagerId())));
        
        MembershipLogger.logStartup(dm.getDistributionManagerId());
      }
      return dm;
    }
    catch (RuntimeException r) {
      if (dm != null) {
        if (logger.isDebugEnabled()) {
          logger.debug(""cleaning up incompletely started DistributionManager due to exception"", r); 
        }
        dm.uncleanShutdown(true);
      }
      throw r;
    }
  }",False
"  public void incUcastReadBytes(long amount) {
    stats.incInt(ucastReadsId, 1);
    stats.incLong(ucastReadBytesId, amount);
  }",True
"  }
  public long getAsyncQueueAddTime() {
     return stats.getLong(asyncQueueAddTimeId);
  }",False
"  public void incUcastWriteBytes(int bytesWritten) {
    stats.incInt(ucastWritesId, 1);
    stats.incLong(ucastWriteBytesId, bytesWritten);
  }",False
"  public void incFlowControlResponses() {
    stats.incInt(flowControlResponsesId, 1);
  }",True
"  }
  
  public Statistics getStats(){",False
"  public void incjgUpTime(long value)
  {
    stats.incLong(jgUpTimeId, value);
  }",True
"  public void incjChannelUpTime(long value)
  {
    stats.incLong(jChannelUpTimeId, value);
  }",True
"  public void incFlowControlRequests() {
    stats.incInt(flowControlRequestsId, 1);
  }",True
"  }
  public void incInitialImageRequestsInProgress(int val) {
    this.stats.incInt(initialImageRequestsInProgressId, val);",False
"  public void setJgUNICASTsentHighPriorityMessagesSize(long amount) {
    stats.setLong(jgUcastSentHighPriorityMessagesSizeId, amount);
  }",True
"  public void incJgFCsentThrottleRequests(long value)
  {
    stats.incLong(jgFCsentThrottleRequestsId, value);
  }",True
"  public void incJgFragmentsCreated(long numFrags) {
    stats.incLong(jgFragmentsCreatedId, numFrags);
  }",True
"  public void incJgUNICASTdataReceived(long amount) {
    stats.incLong(jgUNICASTdataReceivedTimeId, amount);
  }",True
"  public long startMcastWrite() {
    return getStatTime();
  }",True
"      }
    }
  }",False
"  public void setJgQueuedMessagesSize(long amount) {
    stats.setLong(jgQueuedMessagesSizeId, amount);
  }",True
"  public void setJgUNICASTreceivedMessagesSize(long amount) {
    stats.setLong(jgUcastReceivedMessagesSizeId, amount);
  }",True
"  public void incMcastReadBytes(long amount) {
    stats.incInt(mcastReadsId, 1);
    stats.incLong(mcastReadBytesId, amount);
  }",True
"  public void incMcastReadBytes(int amount) {
    stats.incInt(mcastReadsId, 1);
    stats.incLong(mcastReadBytesId, amount);
  }",False
"  public void incJgFragmentationsPerformed() {
    stats.incLong(jgFragmentationsPerformedId, 1);
  }",True
"  public void incJgFCreplenish(long value)
  {
    stats.incLong(jgFCreplenishId, value);

  }",True
"  public void incUcastReadBytes(int amount) {
    stats.incInt(ucastReadsId, 1);
    stats.incLong(ucastReadBytesId, amount);
  }",False
"  public long startFlowControlThrottleWait() {
    stats.incInt(flowControlThrottleWaitsInProgressId, 1);
    return 1;
  }",True
"  public void setJgSTABLEsentMessagesSize(long amount) {
    stats.setLong(jgSentMessagesPoolSizeId, amount);
  }",True
"  public long startUcastWrite() {
    return getStatTime();
  }",True
"    if (shared) {
      if (preserveOrder) {
        stats.incInt(sharedOrderedSenderConnectionsId, -1);",False
"  public void endUcastWrite(long start, int bytesWritten) {
    if (enableClockStats) {
      stats.incLong(ucastWriteTimeId, getStatTime()-start);
    }
    stats.incInt(ucastWritesId, 1);
    stats.incLong(ucastWriteBytesId, bytesWritten);
  }",True
"      } else {
        stats.incInt(sharedUnorderedSenderConnectionsId, -1);
      }
    } else {
      if (preserveOrder) {
        stats.incInt(threadOrderedSenderConnectionsId, -1);
      } else {",False
"  public void incJgFCresumes(long value)
  {
   stats.incLong(jgFCresumesId, value);
  }",True
"  public void endUcastFlush(long start) {
    if (enableClockStats) {
      stats.incLong(ucastFlushTimeId, getStatTime()-start);
    }
  }",True
"    this.stats.incInt(initialImageMessagesInFlightId, val);
  }
  
  public int getInitialImageRequestsInProgress() {
    return this.stats.getInt(initialImageRequestsInProgressId);",False
"  public void endMcastWrite(long start, int bytesWritten) {
    stats.incInt(mcastWritesId, 1);
    if (enableClockStats) {
      stats.incLong(mcastWriteTimeId, getStatTime()-start);
    }
    stats.incLong(mcastWriteBytesId, bytesWritten);
  }",True
"
  public int getAsyncSocketWritesInProgress() {
     return stats.getInt(asyncSocketWritesInProgressId);
  }
  public int getAsyncSocketWrites() {
     return stats.getInt(asyncSocketWritesId);
  }",False
"     return stats.getLong(asyncSocketWriteBytesId);
  }
  public long getAsyncSocketWriteTime() {
     return stats.getLong(asyncSocketWriteTimeId);",False
"  public void incJgSTABLEmessages(long value)
  {
    stats.incLong(jgSTABLEmessagesId, value);
  }",True
"  public void incJgFCsendBlocks(long value)
  {
   stats.incLong(jgFCsendBlocksId, value);

  }",True
"  public void incJgFCsentCredits(long value)
  {
    stats.incLong(jgFCsentCreditsId, value);
  }",True
"  public void endFlowControlWait(long start) {
    stats.incInt(flowControlWaitsInProgressId, -1);
  }",True
"  public void incjgDownTime(long value)
  {
    stats.incLong(jgDownTimeId, value);
  }",True
"  public void incJgNAKACKwaits(long value) {
    stats.incLong(jgNAKACKwaitsId, value);
  }",True
"  public void incJgSTABLEmessagesSent(long value)
  {
    stats.incLong(jgSTABLEmessagesSentId, value);
  }",True
"  public void incJgSTABLEsuspendTime(long value)
  {
    stats.incLong(jgSTABLEsuspendTimeId, value);
  }",True
"  public void incJgFCautoRequests(long value)
  {
    stats.incLong(jgFCautoRequestsId, value);

  }",True
"  public void incJgSTABILITYmessages(long value)
  {
    stats.incLong(jgSTABILITYmessagesId, value);
  }",True
"  public void incMcastWriteBytes(int bytesWritten) {
    stats.incInt(mcastWritesId, 1);
    stats.incLong(mcastWriteBytesId, bytesWritten);
  }",False
"  public void endFlowControlThrottleWait(long start) {
    stats.incInt(flowControlThrottleWaitsInProgressId, -1);
  }",True
"  public void setJgSTABLEreceivedMessagesSize(long amount) {
    stats.setLong(jgReceivedMessagesSizeId, amount);
  }",True
"  public void setJgUNICASTsentMessagesSize(long amount) {
    stats.setLong(jgUcastSentMessagesSizeId, amount);
  }",True
"  public long startFlowControlWait() {
    stats.incInt(flowControlWaitsInProgressId, 1);
    return 1;
  }",True
"    return stats;
  }
}
",False
"  public long startUcastFlush() {
    stats.incInt(ucastFlushesId, 1);
    return getStatTime();
  }",True
"  public int getInitialImageMessagesInFlight() {
    return this.stats.getInt(initialImageMessagesInFlightId);
  }
  public void incInitialImageMessagesInFlight(int val) {",False
    public void setJgSTABLEreceivedMessagesSize(long value) {},True
"    public void decSenders(boolean shared, boolean preserveOrder) {}",False
    public int getDLockWaitsCompleted() {return 0;},True
    public void incMcastReadBytes(long amount) {},True
    public void incLostLease() {},False
    public void incJgNAKACKwaits(long value) {},True
    public void endAsyncQueueFlush(long start) {},False
    public long startUcastWrite() { return 0; },True
    public long getReplyWaitTime() {return 0;},False
    public void incDLockVetosSent(int ops) {},True
    public long getDLockWaitTime() {return 0;},True
    public void incBroadcastMessagesTime(long nanos) {},False
    public void incDLockVetosReceived(int ops) {},True
    public void incReceivedMessages(long messages) {},False
"    public void endUcastWrite(long start, int bytesWritten) {}",True
    public void endFlowControlWait(long start) {},True
    public void incFailedConnect() {},False
    public void incUcastWrites(int bytesWritten) {},True
    public long startReplyWait() {return 0;},False
"    public void incJgFCsentThrottleRequests(long value)
    {}",True
"    @Override
    public void incBatchSendTime(long start) {}",False
    public void incFlowControlRequests() {},True
    public void incUcastReadBytes(long amount) {},True
    public void incjgDownTime(long value){},True
    public void setJgSTABLEsentMessagesSize(long value) {},True
    public void incjChannelUpTime(long value){},True
    public void incDLockAbstainsSent(int ops) {},True
    public void incJgSTABLEmessages(long value) {},True
    public void incDLockYesVotesReceived(int ops) {},True
    public long getReceivedBytes() {return 0;},False
    public void endFlowControlThrottleWait(long start) {},True
    public void incReconnectAttempts() {},False
"    public void endMcastWrite(long start, int bytesWritten) {}",True
"    public void endReplyWait(long startNanos, long startMillis) {}",False
"    public void incJgFCsendBlocks(long value)
    {}",True
"    @Override
    public void endDeserialization(long start, int bytes) {}",False
    public void incDLockNoVotesSent(int ops) {},True
"    public void incJgFCsentCredits(long value)
    {}",True
"    @Override
    public void endMsgDeserialization(long start) {}",False
    public int getDLockWaitsInProgress() {return 0;},True
    public long getBroadcastMessagesTime() {return 0;},False
"    public void incJgFragmentsCreated(long numFrags)
    {}",True
"    @Override
    public void incBatchWaitTime(long start) {}",False
    public long startUcastFlush() { return 0; },True
    public void incDLockYesVotesSent(int ops) {},True
"    public void setJgUNICASTsentMessagesSize(long amount) {
    }",True
"    @Override
    public void incUcastWriteBytes(int bytesWritten) {}",False
    public void incJgSTABLEsuspendTime(long value) {},True
    public int getSendersSU() { return 0; },False
    public void incJgSTABLEmessagesSent(long value) {},True
    public long startSocketWrite(boolean sync) {return 0; },False
"    public void incThreadOwnedReceivers(long value, int dominoCount) {}",True
"    public void incThreadOwnedReceivers(long value, int dominoCount) {
    }",False
    public void incMcastReadBytes(int amount) {},False
    public void incUcastReadBytes(int amount) {},False
    public void incJgSTABILITYmessages(long value) {},True
"    public void incJgFCresumes(long value)
    {}",True
"    @Override
    public long startMsgDeserialization() {return 0;}",False
"    public void setJgUNICASTsentHighPriorityMessagesSize(long amount) {
    }",True
"    @Override
    public void incMcastWriteBytes(int bytesWritten) {}",False
    public void incUcastWriteBytes(int bytesWritten) {},False
    public void endUcastFlush(long start) {},True
    public void decReceivers() {},False
    public void incJgUNICASTdataReceived(long amount) {},True
"    public void incJgFCautoRequests(long value)
    {}",True
"    @Override
    public long startMsgSerialization() {return 0;}",False
"    public void endDLockWait(long start, boolean gotit) {}",True
    public long getReceivedMessages() {return 0;},False
"    public void setJgUNICASTreceivedMessagesSize(long amount) {
    }",True
"    @Override
    public void incBatchFlushTime(long start) {}",False
    public void setJgQueuedMessagesSize(long value) {},True
    public void incMcastWriteBytes(int bytesWritten) {},False
    public void incDLockAbstainsReceived(int ops) {},True
    public void incSentBytes(long bytes) {},False
    public void incDLockNoVotesReceived(int ops) {},True
    public void incReceivedBytes(long bytes) {},False
    public void incMcastWrites(int bytesWritten) {},True
    public long startDLockWait() {return 0;},True
    public void incjgUpTime(long value){},True
    public long startSerialization() {return 0;},False
    public long startFlowControlWait() { return 0; },True
    public void incFlowControlResponses() {},True
    public void incFailedAccept() {},False
    public long startMcastWrite() { return 0; },True
"    public void incJgFCreplenish(long value)
    {}",True
"    @Override
    public void endMsgSerialization(long start) {}",False
    public long startFlowControlThrottleWait() { return 0; },True
"    public void incJgFragmentationsPerformed()
    {}",True
"    @Override
    public void incBatchCopyTime(long start) {}",False
"  public static void main(String... args) throws Exception {
    if (args.length == 0) {
      printHelp();
      return;
    }
    
    DependencyGraph graph;

    switch (args[0]) {
    case ""print"":
      graph = loadGraphs(1, args);
      System.out.println(prettyFormat(graph));
      break;
    case ""findDeadlockOnly"":
      graph = loadGraphs(1, args);
      List<Dependency> cycle = graph.findCycle();
      if (cycle == null) {
        System.out.println(""no deadlock found"");
      } else {
        System.out.println(""deadlocked threads: \n"" + cycle);
      }
      break;
    case ""findDeepestGraph"":
      graph = loadGraphs(1, args);
      DependencyGraph result = graph.findDeepestGraph();
      if (result == null) {
        System.out.println(""no deepest graph could be found!"");
      } else {
        System.out.println(""deepest graph: \n"" + prettyFormat(result));
      }
      break;
    case ""findThread"":
      graph = loadGraphs(2, args);
      result = graph.findDependenciesWith(args[1]);
      if (result == null) {
        System.out.println(""thread not found!"");
      } else {
        System.out.println(prettyFormat(sortDependencies(result.getEdges())));
      }
      break;
    default:
      printHelp();
      break;
    }
    
  }",True
"  public static void main(String... args) throws Exception {
    if (args.length == 0) {
      printHelp();
      return;
    }
    
    DependencyGraph graph;

    switch (args[0]) {
    case ""print"":
      graph = loadGraphs(1, args);
      System.out.println(prettyFormat(graph));
      break;
    case ""findDeadlockOnly"":
      graph = loadGraphs(1, args);
      List<Dependency> cycle = graph.findCycle();
      if (cycle == null) {
        System.out.println(""no deadlock found"");
      } else {
        System.out.println(""deadlocked threads: \n"" + cycle);
      }
      break;
    case ""findDeepestGraph"":
      graph = loadGraphs(1, args);
      graph = graph.findDeepestGraph();
      if (graph == null) {
        System.out.println(""no deepest graph could be found!"");
      } else {
        System.out.println(""deepest graph: \n"" + prettyFormat(graph));
      }
      break;
    case ""findThread"":
      graph = loadGraphs(2, args);
      graph = graph.findDependenciesWith(args[1]);
      if (graph == null) {
        System.out.println(""thread not found! Try using the print command to see all threads and locate the name of the one you're interested in?"");
      } else {
        System.out.println(prettyFormat(sortDependencies(graph.getEdges())));
      }
      break;
    default:
      printHelp();
      break;
    }
    
  }",False
"  public DependencyGraph findDependenciesWith(String objectName) {
    Object obj = null;
    Dependency objDep = null;
    for (Dependency dep: edges) {
      if (dep.depender.toString().contains(objectName)) {
        obj = dep.depender;
        objDep = dep;
        break;
      }
      if (dep.dependsOn.toString().contains(objectName)) {
        obj = dep.dependsOn;
        objDep = dep;
        break;
      }
    }
    if (obj == null) {
      return null;
    }
    
    DependencyGraph result = new DependencyGraph();
    
    Set<Object> dependsOnObj = new HashSet<>();
    dependsOnObj.add(obj);
    boolean anyAdded = true;
    while (anyAdded) {
      anyAdded = false;
      for (Dependency dep: edges) {
        if (dependsOnObj.contains(dep.dependsOn)
            && !dependsOnObj.contains(dep.depender)) {
          anyAdded = true;
          dependsOnObj.add(dep.depender);
        }
      }
    }
    for (Object depender: dependsOnObj) {
      if (!result.getVertices().contains(depender)) {
        DependencyGraph subgraph = getSubGraph(depender);
        result.addEdges(subgraph.getEdges());
      }
    }
    return result;
  }",True
"  public DependencyGraph findDependenciesWith(String objectName) {
    Object obj = null;
    Dependency objDep = null;
    for (Dependency dep: edges) {
      if (dep.depender.toString().contains(objectName)) {
        obj = dep.depender;
        objDep = dep;
        break;
      }
      if (dep.dependsOn.toString().contains(objectName)) {
        obj = dep.dependsOn;
        objDep = dep;
        break;
      }
    }
    if (obj == null) {
      return null;
    }
    
    DependencyGraph result = new DependencyGraph();
    
    // expand the dependency set to include all incoming
    // references.  These will give us graphs of endpoints
    // that reach to the node we're interested in
    Set<Object> dependsOnObj = new HashSet<>();
    dependsOnObj.add(obj);
    boolean anyAdded = true;
    while (anyAdded) {
      anyAdded = false;
      for (Dependency dep: edges) {
        if (dependsOnObj.contains(dep.dependsOn)
            && !dependsOnObj.contains(dep.depender)) {
          anyAdded = true;
          dependsOnObj.add(dep.depender);
        }
      }
    }
    // find all of the downward graphs for each depender
    // and add their vertices.  These are things dependedOn
    // by the node we're interested in.
    for (Object depender: dependsOnObj) {
      if (!result.getVertices().contains(depender)) {
        DependencyGraph subgraph = getSubGraph(depender);
        result.addEdges(subgraph.getEdges());
      }
    }
    return result;
  }",False
"  public void setVmViewId(int p) {
    this.vmViewId = p;
    synchPayload();
  }",True
"  public void setVmViewId(int p) {
    this.vmViewId = p;
    synchPayload();
    cachedToString = null;
  }",False
"  public void readAdditionalData(DataInput in) throws ClassNotFoundException,
      IOException {
    this.uuidMSBs = in.readLong();
    this.uuidLSBs = in.readLong();
//    this.uuidLSBs = InternalDataSerializer.readUnsignedVL(in);
//    this.uuidMSBs = InternalDataSerializer.readUnsignedVL(in);
  }",True
"  public void writeAdditionalData(DataOutput out) throws IOException {
    out.writeLong(uuidMSBs);
    out.writeLong(uuidLSBs);
//    InternalDataSerializer.writeSignedVL(uuidLSBs, out);
//    InternalDataSerializer.writeSignedVL(uuidMSBs, out);
  }",True
"
  @Override
  public void readAdditionalData(DataInput in) throws ClassNotFoundException,
      IOException {
    this.uuidMSBs = in.readLong();
    this.uuidLSBs = in.readLong();",False
"  public void fromData(DataInput in) throws IOException, ClassNotFoundException {
    this.versionOrdinal = Version.readOrdinal(in);
    
    int flags = in.readInt();
    this.splitBrainEnabled = (flags & SB_ENABLED) != 0;
    this.preferredForCoordinator = (flags & PREFERRED_FOR_COORD) != 0;
    
    this.inetAddr = DataSerializer.readInetAddress(in);
    this.udpPort = in.readInt();
    this.vmViewId = in.readInt();
    this.directPort = in.readInt();
    this.memberWeight = in.readByte();
    this.processId = in.readInt();
    this.vmKind = in.readInt();
    this.name = DataSerializer.readString(in);
    this.groups = DataSerializer.readStringArray(in);
    this.uuidLSBs = in.readLong();
    this.uuidMSBs = in.readLong();
//    this.uuidLSBs = InternalDataSerializer.readUnsignedVL(in);
//    this.uuidMSBs = InternalDataSerializer.readUnsignedVL(in);
  }",True
"  public void fromData(DataInput in) throws IOException, ClassNotFoundException {
    this.versionOrdinal = Version.readOrdinal(in);
    
    int flags = in.readInt();
    this.splitBrainEnabled = (flags & SB_ENABLED) != 0;
    this.preferredForCoordinator = (flags & PREFERRED_FOR_COORD) != 0;
    
    this.inetAddr = DataSerializer.readInetAddress(in);
    this.udpPort = in.readInt();
    this.vmViewId = in.readInt();
    this.directPort = in.readInt();
    this.memberWeight = in.readByte();
    this.processId = in.readInt();
    this.vmKind = in.readInt();
    this.name = DataSerializer.readString(in);
    this.groups = DataSerializer.readStringArray(in);
    this.uuidMSBs = in.readLong();
    this.uuidLSBs = in.readLong();
  }",False
"  public void toData(DataOutput out) throws IOException {
    Version.writeOrdinal(out, this.versionOrdinal, true);
    
    int flags = 0;
    if (splitBrainEnabled) flags |= SB_ENABLED;
    if (preferredForCoordinator) flags |= PREFERRED_FOR_COORD;
    out.writeInt(flags);

    DataSerializer.writeInetAddress(inetAddr, out);
    out.writeInt(udpPort);
    out.writeInt(vmViewId);
    out.writeInt(directPort);
    out.writeByte(memberWeight);
    out.writeInt(processId);
    out.writeInt(vmKind);
    DataSerializer.writeString(name,  out);
    DataSerializer.writeStringArray(groups, out);
    out.writeLong(uuidMSBs);
    out.writeLong(uuidLSBs);
//    InternalDataSerializer.writeSignedVL(uuidLSBs, out);
//    InternalDataSerializer.writeSignedVL(uuidMSBs, out);
  }",True
"  public void toData(DataOutput out) throws IOException {
    Version.writeOrdinal(out, this.versionOrdinal, true);
    
    int flags = 0;
    if (splitBrainEnabled) flags |= SB_ENABLED;
    if (preferredForCoordinator) flags |= PREFERRED_FOR_COORD;
    out.writeInt(flags);

    DataSerializer.writeInetAddress(inetAddr, out);
    out.writeInt(udpPort);
    out.writeInt(vmViewId);
    out.writeInt(directPort);
    out.writeByte(memberWeight);
    out.writeInt(processId);
    out.writeInt(vmKind);
    DataSerializer.writeString(name,  out);
    DataSerializer.writeStringArray(groups, out);
    out.writeLong(uuidMSBs);
    out.writeLong(uuidLSBs);
  }

  @Override",False
"  public void memberShutdown(DistributedMember mbr, String reason) {
  }",False
"  private boolean attemptToJoin(InternalDistributedMember coord) {
    // send a join request to the coordinator and wait for a response
    logger.info(""Attempting to join the distributed system through coordinator "" + coord + "" using address "" + this.localAddress);
    JoinRequestMessage req = new JoinRequestMessage(coord, this.localAddress, 
        services.getAuthenticator().getCredentials(coord));

    services.getMessenger().send(req);
    
    JoinResponseMessage response = null;
    synchronized(joinResponse) {
      if (joinResponse[0] == null) {
        try {
          joinResponse.wait(services.getConfig().getJoinTimeout()/JOIN_ATTEMPTS);
        } catch (InterruptedException e) {
          Thread.currentThread().interrupt();
          return false;
        }
      }
      response = joinResponse[0];
    }
    if (response != null) {
      joinResponse[0] = null;
      String failReason = response.getRejectionMessage();
      if (failReason != null) {
        if (failReason.contains(""Rejecting the attempt of a member using an older version"")
            || failReason.contains(""15806"")) {
          throw new SystemConnectException(failReason);
        }
        throw new AuthenticationFailedException(failReason);
      }
      if (response.getCurrentView() != null) {
        this.birthViewId = response.getMemberID().getVmViewId();
        this.localAddress.setVmViewId(this.birthViewId);
        GMSMember me = (GMSMember)this.localAddress.getNetMember();
        GMSMember o = (GMSMember)response.getMemberID().getNetMember();
        me.setSplitBrainEnabled(o.isSplitBrainEnabled());
        me.setPreferredForCoordinator(o.preferredForCoordinator());
        installView(response.getCurrentView());
        return true;
      }
    }
    return false;
  }",True
"  private boolean attemptToJoin(InternalDistributedMember coord) {
    // send a join request to the coordinator and wait for a response
    logger.info(""Attempting to join the distributed system through coordinator "" + coord + "" using address "" + this.localAddress);
    JoinRequestMessage req = new JoinRequestMessage(coord, this.localAddress, 
        services.getAuthenticator().getCredentials(coord));

    services.getMessenger().send(req);
    
    JoinResponseMessage response = null;
    synchronized(joinResponse) {
      if (joinResponse[0] == null) {
        try {
          joinResponse.wait(services.getConfig().getJoinTimeout()/JOIN_ATTEMPTS);
        } catch (InterruptedException e) {
          Thread.currentThread().interrupt();
          return false;
        }
      }
      response = joinResponse[0];
    }
    if (response != null) {
// DEBUGGING - REMOVE
logger.info(""received join response {}"", response);
      joinResponse[0] = null;
      String failReason = response.getRejectionMessage();
      if (failReason != null) {
        if (failReason.contains(""Rejecting the attempt of a member using an older version"")
            || failReason.contains(""15806"")) {
          throw new SystemConnectException(failReason);
        }
        throw new AuthenticationFailedException(failReason);
      }
      if (response.getCurrentView() != null) {
        this.birthViewId = response.getMemberID().getVmViewId();
        this.localAddress.setVmViewId(this.birthViewId);
        GMSMember me = (GMSMember)this.localAddress.getNetMember();
        GMSMember o = (GMSMember)response.getMemberID().getNetMember();
        me.setBirthViewId(birthViewId);
        me.setSplitBrainEnabled(o.isSplitBrainEnabled());
        me.setPreferredForCoordinator(o.preferredForCoordinator());
        installView(response.getCurrentView());
        return true;
      } else {
        logger.info(""received join response with no membership view: {}"", response);
      }
    }
    return false;
  }",False
"    boolean createAndSendView(List<DistributionMessage> requests) {
      List<InternalDistributedMember> joinReqs = new ArrayList<InternalDistributedMember>();
      List<InternalDistributedMember> leaveReqs = new ArrayList<InternalDistributedMember>();
      List<InternalDistributedMember> removalReqs = new ArrayList<InternalDistributedMember>();
      List<String> removalReasons = new ArrayList<String>();
      
      for (DistributionMessage msg: requests) {
        logger.debug(""processing request {}"", msg);
        if (msg instanceof JoinRequestMessage) {
          InternalDistributedMember mbr = ((JoinRequestMessage)msg).getMemberID();
          joinReqs.add(mbr);
        }
        else if (msg instanceof LeaveRequestMessage) {
          leaveReqs.add(((LeaveRequestMessage) msg).getMemberID());
        }
        else if (msg instanceof RemoveMemberMessage) {
          removalReqs.add(((RemoveMemberMessage) msg).getMemberID());
          removalReasons.add(((RemoveMemberMessage) msg).getReason());
        }
        else {
          // TODO: handle removals
          logger.warn(""Unknown membership request encountered: {}"", msg);
        }
      }
      
      NetView newView;
      synchronized(viewInstallationLock) {
        int viewNumber = 0;
        List<InternalDistributedMember> mbrs;
        if (currentView == null) {
          mbrs = new ArrayList<InternalDistributedMember>(joinReqs.size());
        } else {
          viewNumber = currentView.getViewId()+1;
          mbrs = new ArrayList<InternalDistributedMember>(currentView.getMembers());
        }
        mbrs.addAll(joinReqs);
        mbrs.removeAll(leaveReqs);
        mbrs.removeAll(removalReqs);
        newView = new NetView(localAddress, viewNumber, mbrs, leaveReqs,
            removalReqs);
      }
      
      for (InternalDistributedMember mbr: joinReqs) {
        mbr.setVmViewId(newView.getViewId());
      }
      // send removal messages before installing the view so we stop
      // getting messages from members that have been kicked out
      sendRemoveMessages(removalReqs, removalReasons, newView);
      
      // we want to always check for quorum loss but don't act on it
      // unless network-partition-detection is enabled
      if ( !(checkForPartition(newView) && quorumRequired) ) {
        sendJoinResponses(joinReqs, newView);
      }

      if (quorumRequired) {
        boolean prepared = false;
        do {
          if (this.shutdown || Thread.currentThread().isInterrupted()) {
            return false;
          }
          prepared = prepareView(newView, joinReqs);
          if (!prepared && quorumRequired) {
            Set<InternalDistributedMember> unresponsive = prepareProcessor.getUnresponsiveMembers();
            try {
              removeHealthyMembers(unresponsive);
            } catch (InterruptedException e) {
              // abort the view if interrupted
              shutdown = true;
              return false;
            }
  
            if (!unresponsive.isEmpty()) {
              List<InternalDistributedMember> failures = new ArrayList<InternalDistributedMember>(currentView.getCrashedMembers().size() + unresponsive.size());
              failures.addAll(unresponsive);

              NetView conflictingView = prepareProcessor.getConflictingView();
              if (conflictingView != null
                  && !conflictingView.getCreator().equals(localAddress)
                  && conflictingView.getViewId() > newView.getViewId()
                  && (lastConflictingView == null || conflictingView.getViewId() > lastConflictingView.getViewId())) {
                lastConflictingView = conflictingView;
                failures.addAll(conflictingView.getCrashedMembers());
              }

              failures.removeAll(removalReqs);
              if (failures.size() > 0) {
                // abort the current view and try again
                removalReqs.addAll(failures);
                newView = new NetView(localAddress, newView.getViewId()+1, newView.getMembers(), leaveReqs,
                    removalReqs);
              }
            }
          }
        } while (!prepared);
      } // quorumRequired
      
      lastConflictingView = null;
      
      sendView(newView, joinReqs);
      return true;
    }",True
"    boolean createAndSendView(List<DistributionMessage> requests) {
      List<InternalDistributedMember> joinReqs = new ArrayList<InternalDistributedMember>();
      List<InternalDistributedMember> leaveReqs = new ArrayList<InternalDistributedMember>();
      List<InternalDistributedMember> removalReqs = new ArrayList<InternalDistributedMember>();
      List<String> removalReasons = new ArrayList<String>();
      
      NetView oldView = currentView;
      List<InternalDistributedMember> oldMembers;
      if (oldView != null) {
        oldMembers = oldView.getMembers();
      } else {
        oldMembers = Collections.emptyList();
      }
      
      for (DistributionMessage msg: requests) {
        logger.debug(""processing request {}"", msg);

        InternalDistributedMember mbr = null;
        
        if (msg instanceof JoinRequestMessage) {
          mbr = ((JoinRequestMessage)msg).getMemberID();
          if (!oldMembers.contains(mbr)) {
            joinReqs.add(mbr);
          }
        }
        else if (msg instanceof LeaveRequestMessage) {
          mbr = ((LeaveRequestMessage) msg).getMemberID();
          if (oldMembers.contains(mbr)) {
            leaveReqs.add(mbr);
          }
        }
        else if (msg instanceof RemoveMemberMessage) {
          mbr = ((RemoveMemberMessage) msg).getMemberID();
          if (oldMembers.contains(mbr)) {
            removalReqs.add(mbr);
            removalReasons.add(((RemoveMemberMessage) msg).getReason());
          }
        }
        else {
          // TODO: handle removals
          logger.warn(""Unknown membership request encountered: {}"", msg);
        }
      }
      
      NetView newView;
      synchronized(viewInstallationLock) {
        int viewNumber = 0;
        List<InternalDistributedMember> mbrs;
        if (currentView == null) {
          mbrs = new ArrayList<InternalDistributedMember>(joinReqs.size());
        } else {
          viewNumber = currentView.getViewId()+1;
          mbrs = new ArrayList<InternalDistributedMember>(currentView.getMembers());
        }
        mbrs.addAll(joinReqs);
        mbrs.removeAll(leaveReqs);
        mbrs.removeAll(removalReqs);
        newView = new NetView(localAddress, viewNumber, mbrs, leaveReqs,
            removalReqs);
      }
      
      for (InternalDistributedMember mbr: joinReqs) {
        mbr.setVmViewId(newView.getViewId());
      }
      // send removal messages before installing the view so we stop
      // getting messages from members that have been kicked out
      sendRemoveMessages(removalReqs, removalReasons, newView);
      
      // we want to always check for quorum loss but don't act on it
      // unless network-partition-detection is enabled
      if ( !(checkForPartition(newView) && quorumRequired) ) {
        sendJoinResponses(joinReqs, newView);
      }

      if (quorumRequired) {
        boolean prepared = false;
        do {
          if (this.shutdown || Thread.currentThread().isInterrupted()) {
            return false;
          }
          prepared = prepareView(newView, joinReqs);
          if (!prepared && quorumRequired) {
            Set<InternalDistributedMember> unresponsive = prepareProcessor.getUnresponsiveMembers();
            try {
              removeHealthyMembers(unresponsive);
            } catch (InterruptedException e) {
              // abort the view if interrupted
              shutdown = true;
              return false;
            }
  
            if (!unresponsive.isEmpty()) {
              List<InternalDistributedMember> failures = new ArrayList<InternalDistributedMember>(currentView.getCrashedMembers().size() + unresponsive.size());
              failures.addAll(unresponsive);

              NetView conflictingView = prepareProcessor.getConflictingView();
              if (conflictingView != null
                  && !conflictingView.getCreator().equals(localAddress)
                  && conflictingView.getViewId() > newView.getViewId()
                  && (lastConflictingView == null || conflictingView.getViewId() > lastConflictingView.getViewId())) {
                lastConflictingView = conflictingView;
                failures.addAll(conflictingView.getCrashedMembers());
              }

              failures.removeAll(removalReqs);
              if (failures.size() > 0) {
                // abort the current view and try again
                removalReqs.addAll(failures);
                newView = new NetView(localAddress, newView.getViewId()+1, newView.getMembers(), leaveReqs,
                    removalReqs);
              }
            }
          }
        } while (!prepared);
      } // quorumRequired
      
      lastConflictingView = null;
      
      sendView(newView, joinReqs);
      return true;
    }",False
"  public void init(Services s) {
    this.services = s;
    services.getMessenger().addHandler(JoinRequestMessage.class, this);
    services.getMessenger().addHandler(JoinResponseMessage.class, this);
    services.getMessenger().addHandler(InstallViewMessage.class, this);
    services.getMessenger().addHandler(ViewAckMessage.class, this);
    services.getMessenger().addHandler(LeaveRequestMessage.class, this);
    services.getMessenger().addHandler(RemoveMemberMessage.class, this);
    services.getMessenger().addHandler(JoinRequestMessage.class, this);
    services.getMessenger().addHandler(JoinResponseMessage.class, this);

    DistributionConfig dc = services.getConfig().getDistributionConfig();
    int ackCollectionTimeout = dc.getMemberTimeout() * 2 * 12437 / 10000;
    if (ackCollectionTimeout < 1500) {
      ackCollectionTimeout = 1500;
    } else if (ackCollectionTimeout > 12437) {
      ackCollectionTimeout = 12437;
    }
    ackCollectionTimeout = Integer.getInteger(""gemfire.VIEW_ACK_TIMEOUT"", ackCollectionTimeout).intValue();
    this.viewAckTimeout = ackCollectionTimeout;
    
    this.quorumRequired = services.getConfig().getDistributionConfig().getEnableNetworkPartitionDetection();
    
    DistributionConfig dconfig = services.getConfig().getDistributionConfig();
    String bindAddr = dconfig.getBindAddress();
    locators = GMSUtil.parseLocators(dconfig.getLocators(), bindAddr);
  }",True
"  public void init(Services s) {
    this.services = s;
    
    DistributionConfig dc = services.getConfig().getDistributionConfig();
    if (dc.getMcastPort() != 0
        && dc.getLocators().trim().isEmpty()
        && dc.getStartLocator().trim().isEmpty()) {
      throw new GemFireConfigException(""Multicast cannot be configured for a non-distributed cache.""
          + ""  Please configure the locator services for this cache using ""+DistributionConfig.LOCATORS_NAME
          + "" or "" + DistributionConfig.START_LOCATOR_NAME+""."");
    }
  
    services.getMessenger().addHandler(JoinRequestMessage.class, this);
    services.getMessenger().addHandler(JoinResponseMessage.class, this);
    services.getMessenger().addHandler(InstallViewMessage.class, this);
    services.getMessenger().addHandler(ViewAckMessage.class, this);
    services.getMessenger().addHandler(LeaveRequestMessage.class, this);
    services.getMessenger().addHandler(RemoveMemberMessage.class, this);
    services.getMessenger().addHandler(JoinRequestMessage.class, this);
    services.getMessenger().addHandler(JoinResponseMessage.class, this);

    int ackCollectionTimeout = dc.getMemberTimeout() * 2 * 12437 / 10000;
    if (ackCollectionTimeout < 1500) {
      ackCollectionTimeout = 1500;
    } else if (ackCollectionTimeout > 12437) {
      ackCollectionTimeout = 12437;
    }
    ackCollectionTimeout = Integer.getInteger(""gemfire.VIEW_ACK_TIMEOUT"", ackCollectionTimeout).intValue();
    this.viewAckTimeout = ackCollectionTimeout;
    
    this.quorumRequired = services.getConfig().getDistributionConfig().getEnableNetworkPartitionDetection();
    
    DistributionConfig dconfig = services.getConfig().getDistributionConfig();
    String bindAddr = dconfig.getBindAddress();
    locators = GMSUtil.parseLocators(dconfig.getLocators(), bindAddr);
  }",False
"  public void memberShutdown(DistributedMember mbr, String reason) {
    if (this.isCoordinator) {
      LeaveRequestMessage msg = new LeaveRequestMessage(this.localAddress, (InternalDistributedMember)mbr);
      recordViewRequest(msg);
    }
  }",False
"  public Set<InternalDistributedMember> send(DistributionMessage msg) {
    
    // perform the same jgroups messaging as in 8.2's GMSMembershipManager.send() method

    // BUT: when marshalling messages we need to include the version of the product and
    // localAddress at the beginning of the message.  These should be used in the receiver
    // code to create a versioned input stream, read the sender address, then read the message
    // and set its sender address
    DMStats theStats = services.getStatistics();

    if (!myChannel.isConnected()) {
      throw new DistributedSystemDisconnectedException(""Distributed System is shutting down"");
    }
    
    filterOutgoingMessage(msg);
    
    if (logger.isDebugEnabled()) {
      logger.debug(""JGroupsMessenger sending [{}] recipients: {}"", msg, msg.getRecipientsDescription());
    }
    
    InternalDistributedMember[] destinations = msg.getRecipients();
    boolean allDestinations = msg.forAll();
    
    boolean useMcast = false;
    if (services.getConfig().getTransport().isMcastEnabled()) {
      useMcast = !services.getManager().isMulticastAllowed()
          && (msg.getMulticast() || allDestinations);
    }
    
    JGAddress local = this.jgAddress;
    
    if (useMcast) {
      if (logger.isTraceEnabled())
        logger.trace(""This message is being multicast"");

      Exception problem = null;
      try {
        long startSer = theStats.startMsgSerialization();
        Message jmsg = createJGMessage(msg, local, Version.CURRENT_ORDINAL);
        theStats.endMsgSerialization(startSer);
        theStats.incSentBytes(jmsg.getLength());
        myChannel.send(jmsg);
      }
      catch (IllegalArgumentException e) {
        problem = e;
      }
      catch (Exception e) {
        logger.info(""caught unexpected exception"", e);
        Throwable cause = e.getCause();
        if (cause instanceof ForcedDisconnectException) {
          problem = (Exception) cause;
        } else {
          problem = e;
        }
      }
      if (problem != null) {
        if (services.getManager().getShutdownCause() != null) {
          Throwable cause = services.getManager().getShutdownCause();
          // If ForcedDisconnectException occurred then report it as actual
          // problem.
          if (cause instanceof ForcedDisconnectException) {
            problem = (Exception) cause;
          } else {
            Throwable ne = problem;
            while (ne.getCause() != null) {
              ne = ne.getCause();
            }
            ne.initCause(services.getManager().getShutdownCause());
          }
        }
        final String channelClosed = LocalizedStrings.GroupMembershipService_CHANNEL_CLOSED.toLocalizedString();
        services.getManager().membershipFailure(channelClosed, problem);
        throw new DistributedSystemDisconnectedException(channelClosed, problem);
      }
    } // useMcast
    else { // ! useMcast
      int len = destinations.length;
        List<GMSMember> calculatedMembers; // explicit list of members
        int calculatedLen; // == calculatedMembers.len
        if (len == 1 && destinations[0] == DistributionMessage.ALL_RECIPIENTS) { // send to all
          // Grab a copy of the current membership
          NetView v = services.getJoinLeave().getView();
          
          // Construct the list
          calculatedLen = v.size();
          calculatedMembers = new LinkedList<GMSMember>();
          for (int i = 0; i < calculatedLen; i ++) {
            InternalDistributedMember m = (InternalDistributedMember)v.get(i);
            calculatedMembers.add((GMSMember)m.getNetMember());
          }
        } // send to all
        else { // send to explicit list
          calculatedLen = len;
          calculatedMembers = new LinkedList<GMSMember>();
          for (int i = 0; i < calculatedLen; i ++) {
            calculatedMembers.add((GMSMember)destinations[i].getNetMember());
          }
        } // send to explicit list
        Int2ObjectOpenHashMap<Message> messages = new Int2ObjectOpenHashMap<>();
        long startSer = theStats.startMsgSerialization();
        boolean firstMessage = true;
        for (Iterator<GMSMember> it=calculatedMembers.iterator(); it.hasNext(); ) {
          GMSMember mbr = it.next();
          short version = mbr.getVersionOrdinal();
          if ( !messages.containsKey(version) ) {
            Message jmsg = createJGMessage(msg, local, version);
            messages.put(version, jmsg);
            if (firstMessage) {
              theStats.incSentBytes(jmsg.getLength());
              firstMessage = false;
            }
          }
        }
        theStats.endMsgSerialization(startSer);
        Collections.shuffle(calculatedMembers);
        int i=0;
        for (GMSMember mbr: calculatedMembers) {
          JGAddress to = new JGAddress(mbr);
          short version = mbr.getVersionOrdinal();
          Message jmsg = (Message)messages.get(version);
          Exception problem = null;
          try {
            Message tmp = (i < (calculatedLen-1)) ? jmsg.copy(true) : jmsg;
            tmp.setDest(to);
            tmp.setSrc(this.jgAddress);
            if (logger.isTraceEnabled())
              logger.trace(""Unicasting to {}"", to);
            myChannel.send(tmp);
          }
          catch (Exception e) {
            problem = e;
          }
          if (problem != null) {
            if (services.getManager().getShutdownCause() != null) {
              Throwable cause = services.getManager().getShutdownCause();
              // If ForcedDisconnectException occurred then report it as actual
              // problem.
              if (cause instanceof ForcedDisconnectException) {
                problem = (Exception) cause;
              } else {
                Throwable ne = problem;
                while (ne.getCause() != null) {
                  ne = ne.getCause();
                }
                ne.initCause(services.getManager().getShutdownCause());
              }
            }
            services.getManager().membershipFailure(""Channel closed"", problem);
            throw new DistributedSystemDisconnectedException(""Channel closed"", problem);
          }
        } // send individually
    } // !useMcast

    // The contract is that every destination enumerated in the
    // message should have received the message.  If one left
    // (i.e., left the view), we signal it here.
    if (msg.forAll())
      return null;
    Set<InternalDistributedMember> result = new HashSet<InternalDistributedMember>();
    NetView newView = services.getJoinLeave().getView();
    if (newView != null) {
      for (int i = 0; i < destinations.length; i ++) {
        InternalDistributedMember d = destinations[i];
        if (!newView.contains(d)) {
          result.add(d);
        }
      }
    }
    if (result.size() == 0)
      return null;
    return result;
  }",True
"  public Set<InternalDistributedMember> send(DistributionMessage msg) {
    
    // perform the same jgroups messaging as in 8.2's GMSMembershipManager.send() method

    // BUT: when marshalling messages we need to include the version of the product and
    // localAddress at the beginning of the message.  These should be used in the receiver
    // code to create a versioned input stream, read the sender address, then read the message
    // and set its sender address
    DMStats theStats = services.getStatistics();

    if (!myChannel.isConnected()) {
      throw new DistributedSystemDisconnectedException(""Distributed System is shutting down"");
    }
    
    filterOutgoingMessage(msg);
    
    if (logger.isDebugEnabled()) {
      logger.debug(""JGroupsMessenger sending [{}] recipients: {}"", msg, msg.getRecipientsDescription());
    }
    
    InternalDistributedMember[] destinations = msg.getRecipients();
    boolean allDestinations = msg.forAll();
    
    boolean useMcast = false;
    if (services.getConfig().getTransport().isMcastEnabled()) {
      useMcast = !services.getManager().isMulticastAllowed()
          && (msg.getMulticast() || allDestinations);
    }
    
    JGAddress local = this.jgAddress;
    
    if (useMcast) {
      if (logger.isTraceEnabled())
        logger.trace(""This message is being multicast"");

      Exception problem = null;
      try {
        long startSer = theStats.startMsgSerialization();
        Message jmsg = createJGMessage(msg, local, Version.CURRENT_ORDINAL);
        theStats.endMsgSerialization(startSer);
        theStats.incSentBytes(jmsg.getLength());
        myChannel.send(jmsg);
      }
      catch (IllegalArgumentException e) {
        problem = e;
      }
      catch (Exception e) {
        logger.info(""caught unexpected exception"", e);
        Throwable cause = e.getCause();
        if (cause instanceof ForcedDisconnectException) {
          problem = (Exception) cause;
        } else {
          problem = e;
        }
      }
      if (problem != null) {
        if (services.getManager().getShutdownCause() != null) {
          Throwable cause = services.getManager().getShutdownCause();
          // If ForcedDisconnectException occurred then report it as actual
          // problem.
          if (cause instanceof ForcedDisconnectException) {
            problem = (Exception) cause;
          } else {
            Throwable ne = problem;
            while (ne.getCause() != null) {
              ne = ne.getCause();
            }
            ne.initCause(services.getManager().getShutdownCause());
          }
        }
        final String channelClosed = LocalizedStrings.GroupMembershipService_CHANNEL_CLOSED.toLocalizedString();
        services.getManager().membershipFailure(channelClosed, problem);
        throw new DistributedSystemDisconnectedException(channelClosed, problem);
      }
    } // useMcast
    else { // ! useMcast
      int len = destinations.length;
        List<GMSMember> calculatedMembers; // explicit list of members
        int calculatedLen; // == calculatedMembers.len
        if (len == 1 && destinations[0] == DistributionMessage.ALL_RECIPIENTS) { // send to all
          // Grab a copy of the current membership
          NetView v = services.getJoinLeave().getView();
          
          // Construct the list
          calculatedLen = v.size();
          calculatedMembers = new LinkedList<GMSMember>();
          for (int i = 0; i < calculatedLen; i ++) {
            InternalDistributedMember m = (InternalDistributedMember)v.get(i);
            calculatedMembers.add((GMSMember)m.getNetMember());
          }
        } // send to all
        else { // send to explicit list
          calculatedLen = len;
          calculatedMembers = new LinkedList<GMSMember>();
          for (int i = 0; i < calculatedLen; i ++) {
            calculatedMembers.add((GMSMember)destinations[i].getNetMember());
          }
        } // send to explicit list
        Int2ObjectOpenHashMap<Message> messages = new Int2ObjectOpenHashMap<>();
        long startSer = theStats.startMsgSerialization();
        boolean firstMessage = true;
        for (Iterator<GMSMember> it=calculatedMembers.iterator(); it.hasNext(); ) {
          GMSMember mbr = it.next();
          short version = mbr.getVersionOrdinal();
          if ( !messages.containsKey(version) ) {
            Message jmsg = createJGMessage(msg, local, version);
            messages.put(version, jmsg);
            if (firstMessage) {
              theStats.incSentBytes(jmsg.getLength());
              firstMessage = false;
            }
          }
        }
        theStats.endMsgSerialization(startSer);
        Collections.shuffle(calculatedMembers);
        int i=0;
        for (GMSMember mbr: calculatedMembers) {
          JGAddress to = new JGAddress(mbr);
          short version = mbr.getVersionOrdinal();
          Message jmsg = (Message)messages.get(version);
          Exception problem = null;
          try {
            Message tmp = (i < (calculatedLen-1)) ? jmsg.copy(true) : jmsg;
            tmp.setDest(to);
            tmp.setSrc(this.jgAddress);
            if (logger.isTraceEnabled())
              logger.trace(""Unicasting to {}"", to);
            myChannel.send(tmp);
          }
          catch (Exception e) {
            problem = e;
          }
          if (problem != null) {
            if (services.getManager().getShutdownCause() != null) {
              Throwable cause = services.getManager().getShutdownCause();
              // If ForcedDisconnectException occurred then report it as actual
              // problem.
              if (cause instanceof ForcedDisconnectException) {
                problem = (Exception) cause;
              } else {
                Throwable ne = problem;
                while (ne.getCause() != null) {
                  ne = ne.getCause();
                }
                ne.initCause(services.getManager().getShutdownCause());
              }
            }
            services.getManager().membershipFailure(""Channel closed"", problem);
            throw new DistributedSystemDisconnectedException(""Channel closed"", problem);
          }
        } // send individually
    } // !useMcast

    // The contract is that every destination enumerated in the
    // message should have received the message.  If one left
    // (i.e., left the view), we signal it here.
    if (msg.forAll()) {
      return Collections.emptySet();
    }
    Set<InternalDistributedMember> result = new HashSet<InternalDistributedMember>();
    NetView newView = services.getJoinLeave().getView();
    if (newView != null) {
      for (int i = 0; i < destinations.length; i ++) {
        InternalDistributedMember d = destinations[i];
        if (!newView.contains(d)) {
          result.add(d);
        }
      }
    }
    return result;
  }",False
"  private Message createJGMessage(DistributionMessage gfmsg, JGAddress src, short version) {
    if(gfmsg instanceof DirectReplyMessage) {
      ((DirectReplyMessage) gfmsg).registerProcessor();
    }
    Message msg = new Message();
    msg.setDest(null);
    msg.setSrc(src);
    //log.info(""Creating message with payload "" + gfmsg);
    if (gfmsg.getProcessorType() == DistributionManager.HIGH_PRIORITY_EXECUTOR
        || gfmsg instanceof HighPriorityDistributionMessage) {
      msg.setFlag(Flag.OOB);
      msg.setFlag(Flag.DONT_BUNDLE);
      msg.setFlag(Flag.NO_FC);
      msg.setFlag(Flag.SKIP_BARRIER);
    }
    if (gfmsg instanceof DistributedCacheOperation.CacheOperationMessage) {
      // we don't want to see our own cache operation messages
      msg.setTransientFlag(Message.TransientFlag.DONT_LOOPBACK);
    }
    try {
      HeapDataOutputStream out_stream =
        new HeapDataOutputStream(Version.fromOrdinalOrCurrent(version));
        Version.CURRENT.writeOrdinal(out_stream, true);
        DataSerializer.writeObject(this.localAddress.getNetMember(), out_stream);
        DataSerializer.writeObject(gfmsg, out_stream);
        msg.setBuffer(out_stream.toByteArray());
    }
    catch(IOException ex) {
        IllegalArgumentException ia = new
          IllegalArgumentException(""Error serializing message"");
        ia.initCause(ex);
        throw ia;
        //throw new IllegalArgumentException(ex.toString());
    }
    return msg;
  }",True
"  private Message createJGMessage(DistributionMessage gfmsg, JGAddress src, short version) {
    if(gfmsg instanceof DirectReplyMessage) {
      ((DirectReplyMessage) gfmsg).registerProcessor();
    }
    Message msg = new Message();
    msg.setDest(null);
    msg.setSrc(src);
    //log.info(""Creating message with payload "" + gfmsg);
    if (gfmsg.getProcessorType() == DistributionManager.HIGH_PRIORITY_EXECUTOR
        || gfmsg instanceof HighPriorityDistributionMessage) {
      msg.setFlag(Flag.OOB);
      msg.setFlag(Flag.DONT_BUNDLE);
      msg.setFlag(Flag.NO_FC);
      msg.setFlag(Flag.SKIP_BARRIER);
    }
    if (gfmsg instanceof DistributedCacheOperation.CacheOperationMessage) {
      // we don't want to see our own cache operation messages
      msg.setTransientFlag(Message.TransientFlag.DONT_LOOPBACK);
    }
    try {
      long start = services.getStatistics().startMsgSerialization();
      HeapDataOutputStream out_stream =
        new HeapDataOutputStream(Version.fromOrdinalOrCurrent(version));
      Version.CURRENT.writeOrdinal(out_stream, true);
      DataSerializer.writeObject(this.localAddress.getNetMember(), out_stream);
      DataSerializer.writeObject(gfmsg, out_stream);
      msg.setBuffer(out_stream.toByteArray());
      services.getStatistics().endMsgSerialization(start);
    }
    catch(IOException ex) {
        IllegalArgumentException ia = new
          IllegalArgumentException(""Error serializing message"");
        ia.initCause(ex);
        throw ia;
        //throw new IllegalArgumentException(ex.toString());
    }
    return msg;
  }",False
"  public void start() {
    // create the configuration XML string for JGroups
    String properties = this.jgStackConfig;
    
    logger.debug(""JGroups configuration: {}"", properties);
    
    long start = System.currentTimeMillis();
    
    // start the jgroups channel and establish the membership ID
    boolean reconnecting = false;
    try {
      Object oldChannel = services.getConfig().getTransport().getOldDSMembershipInfo();
      if (oldChannel != null) {
        myChannel = (JChannel)oldChannel;
        reconnecting = true;
      }
      else {
        InputStream is = new ByteArrayInputStream(properties.getBytes(""UTF-8""));
        myChannel = new JChannel(is);
      }
    } catch (Exception e) {
      throw new GemFireConfigException(""unable to create jgroups channel"", e);
    }

    try {
      
      myChannel.setReceiver(new JGroupsReceiver());
      if (!reconnecting) {
        myChannel.connect(""AG""); // apache g***** (whatever we end up calling it)
      }
    } catch (Exception e) {
      throw new SystemConnectException(""unable to create jgroups channel"", e);
    }
    
    establishLocalAddress();
    
    logger.info(""JGroups channel created (took {}ms)"", System.currentTimeMillis()-start);
    
  }",True
"  public void start() {
    // create the configuration XML string for JGroups
    String properties = this.jgStackConfig;
    
    logger.debug(""JGroups configuration: {}"", properties);
    
    long start = System.currentTimeMillis();
    
    // start the jgroups channel and establish the membership ID
    boolean reconnecting = false;
    try {
      Object oldChannel = services.getConfig().getTransport().getOldDSMembershipInfo();
      if (oldChannel != null) {
        myChannel = (JChannel)oldChannel;
        reconnecting = true;
      }
      else {
        InputStream is = new ByteArrayInputStream(properties.getBytes(""UTF-8""));
        myChannel = new JChannel(is);
      }
    } catch (Exception e) {
      throw new GemFireConfigException(""unable to create jgroups channel"", e);
    }
    
    // give the stats to the jchannel statistics recorder
    StatRecorder sr = (StatRecorder)myChannel.getProtocolStack().findProtocol(StatRecorder.class);
    if (sr != null) {
      sr.setDMStats(services.getStatistics());
    }

    try {
      
      myChannel.setReceiver(new JGroupsReceiver());
      if (!reconnecting) {
        myChannel.connect(""AG""); // apache g***** (whatever we end up calling it)
      }
    } catch (Exception e) {
      throw new SystemConnectException(""unable to create jgroups channel"", e);
    }
    
    establishLocalAddress();
    
    logger.info(""JGroups channel created (took {}ms)"", System.currentTimeMillis()-start);
    
  }",False
"  Object readJGMessage(Message jgmsg) {
    Object result = null;
    
    int messageLength = jgmsg.getLength();
    
    if (logger.isTraceEnabled()) {
      logger.trace(""deserializing a message of length ""+messageLength);
    }
    
    if (messageLength == 0) {
      // jgroups messages with no payload are used for protocol interchange, such
      // as STABLE_GOSSIP
      logger.trace(""message length is zero - ignoring"");
      return null;
    }

    InternalDistributedMember sender = null;

    Exception problem = null;
    try {
      byte[] buf = jgmsg.getRawBuffer();
      DataInputStream dis = new DataInputStream(new ByteArrayInputStream(buf, 
          jgmsg.getOffset(), jgmsg.getLength()));

      short ordinal = Version.readOrdinal(dis);
      
      if (ordinal < Version.CURRENT_ORDINAL) {
        dis = new VersionedDataInputStream(dis, Version.fromOrdinalNoThrow(
            ordinal, true));
      }
      
      GMSMember m = DataSerializer.readObject(dis);
      sender = getMemberFromView(m, ordinal);

      result = DataSerializer.readObject(dis);
      if (result instanceof DistributionMessage) {
        ((DistributionMessage)result).setSender(sender);
      }

      logger.debug(""JGroupsReceiver deserialized {}"", result);

    }
    catch (ClassNotFoundException | IOException | RuntimeException e) {
      problem = e;
    }
    if (problem != null) {
      logger.error(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_EXCEPTION_DESERIALIZING_MESSAGE_PAYLOAD_0, jgmsg), problem);
      return null;
    }

    return result;
  }",True
"  Object readJGMessage(Message jgmsg) {
    Object result = null;
    
    int messageLength = jgmsg.getLength();
    
    if (logger.isTraceEnabled()) {
      logger.trace(""deserializing a message of length ""+messageLength);
    }
    
    if (messageLength == 0) {
      // jgroups messages with no payload are used for protocol interchange, such
      // as STABLE_GOSSIP
      logger.trace(""message length is zero - ignoring"");
      return null;
    }

    InternalDistributedMember sender = null;

    Exception problem = null;
    try {
      long start = services.getStatistics().startMsgDeserialization();
      
      byte[] buf = jgmsg.getRawBuffer();
      DataInputStream dis = new DataInputStream(new ByteArrayInputStream(buf, 
          jgmsg.getOffset(), jgmsg.getLength()));

      short ordinal = Version.readOrdinal(dis);
      
      if (ordinal < Version.CURRENT_ORDINAL) {
        dis = new VersionedDataInputStream(dis, Version.fromOrdinalNoThrow(
            ordinal, true));
      }
      
      GMSMember m = DataSerializer.readObject(dis);
      sender = getMemberFromView(m, ordinal);

      result = DataSerializer.readObject(dis);
      if (result instanceof DistributionMessage) {
        ((DistributionMessage)result).setSender(sender);
      }
      
      services.getStatistics().endMsgDeserialization(start);

      logger.debug(""JGroupsReceiver deserialized {}"", result);

    }
    catch (ClassNotFoundException | IOException | RuntimeException e) {
      problem = e;
    }
    if (problem != null) {
      logger.error(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_EXCEPTION_DESERIALIZING_MESSAGE_PAYLOAD_0, jgmsg), problem);
      return null;
    }

    return result;
  }",False
"  private void processForMulticast(Message msg, int direction) {
    Object o = msg.getHeader(nakackHeaderId);
    if (o instanceof NakAckHeader2  &&  stats != null) {
      NakAckHeader2 hdr = (NakAckHeader2)o;
      switch (direction) {
      case INCOMING:
        stats.incMcastReadBytes((int)msg.size());
        break;
      case OUTGOING:
        stats.incMcastWriteBytes((int)msg.size());
        switch (hdr.getType()) {
        case NakAckHeader2.XMIT_RSP:
          stats.incMcastRetransmits();
          break;
        case NakAckHeader2.XMIT_REQ:
          stats.incMcastRetransmitRequests();
          break;
        }
        break;
      }
    }
  }",False
"  private void processForUnicast(Message msg, int direction) {
    Object o = msg.getHeader(unicastHeaderId);
    if (o instanceof UNICAST3.Header  &&  stats != null) {
      UNICAST3.Header hdr = (UNICAST3.Header)o;
      switch (direction) {
      case INCOMING:
        stats.incUcastReadBytes((int)msg.size());
        break;
      case OUTGOING:
        stats.incUcastWriteBytes((int)msg.size());
        switch (hdr.type()) {
        case UNICAST3.Header.XMIT_REQ:
          stats.incUcastRetransmits();
          break;
        }
        break;
      }
    }
  }",False
"  public void setDMStats(DMStats stats) {
    this.stats = stats;
  }",False
"  public Object down(Event evt) {
    switch (evt.getType()) {
    case Event.MSG:
      Message msg = (Message)evt.getArg();
      processForMulticast(msg, INCOMING);
      processForUnicast(msg, INCOMING);
    }
    return down_prot.down(evt);
  }",False
"  public Object up(Event evt) {
    switch (evt.getType()) {
    case Event.MSG:
      Message msg = (Message)evt.getArg();
      processForMulticast(msg, INCOMING);
      processForUnicast(msg, INCOMING);
    }
    return up_prot.up(evt);
  }",False
"  public void shutdownMessageReceived(InternalDistributedMember id, String reason) {
    if (logger.isDebugEnabled()) {
      logger.debug(""Membership: recording shutdown status of {}"", id);
    }
    synchronized(this.shutdownMembers) { 
      this.shutdownMembers.put(id, id);
    }
  }",True
"  public void shutdownMessageReceived(InternalDistributedMember id, String reason) {
    if (logger.isDebugEnabled()) {
      logger.debug(""Membership: recording shutdown status of {}"", id);
    }
    synchronized(this.shutdownMembers) { 
      this.shutdownMembers.put(id, id);
      services.getHealthMonitor().memberShutdown(id, reason);
      services.getJoinLeave().memberShutdown(id, reason);
    }
  }",False
"  public void memberSuspected(SuspectMember suspect) {
    handleOrDeferSuspect(suspect);
  }",False
"  public void join(long millis) throws InterruptedException {
    if(serverThread != null) {
      serverThread.join(millis);
    }
  }",True
"  public void join() throws InterruptedException {
//    this.log.info(""TcpServer@""+System.identityHashCode(this)+"" join() invoked.  Server thread=""+serverThread+""@""+System.identityHashCode(serverThread)+"";alive=""+serverThread.isAlive());
    if(serverThread != null) { 
      serverThread.join();
    }
  }",False
"  public Result showDeadlock(
      @CliOption(key = CliStrings.SHOW_DEADLOCK__DEPENDENCIES__FILE,
      help = CliStrings.SHOW_DEADLOCK__DEPENDENCIES__FILE__HELP,
      mandatory = true) String filename) {

    Result result = null;
    try {
      if (!filename.endsWith("".txt"")) {
        return ResultBuilder.createUserErrorResult(CliStrings.format(CliStrings.INVALID_FILE_EXTENTION, "".txt""));
      }
      Cache cache = CacheFactory.getAnyInstance();

      Set<DistributedMember> allMembers = CliUtil.getAllMembers(cache);
      GemFireDeadlockDetector gfeDeadLockDetector = new GemFireDeadlockDetector(allMembers);
      DependencyGraph dependencyGraph = gfeDeadLockDetector.find();
      LinkedList<Dependency> deadlock = dependencyGraph.findCycle();
      Set<Dependency> dependencies = (Set<Dependency>) dependencyGraph.getEdges();

      InfoResultData resultData = ResultBuilder.createInfoResultData();

      if (deadlock != null) {
        resultData.addLine(CliStrings.SHOW_DEADLOCK__DEADLOCK__DETECTED);
        resultData.addLine(DeadlockDetector.prettyFormat(deadlock));
      } else {
        resultData.addLine(CliStrings.SHOW_DEADLOCK__NO__DEADLOCK);
      }
      resultData.addAsFile(filename, DeadlockDetector.prettyFormat(dependencies),
          MessageFormat.format(CliStrings.SHOW_DEADLOCK__DEPENDENCIES__REVIEW,filename), false);
      result = ResultBuilder.buildResult(resultData);

    } catch (Exception e) {
      result = ResultBuilder.createGemFireErrorResult(CliStrings.SHOW_DEADLOCK__ERROR + "" : "" + e.getMessage());
    }
    return result;
  }",True
"  public Result showDeadlock(
      @CliOption(key = CliStrings.SHOW_DEADLOCK__DEPENDENCIES__FILE,
      help = CliStrings.SHOW_DEADLOCK__DEPENDENCIES__FILE__HELP,
      mandatory = true) String filename) {

    Result result = null;
    try {
      if (!filename.endsWith("".txt"")) {
        return ResultBuilder.createUserErrorResult(CliStrings.format(CliStrings.INVALID_FILE_EXTENTION, "".txt""));
      }
      Cache cache = CacheFactory.getAnyInstance();

      Set<DistributedMember> allMembers = CliUtil.getAllMembers(cache);
      GemFireDeadlockDetector gfeDeadLockDetector = new GemFireDeadlockDetector(allMembers);
      DependencyGraph dependencyGraph = gfeDeadLockDetector.find();
      Collection<Dependency> deadlock = dependencyGraph.findCycle();
      DependencyGraph deepest = null;
      if (deadlock == null) {
        deepest = dependencyGraph.findDeepestGraph();
        if (deepest != null) {
          deadlock = deepest.getEdges();
        }
      }
      Set<Dependency> dependencies = (Set<Dependency>) dependencyGraph.getEdges();

      InfoResultData resultData = ResultBuilder.createInfoResultData();

      if (deadlock != null) {
        if (deepest != null) {
          resultData.addLine(CliStrings.SHOW_DEADLOCK__DEEPEST_FOUND);
        } else {
          resultData.addLine(CliStrings.SHOW_DEADLOCK__DEADLOCK__DETECTED);
        }
        resultData.addLine(DeadlockDetector.prettyFormat(deadlock));
      } else {
        resultData.addLine(CliStrings.SHOW_DEADLOCK__NO__DEADLOCK);
      }
      resultData.addAsFile(filename, DeadlockDetector.prettyFormat(dependencies),
          MessageFormat.format(CliStrings.SHOW_DEADLOCK__DEPENDENCIES__REVIEW,filename), false);
      result = ResultBuilder.buildResult(resultData);

    } catch (Exception e) {
      result = ResultBuilder.createGemFireErrorResult(CliStrings.SHOW_DEADLOCK__ERROR + "" : "" + e.getMessage());
    }
    return result;
  }",False
"    public void incUcastWriteBytes(int i) {
      ucastMessagesSent += i;
    }",False
"    public void incUcastRetransmits() {
      ucastRetransmits++;
    }",False
"  public void initMocks() throws Exception {
    // create a StatRecorder that has mock up/down protocols and stats
    mockDownProtocol = mock(Protocol.class);
    mockUpProtocol = mock(Protocol.class);
    recorder = new StatRecorder();
    recorder.setDMStats(stats);
    recorder.setUpProtocol(mockUpProtocol);
    recorder.setDownProtocol(mockDownProtocol);
  }",False
"  public void messengerStackHoldsStatRecorder() throws Exception {
    Services mockServices = mock(Services.class);
    ServiceConfig mockConfig = mock(ServiceConfig.class);
    when(mockServices.getConfig()).thenReturn(mockConfig);
    
    // first test to see if the non-multicast stack has the recorder installed
    Properties nonDefault = new Properties();
    nonDefault.put(DistributionConfig.MCAST_PORT_NAME, ""0"");
    nonDefault.put(DistributionConfig.LOCATORS_NAME, ""localhost[12345]"");
    DistributionConfigImpl config = new DistributionConfigImpl(nonDefault);
    when(mockConfig.getDistributionConfig()).thenReturn(config);

    RemoteTransportConfig transport = new RemoteTransportConfig(config,
        DistributionManager.NORMAL_DM_TYPE);
    when(mockConfig.getTransport()).thenReturn(transport);

    JGroupsMessenger messenger = new JGroupsMessenger();
    messenger.init(mockServices);
    String jgroupsConfig = messenger.getJGroupsStackConfig();
    System.out.println(jgroupsConfig);
    assert jgroupsConfig.contains(""gms.messenger.StatRecorder"");
    
    // now test to see if the multicast stack has the recorder installed
    nonDefault.put(DistributionConfig.MCAST_PORT_NAME, ""12345"");
    config = new DistributionConfigImpl(nonDefault);
    transport = new RemoteTransportConfig(config, DistributionManager.NORMAL_DM_TYPE);
    when(mockConfig.getDistributionConfig()).thenReturn(config);
    when(mockConfig.getTransport()).thenReturn(transport);
    messenger = new JGroupsMessenger();
    messenger.init(mockServices);
    assert jgroupsConfig.contains(""gms.messenger.StatRecorder"");
  }",False
"  public void testUnicastStats() throws Exception {
    Message msg = mock(Message.class);
    when(msg.getHeader(any(Short.class))).thenReturn(Header.createDataHeader(1L, (short)1, true));
    when(msg.size()).thenReturn(150L);
    
    Event evt = new Event(Event.MSG, msg);
    recorder.up(evt);
    assert stats.ucastMessagesReceived == 1;
    
    recorder.down(evt);
    assert stats.ucastMessagesSent == 1;
    
    when(msg.getHeader(any(Short.class))).thenReturn(Header.createXmitReqHeader());
    recorder.up(evt);
    assert stats.ucastRetransmits == 1;
  }",False
"  public void testMulticastStats() throws Exception {
    Message msg = mock(Message.class);
    when(msg.getHeader(any(Short.class))).thenReturn(NakAckHeader2.createMessageHeader(1L));
    when(msg.size()).thenReturn(150L);
    
    Event evt = new Event(Event.MSG, msg);
    recorder.up(evt);
    assert stats.mcastMessagesReceived == 1;
    
    recorder.down(evt);
    assert stats.mcastMessagesSent == 1;
    
    when(msg.getHeader(any(Short.class))).thenReturn(NakAckHeader2.createXmitRequestHeader(null));
    recorder.up(evt);
    assert stats.mcastRetransmitRequests == 1;

    when(msg.getHeader(any(Short.class))).thenReturn(NakAckHeader2.createXmitResponseHeader());
    recorder.up(evt);
    assert stats.mcastRetransmits == 1;
  }",False
"    public void incMcastRetransmits() {
      mcastRetransmits++;
    }",False
"    public void incMcastRetransmitRequests() {
      mcastRetransmitRequests++;
    }",False
"    public void incMcastWriteBytes(int i) {
      mcastMessagesSent += i;
    }",False
"    public void incMcastReadBytes(int i) {
      mcastMessagesReceived += i;
    }",False
"    public void incUcastReadBytes(int i) {
      ucastMessagesReceived += i;
    }",False
"  public static void main(String... args) throws Exception {
    if (args.length == 0) {
      printHelp();
      return;
    }
    
    DependencyGraph graph;

    switch (args[0]) {
    case ""print"":
      graph = loadGraphs(1, args);
      System.out.println(prettyFormat(graph));
      break;
    case ""findDeadlockOnly"":
      graph = loadGraphs(1, args);
      List<Dependency> cycle = graph.findCycle();
      if (cycle == null) {
        System.out.println(""no deadlock found"");
      } else {
        System.out.println(""deadlocked threads: \n"" + cycle);
      }
      break;
    case ""findDeepestGraph"":
      graph = loadGraphs(1, args);
      graph = graph.findDeepestGraph();
      if (graph == null) {
        System.out.println(""no deepest graph could be found!"");
      } else {
        System.out.println(""deepest graph: \n"" + prettyFormat(graph));
      }
      break;
    case ""findThread"":
      graph = loadGraphs(2, args);
      graph = graph.findDependenciesWith(args[1]);
      if (graph == null) {
        System.out.println(""thread not found! Try using the print command to see all threads and locate the name of the one you're interested in?"");
      } else {
        System.out.println(prettyFormat(sortDependencies(graph.getEdges())));
      }
      break;
    default:
      printHelp();
      break;
    }
    
  }",True
"  public static void main(String... args) throws Exception {
    if (args.length == 0) {
      printHelp();
      return;
    }
    
    DependencyGraph graph;

    switch (args[0]) {
    case ""print"":
      graph = loadGraphs(1, args);
      System.out.println(prettyFormat(graph));
      break;
    case ""findDeadlockOnly"":
      graph = loadGraphs(1, args);
      List<Dependency> cycle = graph.findCycle();
      if (cycle == null) {
        System.out.println(""no deadlock found"");
      } else {
        System.out.println(""deadlocked threads: \n"" + cycle);
      }
      break;
    case ""findDeepestGraph"":
      graph = loadGraphs(1, args);
      graph = graph.findDeepestGraph();
      if (graph == null) {
        System.out.println(""no deepest graph could be found!"");
      } else {
        System.out.println(""deepest graph: \n"" + prettyFormat(graph));
      }
      break;
    case ""findThread"":
      graph = loadGraphs(2, args);
      List<DependencyGraph> graphs = graph.findDependenciesWith(args[1]);
      if (graphs.isEmpty()) {
        System.out.println(""thread not found! Try using the print command to see all threads and locate the name of the one you're interested in?"");
      } else {
        int numGraphs = graphs.size();
        int i=0;
        System.out.println(""findThread \"""" + args[1]+""\n\n"");
        for (DependencyGraph g: graphs) {
          i += 1;
          System.out.println(""graph "" + i + "" of "" + numGraphs + "":"");
          System.out.println(prettyFormat(sortDependencies(g.getEdges())));
          if (i < numGraphs) {
            System.out.println(""\n\n\n"");
          }
        }
      }
      break;
    default:
      printHelp();
      break;
    }
    
  }",False
"  public DependencyGraph findDependenciesWith(String objectName) {
    Object obj = null;
    Dependency objDep = null;
    for (Dependency dep: edges) {
      if (dep.depender.toString().contains(objectName)) {
        obj = dep.depender;
        objDep = dep;
        break;
      }
      if (dep.dependsOn.toString().contains(objectName)) {
        obj = dep.dependsOn;
        objDep = dep;
        break;
      }
    }
    if (obj == null) {
      return null;
    }
    
    DependencyGraph result = new DependencyGraph();
    
    // expand the dependency set to include all incoming
    // references.  These will give us graphs of endpoints
    // that reach to the node we're interested in
    Set<Object> dependsOnObj = new HashSet<>();
    dependsOnObj.add(obj);
    boolean anyAdded = true;
    while (anyAdded) {
      anyAdded = false;
      for (Dependency dep: edges) {
        if (dependsOnObj.contains(dep.dependsOn)
            && !dependsOnObj.contains(dep.depender)) {
          anyAdded = true;
          dependsOnObj.add(dep.depender);
        }
      }
    }
    // find all of the downward graphs for each depender
    // and add their vertices.  These are things dependedOn
    // by the node we're interested in.
    for (Object depender: dependsOnObj) {
      if (!result.getVertices().contains(depender)) {
        DependencyGraph subgraph = getSubGraph(depender);
        result.addEdges(subgraph.getEdges());
      }
    }
    return result;
  }",True
"  public List<DependencyGraph> findDependenciesWith(String objectName) {
    
    // first find a dependency containing the node.  If we can't find one
    // we can just quit
    Object obj = null;
    Dependency objDep = null;
    for (Dependency dep: edges) {
      if (dep.depender.toString().contains(objectName)) {
        obj = dep.depender;
        objDep = dep;
        break;
      }
      if (dep.dependsOn.toString().contains(objectName)) {
        obj = dep.dependsOn;
        objDep = dep;
        break;
      }
    }
    if (obj == null) {
      return Collections.emptyList();
    }
    
    // expand the dependency set to include all incoming
    // references, references to those references, etc.
    // This should give us a collection that includes all
    // top-level nodes that have no references to them
    Set<Object> dependsOnObj = new HashSet<>();
    dependsOnObj.add(obj);
    boolean anyAdded = true;
    while (anyAdded) {
      anyAdded = false;
      for (Dependency dep: edges) {
        if (dependsOnObj.contains(dep.dependsOn)
            && !dependsOnObj.contains(dep.depender)) {
          anyAdded = true;
          dependsOnObj.add(dep.depender);
        }
      }
    }

    // find all terminal nodes having no incoming
    // dependers.
    Set<Object> allDependants = new HashSet<>();
    for (Dependency dep: edges) {
      allDependants.add(dep.dependsOn);
    }
    
    List<DependencyGraph> result = new LinkedList<>();
    for (Object depender: dependsOnObj) {
      if (!allDependants.contains(depender)) {
        result.add(getSubGraph(depender));
      }
    }
    
    return result;
  }",False
"   public void readExternal(ObjectInput in)
   throws IOException, ClassNotFoundException {
     int len = in.readInt(); // IPv6 compatible
     byte addr[] = new byte[len];
     in.readFully(addr);
     InetAddress inetAddr = InetAddress.getByAddress(addr);
     int port = in.readInt();
     
     this.hostName = DataSerializer.readString(in);

     int flags = in.readUnsignedByte();
     boolean sbEnabled = (flags & SB_ENABLED_MASK) != 0;
     boolean elCoord = (flags & COORD_ENABLED_MASK) != 0;
     this.isPartial = (flags & PARTIAL_ID_MASK) != 0;
     
     this.dcPort = in.readInt();
     this.vmPid = in.readInt();
     this.vmKind = in.readInt();
     this.vmViewId = in.readInt();
     this.groups = DataSerializer.readStringArray(in);

     this.name = DataSerializer.readString(in);
     this.uniqueTag = DataSerializer.readString(in);
     String durableId = DataSerializer.readString(in);
     int durableTimeout = DataSerializer.readInteger(in).intValue();
     this.durableClientAttributes = new DurableClientAttributes(durableId, durableTimeout);

     readVersion(flags, in);

     netMbr = MemberFactory.newNetMember(inetAddr, port, sbEnabled, elCoord, version,
         new MemberAttributes(dcPort, vmPid, vmKind, vmViewId, name, groups, durableClientAttributes));
     netMbr.readAdditionalData(in);

     Assert.assertTrue(this.vmKind > 0);
   }",True
"   public void readExternal(ObjectInput in)
   throws IOException, ClassNotFoundException {
     int len = in.readInt(); // IPv6 compatible
     byte addr[] = new byte[len];
     in.readFully(addr);
     InetAddress inetAddr = InetAddress.getByAddress(addr);
     int port = in.readInt();
     
     this.hostName = DataSerializer.readString(in);

     int flags = in.readUnsignedByte();
     boolean sbEnabled = (flags & SB_ENABLED_MASK) != 0;
     boolean elCoord = (flags & COORD_ENABLED_MASK) != 0;
     this.isPartial = (flags & PARTIAL_ID_MASK) != 0;
     
     this.dcPort = in.readInt();
     this.vmPid = in.readInt();
     this.vmKind = in.readInt();
     this.vmViewId = in.readInt();
     this.groups = DataSerializer.readStringArray(in);

     this.name = DataSerializer.readString(in);
     this.uniqueTag = DataSerializer.readString(in);
     String durableId = DataSerializer.readString(in);
     int durableTimeout = DataSerializer.readInteger(in).intValue();
     this.durableClientAttributes = new DurableClientAttributes(durableId, durableTimeout);

     readVersion(flags, in);

     netMbr = MemberFactory.newNetMember(inetAddr, port, sbEnabled, elCoord, version,
         new MemberAttributes(dcPort, vmPid, vmKind, vmViewId, name, groups, durableClientAttributes));
     if (this.version >= Version.GFE_90.ordinal()) {
       try {
         netMbr.readAdditionalData(in);
       } catch (java.io.EOFException e) {
         // old version quand-meme
       }
     }

     Assert.assertTrue(this.vmKind > 0);
   }",False
"  public void fromData(DataInput in)
  throws IOException, ClassNotFoundException {
    fromDataPre_GFE_9_0_0_0(in);
    netMbr.readAdditionalData(in);
  }",True
"  public void fromData(DataInput in)
  throws IOException, ClassNotFoundException {
    fromDataPre_GFE_9_0_0_0(in);
    // just in case this is just a non-versioned read
    // from a file we ought to check the version
    if (this.version >= Version.GFE_90.ordinal()) {
      netMbr.readAdditionalData(in);
    }
  }",False
"  public void stop() {
    logger.info(""Membership: stopping services"");
    this.joinLeave.stop();
    this.healthMon.stop();
    this.auth.stop();
    this.messenger.stop();
    this.manager.stop();
    this.timer.cancel();
  }",True
"  public void stop() {
    logger.info(""Membership: stopping services"");
    this.joinLeave.stop();
    this.healthMon.stop();
    this.auth.stop();
    this.messenger.stop();
    this.manager.stop();
    this.timer.cancel();
    this.cancelCriterion.cancel(""Membership services are shut down"");
  }",False
"  public void processMessage(DistributionMessage m) {
    if (isStopping) {
      return;
    }
    logger.debug(""JoinLeave processing {}"", m);
    switch (m.getDSFID()) {
    case JOIN_REQUEST:
      processJoinRequest((JoinRequestMessage)m);
      break;
    case JOIN_RESPONSE:
      processJoinResponse((JoinResponseMessage)m);
      break;
    case INSTALL_VIEW_MESSAGE:
      processViewMessage((InstallViewMessage)m);
      break;
    case VIEW_ACK_MESSAGE:
      processViewAckMessage((ViewAckMessage)m);
      break;
    case LEAVE_REQUEST_MESSAGE:
      processLeaveRequest((LeaveRequestMessage)m);
      break;
    case REMOVE_MEMBER_MESSAGE:
      processRemoveRequest((RemoveMemberMessage)m);
      break;
    default:
      throw new IllegalArgumentException(""unknown message type: "" + m);
    }
  }",True
"  public void processMessage(DistributionMessage m) {
    if (isStopping) {
      return;
    }
    logger.debug(""JoinLeave processing {}"", m);
    switch (m.getDSFID()) {
    case JOIN_REQUEST:
      processJoinRequest((JoinRequestMessage)m);
      break;
    case JOIN_RESPONSE:
      processJoinResponse((JoinResponseMessage)m);
      break;
    case INSTALL_VIEW_MESSAGE:
      processViewMessage((InstallViewMessage)m);
      break;
    case VIEW_ACK_MESSAGE:
      processViewAckMessage((ViewAckMessage)m);
      break;
    case LEAVE_REQUEST_MESSAGE:
      processLeaveRequest((LeaveRequestMessage)m);
      break;
    case REMOVE_MEMBER_REQUEST:
      processRemoveRequest((RemoveMemberMessage)m);
      break;
    default:
      throw new IllegalArgumentException(""unknown message type: "" + m);
    }
  }",False
"  private void processJoinRequest(JoinRequestMessage incomingRequest) {
    if (incomingRequest.getMemberID().getVersionObject().compareTo(Version.CURRENT) < 0) {
      logger.warn(""detected an attempt to start a peer using an older version of the product {}"",
          incomingRequest.getMemberID());
      JoinResponseMessage m = new JoinResponseMessage(""Rejecting the attempt of a member using an older version"");
      m.setRecipient(incomingRequest.getMemberID());
      services.getMessenger().send(m);
      return;
    }
    Object creds = incomingRequest.getCredentials();
    if (creds != null) {
      String rejection = null;
      try {
        rejection = services.getAuthenticator().authenticate(incomingRequest.getMemberID(), creds);
      } catch (Exception e) {
        rejection = e.getMessage();
      }
      if (rejection != null  &&  rejection.length() > 0) {
        JoinResponseMessage m = new JoinResponseMessage(rejection);
        m.setRecipient(incomingRequest.getMemberID());
        services.getMessenger().send(m);
      }
    }
    recordViewRequest(incomingRequest);
  }",True
"  private void processJoinRequest(JoinRequestMessage incomingRequest) {
    if (incomingRequest.getMemberID().getVersionObject().compareTo(Version.CURRENT) < 0) {
      logger.warn(""detected an attempt to start a peer using an older version of the product {}"",
          incomingRequest.getMemberID());
      JoinResponseMessage m = new JoinResponseMessage(""Rejecting the attempt of a member using an older version"");
      m.setRecipient(incomingRequest.getMemberID());
      services.getMessenger().send(m);
      return;
    }
    Object creds = incomingRequest.getCredentials();
    String rejection = null;
    try {
      rejection = services.getAuthenticator().authenticate(incomingRequest.getMemberID(), creds);
    } catch (Exception e) {
      rejection = e.getMessage();
      e.printStackTrace();
    }
    if (rejection != null  &&  rejection.length() > 0) {
      JoinResponseMessage m = new JoinResponseMessage(rejection);
      m.setRecipient(incomingRequest.getMemberID());
      services.getMessenger().send(m);
      return;
    }
    recordViewRequest(incomingRequest);
  }",False
"  public int getDSFID() {
    return JOIN_REQUEST;
  }",True
"  public int getDSFID() {
    return REMOVE_MEMBER_REQUEST;
  }",False
"  private static void registerDSFIDTypes() {
    registerDSFID(REMOVE_MEMBER_MESSAGE, RemoveMemberMessage.class);
    registerDSFID(LEAVE_REQUEST_MESSAGE, LeaveRequestMessage.class);
    registerDSFID(VIEW_ACK_MESSAGE, ViewAckMessage.class);
    registerDSFID(INSTALL_VIEW_MESSAGE, InstallViewMessage.class);
    registerDSFID(GMSMEMBER, GMSMember.class);
    registerDSFID(NETVIEW, NetView.class);
    registerDSFID(GET_VIEW_REQ, GetViewRequest.class);
    registerDSFID(GET_VIEW_RESP, GetViewResponse.class);
    registerDSFID(FIND_COORDINATOR_REQ, FindCoordinatorRequest.class);
    registerDSFID(FIND_COORDINATOR_RESP, FindCoordinatorResponse.class);
    registerDSFID(JOIN_RESPONSE, JoinResponseMessage.class);
    registerDSFID(JOIN_REQUEST, JoinRequestMessage.class);
    registerDSFID(CLIENT_TOMBSTONE_MESSAGE, ClientTombstoneMessage.class);
    registerDSFID(R_REGION_OP, RemoteRegionOperation.class);
    registerDSFID(R_REGION_OP_REPLY, RemoteRegionOperationReplyMessage.class);
    registerDSFID(WAIT_FOR_VIEW_INSTALLATION, WaitForViewInstallation.class);
    registerDSFID(DISPATCHED_AND_CURRENT_EVENTS,
        DispatchedAndCurrentEvents.class);
    registerDSFID(DISTRIBUTED_MEMBER, InternalDistributedMember.class);
    registerDSFID(UPDATE_MESSAGE, UpdateOperation.UpdateMessage.class);
    registerDSFID(REPLY_MESSAGE, ReplyMessage.class);
    registerDSFID(PR_DESTROY, DestroyMessage.class);
    registerDSFID(CREATE_REGION_MESSAGE,
        CreateRegionProcessor.CreateRegionMessage.class);
    registerDSFID(CREATE_REGION_REPLY_MESSAGE,
        CreateRegionProcessor.CreateRegionReplyMessage.class);
    registerDSFID(REGION_STATE_MESSAGE,
        InitialImageOperation.RegionStateMessage.class);
    registerDSFID(QUERY_MESSAGE, SearchLoadAndWriteProcessor.QueryMessage.class);
    registerDSFID(RESPONSE_MESSAGE,
        SearchLoadAndWriteProcessor.ResponseMessage.class);
    registerDSFID(NET_SEARCH_REQUEST_MESSAGE,
        SearchLoadAndWriteProcessor.NetSearchRequestMessage.class);
    registerDSFID(NET_SEARCH_REPLY_MESSAGE,
        SearchLoadAndWriteProcessor.NetSearchReplyMessage.class);
    registerDSFID(NET_LOAD_REQUEST_MESSAGE,
        SearchLoadAndWriteProcessor.NetLoadRequestMessage.class);
    registerDSFID(NET_LOAD_REPLY_MESSAGE,
        SearchLoadAndWriteProcessor.NetLoadReplyMessage.class);
    registerDSFID(NET_WRITE_REQUEST_MESSAGE,
        SearchLoadAndWriteProcessor.NetWriteRequestMessage.class);
    registerDSFID(NET_WRITE_REPLY_MESSAGE,
        SearchLoadAndWriteProcessor.NetWriteReplyMessage.class);
    registerDSFID(DLOCK_REQUEST_MESSAGE,
        DLockRequestProcessor.DLockRequestMessage.class);
    registerDSFID(DLOCK_RESPONSE_MESSAGE,
        DLockRequestProcessor.DLockResponseMessage.class);
    registerDSFID(DLOCK_RELEASE_MESSAGE,
        DLockReleaseProcessor.DLockReleaseMessage.class);
    registerDSFID(ADMIN_CACHE_EVENT_MESSAGE,
        SystemMemberCacheEventProcessor.SystemMemberCacheMessage.class);
    registerDSFID(CQ_ENTRY_EVENT, CqEntry.class);
    registerDSFID(REQUEST_IMAGE_MESSAGE,
        InitialImageOperation.RequestImageMessage.class);
    registerDSFID(IMAGE_REPLY_MESSAGE,
        InitialImageOperation.ImageReplyMessage.class);
    registerDSFID(IMAGE_ENTRY, InitialImageOperation.Entry.class);
    registerDSFID(CLOSE_CACHE_MESSAGE, CloseCacheMessage.class);
    registerDSFID(NON_GRANTOR_DESTROYED_MESSAGE,
        NonGrantorDestroyedProcessor.NonGrantorDestroyedMessage.class);
    registerDSFID(DLOCK_RELEASE_REPLY,
        DLockReleaseProcessor.DLockReleaseReplyMessage.class);
    registerDSFID(GRANTOR_REQUEST_MESSAGE,
        GrantorRequestProcessor.GrantorRequestMessage.class);
    registerDSFID(GRANTOR_INFO_REPLY_MESSAGE,
        GrantorRequestProcessor.GrantorInfoReplyMessage.class);
    registerDSFID(ELDER_INIT_MESSAGE, ElderInitProcessor.ElderInitMessage.class);
    registerDSFID(ELDER_INIT_REPLY_MESSAGE,
        ElderInitProcessor.ElderInitReplyMessage.class);
    registerDSFID(DEPOSE_GRANTOR_MESSAGE,
        DeposeGrantorProcessor.DeposeGrantorMessage.class);
    registerDSFID(STARTUP_MESSAGE, StartupMessage.class);
    registerDSFID(STARTUP_RESPONSE_MESSAGE, StartupResponseMessage.class);
    registerDSFID(STARTUP_RESPONSE_WITHVERSION_MESSAGE,
        StartupResponseWithVersionMessage.class);
    registerDSFID(SHUTDOWN_MESSAGE, ShutdownMessage.class);
    registerDSFID(DESTROY_REGION_MESSAGE,
        DestroyRegionOperation.DestroyRegionMessage.class);
    registerDSFID(PR_PUTALL_MESSAGE, PutAllPRMessage.class);
    registerDSFID(PR_REMOVE_ALL_MESSAGE, RemoveAllPRMessage.class);
    registerDSFID(PR_REMOVE_ALL_REPLY_MESSAGE, RemoveAllPRMessage.RemoveAllReplyMessage.class);
    registerDSFID(REMOTE_REMOVE_ALL_MESSAGE, RemoteRemoveAllMessage.class);
    registerDSFID(REMOTE_REMOVE_ALL_REPLY_MESSAGE, RemoteRemoveAllMessage.RemoveAllReplyMessage.class);
    registerDSFID(DISTTX_ROLLBACK_MESSAGE, DistTXRollbackMessage.class);
    registerDSFID(DISTTX_COMMIT_MESSAGE, DistTXCommitMessage.class);
    registerDSFID(DISTTX_PRE_COMMIT_MESSAGE, DistTXPrecommitMessage.class);
    registerDSFID(DISTTX_ROLLBACK_REPLY_MESSAGE, DistTXRollbackMessage.DistTXRollbackReplyMessage.class);
    registerDSFID(DISTTX_COMMIT_REPLY_MESSAGE, DistTXCommitMessage.DistTXCommitReplyMessage.class);
    registerDSFID(DISTTX_PRE_COMMIT_REPLY_MESSAGE, DistTXPrecommitMessage.DistTXPrecommitReplyMessage.class);
    registerDSFID(PR_PUT_MESSAGE, PutMessage.class);
    registerDSFID(INVALIDATE_MESSAGE,
        InvalidateOperation.InvalidateMessage.class);
    registerDSFID(DESTROY_MESSAGE, DestroyOperation.DestroyMessage.class);
    registerDSFID(DA_PROFILE, DistributionAdvisor.Profile.class);
    registerDSFID(CACHE_PROFILE, CacheDistributionAdvisor.CacheProfile.class);
    registerDSFID(HA_PROFILE, HARegion.HARegionAdvisor.HAProfile.class);
    registerDSFID(ENTRY_EVENT, EntryEventImpl.class);
    registerDSFID(UPDATE_ATTRIBUTES_MESSAGE,
        UpdateAttributesProcessor.UpdateAttributesMessage.class);
    registerDSFID(PROFILE_REPLY_MESSAGE,
        UpdateAttributesProcessor.ProfileReplyMessage.class);
    registerDSFID(PROFILES_REPLY_MESSAGE,
        UpdateAttributesProcessor.ProfilesReplyMessage.class);
    registerDSFID(REGION_EVENT, RegionEventImpl.class);
    registerDSFID(TX_COMMIT_MESSAGE, TXCommitMessage.class);
    registerDSFID(COMMIT_PROCESS_FOR_LOCKID_MESSAGE,
        CommitProcessForLockIdMessage.class);
    registerDSFID(COMMIT_PROCESS_FOR_TXID_MESSAGE,
        CommitProcessForTXIdMessage.class);
    registerDSFID(FILTER_PROFILE, FilterProfile.class);
    registerDSFID(REMOTE_PUTALL_REPLY_MESSAGE,
        RemotePutAllMessage.PutAllReplyMessage.class);
    registerDSFID(REMOTE_PUTALL_MESSAGE, RemotePutAllMessage.class);
    registerDSFID(VERSION_TAG, VMVersionTag.class);
    registerDSFID(ADD_CACHESERVER_PROFILE_UPDATE,
        AddCacheServerProfileMessage.class);
    registerDSFID(SERVER_INTEREST_REGISTRATION_MESSAGE,
        ServerInterestRegistrationMessage.class);
    registerDSFID(FILTER_PROFILE_UPDATE, FilterProfile.OperationMessage.class);
    registerDSFID(PR_GET_MESSAGE, GetMessage.class);
    registerDSFID(R_FETCH_ENTRY_MESSAGE, RemoteFetchEntryMessage.class);
    registerDSFID(R_FETCH_ENTRY_REPLY_MESSAGE,
        RemoteFetchEntryMessage.FetchEntryReplyMessage.class);
    registerDSFID(R_CONTAINS_MESSAGE, RemoteContainsKeyValueMessage.class);
    registerDSFID(R_CONTAINS_REPLY_MESSAGE,
        RemoteContainsKeyValueMessage.RemoteContainsKeyValueReplyMessage.class);
    registerDSFID(R_DESTROY_MESSAGE, RemoteDestroyMessage.class);
    registerDSFID(R_DESTROY_REPLY_MESSAGE,
        RemoteDestroyMessage.DestroyReplyMessage.class);
    registerDSFID(R_INVALIDATE_MESSAGE, RemoteInvalidateMessage.class);
    registerDSFID(R_INVALIDATE_REPLY_MESSAGE,
        RemoteInvalidateMessage.InvalidateReplyMessage.class);
    registerDSFID(R_GET_MESSAGE, RemoteGetMessage.class);
    registerDSFID(R_GET_REPLY_MESSAGE, RemoteGetMessage.GetReplyMessage.class);
    registerDSFID(R_PUT_MESSAGE, RemotePutMessage.class);
    registerDSFID(R_PUT_REPLY_MESSAGE, RemotePutMessage.PutReplyMessage.class);
    registerDSFID(R_SIZE_MESSAGE, RemoteSizeMessage.class);
    registerDSFID(R_SIZE_REPLY_MESSAGE,
        RemoteSizeMessage.SizeReplyMessage.class);
    registerDSFID(PR_DESTROY_REPLY_MESSAGE,
        DestroyMessage.DestroyReplyMessage.class);
    registerDSFID(CLI_FUNCTION_RESULT, CliFunctionResult.class);
    registerDSFID(R_FETCH_KEYS_MESSAGE, RemoteFetchKeysMessage.class);
    registerDSFID(R_FETCH_KEYS_REPLY,
        RemoteFetchKeysMessage.RemoteFetchKeysReplyMessage.class);
    registerDSFID(R_REMOTE_COMMIT_REPLY_MESSAGE,
        TXRemoteCommitReplyMessage.class);
    registerDSFID(TRANSACTION_LOCK_ID, TXLockIdImpl.class);
    registerDSFID(PR_GET_REPLY_MESSAGE, GetReplyMessage.class);
    registerDSFID(PR_NODE, Node.class);
    registerDSFID(UPDATE_WITH_CONTEXT_MESSAGE,
        UpdateOperation.UpdateWithContextMessage.class);
    registerDSFID(DESTROY_WITH_CONTEXT_MESSAGE,
        DestroyOperation.DestroyWithContextMessage.class);
    registerDSFID(INVALIDATE_WITH_CONTEXT_MESSAGE,
        InvalidateOperation.InvalidateWithContextMessage.class);
    registerDSFID(REGION_VERSION_VECTOR, VMRegionVersionVector.class);
    registerDSFID(CLIENT_PROXY_MEMBERSHIPID, ClientProxyMembershipID.class);
    registerDSFID(EVENT_ID, EventID.class);
    registerDSFID(CLIENT_UPDATE_MESSAGE, ClientUpdateMessageImpl.class);
    registerDSFID(CLEAR_REGION_MESSAGE_WITH_CONTEXT,
        ClearRegionWithContextMessage.class);
    registerDSFID(CLIENT_INSTANTIATOR_MESSAGE, ClientInstantiatorMessage.class);
    registerDSFID(CLIENT_DATASERIALIZER_MESSAGE,
        ClientDataSerializerMessage.class);
    registerDSFID(REGISTRATION_MESSAGE,
        InternalInstantiator.RegistrationMessage.class);
    registerDSFID(REGISTRATION_CONTEXT_MESSAGE,
        InternalInstantiator.RegistrationContextMessage.class);
    registerDSFID(RESULTS_COLLECTION_WRAPPER, ResultsCollectionWrapper.class);
    registerDSFID(RESULTS_SET, ResultsSet.class);
    registerDSFID(SORTED_RESULT_SET, SortedResultSet.class);
    registerDSFID(SORTED_STRUCT_SET, SortedStructSet.class);
    registerDSFID(NWAY_MERGE_RESULTS, NWayMergeResults.class);
    registerDSFID(CUMULATIVE_RESULTS, CumulativeNonDistinctResults.class);
    registerDSFID(UNDEFINED, Undefined.class);
    registerDSFID(STRUCT_IMPL, StructImpl.class);
    registerDSFID(STRUCT_SET, StructSet.class);
    registerDSFID(END_OF_BUCKET, PRQueryProcessor.EndOfBucket.class);
    registerDSFID(STRUCT_BAG, StructBag.class);
    registerDSFID(LINKED_RESULTSET, LinkedResultSet.class);
    registerDSFID(LINKED_STRUCTSET, LinkedStructSet.class);
    registerDSFID(PR_BUCKET_BACKUP_MESSAGE, BucketBackupMessage.class);
    registerDSFID(PR_BUCKET_PROFILE_UPDATE_MESSAGE,
        BucketProfileUpdateMessage.class);
    registerDSFID(PR_ALL_BUCKET_PROFILES_UPDATE_MESSAGE,
        AllBucketProfilesUpdateMessage.class);
    registerDSFID(PR_BUCKET_SIZE_MESSAGE, BucketSizeMessage.class);
    registerDSFID(PR_CONTAINS_KEY_VALUE_MESSAGE, ContainsKeyValueMessage.class);
    registerDSFID(PR_DUMP_ALL_PR_CONFIG_MESSAGE, DumpAllPRConfigMessage.class);
    registerDSFID(PR_DUMP_BUCKETS_MESSAGE, DumpBucketsMessage.class);
    registerDSFID(PR_FETCH_ENTRIES_MESSAGE, FetchEntriesMessage.class);
    registerDSFID(PR_FETCH_ENTRY_MESSAGE, FetchEntryMessage.class);
    registerDSFID(PR_FETCH_KEYS_MESSAGE, FetchKeysMessage.class);
    registerDSFID(PR_FLUSH_MESSAGE, FlushMessage.class);
    registerDSFID(PR_IDENTITY_REQUEST_MESSAGE, IdentityRequestMessage.class);
    registerDSFID(PR_IDENTITY_UPDATE_MESSAGE, IdentityUpdateMessage.class);
    registerDSFID(PR_INDEX_CREATION_MSG, IndexCreationMsg.class);
    registerDSFID(PR_MANAGE_BUCKET_MESSAGE, ManageBucketMessage.class);
    registerDSFID(PR_PRIMARY_REQUEST_MESSAGE, PrimaryRequestMessage.class);
    registerDSFID(PR_PRIMARY_REQUEST_REPLY_MESSAGE,
        PrimaryRequestReplyMessage.class);
    registerDSFID(PR_SANITY_CHECK_MESSAGE, PRSanityCheckMessage.class);
    registerDSFID(PR_PUTALL_REPLY_MESSAGE, PutAllReplyMessage.class);
    registerDSFID(PR_PUT_REPLY_MESSAGE, PutReplyMessage.class);
    registerDSFID(PR_QUERY_MESSAGE, QueryMessage.class);
    registerDSFID(PR_REMOVE_INDEXES_MESSAGE, RemoveIndexesMessage.class);
    registerDSFID(PR_REMOVE_INDEXES_REPLY_MESSAGE,
        RemoveIndexesReplyMessage.class);
    registerDSFID(PR_SIZE_MESSAGE, SizeMessage.class);
    registerDSFID(PR_SIZE_REPLY_MESSAGE, SizeReplyMessage.class);
    registerDSFID(PR_BUCKET_SIZE_REPLY_MESSAGE, BucketSizeReplyMessage.class);
    registerDSFID(PR_CONTAINS_KEY_VALUE_REPLY_MESSAGE,
        ContainsKeyValueReplyMessage.class);
    registerDSFID(PR_FETCH_ENTRIES_REPLY_MESSAGE,
        FetchEntriesReplyMessage.class);
    registerDSFID(PR_FETCH_ENTRY_REPLY_MESSAGE, FetchEntryReplyMessage.class);
    registerDSFID(PR_IDENTITY_REPLY_MESSAGE, IdentityReplyMessage.class);
    registerDSFID(PR_INDEX_CREATION_REPLY_MSG, IndexCreationReplyMsg.class);
    registerDSFID(PR_MANAGE_BUCKET_REPLY_MESSAGE,
        ManageBucketReplyMessage.class);
    registerDSFID(PR_FETCH_KEYS_REPLY_MESSAGE, FetchKeysReplyMessage.class);
    registerDSFID(PR_DUMP_B2N_REGION_MSG, DumpB2NRegion.class);
    registerDSFID(PR_DUMP_B2N_REPLY_MESSAGE, DumpB2NReplyMessage.class);
    registerDSFID(DESTROY_PARTITIONED_REGION_MESSAGE,
        DestroyPartitionedRegionMessage.class);
    registerDSFID(INVALIDATE_PARTITIONED_REGION_MESSAGE,
        InvalidatePartitionedRegionMessage.class);
    registerDSFID(COMMIT_PROCESS_QUERY_MESSAGE,
        CommitProcessQueryMessage.class);
    registerDSFID(COMMIT_PROCESS_QUERY_REPLY_MESSAGE,
        CommitProcessQueryReplyMessage.class);
    registerDSFID(DESTROY_REGION_WITH_CONTEXT_MESSAGE,
        DestroyRegionOperation.DestroyRegionWithContextMessage.class);
    registerDSFID(PUT_ALL_MESSAGE, PutAllMessage.class);
    registerDSFID(REMOVE_ALL_MESSAGE, RemoveAllMessage.class);
    registerDSFID(CLEAR_REGION_MESSAGE, ClearRegionMessage.class);
    registerDSFID(TOMBSTONE_MESSAGE, TombstoneMessage.class);
    registerDSFID(INVALIDATE_REGION_MESSAGE, InvalidateRegionMessage.class);
    registerDSFID(SEND_QUEUE_MESSAGE, SendQueueMessage.class);
    registerDSFID(STATE_MARKER_MESSAGE, StateMarkerMessage.class);
    registerDSFID(STATE_STABILIZATION_MESSAGE, StateStabilizationMessage.class);
    registerDSFID(STATE_STABILIZED_MESSAGE, StateStabilizedMessage.class);
    registerDSFID(CLIENT_MARKER_MESSAGE_IMPL, ClientMarkerMessageImpl.class);
    registerDSFID(TX_LOCK_UPDATE_PARTICIPANTS_MESSAGE,
        TXLockUpdateParticipantsMessage.class);
    registerDSFID(TX_ORIGINATOR_RECOVERY_MESSAGE,
        TXOriginatorRecoveryMessage.class);
    registerDSFID(TX_ORIGINATOR_RECOVERY_REPLY_MESSAGE,
        TXOriginatorRecoveryReplyMessage.class);
    registerDSFID(TX_REMOTE_COMMIT_MESSAGE, TXRemoteCommitMessage.class);
    registerDSFID(TX_REMOTE_ROLLBACK_MESSAGE, TXRemoteRollbackMessage.class);
    registerDSFID(JTA_BEFORE_COMPLETION_MESSAGE,
        JtaBeforeCompletionMessage.class);
    registerDSFID(JTA_AFTER_COMPLETION_MESSAGE,
        JtaAfterCompletionMessage.class);
    registerDSFID(QUEUE_REMOVAL_MESSAGE, QueueRemovalMessage.class);
    registerDSFID(DLOCK_RECOVER_GRANTOR_MESSAGE,
        DLockRecoverGrantorMessage.class);
    registerDSFID(DLOCK_RECOVER_GRANTOR_REPLY_MESSAGE,
        DLockRecoverGrantorReplyMessage.class);
    registerDSFID(NON_GRANTOR_DESTROYED_REPLY_MESSAGE,
        NonGrantorDestroyedReplyMessage.class);
    registerDSFID(IDS_REGISTRATION_MESSAGE,
        InternalDataSerializer.RegistrationMessage.class);
    registerDSFID(PR_FETCH_PARTITION_DETAILS_MESSAGE,
        FetchPartitionDetailsMessage.class);
    registerDSFID(PR_FETCH_PARTITION_DETAILS_REPLY,
        FetchPartitionDetailsReplyMessage.class);
    registerDSFID(PR_DEPOSE_PRIMARY_BUCKET_MESSAGE,
        DeposePrimaryBucketMessage.class);
    registerDSFID(PR_DEPOSE_PRIMARY_BUCKET_REPLY,
        DeposePrimaryBucketReplyMessage.class);
    registerDSFID(PR_BECOME_PRIMARY_BUCKET_MESSAGE,
        BecomePrimaryBucketMessage.class);
    registerDSFID(PR_BECOME_PRIMARY_BUCKET_REPLY,
        BecomePrimaryBucketReplyMessage.class);
    registerDSFID(PR_REMOVE_BUCKET_MESSAGE, RemoveBucketMessage.class);
    registerDSFID(TX_MANAGER_REMOVE_TRANSACTIONS,
        TXManagerImpl.TXRemovalMessage.class);
    registerDSFID(PR_REMOVE_BUCKET_REPLY, RemoveBucketReplyMessage.class);
    registerDSFID(PR_MOVE_BUCKET_MESSAGE, MoveBucketMessage.class);
    registerDSFID(PR_MOVE_BUCKET_REPLY, MoveBucketReplyMessage.class);
    registerDSFID(ADD_HEALTH_LISTENER_REQUEST, AddHealthListenerRequest.class);
    registerDSFID(ADD_HEALTH_LISTENER_RESPONSE, AddHealthListenerResponse.class);
    registerDSFID(ADD_STAT_LISTENER_REQUEST, AddStatListenerRequest.class);
    registerDSFID(ADD_STAT_LISTENER_RESPONSE, AddStatListenerResponse.class);
    registerDSFID(ADMIN_CONSOLE_DISCONNECT_MESSAGE,
        AdminConsoleDisconnectMessage.class);
    registerDSFID(ADMIN_CONSOLE_MESSAGE, AdminConsoleMessage.class);
    registerDSFID(MANAGER_STARTUP_MESSAGE, ManagerStartupMessage.class);
    registerDSFID(JMX_MANAGER_LOCATOR_REQUEST, JmxManagerLocatorRequest.class);
    registerDSFID(JMX_MANAGER_LOCATOR_RESPONSE, JmxManagerLocatorResponse.class);
    registerDSFID(ADMIN_FAILURE_RESPONSE, AdminFailureResponse.class);
    registerDSFID(ALERT_LEVEL_CHANGE_MESSAGE, AlertLevelChangeMessage.class);
    registerDSFID(ALERT_LISTENER_MESSAGE, AlertListenerMessage.class);
    registerDSFID(APP_CACHE_SNAPSHOT_MESSAGE, AppCacheSnapshotMessage.class);
    registerDSFID(BRIDGE_SERVER_REQUEST, BridgeServerRequest.class);
    registerDSFID(BRIDGE_SERVER_RESPONSE, BridgeServerResponse.class);
    registerDSFID(CACHE_CONFIG_REQUEST, CacheConfigRequest.class);
    registerDSFID(CACHE_CONFIG_RESPONSE, CacheConfigResponse.class);
    registerDSFID(CACHE_INFO_REQUEST, CacheInfoRequest.class);
    registerDSFID(CACHE_INFO_RESPONSE, CacheInfoResponse.class);
    registerDSFID(CANCELLATION_MESSAGE, CancellationMessage.class);
    registerDSFID(CANCEL_STAT_LISTENER_REQUEST, CancelStatListenerRequest.class);
    registerDSFID(CANCEL_STAT_LISTENER_RESPONSE,
        CancelStatListenerResponse.class);
    registerDSFID(DESTROY_ENTRY_MESSAGE, DestroyEntryMessage.class);
    registerDSFID(ADMIN_DESTROY_REGION_MESSAGE, DestroyRegionMessage.class);
    registerDSFID(FETCH_DIST_LOCK_INFO_REQUEST, FetchDistLockInfoRequest.class);
    registerDSFID(FETCH_DIST_LOCK_INFO_RESPONSE,
        FetchDistLockInfoResponse.class);
    registerDSFID(FETCH_HEALTH_DIAGNOSIS_REQUEST,
        FetchHealthDiagnosisRequest.class);
    registerDSFID(FETCH_HEALTH_DIAGNOSIS_RESPONSE,
        FetchHealthDiagnosisResponse.class);
    registerDSFID(FETCH_HOST_REQUEST, FetchHostRequest.class);
    registerDSFID(FETCH_HOST_RESPONSE, FetchHostResponse.class);
    registerDSFID(FETCH_RESOURCE_ATTRIBUTES_REQUEST,
        FetchResourceAttributesRequest.class);
    registerDSFID(FETCH_RESOURCE_ATTRIBUTES_RESPONSE,
        FetchResourceAttributesResponse.class);
    registerDSFID(FETCH_STATS_REQUEST, FetchStatsRequest.class);
    registerDSFID(FETCH_STATS_RESPONSE, FetchStatsResponse.class);
    registerDSFID(FETCH_SYS_CFG_REQUEST, FetchSysCfgRequest.class);
    registerDSFID(FETCH_SYS_CFG_RESPONSE, FetchSysCfgResponse.class);
    registerDSFID(FLUSH_APP_CACHE_SNAPSHOT_MESSAGE,
        FlushAppCacheSnapshotMessage.class);
    registerDSFID(HEALTH_LISTENER_MESSAGE, HealthListenerMessage.class);
    registerDSFID(OBJECT_DETAILS_REQUEST, ObjectDetailsRequest.class);
    registerDSFID(OBJECT_DETAILS_RESPONSE, ObjectDetailsResponse.class);
    registerDSFID(OBJECT_NAMES_REQUEST, ObjectNamesRequest.class);
    registerDSFID(LICENSE_INFO_REQUEST, LicenseInfoRequest.class);
    registerDSFID(LICENSE_INFO_RESPONSE, LicenseInfoResponse.class);
    registerDSFID(OBJECT_NAMES_RESPONSE, ObjectNamesResponse.class);
    registerDSFID(REGION_ATTRIBUTES_REQUEST, RegionAttributesRequest.class);
    registerDSFID(REGION_ATTRIBUTES_RESPONSE, RegionAttributesResponse.class);
    registerDSFID(REGION_REQUEST, RegionRequest.class);
    registerDSFID(REGION_RESPONSE, RegionResponse.class);
    registerDSFID(REGION_SIZE_REQUEST, RegionSizeRequest.class);
    registerDSFID(REGION_SIZE_RESPONSE, RegionSizeResponse.class);
    registerDSFID(REGION_STATISTICS_REQUEST, RegionStatisticsRequest.class);
    registerDSFID(REGION_STATISTICS_RESPONSE, RegionStatisticsResponse.class);
    registerDSFID(REMOVE_HEALTH_LISTENER_REQUEST,
        RemoveHealthListenerRequest.class);
    registerDSFID(REMOVE_HEALTH_LISTENER_RESPONSE,
        RemoveHealthListenerResponse.class);
    registerDSFID(RESET_HEALTH_STATUS_REQUEST, ResetHealthStatusRequest.class);
    registerDSFID(RESET_HEALTH_STATUS_RESPONSE, ResetHealthStatusResponse.class);
    registerDSFID(ROOT_REGION_REQUEST, RootRegionRequest.class);
    registerDSFID(ROOT_REGION_RESPONSE, RootRegionResponse.class);
    registerDSFID(SNAPSHOT_RESULT_MESSAGE, SnapshotResultMessage.class);
    registerDSFID(STAT_LISTENER_MESSAGE, StatListenerMessage.class);
    registerDSFID(STORE_SYS_CFG_REQUEST, StoreSysCfgRequest.class);
    registerDSFID(STORE_SYS_CFG_RESPONSE, StoreSysCfgResponse.class);
    registerDSFID(SUB_REGION_REQUEST, SubRegionRequest.class);
    registerDSFID(SUB_REGION_RESPONSE, SubRegionResponse.class);
    registerDSFID(TAIL_LOG_REQUEST, TailLogRequest.class);
    registerDSFID(TAIL_LOG_RESPONSE, TailLogResponse.class);
    registerDSFID(VERSION_INFO_REQUEST, VersionInfoRequest.class);
    registerDSFID(VERSION_INFO_RESPONSE, VersionInfoResponse.class);
    registerDSFID(HIGH_PRIORITY_ACKED_MESSAGE, HighPriorityAckedMessage.class);
    registerDSFID(SERIAL_ACKED_MESSAGE, SerialAckedMessage.class);
    registerDSFID(BUCKET_PROFILE, BucketAdvisor.BucketProfile.class);
    registerDSFID(SERVER_BUCKET_PROFILE,
        BucketAdvisor.ServerBucketProfile.class);
    registerDSFID(PARTITION_PROFILE, RegionAdvisor.PartitionProfile.class);
    registerDSFID(GATEWAY_SENDER_PROFILE,
        GatewaySenderAdvisor.GatewaySenderProfile.class);
    registerDSFID(ROLE_EVENT, RoleEventImpl.class);
    registerDSFID(BRIDGE_REGION_EVENT, BridgeRegionEventImpl.class);
    registerDSFID(PR_INVALIDATE_MESSAGE, InvalidateMessage.class);
    registerDSFID(PR_INVALIDATE_REPLY_MESSAGE,
        InvalidateMessage.InvalidateReplyMessage.class);
    registerDSFID(TX_LOCK_UPDATE_PARTICIPANTS_REPLY_MESSAGE,
        TXLockUpdateParticipantsReplyMessage.class);
    registerDSFID(STREAMING_REPLY_MESSAGE, StreamingReplyMessage.class);
    registerDSFID(PARTITION_REGION_CONFIG, PartitionRegionConfig.class);
    registerDSFID(PREFER_BYTES_CACHED_DESERIALIZABLE,
        PreferBytesCachedDeserializable.class);
    registerDSFID(VM_CACHED_DESERIALIZABLE, VMCachedDeserializable.class);
    registerDSFID(GATEWAY_SENDER_EVENT_IMPL, GatewaySenderEventImpl.class);
    registerDSFID(SUSPEND_LOCKING_TOKEN, DLockService.SuspendLockingToken.class);
    registerDSFID(OBJECT_TYPE_IMPL, ObjectTypeImpl.class);
    registerDSFID(STRUCT_TYPE_IMPL, StructTypeImpl.class);
    registerDSFID(COLLECTION_TYPE_IMPL, CollectionTypeImpl.class);
    registerDSFID(TX_LOCK_BATCH, TXLockBatch.class);
    registerDSFID(GATEWAY_SENDER_EVENT_CALLBACK_ARGUMENT,
        GatewaySenderEventCallbackArgument.class);
    registerDSFID(MAP_TYPE_IMPL, MapTypeImpl.class);
    registerDSFID(STORE_ALL_CACHED_DESERIALIZABLE,
        StoreAllCachedDeserializable.class);
    registerDSFID(INTEREST_EVENT_MESSAGE, InterestEventMessage.class);
    registerDSFID(INTEREST_EVENT_REPLY_MESSAGE, InterestEventReplyMessage.class);
    registerDSFID(HA_EVENT_WRAPPER, HAEventWrapper.class);
    registerDSFID(STAT_ALERTS_MGR_ASSIGN_MESSAGE,
        StatAlertsManagerAssignMessage.class);
    registerDSFID(UPDATE_ALERTS_DEFN_MESSAGE,
        UpdateAlertDefinitionMessage.class);
    registerDSFID(REFRESH_MEMBER_SNAP_REQUEST,
        RefreshMemberSnapshotRequest.class);
    registerDSFID(REFRESH_MEMBER_SNAP_RESPONSE,
        RefreshMemberSnapshotResponse.class);
    registerDSFID(REGION_SUB_SIZE_REQUEST, RegionSubRegionSizeRequest.class);
    registerDSFID(REGION_SUB_SIZE_RESPONSE, RegionSubRegionsSizeResponse.class);
    registerDSFID(CHANGE_REFRESH_INT_MESSAGE,
        ChangeRefreshIntervalMessage.class);
    registerDSFID(ALERTS_NOTIF_MESSAGE, AlertsNotificationMessage.class);
    registerDSFID(FIND_DURABLE_QUEUE, FindDurableQueueMessage.class);
    registerDSFID(FIND_DURABLE_QUEUE_REPLY, FindDurableQueueReply.class);
    registerDSFID(BRIDGE_SERVER_LOAD_MESSAGE, BridgeServerLoadMessage.class);
    registerDSFID(BRIDGE_SERVER_PROFILE, BridgeServerProfile.class);
    registerDSFID(CONTROLLER_PROFILE, ControllerProfile.class);
    registerDSFID(DLOCK_QUERY_MESSAGE,
        DLockQueryProcessor.DLockQueryMessage.class);
    registerDSFID(DLOCK_QUERY_REPLY,
        DLockQueryProcessor.DLockQueryReplyMessage.class);
    registerDSFID(LOCATOR_LIST_REQUEST, LocatorListRequest.class);
    registerDSFID(LOCATOR_LIST_RESPONSE, LocatorListResponse.class);
    registerDSFID(CLIENT_CONNECTION_REQUEST, ClientConnectionRequest.class);
    registerDSFID(CLIENT_CONNECTION_RESPONSE, ClientConnectionResponse.class);
    registerDSFID(QUEUE_CONNECTION_REQUEST, QueueConnectionRequest.class);
    registerDSFID(QUEUE_CONNECTION_RESPONSE, QueueConnectionResponse.class);
    registerDSFID(CLIENT_REPLACEMENT_REQUEST, ClientReplacementRequest.class);
    registerDSFID(OBJECT_PART_LIST, ObjectPartList.class);
    registerDSFID(VERSIONED_OBJECT_LIST, VersionedObjectList.class);
    registerDSFID(OBJECT_PART_LIST66, ObjectPartList651.class);
    registerDSFID(PUTALL_VERSIONS_LIST, EntryVersionsList.class);
    registerDSFID(INITIAL_IMAGE_VERSIONED_OBJECT_LIST,
        InitialImageVersionedEntryList.class);
    registerDSFID(FIND_VERSION_TAG, FindVersionTagMessage.class);
    registerDSFID(VERSION_TAG_REPLY, VersionTagReply.class);
    registerDSFID(DURABLE_CLIENT_INFO_REQUEST, DurableClientInfoRequest.class);
    registerDSFID(DURABLE_CLIENT_INFO_RESPONSE, DurableClientInfoResponse.class);
    registerDSFID(CLIENT_INTEREST_MESSAGE, ClientInterestMessageImpl.class);
    registerDSFID(STAT_ALERT_DEFN_NUM_THRESHOLD,
        NumberThresholdDecoratorImpl.class);
    registerDSFID(STAT_ALERT_DEFN_GAUGE_THRESHOLD,
        GaugeThresholdDecoratorImpl.class);
    registerDSFID(CLIENT_HEALTH_STATS, ClientHealthStats.class);
    registerDSFID(STAT_ALERT_NOTIFICATION, StatAlertNotification.class);
    registerDSFID(FILTER_INFO_MESSAGE,
        InitialImageOperation.FilterInfoMessage.class);
    registerDSFID(SIZED_BASED_LOAD_PROBE, SizedBasedLoadProbe.class);
    registerDSFID(PR_MANAGE_BACKUP_BUCKET_MESSAGE,
        ManageBackupBucketMessage.class);
    registerDSFID(PR_MANAGE_BACKUP_BUCKET_REPLY_MESSAGE,
        ManageBackupBucketReplyMessage.class);
    registerDSFID(PR_CREATE_BUCKET_MESSAGE, CreateBucketMessage.class);
    registerDSFID(PR_CREATE_BUCKET_REPLY_MESSAGE,
        CreateBucketReplyMessage.class);
    registerDSFID(RESOURCE_MANAGER_PROFILE, ResourceManagerProfile.class);
    registerDSFID(RESOURCE_PROFILE_MESSAGE, ResourceProfileMessage.class);
    registerDSFID(JMX_MANAGER_PROFILE, JmxManagerProfile.class);
    registerDSFID(JMX_MANAGER_PROFILE_MESSAGE, JmxManagerProfileMessage.class);
    registerDSFID(CLIENT_BLACKLIST_MESSAGE, ClientBlacklistMessage.class);
    registerDSFID(REMOVE_CLIENT_FROM_BLACKLIST_MESSAGE,
        RemoveClientFromBlacklistMessage.class);
    registerDSFID(PR_FUNCTION_STREAMING_MESSAGE,
        PartitionedRegionFunctionStreamingMessage.class);
    registerDSFID(MEMBER_FUNCTION_STREAMING_MESSAGE,
        MemberFunctionStreamingMessage.class);
    registerDSFID(DR_FUNCTION_STREAMING_MESSAGE,
        DistributedRegionFunctionStreamingMessage.class);
    registerDSFID(FUNCTION_STREAMING_REPLY_MESSAGE,
        FunctionStreamingReplyMessage.class);
    registerDSFID(GET_ALL_SERVERS_REQUEST, GetAllServersRequest.class);
    registerDSFID(GET_ALL_SERVRES_RESPONSE, GetAllServersResponse.class);
    registerDSFID(PERSISTENT_MEMBERSHIP_VIEW_REQUEST,
        MembershipViewRequest.class);
    registerDSFID(PERSISTENT_MEMBERSHIP_VIEW_REPLY,
        MembershipViewReplyMessage.class);
    registerDSFID(PERSISTENT_STATE_QUERY_REQUEST,
        PersistentStateQueryMessage.class);
    registerDSFID(PERSISTENT_STATE_QUERY_REPLY,
        PersistentStateQueryReplyMessage.class);
    registerDSFID(PREPARE_NEW_PERSISTENT_MEMBER_REQUEST,
        PrepareNewPersistentMemberMessage.class);
    registerDSFID(MISSING_PERSISTENT_IDS_REQUEST,
        MissingPersistentIDsRequest.class);
    registerDSFID(MISSING_PERSISTENT_IDS_RESPONSE,
        MissingPersistentIDsResponse.class);
    registerDSFID(REVOKE_PERSISTENT_ID_REQUEST, RevokePersistentIDRequest.class);
    registerDSFID(REVOKE_PERSISTENT_ID_RESPONSE,
        RevokePersistentIDResponse.class);
    registerDSFID(REMOVE_PERSISTENT_MEMBER_REQUEST,
        RemovePersistentMemberMessage.class);
    registerDSFID(FUNCTION_STREAMING_ORDERED_REPLY_MESSAGE,
        FunctionStreamingOrderedReplyMessage.class);
    registerDSFID(REQUEST_SYNC_MESSAGE,
        InitialImageOperation.RequestSyncMessage.class);
    registerDSFID(PERSISTENT_MEMBERSHIP_FLUSH_REQUEST,
        MembershipFlushRequest.class);
    registerDSFID(SHUTDOWN_ALL_REQUEST, ShutdownAllRequest.class);
    registerDSFID(SHUTDOWN_ALL_RESPONSE, ShutdownAllResponse.class);
    registerDSFID(CLIENT_MEMBERSHIP_MESSAGE, ClientMembershipMessage.class);
    registerDSFID(END_BUCKET_CREATION_MESSAGE, EndBucketCreationMessage.class);
    registerDSFID(PREPARE_BACKUP_REQUEST, PrepareBackupRequest.class);
    registerDSFID(PREPARE_BACKUP_RESPONSE, PrepareBackupResponse.class);
    registerDSFID(FINISH_BACKUP_REQUEST, FinishBackupRequest.class);
    registerDSFID(FINISH_BACKUP_RESPONSE, FinishBackupResponse.class);
    registerDSFID(COMPACT_REQUEST, CompactRequest.class);
    registerDSFID(COMPACT_RESPONSE, CompactResponse.class);
    registerDSFID(FLOW_CONTROL_PERMIT_MESSAGE, FlowControlPermitMessage.class);
    registerDSFID(REQUEST_FILTERINFO_MESSAGE,
        InitialImageOperation.RequestFilterInfoMessage.class);
    registerDSFID(PARALLEL_QUEUE_REMOVAL_MESSAGE,
        ParallelQueueRemovalMessage.class);
    registerDSFID(PARALLEL_QUEUE_BATCH_REMOVAL_MESSAGE,
        ParallelQueueBatchRemovalMessage.class);
    registerDSFID(PARALLEL_QUEUE_BATCH_REMOVAL_REPLY,
        BatchRemovalReplyMessage.class);
    registerDSFID(BATCH_DESTROY_MESSAGE,
        BatchDestroyOperation.DestroyMessage.class);
    registerDSFID(FIND_REMOTE_TX_MESSAGE, FindRemoteTXMessage.class);
    registerDSFID(FIND_REMOTE_TX_REPLY, FindRemoteTXMessageReply.class);
    registerDSFID(SERIALIZED_OBJECT_PART_LIST, SerializedObjectPartList.class);
    registerDSFID(FLUSH_TO_DISK_REQUEST, FlushToDiskRequest.class);
    registerDSFID(FLUSH_TO_DISK_RESPONSE, FlushToDiskResponse.class);
    registerDSFID(ENUM_ID, EnumId.class);
    registerDSFID(ENUM_INFO, EnumInfo.class);
    registerDSFID(CHECK_TYPE_REGISTRY_STATE, CheckTypeRegistryState.class);
    registerDSFID(PREPARE_REVOKE_PERSISTENT_ID_REQUEST,
        PrepareRevokePersistentIDRequest.class);
    registerDSFID(PERSISTENT_RVV, DiskRegionVersionVector.class);
    registerDSFID(PERSISTENT_VERSION_TAG, DiskVersionTag.class);
    registerDSFID(DISK_STORE_ID, DiskStoreID.class);
    registerDSFID(CLIENT_PING_MESSAGE_IMPL, ClientPingMessageImpl.class);
    registerDSFID(SNAPSHOT_PACKET, SnapshotPacket.class);
    registerDSFID(SNAPSHOT_RECORD, SnapshotRecord.class);
    registerDSFID(FLOW_CONTROL_ACK, FlowControlAckMessage.class);
    registerDSFID(FLOW_CONTROL_ABORT, FlowControlAbortMessage.class);
    registerDSFID(MGMT_COMPACT_REQUEST,
        com.gemstone.gemfire.management.internal.messages.CompactRequest.class);
    registerDSFID(MGMT_COMPACT_RESPONSE,
        com.gemstone.gemfire.management.internal.messages.CompactResponse.class);
    registerDSFID(MGMT_FEDERATION_COMPONENT,
        com.gemstone.gemfire.management.internal.FederationComponent.class);
    registerDSFID(LOCATOR_STATUS_REQUEST, LocatorStatusRequest.class);
    registerDSFID(LOCATOR_STATUS_RESPONSE, LocatorStatusResponse.class);
    registerDSFID(R_FETCH_VERSION_MESSAGE, RemoteFetchVersionMessage.class);
    registerDSFID(R_FETCH_VERSION_REPLY,
        RemoteFetchVersionMessage.FetchVersionReplyMessage.class);
    registerDSFID(RELEASE_CLEAR_LOCK_MESSAGE, ReleaseClearLockMessage.class);
    registerDSFID(PR_TOMBSTONE_MESSAGE, PRTombstoneMessage.class);
    registerDSFID(HDFS_GATEWAY_EVENT_IMPL, HDFSGatewayEventImpl.class);
    
    registerDSFID(REQUEST_RVV_MESSAGE, InitialImageOperation.RequestRVVMessage.class);
    registerDSFID(RVV_REPLY_MESSAGE, InitialImageOperation.RVVReplyMessage.class);
    registerDSFID(SNAPPY_COMPRESSED_CACHED_DESERIALIZABLE, SnappyCompressedCachedDeserializable.class);
    registerDSFID(UPDATE_ENTRY_VERSION_MESSAGE, UpdateEntryVersionMessage.class);
    registerDSFID(PR_UPDATE_ENTRY_VERSION_MESSAGE,
        PRUpdateEntryVersionMessage.class);
    registerDSFID(PR_FETCH_BULK_ENTRIES_MESSAGE, FetchBulkEntriesMessage.class);
    registerDSFID(PR_FETCH_BULK_ENTRIES_REPLY_MESSAGE, FetchBulkEntriesReplyMessage.class);
    registerDSFID(PR_QUERY_TRACE_INFO, PRQueryTraceInfo.class);
    registerDSFID(INDEX_CREATION_DATA, IndexCreationData.class);
    registerDSFID(DIST_TX_OP, DistTxEntryEvent.class);
    registerDSFID(DIST_TX_PRE_COMMIT_RESPONSE, DistTXPrecommitMessage.DistTxPrecommitResponse.class);
    registerDSFID(DIST_TX_THIN_ENTRY_STATE, TXEntryState.DistTxThinEntryState.class);
    registerDSFID(SERVER_PING_MESSAGE, ServerPingMessage.class);
    registerDSFID(PR_DESTROY_ON_DATA_STORE_MESSAGE,
        DestroyRegionOnDataStoreMessage.class);
    registerDSFID(SHUTDOWN_ALL_GATEWAYHUBS_REQUEST,
        ShutdownAllGatewayHubsRequest.class);
  }",True
"  private static void registerDSFIDTypes() {
    registerDSFID(REMOVE_MEMBER_REQUEST, RemoveMemberMessage.class);
    registerDSFID(LEAVE_REQUEST_MESSAGE, LeaveRequestMessage.class);
    registerDSFID(VIEW_ACK_MESSAGE, ViewAckMessage.class);
    registerDSFID(INSTALL_VIEW_MESSAGE, InstallViewMessage.class);
    registerDSFID(GMSMEMBER, GMSMember.class);
    registerDSFID(NETVIEW, NetView.class);
    registerDSFID(GET_VIEW_REQ, GetViewRequest.class);
    registerDSFID(GET_VIEW_RESP, GetViewResponse.class);
    registerDSFID(FIND_COORDINATOR_REQ, FindCoordinatorRequest.class);
    registerDSFID(FIND_COORDINATOR_RESP, FindCoordinatorResponse.class);
    registerDSFID(JOIN_RESPONSE, JoinResponseMessage.class);
    registerDSFID(JOIN_REQUEST, JoinRequestMessage.class);
    registerDSFID(CLIENT_TOMBSTONE_MESSAGE, ClientTombstoneMessage.class);
    registerDSFID(R_REGION_OP, RemoteRegionOperation.class);
    registerDSFID(R_REGION_OP_REPLY, RemoteRegionOperationReplyMessage.class);
    registerDSFID(WAIT_FOR_VIEW_INSTALLATION, WaitForViewInstallation.class);
    registerDSFID(DISPATCHED_AND_CURRENT_EVENTS,
        DispatchedAndCurrentEvents.class);
    registerDSFID(DISTRIBUTED_MEMBER, InternalDistributedMember.class);
    registerDSFID(UPDATE_MESSAGE, UpdateOperation.UpdateMessage.class);
    registerDSFID(REPLY_MESSAGE, ReplyMessage.class);
    registerDSFID(PR_DESTROY, DestroyMessage.class);
    registerDSFID(CREATE_REGION_MESSAGE,
        CreateRegionProcessor.CreateRegionMessage.class);
    registerDSFID(CREATE_REGION_REPLY_MESSAGE,
        CreateRegionProcessor.CreateRegionReplyMessage.class);
    registerDSFID(REGION_STATE_MESSAGE,
        InitialImageOperation.RegionStateMessage.class);
    registerDSFID(QUERY_MESSAGE, SearchLoadAndWriteProcessor.QueryMessage.class);
    registerDSFID(RESPONSE_MESSAGE,
        SearchLoadAndWriteProcessor.ResponseMessage.class);
    registerDSFID(NET_SEARCH_REQUEST_MESSAGE,
        SearchLoadAndWriteProcessor.NetSearchRequestMessage.class);
    registerDSFID(NET_SEARCH_REPLY_MESSAGE,
        SearchLoadAndWriteProcessor.NetSearchReplyMessage.class);
    registerDSFID(NET_LOAD_REQUEST_MESSAGE,
        SearchLoadAndWriteProcessor.NetLoadRequestMessage.class);
    registerDSFID(NET_LOAD_REPLY_MESSAGE,
        SearchLoadAndWriteProcessor.NetLoadReplyMessage.class);
    registerDSFID(NET_WRITE_REQUEST_MESSAGE,
        SearchLoadAndWriteProcessor.NetWriteRequestMessage.class);
    registerDSFID(NET_WRITE_REPLY_MESSAGE,
        SearchLoadAndWriteProcessor.NetWriteReplyMessage.class);
    registerDSFID(DLOCK_REQUEST_MESSAGE,
        DLockRequestProcessor.DLockRequestMessage.class);
    registerDSFID(DLOCK_RESPONSE_MESSAGE,
        DLockRequestProcessor.DLockResponseMessage.class);
    registerDSFID(DLOCK_RELEASE_MESSAGE,
        DLockReleaseProcessor.DLockReleaseMessage.class);
    registerDSFID(ADMIN_CACHE_EVENT_MESSAGE,
        SystemMemberCacheEventProcessor.SystemMemberCacheMessage.class);
    registerDSFID(CQ_ENTRY_EVENT, CqEntry.class);
    registerDSFID(REQUEST_IMAGE_MESSAGE,
        InitialImageOperation.RequestImageMessage.class);
    registerDSFID(IMAGE_REPLY_MESSAGE,
        InitialImageOperation.ImageReplyMessage.class);
    registerDSFID(IMAGE_ENTRY, InitialImageOperation.Entry.class);
    registerDSFID(CLOSE_CACHE_MESSAGE, CloseCacheMessage.class);
    registerDSFID(NON_GRANTOR_DESTROYED_MESSAGE,
        NonGrantorDestroyedProcessor.NonGrantorDestroyedMessage.class);
    registerDSFID(DLOCK_RELEASE_REPLY,
        DLockReleaseProcessor.DLockReleaseReplyMessage.class);
    registerDSFID(GRANTOR_REQUEST_MESSAGE,
        GrantorRequestProcessor.GrantorRequestMessage.class);
    registerDSFID(GRANTOR_INFO_REPLY_MESSAGE,
        GrantorRequestProcessor.GrantorInfoReplyMessage.class);
    registerDSFID(ELDER_INIT_MESSAGE, ElderInitProcessor.ElderInitMessage.class);
    registerDSFID(ELDER_INIT_REPLY_MESSAGE,
        ElderInitProcessor.ElderInitReplyMessage.class);
    registerDSFID(DEPOSE_GRANTOR_MESSAGE,
        DeposeGrantorProcessor.DeposeGrantorMessage.class);
    registerDSFID(STARTUP_MESSAGE, StartupMessage.class);
    registerDSFID(STARTUP_RESPONSE_MESSAGE, StartupResponseMessage.class);
    registerDSFID(STARTUP_RESPONSE_WITHVERSION_MESSAGE,
        StartupResponseWithVersionMessage.class);
    registerDSFID(SHUTDOWN_MESSAGE, ShutdownMessage.class);
    registerDSFID(DESTROY_REGION_MESSAGE,
        DestroyRegionOperation.DestroyRegionMessage.class);
    registerDSFID(PR_PUTALL_MESSAGE, PutAllPRMessage.class);
    registerDSFID(PR_REMOVE_ALL_MESSAGE, RemoveAllPRMessage.class);
    registerDSFID(PR_REMOVE_ALL_REPLY_MESSAGE, RemoveAllPRMessage.RemoveAllReplyMessage.class);
    registerDSFID(REMOTE_REMOVE_ALL_MESSAGE, RemoteRemoveAllMessage.class);
    registerDSFID(REMOTE_REMOVE_ALL_REPLY_MESSAGE, RemoteRemoveAllMessage.RemoveAllReplyMessage.class);
    registerDSFID(DISTTX_ROLLBACK_MESSAGE, DistTXRollbackMessage.class);
    registerDSFID(DISTTX_COMMIT_MESSAGE, DistTXCommitMessage.class);
    registerDSFID(DISTTX_PRE_COMMIT_MESSAGE, DistTXPrecommitMessage.class);
    registerDSFID(DISTTX_ROLLBACK_REPLY_MESSAGE, DistTXRollbackMessage.DistTXRollbackReplyMessage.class);
    registerDSFID(DISTTX_COMMIT_REPLY_MESSAGE, DistTXCommitMessage.DistTXCommitReplyMessage.class);
    registerDSFID(DISTTX_PRE_COMMIT_REPLY_MESSAGE, DistTXPrecommitMessage.DistTXPrecommitReplyMessage.class);
    registerDSFID(PR_PUT_MESSAGE, PutMessage.class);
    registerDSFID(INVALIDATE_MESSAGE,
        InvalidateOperation.InvalidateMessage.class);
    registerDSFID(DESTROY_MESSAGE, DestroyOperation.DestroyMessage.class);
    registerDSFID(DA_PROFILE, DistributionAdvisor.Profile.class);
    registerDSFID(CACHE_PROFILE, CacheDistributionAdvisor.CacheProfile.class);
    registerDSFID(HA_PROFILE, HARegion.HARegionAdvisor.HAProfile.class);
    registerDSFID(ENTRY_EVENT, EntryEventImpl.class);
    registerDSFID(UPDATE_ATTRIBUTES_MESSAGE,
        UpdateAttributesProcessor.UpdateAttributesMessage.class);
    registerDSFID(PROFILE_REPLY_MESSAGE,
        UpdateAttributesProcessor.ProfileReplyMessage.class);
    registerDSFID(PROFILES_REPLY_MESSAGE,
        UpdateAttributesProcessor.ProfilesReplyMessage.class);
    registerDSFID(REGION_EVENT, RegionEventImpl.class);
    registerDSFID(TX_COMMIT_MESSAGE, TXCommitMessage.class);
    registerDSFID(COMMIT_PROCESS_FOR_LOCKID_MESSAGE,
        CommitProcessForLockIdMessage.class);
    registerDSFID(COMMIT_PROCESS_FOR_TXID_MESSAGE,
        CommitProcessForTXIdMessage.class);
    registerDSFID(FILTER_PROFILE, FilterProfile.class);
    registerDSFID(REMOTE_PUTALL_REPLY_MESSAGE,
        RemotePutAllMessage.PutAllReplyMessage.class);
    registerDSFID(REMOTE_PUTALL_MESSAGE, RemotePutAllMessage.class);
    registerDSFID(VERSION_TAG, VMVersionTag.class);
    registerDSFID(ADD_CACHESERVER_PROFILE_UPDATE,
        AddCacheServerProfileMessage.class);
    registerDSFID(SERVER_INTEREST_REGISTRATION_MESSAGE,
        ServerInterestRegistrationMessage.class);
    registerDSFID(FILTER_PROFILE_UPDATE, FilterProfile.OperationMessage.class);
    registerDSFID(PR_GET_MESSAGE, GetMessage.class);
    registerDSFID(R_FETCH_ENTRY_MESSAGE, RemoteFetchEntryMessage.class);
    registerDSFID(R_FETCH_ENTRY_REPLY_MESSAGE,
        RemoteFetchEntryMessage.FetchEntryReplyMessage.class);
    registerDSFID(R_CONTAINS_MESSAGE, RemoteContainsKeyValueMessage.class);
    registerDSFID(R_CONTAINS_REPLY_MESSAGE,
        RemoteContainsKeyValueMessage.RemoteContainsKeyValueReplyMessage.class);
    registerDSFID(R_DESTROY_MESSAGE, RemoteDestroyMessage.class);
    registerDSFID(R_DESTROY_REPLY_MESSAGE,
        RemoteDestroyMessage.DestroyReplyMessage.class);
    registerDSFID(R_INVALIDATE_MESSAGE, RemoteInvalidateMessage.class);
    registerDSFID(R_INVALIDATE_REPLY_MESSAGE,
        RemoteInvalidateMessage.InvalidateReplyMessage.class);
    registerDSFID(R_GET_MESSAGE, RemoteGetMessage.class);
    registerDSFID(R_GET_REPLY_MESSAGE, RemoteGetMessage.GetReplyMessage.class);
    registerDSFID(R_PUT_MESSAGE, RemotePutMessage.class);
    registerDSFID(R_PUT_REPLY_MESSAGE, RemotePutMessage.PutReplyMessage.class);
    registerDSFID(R_SIZE_MESSAGE, RemoteSizeMessage.class);
    registerDSFID(R_SIZE_REPLY_MESSAGE,
        RemoteSizeMessage.SizeReplyMessage.class);
    registerDSFID(PR_DESTROY_REPLY_MESSAGE,
        DestroyMessage.DestroyReplyMessage.class);
    registerDSFID(CLI_FUNCTION_RESULT, CliFunctionResult.class);
    registerDSFID(R_FETCH_KEYS_MESSAGE, RemoteFetchKeysMessage.class);
    registerDSFID(R_FETCH_KEYS_REPLY,
        RemoteFetchKeysMessage.RemoteFetchKeysReplyMessage.class);
    registerDSFID(R_REMOTE_COMMIT_REPLY_MESSAGE,
        TXRemoteCommitReplyMessage.class);
    registerDSFID(TRANSACTION_LOCK_ID, TXLockIdImpl.class);
    registerDSFID(PR_GET_REPLY_MESSAGE, GetReplyMessage.class);
    registerDSFID(PR_NODE, Node.class);
    registerDSFID(UPDATE_WITH_CONTEXT_MESSAGE,
        UpdateOperation.UpdateWithContextMessage.class);
    registerDSFID(DESTROY_WITH_CONTEXT_MESSAGE,
        DestroyOperation.DestroyWithContextMessage.class);
    registerDSFID(INVALIDATE_WITH_CONTEXT_MESSAGE,
        InvalidateOperation.InvalidateWithContextMessage.class);
    registerDSFID(REGION_VERSION_VECTOR, VMRegionVersionVector.class);
    registerDSFID(CLIENT_PROXY_MEMBERSHIPID, ClientProxyMembershipID.class);
    registerDSFID(EVENT_ID, EventID.class);
    registerDSFID(CLIENT_UPDATE_MESSAGE, ClientUpdateMessageImpl.class);
    registerDSFID(CLEAR_REGION_MESSAGE_WITH_CONTEXT,
        ClearRegionWithContextMessage.class);
    registerDSFID(CLIENT_INSTANTIATOR_MESSAGE, ClientInstantiatorMessage.class);
    registerDSFID(CLIENT_DATASERIALIZER_MESSAGE,
        ClientDataSerializerMessage.class);
    registerDSFID(REGISTRATION_MESSAGE,
        InternalInstantiator.RegistrationMessage.class);
    registerDSFID(REGISTRATION_CONTEXT_MESSAGE,
        InternalInstantiator.RegistrationContextMessage.class);
    registerDSFID(RESULTS_COLLECTION_WRAPPER, ResultsCollectionWrapper.class);
    registerDSFID(RESULTS_SET, ResultsSet.class);
    registerDSFID(SORTED_RESULT_SET, SortedResultSet.class);
    registerDSFID(SORTED_STRUCT_SET, SortedStructSet.class);
    registerDSFID(NWAY_MERGE_RESULTS, NWayMergeResults.class);
    registerDSFID(CUMULATIVE_RESULTS, CumulativeNonDistinctResults.class);
    registerDSFID(UNDEFINED, Undefined.class);
    registerDSFID(STRUCT_IMPL, StructImpl.class);
    registerDSFID(STRUCT_SET, StructSet.class);
    registerDSFID(END_OF_BUCKET, PRQueryProcessor.EndOfBucket.class);
    registerDSFID(STRUCT_BAG, StructBag.class);
    registerDSFID(LINKED_RESULTSET, LinkedResultSet.class);
    registerDSFID(LINKED_STRUCTSET, LinkedStructSet.class);
    registerDSFID(PR_BUCKET_BACKUP_MESSAGE, BucketBackupMessage.class);
    registerDSFID(PR_BUCKET_PROFILE_UPDATE_MESSAGE,
        BucketProfileUpdateMessage.class);
    registerDSFID(PR_ALL_BUCKET_PROFILES_UPDATE_MESSAGE,
        AllBucketProfilesUpdateMessage.class);
    registerDSFID(PR_BUCKET_SIZE_MESSAGE, BucketSizeMessage.class);
    registerDSFID(PR_CONTAINS_KEY_VALUE_MESSAGE, ContainsKeyValueMessage.class);
    registerDSFID(PR_DUMP_ALL_PR_CONFIG_MESSAGE, DumpAllPRConfigMessage.class);
    registerDSFID(PR_DUMP_BUCKETS_MESSAGE, DumpBucketsMessage.class);
    registerDSFID(PR_FETCH_ENTRIES_MESSAGE, FetchEntriesMessage.class);
    registerDSFID(PR_FETCH_ENTRY_MESSAGE, FetchEntryMessage.class);
    registerDSFID(PR_FETCH_KEYS_MESSAGE, FetchKeysMessage.class);
    registerDSFID(PR_FLUSH_MESSAGE, FlushMessage.class);
    registerDSFID(PR_IDENTITY_REQUEST_MESSAGE, IdentityRequestMessage.class);
    registerDSFID(PR_IDENTITY_UPDATE_MESSAGE, IdentityUpdateMessage.class);
    registerDSFID(PR_INDEX_CREATION_MSG, IndexCreationMsg.class);
    registerDSFID(PR_MANAGE_BUCKET_MESSAGE, ManageBucketMessage.class);
    registerDSFID(PR_PRIMARY_REQUEST_MESSAGE, PrimaryRequestMessage.class);
    registerDSFID(PR_PRIMARY_REQUEST_REPLY_MESSAGE,
        PrimaryRequestReplyMessage.class);
    registerDSFID(PR_SANITY_CHECK_MESSAGE, PRSanityCheckMessage.class);
    registerDSFID(PR_PUTALL_REPLY_MESSAGE, PutAllReplyMessage.class);
    registerDSFID(PR_PUT_REPLY_MESSAGE, PutReplyMessage.class);
    registerDSFID(PR_QUERY_MESSAGE, QueryMessage.class);
    registerDSFID(PR_REMOVE_INDEXES_MESSAGE, RemoveIndexesMessage.class);
    registerDSFID(PR_REMOVE_INDEXES_REPLY_MESSAGE,
        RemoveIndexesReplyMessage.class);
    registerDSFID(PR_SIZE_MESSAGE, SizeMessage.class);
    registerDSFID(PR_SIZE_REPLY_MESSAGE, SizeReplyMessage.class);
    registerDSFID(PR_BUCKET_SIZE_REPLY_MESSAGE, BucketSizeReplyMessage.class);
    registerDSFID(PR_CONTAINS_KEY_VALUE_REPLY_MESSAGE,
        ContainsKeyValueReplyMessage.class);
    registerDSFID(PR_FETCH_ENTRIES_REPLY_MESSAGE,
        FetchEntriesReplyMessage.class);
    registerDSFID(PR_FETCH_ENTRY_REPLY_MESSAGE, FetchEntryReplyMessage.class);
    registerDSFID(PR_IDENTITY_REPLY_MESSAGE, IdentityReplyMessage.class);
    registerDSFID(PR_INDEX_CREATION_REPLY_MSG, IndexCreationReplyMsg.class);
    registerDSFID(PR_MANAGE_BUCKET_REPLY_MESSAGE,
        ManageBucketReplyMessage.class);
    registerDSFID(PR_FETCH_KEYS_REPLY_MESSAGE, FetchKeysReplyMessage.class);
    registerDSFID(PR_DUMP_B2N_REGION_MSG, DumpB2NRegion.class);
    registerDSFID(PR_DUMP_B2N_REPLY_MESSAGE, DumpB2NReplyMessage.class);
    registerDSFID(DESTROY_PARTITIONED_REGION_MESSAGE,
        DestroyPartitionedRegionMessage.class);
    registerDSFID(INVALIDATE_PARTITIONED_REGION_MESSAGE,
        InvalidatePartitionedRegionMessage.class);
    registerDSFID(COMMIT_PROCESS_QUERY_MESSAGE,
        CommitProcessQueryMessage.class);
    registerDSFID(COMMIT_PROCESS_QUERY_REPLY_MESSAGE,
        CommitProcessQueryReplyMessage.class);
    registerDSFID(DESTROY_REGION_WITH_CONTEXT_MESSAGE,
        DestroyRegionOperation.DestroyRegionWithContextMessage.class);
    registerDSFID(PUT_ALL_MESSAGE, PutAllMessage.class);
    registerDSFID(REMOVE_ALL_MESSAGE, RemoveAllMessage.class);
    registerDSFID(CLEAR_REGION_MESSAGE, ClearRegionMessage.class);
    registerDSFID(TOMBSTONE_MESSAGE, TombstoneMessage.class);
    registerDSFID(INVALIDATE_REGION_MESSAGE, InvalidateRegionMessage.class);
    registerDSFID(SEND_QUEUE_MESSAGE, SendQueueMessage.class);
    registerDSFID(STATE_MARKER_MESSAGE, StateMarkerMessage.class);
    registerDSFID(STATE_STABILIZATION_MESSAGE, StateStabilizationMessage.class);
    registerDSFID(STATE_STABILIZED_MESSAGE, StateStabilizedMessage.class);
    registerDSFID(CLIENT_MARKER_MESSAGE_IMPL, ClientMarkerMessageImpl.class);
    registerDSFID(TX_LOCK_UPDATE_PARTICIPANTS_MESSAGE,
        TXLockUpdateParticipantsMessage.class);
    registerDSFID(TX_ORIGINATOR_RECOVERY_MESSAGE,
        TXOriginatorRecoveryMessage.class);
    registerDSFID(TX_ORIGINATOR_RECOVERY_REPLY_MESSAGE,
        TXOriginatorRecoveryReplyMessage.class);
    registerDSFID(TX_REMOTE_COMMIT_MESSAGE, TXRemoteCommitMessage.class);
    registerDSFID(TX_REMOTE_ROLLBACK_MESSAGE, TXRemoteRollbackMessage.class);
    registerDSFID(JTA_BEFORE_COMPLETION_MESSAGE,
        JtaBeforeCompletionMessage.class);
    registerDSFID(JTA_AFTER_COMPLETION_MESSAGE,
        JtaAfterCompletionMessage.class);
    registerDSFID(QUEUE_REMOVAL_MESSAGE, QueueRemovalMessage.class);
    registerDSFID(DLOCK_RECOVER_GRANTOR_MESSAGE,
        DLockRecoverGrantorMessage.class);
    registerDSFID(DLOCK_RECOVER_GRANTOR_REPLY_MESSAGE,
        DLockRecoverGrantorReplyMessage.class);
    registerDSFID(NON_GRANTOR_DESTROYED_REPLY_MESSAGE,
        NonGrantorDestroyedReplyMessage.class);
    registerDSFID(IDS_REGISTRATION_MESSAGE,
        InternalDataSerializer.RegistrationMessage.class);
    registerDSFID(PR_FETCH_PARTITION_DETAILS_MESSAGE,
        FetchPartitionDetailsMessage.class);
    registerDSFID(PR_FETCH_PARTITION_DETAILS_REPLY,
        FetchPartitionDetailsReplyMessage.class);
    registerDSFID(PR_DEPOSE_PRIMARY_BUCKET_MESSAGE,
        DeposePrimaryBucketMessage.class);
    registerDSFID(PR_DEPOSE_PRIMARY_BUCKET_REPLY,
        DeposePrimaryBucketReplyMessage.class);
    registerDSFID(PR_BECOME_PRIMARY_BUCKET_MESSAGE,
        BecomePrimaryBucketMessage.class);
    registerDSFID(PR_BECOME_PRIMARY_BUCKET_REPLY,
        BecomePrimaryBucketReplyMessage.class);
    registerDSFID(PR_REMOVE_BUCKET_MESSAGE, RemoveBucketMessage.class);
    registerDSFID(TX_MANAGER_REMOVE_TRANSACTIONS,
        TXManagerImpl.TXRemovalMessage.class);
    registerDSFID(PR_REMOVE_BUCKET_REPLY, RemoveBucketReplyMessage.class);
    registerDSFID(PR_MOVE_BUCKET_MESSAGE, MoveBucketMessage.class);
    registerDSFID(PR_MOVE_BUCKET_REPLY, MoveBucketReplyMessage.class);
    registerDSFID(ADD_HEALTH_LISTENER_REQUEST, AddHealthListenerRequest.class);
    registerDSFID(ADD_HEALTH_LISTENER_RESPONSE, AddHealthListenerResponse.class);
    registerDSFID(ADD_STAT_LISTENER_REQUEST, AddStatListenerRequest.class);
    registerDSFID(ADD_STAT_LISTENER_RESPONSE, AddStatListenerResponse.class);
    registerDSFID(ADMIN_CONSOLE_DISCONNECT_MESSAGE,
        AdminConsoleDisconnectMessage.class);
    registerDSFID(ADMIN_CONSOLE_MESSAGE, AdminConsoleMessage.class);
    registerDSFID(MANAGER_STARTUP_MESSAGE, ManagerStartupMessage.class);
    registerDSFID(JMX_MANAGER_LOCATOR_REQUEST, JmxManagerLocatorRequest.class);
    registerDSFID(JMX_MANAGER_LOCATOR_RESPONSE, JmxManagerLocatorResponse.class);
    registerDSFID(ADMIN_FAILURE_RESPONSE, AdminFailureResponse.class);
    registerDSFID(ALERT_LEVEL_CHANGE_MESSAGE, AlertLevelChangeMessage.class);
    registerDSFID(ALERT_LISTENER_MESSAGE, AlertListenerMessage.class);
    registerDSFID(APP_CACHE_SNAPSHOT_MESSAGE, AppCacheSnapshotMessage.class);
    registerDSFID(BRIDGE_SERVER_REQUEST, BridgeServerRequest.class);
    registerDSFID(BRIDGE_SERVER_RESPONSE, BridgeServerResponse.class);
    registerDSFID(CACHE_CONFIG_REQUEST, CacheConfigRequest.class);
    registerDSFID(CACHE_CONFIG_RESPONSE, CacheConfigResponse.class);
    registerDSFID(CACHE_INFO_REQUEST, CacheInfoRequest.class);
    registerDSFID(CACHE_INFO_RESPONSE, CacheInfoResponse.class);
    registerDSFID(CANCELLATION_MESSAGE, CancellationMessage.class);
    registerDSFID(CANCEL_STAT_LISTENER_REQUEST, CancelStatListenerRequest.class);
    registerDSFID(CANCEL_STAT_LISTENER_RESPONSE,
        CancelStatListenerResponse.class);
    registerDSFID(DESTROY_ENTRY_MESSAGE, DestroyEntryMessage.class);
    registerDSFID(ADMIN_DESTROY_REGION_MESSAGE, DestroyRegionMessage.class);
    registerDSFID(FETCH_DIST_LOCK_INFO_REQUEST, FetchDistLockInfoRequest.class);
    registerDSFID(FETCH_DIST_LOCK_INFO_RESPONSE,
        FetchDistLockInfoResponse.class);
    registerDSFID(FETCH_HEALTH_DIAGNOSIS_REQUEST,
        FetchHealthDiagnosisRequest.class);
    registerDSFID(FETCH_HEALTH_DIAGNOSIS_RESPONSE,
        FetchHealthDiagnosisResponse.class);
    registerDSFID(FETCH_HOST_REQUEST, FetchHostRequest.class);
    registerDSFID(FETCH_HOST_RESPONSE, FetchHostResponse.class);
    registerDSFID(FETCH_RESOURCE_ATTRIBUTES_REQUEST,
        FetchResourceAttributesRequest.class);
    registerDSFID(FETCH_RESOURCE_ATTRIBUTES_RESPONSE,
        FetchResourceAttributesResponse.class);
    registerDSFID(FETCH_STATS_REQUEST, FetchStatsRequest.class);
    registerDSFID(FETCH_STATS_RESPONSE, FetchStatsResponse.class);
    registerDSFID(FETCH_SYS_CFG_REQUEST, FetchSysCfgRequest.class);
    registerDSFID(FETCH_SYS_CFG_RESPONSE, FetchSysCfgResponse.class);
    registerDSFID(FLUSH_APP_CACHE_SNAPSHOT_MESSAGE,
        FlushAppCacheSnapshotMessage.class);
    registerDSFID(HEALTH_LISTENER_MESSAGE, HealthListenerMessage.class);
    registerDSFID(OBJECT_DETAILS_REQUEST, ObjectDetailsRequest.class);
    registerDSFID(OBJECT_DETAILS_RESPONSE, ObjectDetailsResponse.class);
    registerDSFID(OBJECT_NAMES_REQUEST, ObjectNamesRequest.class);
    registerDSFID(LICENSE_INFO_REQUEST, LicenseInfoRequest.class);
    registerDSFID(LICENSE_INFO_RESPONSE, LicenseInfoResponse.class);
    registerDSFID(OBJECT_NAMES_RESPONSE, ObjectNamesResponse.class);
    registerDSFID(REGION_ATTRIBUTES_REQUEST, RegionAttributesRequest.class);
    registerDSFID(REGION_ATTRIBUTES_RESPONSE, RegionAttributesResponse.class);
    registerDSFID(REGION_REQUEST, RegionRequest.class);
    registerDSFID(REGION_RESPONSE, RegionResponse.class);
    registerDSFID(REGION_SIZE_REQUEST, RegionSizeRequest.class);
    registerDSFID(REGION_SIZE_RESPONSE, RegionSizeResponse.class);
    registerDSFID(REGION_STATISTICS_REQUEST, RegionStatisticsRequest.class);
    registerDSFID(REGION_STATISTICS_RESPONSE, RegionStatisticsResponse.class);
    registerDSFID(REMOVE_HEALTH_LISTENER_REQUEST,
        RemoveHealthListenerRequest.class);
    registerDSFID(REMOVE_HEALTH_LISTENER_RESPONSE,
        RemoveHealthListenerResponse.class);
    registerDSFID(RESET_HEALTH_STATUS_REQUEST, ResetHealthStatusRequest.class);
    registerDSFID(RESET_HEALTH_STATUS_RESPONSE, ResetHealthStatusResponse.class);
    registerDSFID(ROOT_REGION_REQUEST, RootRegionRequest.class);
    registerDSFID(ROOT_REGION_RESPONSE, RootRegionResponse.class);
    registerDSFID(SNAPSHOT_RESULT_MESSAGE, SnapshotResultMessage.class);
    registerDSFID(STAT_LISTENER_MESSAGE, StatListenerMessage.class);
    registerDSFID(STORE_SYS_CFG_REQUEST, StoreSysCfgRequest.class);
    registerDSFID(STORE_SYS_CFG_RESPONSE, StoreSysCfgResponse.class);
    registerDSFID(SUB_REGION_REQUEST, SubRegionRequest.class);
    registerDSFID(SUB_REGION_RESPONSE, SubRegionResponse.class);
    registerDSFID(TAIL_LOG_REQUEST, TailLogRequest.class);
    registerDSFID(TAIL_LOG_RESPONSE, TailLogResponse.class);
    registerDSFID(VERSION_INFO_REQUEST, VersionInfoRequest.class);
    registerDSFID(VERSION_INFO_RESPONSE, VersionInfoResponse.class);
    registerDSFID(HIGH_PRIORITY_ACKED_MESSAGE, HighPriorityAckedMessage.class);
    registerDSFID(SERIAL_ACKED_MESSAGE, SerialAckedMessage.class);
    registerDSFID(BUCKET_PROFILE, BucketAdvisor.BucketProfile.class);
    registerDSFID(SERVER_BUCKET_PROFILE,
        BucketAdvisor.ServerBucketProfile.class);
    registerDSFID(PARTITION_PROFILE, RegionAdvisor.PartitionProfile.class);
    registerDSFID(GATEWAY_SENDER_PROFILE,
        GatewaySenderAdvisor.GatewaySenderProfile.class);
    registerDSFID(ROLE_EVENT, RoleEventImpl.class);
    registerDSFID(BRIDGE_REGION_EVENT, BridgeRegionEventImpl.class);
    registerDSFID(PR_INVALIDATE_MESSAGE, InvalidateMessage.class);
    registerDSFID(PR_INVALIDATE_REPLY_MESSAGE,
        InvalidateMessage.InvalidateReplyMessage.class);
    registerDSFID(TX_LOCK_UPDATE_PARTICIPANTS_REPLY_MESSAGE,
        TXLockUpdateParticipantsReplyMessage.class);
    registerDSFID(STREAMING_REPLY_MESSAGE, StreamingReplyMessage.class);
    registerDSFID(PARTITION_REGION_CONFIG, PartitionRegionConfig.class);
    registerDSFID(PREFER_BYTES_CACHED_DESERIALIZABLE,
        PreferBytesCachedDeserializable.class);
    registerDSFID(VM_CACHED_DESERIALIZABLE, VMCachedDeserializable.class);
    registerDSFID(GATEWAY_SENDER_EVENT_IMPL, GatewaySenderEventImpl.class);
    registerDSFID(SUSPEND_LOCKING_TOKEN, DLockService.SuspendLockingToken.class);
    registerDSFID(OBJECT_TYPE_IMPL, ObjectTypeImpl.class);
    registerDSFID(STRUCT_TYPE_IMPL, StructTypeImpl.class);
    registerDSFID(COLLECTION_TYPE_IMPL, CollectionTypeImpl.class);
    registerDSFID(TX_LOCK_BATCH, TXLockBatch.class);
    registerDSFID(GATEWAY_SENDER_EVENT_CALLBACK_ARGUMENT,
        GatewaySenderEventCallbackArgument.class);
    registerDSFID(MAP_TYPE_IMPL, MapTypeImpl.class);
    registerDSFID(STORE_ALL_CACHED_DESERIALIZABLE,
        StoreAllCachedDeserializable.class);
    registerDSFID(INTEREST_EVENT_MESSAGE, InterestEventMessage.class);
    registerDSFID(INTEREST_EVENT_REPLY_MESSAGE, InterestEventReplyMessage.class);
    registerDSFID(HA_EVENT_WRAPPER, HAEventWrapper.class);
    registerDSFID(STAT_ALERTS_MGR_ASSIGN_MESSAGE,
        StatAlertsManagerAssignMessage.class);
    registerDSFID(UPDATE_ALERTS_DEFN_MESSAGE,
        UpdateAlertDefinitionMessage.class);
    registerDSFID(REFRESH_MEMBER_SNAP_REQUEST,
        RefreshMemberSnapshotRequest.class);
    registerDSFID(REFRESH_MEMBER_SNAP_RESPONSE,
        RefreshMemberSnapshotResponse.class);
    registerDSFID(REGION_SUB_SIZE_REQUEST, RegionSubRegionSizeRequest.class);
    registerDSFID(REGION_SUB_SIZE_RESPONSE, RegionSubRegionsSizeResponse.class);
    registerDSFID(CHANGE_REFRESH_INT_MESSAGE,
        ChangeRefreshIntervalMessage.class);
    registerDSFID(ALERTS_NOTIF_MESSAGE, AlertsNotificationMessage.class);
    registerDSFID(FIND_DURABLE_QUEUE, FindDurableQueueMessage.class);
    registerDSFID(FIND_DURABLE_QUEUE_REPLY, FindDurableQueueReply.class);
    registerDSFID(BRIDGE_SERVER_LOAD_MESSAGE, BridgeServerLoadMessage.class);
    registerDSFID(BRIDGE_SERVER_PROFILE, BridgeServerProfile.class);
    registerDSFID(CONTROLLER_PROFILE, ControllerProfile.class);
    registerDSFID(DLOCK_QUERY_MESSAGE,
        DLockQueryProcessor.DLockQueryMessage.class);
    registerDSFID(DLOCK_QUERY_REPLY,
        DLockQueryProcessor.DLockQueryReplyMessage.class);
    registerDSFID(LOCATOR_LIST_REQUEST, LocatorListRequest.class);
    registerDSFID(LOCATOR_LIST_RESPONSE, LocatorListResponse.class);
    registerDSFID(CLIENT_CONNECTION_REQUEST, ClientConnectionRequest.class);
    registerDSFID(CLIENT_CONNECTION_RESPONSE, ClientConnectionResponse.class);
    registerDSFID(QUEUE_CONNECTION_REQUEST, QueueConnectionRequest.class);
    registerDSFID(QUEUE_CONNECTION_RESPONSE, QueueConnectionResponse.class);
    registerDSFID(CLIENT_REPLACEMENT_REQUEST, ClientReplacementRequest.class);
    registerDSFID(OBJECT_PART_LIST, ObjectPartList.class);
    registerDSFID(VERSIONED_OBJECT_LIST, VersionedObjectList.class);
    registerDSFID(OBJECT_PART_LIST66, ObjectPartList651.class);
    registerDSFID(PUTALL_VERSIONS_LIST, EntryVersionsList.class);
    registerDSFID(INITIAL_IMAGE_VERSIONED_OBJECT_LIST,
        InitialImageVersionedEntryList.class);
    registerDSFID(FIND_VERSION_TAG, FindVersionTagMessage.class);
    registerDSFID(VERSION_TAG_REPLY, VersionTagReply.class);
    registerDSFID(DURABLE_CLIENT_INFO_REQUEST, DurableClientInfoRequest.class);
    registerDSFID(DURABLE_CLIENT_INFO_RESPONSE, DurableClientInfoResponse.class);
    registerDSFID(CLIENT_INTEREST_MESSAGE, ClientInterestMessageImpl.class);
    registerDSFID(STAT_ALERT_DEFN_NUM_THRESHOLD,
        NumberThresholdDecoratorImpl.class);
    registerDSFID(STAT_ALERT_DEFN_GAUGE_THRESHOLD,
        GaugeThresholdDecoratorImpl.class);
    registerDSFID(CLIENT_HEALTH_STATS, ClientHealthStats.class);
    registerDSFID(STAT_ALERT_NOTIFICATION, StatAlertNotification.class);
    registerDSFID(FILTER_INFO_MESSAGE,
        InitialImageOperation.FilterInfoMessage.class);
    registerDSFID(SIZED_BASED_LOAD_PROBE, SizedBasedLoadProbe.class);
    registerDSFID(PR_MANAGE_BACKUP_BUCKET_MESSAGE,
        ManageBackupBucketMessage.class);
    registerDSFID(PR_MANAGE_BACKUP_BUCKET_REPLY_MESSAGE,
        ManageBackupBucketReplyMessage.class);
    registerDSFID(PR_CREATE_BUCKET_MESSAGE, CreateBucketMessage.class);
    registerDSFID(PR_CREATE_BUCKET_REPLY_MESSAGE,
        CreateBucketReplyMessage.class);
    registerDSFID(RESOURCE_MANAGER_PROFILE, ResourceManagerProfile.class);
    registerDSFID(RESOURCE_PROFILE_MESSAGE, ResourceProfileMessage.class);
    registerDSFID(JMX_MANAGER_PROFILE, JmxManagerProfile.class);
    registerDSFID(JMX_MANAGER_PROFILE_MESSAGE, JmxManagerProfileMessage.class);
    registerDSFID(CLIENT_BLACKLIST_MESSAGE, ClientBlacklistMessage.class);
    registerDSFID(REMOVE_CLIENT_FROM_BLACKLIST_MESSAGE,
        RemoveClientFromBlacklistMessage.class);
    registerDSFID(PR_FUNCTION_STREAMING_MESSAGE,
        PartitionedRegionFunctionStreamingMessage.class);
    registerDSFID(MEMBER_FUNCTION_STREAMING_MESSAGE,
        MemberFunctionStreamingMessage.class);
    registerDSFID(DR_FUNCTION_STREAMING_MESSAGE,
        DistributedRegionFunctionStreamingMessage.class);
    registerDSFID(FUNCTION_STREAMING_REPLY_MESSAGE,
        FunctionStreamingReplyMessage.class);
    registerDSFID(GET_ALL_SERVERS_REQUEST, GetAllServersRequest.class);
    registerDSFID(GET_ALL_SERVRES_RESPONSE, GetAllServersResponse.class);
    registerDSFID(PERSISTENT_MEMBERSHIP_VIEW_REQUEST,
        MembershipViewRequest.class);
    registerDSFID(PERSISTENT_MEMBERSHIP_VIEW_REPLY,
        MembershipViewReplyMessage.class);
    registerDSFID(PERSISTENT_STATE_QUERY_REQUEST,
        PersistentStateQueryMessage.class);
    registerDSFID(PERSISTENT_STATE_QUERY_REPLY,
        PersistentStateQueryReplyMessage.class);
    registerDSFID(PREPARE_NEW_PERSISTENT_MEMBER_REQUEST,
        PrepareNewPersistentMemberMessage.class);
    registerDSFID(MISSING_PERSISTENT_IDS_REQUEST,
        MissingPersistentIDsRequest.class);
    registerDSFID(MISSING_PERSISTENT_IDS_RESPONSE,
        MissingPersistentIDsResponse.class);
    registerDSFID(REVOKE_PERSISTENT_ID_REQUEST, RevokePersistentIDRequest.class);
    registerDSFID(REVOKE_PERSISTENT_ID_RESPONSE,
        RevokePersistentIDResponse.class);
    registerDSFID(REMOVE_PERSISTENT_MEMBER_REQUEST,
        RemovePersistentMemberMessage.class);
    registerDSFID(FUNCTION_STREAMING_ORDERED_REPLY_MESSAGE,
        FunctionStreamingOrderedReplyMessage.class);
    registerDSFID(REQUEST_SYNC_MESSAGE,
        InitialImageOperation.RequestSyncMessage.class);
    registerDSFID(PERSISTENT_MEMBERSHIP_FLUSH_REQUEST,
        MembershipFlushRequest.class);
    registerDSFID(SHUTDOWN_ALL_REQUEST, ShutdownAllRequest.class);
    registerDSFID(SHUTDOWN_ALL_RESPONSE, ShutdownAllResponse.class);
    registerDSFID(CLIENT_MEMBERSHIP_MESSAGE, ClientMembershipMessage.class);
    registerDSFID(END_BUCKET_CREATION_MESSAGE, EndBucketCreationMessage.class);
    registerDSFID(PREPARE_BACKUP_REQUEST, PrepareBackupRequest.class);
    registerDSFID(PREPARE_BACKUP_RESPONSE, PrepareBackupResponse.class);
    registerDSFID(FINISH_BACKUP_REQUEST, FinishBackupRequest.class);
    registerDSFID(FINISH_BACKUP_RESPONSE, FinishBackupResponse.class);
    registerDSFID(COMPACT_REQUEST, CompactRequest.class);
    registerDSFID(COMPACT_RESPONSE, CompactResponse.class);
    registerDSFID(FLOW_CONTROL_PERMIT_MESSAGE, FlowControlPermitMessage.class);
    registerDSFID(REQUEST_FILTERINFO_MESSAGE,
        InitialImageOperation.RequestFilterInfoMessage.class);
    registerDSFID(PARALLEL_QUEUE_REMOVAL_MESSAGE,
        ParallelQueueRemovalMessage.class);
    registerDSFID(PARALLEL_QUEUE_BATCH_REMOVAL_MESSAGE,
        ParallelQueueBatchRemovalMessage.class);
    registerDSFID(PARALLEL_QUEUE_BATCH_REMOVAL_REPLY,
        BatchRemovalReplyMessage.class);
    registerDSFID(BATCH_DESTROY_MESSAGE,
        BatchDestroyOperation.DestroyMessage.class);
    registerDSFID(FIND_REMOTE_TX_MESSAGE, FindRemoteTXMessage.class);
    registerDSFID(FIND_REMOTE_TX_REPLY, FindRemoteTXMessageReply.class);
    registerDSFID(SERIALIZED_OBJECT_PART_LIST, SerializedObjectPartList.class);
    registerDSFID(FLUSH_TO_DISK_REQUEST, FlushToDiskRequest.class);
    registerDSFID(FLUSH_TO_DISK_RESPONSE, FlushToDiskResponse.class);
    registerDSFID(ENUM_ID, EnumId.class);
    registerDSFID(ENUM_INFO, EnumInfo.class);
    registerDSFID(CHECK_TYPE_REGISTRY_STATE, CheckTypeRegistryState.class);
    registerDSFID(PREPARE_REVOKE_PERSISTENT_ID_REQUEST,
        PrepareRevokePersistentIDRequest.class);
    registerDSFID(PERSISTENT_RVV, DiskRegionVersionVector.class);
    registerDSFID(PERSISTENT_VERSION_TAG, DiskVersionTag.class);
    registerDSFID(DISK_STORE_ID, DiskStoreID.class);
    registerDSFID(CLIENT_PING_MESSAGE_IMPL, ClientPingMessageImpl.class);
    registerDSFID(SNAPSHOT_PACKET, SnapshotPacket.class);
    registerDSFID(SNAPSHOT_RECORD, SnapshotRecord.class);
    registerDSFID(FLOW_CONTROL_ACK, FlowControlAckMessage.class);
    registerDSFID(FLOW_CONTROL_ABORT, FlowControlAbortMessage.class);
    registerDSFID(MGMT_COMPACT_REQUEST,
        com.gemstone.gemfire.management.internal.messages.CompactRequest.class);
    registerDSFID(MGMT_COMPACT_RESPONSE,
        com.gemstone.gemfire.management.internal.messages.CompactResponse.class);
    registerDSFID(MGMT_FEDERATION_COMPONENT,
        com.gemstone.gemfire.management.internal.FederationComponent.class);
    registerDSFID(LOCATOR_STATUS_REQUEST, LocatorStatusRequest.class);
    registerDSFID(LOCATOR_STATUS_RESPONSE, LocatorStatusResponse.class);
    registerDSFID(R_FETCH_VERSION_MESSAGE, RemoteFetchVersionMessage.class);
    registerDSFID(R_FETCH_VERSION_REPLY,
        RemoteFetchVersionMessage.FetchVersionReplyMessage.class);
    registerDSFID(RELEASE_CLEAR_LOCK_MESSAGE, ReleaseClearLockMessage.class);
    registerDSFID(PR_TOMBSTONE_MESSAGE, PRTombstoneMessage.class);
    registerDSFID(HDFS_GATEWAY_EVENT_IMPL, HDFSGatewayEventImpl.class);
    
    registerDSFID(REQUEST_RVV_MESSAGE, InitialImageOperation.RequestRVVMessage.class);
    registerDSFID(RVV_REPLY_MESSAGE, InitialImageOperation.RVVReplyMessage.class);
    registerDSFID(SNAPPY_COMPRESSED_CACHED_DESERIALIZABLE, SnappyCompressedCachedDeserializable.class);
    registerDSFID(UPDATE_ENTRY_VERSION_MESSAGE, UpdateEntryVersionMessage.class);
    registerDSFID(PR_UPDATE_ENTRY_VERSION_MESSAGE,
        PRUpdateEntryVersionMessage.class);
    registerDSFID(PR_FETCH_BULK_ENTRIES_MESSAGE, FetchBulkEntriesMessage.class);
    registerDSFID(PR_FETCH_BULK_ENTRIES_REPLY_MESSAGE, FetchBulkEntriesReplyMessage.class);
    registerDSFID(PR_QUERY_TRACE_INFO, PRQueryTraceInfo.class);
    registerDSFID(INDEX_CREATION_DATA, IndexCreationData.class);
    registerDSFID(DIST_TX_OP, DistTxEntryEvent.class);
    registerDSFID(DIST_TX_PRE_COMMIT_RESPONSE, DistTXPrecommitMessage.DistTxPrecommitResponse.class);
    registerDSFID(DIST_TX_THIN_ENTRY_STATE, TXEntryState.DistTxThinEntryState.class);
    registerDSFID(SERVER_PING_MESSAGE, ServerPingMessage.class);
    registerDSFID(PR_DESTROY_ON_DATA_STORE_MESSAGE,
        DestroyRegionOnDataStoreMessage.class);
    registerDSFID(SHUTDOWN_ALL_GATEWAYHUBS_REQUEST,
        ShutdownAllGatewayHubsRequest.class);
  }",False
"  public void initMocks() throws IOException {
    initMocks(false);
  }",True
"  public void initMocks(boolean enableNetworkPartition) throws UnknownHostException {
    mockDistConfig = mock(DistributionConfig.class);
    when(mockDistConfig.getEnableNetworkPartitionDetection()).thenReturn(enableNetworkPartition);
    mockConfig = mock(ServiceConfig.class);
    when(mockConfig.getDistributionConfig()).thenReturn(mockDistConfig);
    when(mockDistConfig.getLocators()).thenReturn(""localhost[12345]"");
    when(mockDistConfig.getMcastPort()).thenReturn(0);
    
    authenticator = mock(Authenticator.class);
    gmsJoinLeaveMemberId = new InternalDistributedMember(""localhost"", 8887);
    
    messenger = mock(Messenger.class);
    when(messenger.getMemberID()).thenReturn(gmsJoinLeaveMemberId);
    
    services = mock(Services.class);
    when(services.getConfig()).thenReturn(mockConfig);
    when(services.getMessenger()).thenReturn(messenger);

    mockMembers = new InternalDistributedMember[4];
    for (int i = 0; i < mockMembers.length; i++) {
      mockMembers[i] = new InternalDistributedMember(""localhost"", 8888 + i);
    }
    mockOldMember = new InternalDistributedMember(""localhost"", 8700, Version.GFE_56);

    gmsJoinLeave = new GMSJoinLeave();
    gmsJoinLeave.init(services);
    gmsJoinLeave.start();
    gmsJoinLeave.started();
  }",False
"  public void testProcessJoinMessageWithAuthenticationButNullCredentials() throws IOException {
    initMocks();
    MethodExecuted messageSent = new MethodExecuted();
    when(services.getAuthenticator()).thenReturn(authenticator);
    when(authenticator.authenticate(mockMembers[0], null)).thenThrow(new AuthenticationFailedException(""we want to fail auth here""));
    when(services.getMessenger()).thenReturn(messenger);
    when(messenger.send(any(JoinResponseMessage.class))).thenAnswer(messageSent);
      
    gmsJoinLeave.processMessage(new JoinRequestMessage(mockMembers[0], mockMembers[0], credentials));
    Assert.assertTrue(""JoinRequest should not have been added to view request"", gmsJoinLeave.getViewRequests().size() == 0);
    Assert.assertTrue(""Join Response should have been sent"", messageSent.isMethodExecuted());
  }",True
"  public void testProcessJoinMessageWithAuthenticationButNullCredentials() throws IOException {
    initMocks();
    MethodExecuted messageSent = new MethodExecuted();
    when(services.getAuthenticator()).thenReturn(authenticator);
    when(authenticator.authenticate(mockMembers[0], null)).thenThrow(new AuthenticationFailedException(""we want to fail auth here""));
    when(services.getMessenger()).thenReturn(messenger);
    when(messenger.send(any(JoinResponseMessage.class))).thenAnswer(messageSent);
      
    gmsJoinLeave.processMessage(new JoinRequestMessage(mockMembers[0], mockMembers[0], null));
    Assert.assertTrue(""JoinRequest should not have been added to view request"", gmsJoinLeave.getViewRequests().size() == 0);
    Assert.assertTrue(""Join Response should have been sent"", messageSent.isMethodExecuted());
  }",False
"  public void testRemoveMember() throws Exception {
    initMocks();
    prepareAndInstallView();
    MethodExecuted removeMessageSent = new MethodExecuted();
    when(messenger.send(any(RemoveMemberMessage.class))).thenAnswer(removeMessageSent);
    gmsJoinLeave.remove(mockMembers[1], ""removing for test"");
    assert removeMessageSent.methodExecuted;
  }",False
"  public NanoTimer() {
    this.lastResetTime = getTime();
    this.constructionTime = this.lastResetTime;
  }",True
"  NanoTimer(TimeService ts) {
    this.timeService = ts;
    this.lastResetTime = ts.getTime();
    this.constructionTime = this.lastResetTime;
  }",False
"  public long getTimeSinceConstruction() {
    return getTime() - this.constructionTime;
  }",True
"  public long getTimeSinceConstruction() {
    return this.timeService.getTime() - this.constructionTime;
  }",False
"  public long getTimeSinceReset() {
    return getTime() - this.lastResetTime;
  }",True
"  public long getTimeSinceReset() {
    return this.timeService.getTime() - this.lastResetTime;
  }",False
"  private final static TimeService systemTimeService = new TimeService() {
    @Override
    public long getTime() {
      return java.lang.System.nanoTime();
    }
  };",False
"  public long reset() {
    long save = this.lastResetTime;
    this.lastResetTime = getTime();
    return this.lastResetTime - save;
  }",True
"  public long reset() {
    long save = this.lastResetTime;
    this.lastResetTime = this.timeService.getTime();
    return this.lastResetTime - save;
  }",False
"  public NanoTimer() {
    this.timeService = systemTimeService;
    this.lastResetTime = systemTimeService.getTime();
    this.constructionTime = this.lastResetTime;
  }",False
"    private long calculateSlop() {
	// calculate how much time this vm takes to do some basic stuff.
	long startTime = NanoTimer.getTime();
	new NanoTimer();
	assertApproximate(""should never fail"", 0, 0, 0);
	long result = NanoTimer.getTime() - startTime;
	return result * 3; // triple to be on the safe side
    }",True
"    private void _testGetTime(int waitTimeSeconds) {
	final int nanosPerMilli = 1000000;
	long start = NanoTimer.getTime();
	long startMillis = System.currentTimeMillis();
	try {
	    Thread.sleep(waitTimeSeconds * 1000);
	} catch (InterruptedException e) {
	  fail(""interrupted"");
	}
	long end = NanoTimer.getTime();
	long endMillis = System.currentTimeMillis();
	long elapsed = (end - start);
	long elapsedMillis = endMillis - startMillis;
	assertApproximate(""expected approximately "" + waitTimeSeconds + "" seconds"", nanosPerMilli*30,
			  elapsedMillis * nanosPerMilli, elapsed);
    }",True
"    public void testGetTime() {
      _testGetTime(2);
    }",True
"    public NanoTimer2JUnitTest(String name) {
        super(name);
    }",True
"    private static void assertApproximate(String message, long range,
					  long expected, long actual) {
	if ((actual < (expected - range)) || (actual > (expected + range))) {
	    fail(message + "" expected to be in the range [""
                 + (expected - range) + "".."" + (expected + range)
                 + ""] but was:<"" + actual + "">"");
	}
    }",True
"    public void testReset() {
	final long slop = calculateSlop();
	NanoTimer nt = new NanoTimer();
	long createTime = NanoTimer.getTime();
	assertApproximate(""create time"", slop, 0, nt.getTimeSinceConstruction());
	assertApproximate(""construction vs. reset"", slop, nt.getTimeSinceConstruction(), nt.getTimeSinceReset());
	assertApproximate(""time since reset time same as construct"", slop, NanoTimer.getTime() - createTime, nt.getTimeSinceReset());
	assertApproximate(""reset time same as construct"", slop, NanoTimer.getTime() - createTime, nt.reset());
	long resetTime = NanoTimer.getTime();
	assertApproximate(""reset time updated"", slop, NanoTimer.getTime() - resetTime, nt.getTimeSinceReset());
    }",True
"  public void testDefaultNanoTimer() {
    // All the other unit test methods of NanoTimer
    // inject TestTimeService into the NanoTimer.
    // This method verifies that the default constructor
    // works.
    final NanoTimer timer = new NanoTimer();
    timer.getConstructionTime();
    timer.getLastResetTime();
    timer.getTimeSinceConstruction();
    timer.getTimeSinceReset();
    timer.reset();
  }",False
"  public void testReset() {
    final NanoTimer timer = new NanoTimer();
    final long nanosOne = NanoTimer.getTime();
    
    waitMillis(10);

    assertEquals(timer.getConstructionTime(), timer.getLastResetTime());
    assertTrue(timer.getTimeSinceConstruction() <= timer.getTimeSinceReset());
    
    final long nanosTwo = NanoTimer.getTime();
    final long resetOne = timer.reset();
    
    assertTrue(resetOne >= nanosTwo - nanosOne);
    assertFalse(timer.getConstructionTime() == timer.getLastResetTime());
    
    final long nanosThree = NanoTimer.getTime();

    waitMillis(10);
    
    assertTrue(timer.getLastResetTime() >= nanosTwo);
    assertTrue(timer.getTimeSinceReset() < timer.getTimeSinceConstruction());
    assertTrue(timer.getLastResetTime() <= nanosThree);
    assertTrue(timer.getTimeSinceReset() < NanoTimer.getTime());
    assertTrue(timer.getTimeSinceReset() <= NanoTimer.getTime() - timer.getLastResetTime());
        
    final long nanosFour = NanoTimer.getTime();
    final long resetTwo = timer.reset();
    
    assertTrue(resetTwo >= nanosFour - nanosThree);
    
    waitMillis(10);

    assertTrue(timer.getLastResetTime() >= nanosFour);
    assertTrue(timer.getTimeSinceReset() < timer.getTimeSinceConstruction());
    assertTrue(timer.getLastResetTime() <= NanoTimer.getTime());
    assertTrue(timer.getTimeSinceReset() <= NanoTimer.getTime() - timer.getLastResetTime());
  }",True
"  public void testReset() {
    TestTimeService ts = new TestTimeService();
    final NanoTimer timer = new NanoTimer(ts);
    final long nanosOne = ts.getTime();
    
    ts.incTime();

    assertEquals(timer.getConstructionTime(), timer.getLastResetTime());
    assertTrue(timer.getTimeSinceConstruction() <= timer.getTimeSinceReset());
    
    final long nanosTwo = ts.getTime();
    final long resetOne = timer.reset();
    
    assertTrue(resetOne >= nanosTwo - nanosOne);
    assertFalse(timer.getConstructionTime() == timer.getLastResetTime());
    
    final long nanosThree = ts.getTime();

    ts.incTime();
    
    assertTrue(timer.getLastResetTime() >= nanosTwo);
    assertTrue(timer.getTimeSinceReset() < timer.getTimeSinceConstruction());
    assertTrue(timer.getLastResetTime() <= nanosThree);
    assertTrue(timer.getTimeSinceReset() <= ts.getTime() - timer.getLastResetTime());
        
    final long nanosFour = ts.getTime();
    final long resetTwo = timer.reset();
    
    assertTrue(resetTwo >= nanosFour - nanosThree);
    
    ts.incTime();

    assertTrue(timer.getLastResetTime() >= nanosFour);
    assertTrue(timer.getTimeSinceReset() < timer.getTimeSinceConstruction());
    assertTrue(timer.getTimeSinceReset() <= ts.getTime() - timer.getLastResetTime());
  }",False
"  public void testInitialTimes() {
    final long nanoTime = NanoTimer.getTime();
    final NanoTimer timer = new NanoTimer();

    assertEquals(timer.getConstructionTime(), timer.getLastResetTime());
    assertTrue(timer.getTimeSinceConstruction() <= timer.getTimeSinceReset());
    assertTrue(timer.getLastResetTime() >= nanoTime);
    assertTrue(timer.getConstructionTime() >= nanoTime);
    assertTrue(NanoTimer.getTime() >= nanoTime);

    final long nanosOne = NanoTimer.getTime();
    
    waitMillis(10);
    
    assertTrue(timer.getTimeSinceConstruction() > NanoTimer.NANOS_PER_MILLISECOND * 10);
    assertTrue(timer.getTimeSinceConstruction() <= NanoTimer.getTime());
    
    final long nanosTwo = NanoTimer.getTime();
    
    assertTrue(timer.getTimeSinceConstruction() >= nanosTwo - nanosOne);
  }",True
"  public void testInitialTimes() {
    TestTimeService ts = new TestTimeService();
    final long nanoTime = ts.getTime();
    final NanoTimer timer = new NanoTimer(ts);

    assertEquals(timer.getConstructionTime(), timer.getLastResetTime());
    assertTrue(timer.getTimeSinceConstruction() <= timer.getTimeSinceReset());
    assertTrue(timer.getLastResetTime() >= nanoTime);
    assertTrue(timer.getConstructionTime() >= nanoTime);
    assertTrue(ts.getTime() >= nanoTime);

    final long nanosOne = ts.getTime();
    
    ts.incTime();
    
    assertEquals(1, timer.getTimeSinceConstruction());
  }",False
"    public long getTime() {
      return this.now;
    }",False
"  public void testNanosToMillis() {
    assertEquals(0, NanoTimer.nanosToMillis(1));
    assertEquals(1, NanoTimer.nanosToMillis(1000000));
  }",False
"  public void testMillisToNanos() {
    assertEquals(0, NanoTimer.millisToNanos(0));
    assertEquals(1000000, NanoTimer.millisToNanos(1));
  }",False
"  public void testGetTimeIncreases() {
    final long startNanos = NanoTimer.getTime();
    final long startMillis = System.currentTimeMillis();

    waitMillis(10);

    final long endMillis = System.currentTimeMillis();
    final long endNanos = NanoTimer.getTime();
    
    long elapsedMillis = endMillis - startMillis;
    long elapsedNanos = endNanos - startNanos;
    
    assertTrue(elapsedMillis > 10);
    assertTrue(endNanos > NanoTimer.NANOS_PER_MILLISECOND * 10);
    assertTrue(elapsedNanos * NanoTimer.NANOS_PER_MILLISECOND >= elapsedMillis);
  }",True
"  }

  @Test
  public void testMillisToNanos() {
    assertEquals(0, NanoTimer.millisToNanos(0));
    assertEquals(1000000, NanoTimer.millisToNanos(1));
  }

  @Test
  public void testNanosToMillis() {
    assertEquals(0, NanoTimer.nanosToMillis(1));
    assertEquals(1, NanoTimer.nanosToMillis(1000000));
  }
  
  @Test
  public void testDefaultNanoTimer() {",False
"    public void incTime() {
      this.now++;
    }",False
"  private void waitMillis(final long millis) {
    long began = System.currentTimeMillis();
    boolean done = false;
    try {
      for (StopWatch time = new StopWatch(true); !done && time.elapsedTimeMillis() < millis; done = (System.currentTimeMillis() - began > millis)) {
        Thread.sleep(1000);
      }
    } catch (InterruptedException e) {
      Thread.currentThread().interrupt();
    }
    assertTrue(""waiting "" + millis + "" millis"", done);
  }",True
"  public void testGetTimeIsPositive() {
    long lastTime = 0;
    for (int i = 0; i < 1000; i++) {
      final long time = NanoTimer.getTime();
      assertTrue(time >= 0);
      assertTrue(time >= lastTime);
      lastTime = time;
    }
  }",True
"   * your clock to tick call incTime.
   */
  private class TestTimeService implements TimeService {
    private long now;
    public void incTime() {
      this.now++;
    }
    @Override
    public long getTime() {",False
"  private static final Object[] getParametersWithMembers() {
    return $(
        new Object[] { ""sender3"", new String[] { }, new String[] { ""member1"" }, false, true },
        new Object[] { ""sender4"", new String[] { }, new String[] { ""member1, member2"" }, false, true }
    );
  }",False
"    protected String processCommand(final String command) {
      this.testableCommand = command;
      return null; // do nothing
    }",False
"  public void shouldDefineStartGatewayReceiverCommandWithEmptyGatewaySenderId() {
    this.wanCommandsController.startGatewaySender("""", null, null);
    
    assertThat(this.wanCommandsController.testableCommand).contains(START_GATEWAYSENDER);
    assertThat(this.wanCommandsController.testableCommand).contains(""--""+START_GATEWAYSENDER__ID+""=""+"""");
  }",False
"  public void shouldDefineStartGatewayReceiverCommandWithGroupsAndMembers(final String gatewaySenderId, final String[] groups, final String[] members, final boolean containsGroups, final boolean containsMembers) {
    this.wanCommandsController.startGatewaySender(gatewaySenderId, groups, members);
    
    assertThat(this.wanCommandsController.testableCommand).contains(START_GATEWAYSENDER);
    assertThat(this.wanCommandsController.testableCommand).contains(""--""+START_GATEWAYSENDER__ID+""=""+gatewaySenderId);
    assertThat(this.wanCommandsController.testableCommand).contains(START_GATEWAYRECEIVER__GROUP);
    assertThat(this.wanCommandsController.testableCommand).contains(START_GATEWAYRECEIVER__MEMBER);
  }",False
"  public void shouldDefineStartGatewayReceiverCommandWithGroups(final String gatewaySenderId, final String[] groups, final String[] members, final boolean containsGroups, final boolean containsMembers) {
    this.wanCommandsController.startGatewaySender(gatewaySenderId, groups, members);
    
    assertThat(this.wanCommandsController.testableCommand).contains(START_GATEWAYSENDER);
    assertThat(this.wanCommandsController.testableCommand).contains(""--""+START_GATEWAYSENDER__ID+""=""+gatewaySenderId);
    assertThat(this.wanCommandsController.testableCommand).contains(START_GATEWAYRECEIVER__GROUP);
    assertThat(this.wanCommandsController.testableCommand).doesNotContain(START_GATEWAYRECEIVER__MEMBER);
  }",False
"  public void shouldDefineStartGatewayReceiverCommandWithMembers(final String gatewaySenderId, final String[] groups, final String[] members, final boolean containsGroups, final boolean containsMembers) {
    this.wanCommandsController.startGatewaySender(gatewaySenderId, groups, members);
    
    assertThat(this.wanCommandsController.testableCommand).contains(START_GATEWAYSENDER);
    assertThat(this.wanCommandsController.testableCommand).contains(""--""+START_GATEWAYSENDER__ID+""=""+gatewaySenderId);
    assertThat(this.wanCommandsController.testableCommand).doesNotContain(START_GATEWAYRECEIVER__GROUP);
    assertThat(this.wanCommandsController.testableCommand).contains(START_GATEWAYRECEIVER__MEMBER);
  }",False
"  private static final Object[] getParametersWithGroups() {
    return $(
        new Object[] { ""sender1"", new String[] { ""group1"" }, new String[] { }, true, false },
        new Object[] { ""sender2"", new String[] { ""group1, group2"" }, new String[] { }, true, false }
    );
  }",False
"  public void setUp() {
    this.wanCommandsController = new TestableWanCommandsController();
  }",False
"  public void shouldDefineStartGatewayReceiverCommandWithNullGatewaySenderId() {
    this.wanCommandsController.startGatewaySender(null, null, null);
    
    assertThat(this.wanCommandsController.testableCommand).contains(START_GATEWAYSENDER);
    assertThat(this.wanCommandsController.testableCommand).contains(""--""+START_GATEWAYSENDER__ID+""=""+null);
  }",False
"  public void shouldDefineStartGatewayReceiverCommandWithNulls() {
    this.wanCommandsController.startGatewaySender(null, null, null);
    
    assertThat(this.wanCommandsController.testableCommand).contains(""--""+START_GATEWAYSENDER__ID+""=""+null);
    assertThat(this.wanCommandsController.testableCommand).contains(START_GATEWAYSENDER);
    assertThat(this.wanCommandsController.testableCommand).doesNotContain(START_GATEWAYRECEIVER__GROUP);
    assertThat(this.wanCommandsController.testableCommand).doesNotContain(START_GATEWAYRECEIVER__MEMBER);
  }",False
"  public void shouldDefineStartGatewayReceiverCommandWithOutGroupsOrMembers() {
    final String gatewaySenderId = ""senderA"";
        
    this.wanCommandsController.startGatewaySender(""senderA"", new String[] {}, new String[] {});
    
    assertThat(this.wanCommandsController.testableCommand).contains(START_GATEWAYSENDER);
    assertThat(this.wanCommandsController.testableCommand).contains(""--""+START_GATEWAYSENDER__ID+""=""+gatewaySenderId);
    assertThat(this.wanCommandsController.testableCommand).doesNotContain(START_GATEWAYRECEIVER__GROUP);
    assertThat(this.wanCommandsController.testableCommand).doesNotContain(START_GATEWAYRECEIVER__MEMBER);
  }",False
"  private static final Object[] getParametersWithGroupsAndMembers() {
    return $(
        new Object[] { ""sender5"", new String[] { ""group1"" }, new String[] { ""member1"" }, true, true },
        new Object[] { ""sender6"", new String[] { ""group1,group2"" }, new String[] { ""member1,member2"" }, true, true },
        new Object[] { ""sender7"", new String[] { ""group1, group2"" }, new String[] { ""member1, member2"" }, true, true }
    );
  }",False
"  public void testNonDefaultCompaction() {
    DiskRegionProperties props = new DiskRegionProperties();
    props.setRegionName(""testForceCompactionDoesRoll"");
    props.setRolling(false);
    props.setDiskDirs(dirs);
    props.setAllowForceCompaction(true);
    props.setPersistBackup(true);
    props.setCompactionThreshold(90);
    region = DiskRegionHelperFactory.getSyncPersistOnlyRegion(cache, props, Scope.LOCAL);
    DiskRegion dr = ((LocalRegion)region).getDiskRegion();
    logWriter.info(""putting key1"");
    region.put(""key1"", ""value1"");
    logWriter.info(""putting key2"");
    region.put(""key2"", ""value2"");
    //Only remove 1 of the entries. This wouldn't trigger compaction with
    //the default threshold, since there are two entries.
    logWriter.info(""removing key1"");
    region.remove(""key1"");
    // now that it is compactable the following forceCompaction should
    // go ahead and do a roll and compact it.
    Oplog oplog = dr.testHook_getChild();
    boolean compacted = ((LocalRegion)region).getDiskStore().forceCompaction();
    assertEquals(true, oplog.testConfirmCompacted());
    assertEquals(true, compacted);
  }",False
"  public static String replaceStrings(String properties, String property, String value) {
    StringBuffer sb = new StringBuffer();
    int start = 0;
    int index = properties.indexOf(property);
    while (index != -1) {
      sb.append(properties.substring(start, index));
      sb.append(value);

      start = index + property.length();
      index = properties.indexOf(property, start);
    }
    sb.append(properties.substring(start));
    return sb.toString();
  }",False
"  public void stop() {
    logger.info(""Membership: stopping services"");
    this.joinLeave.stop();
    this.healthMon.stop();
    this.auth.stop();
    this.messenger.stop();
    this.manager.stop();
    this.timer.cancel();
    this.cancelCriterion.cancel(""Membership services are shut down"");
  }",True
"  public void stop() {
    logger.info(""Membership: stopping services"");
    if (stopping) {
      return;
    }
    stopping = true;
    this.joinLeave.stop();
    this.healthMon.stop();
    this.auth.stop();
    this.messenger.stop();
    this.manager.stop();
    this.timer.cancel();
    this.cancelCriterion.cancel(""Membership services are shut down"");
  }",False
"    boolean createAndSendView(List<DistributionMessage> requests) {
      List<InternalDistributedMember> joinReqs = new ArrayList<InternalDistributedMember>();
      List<InternalDistributedMember> leaveReqs = new ArrayList<InternalDistributedMember>();
      List<InternalDistributedMember> removalReqs = new ArrayList<InternalDistributedMember>();
      List<String> removalReasons = new ArrayList<String>();
      
      NetView oldView = currentView;
      List<InternalDistributedMember> oldMembers;
      if (oldView != null) {
        oldMembers = oldView.getMembers();
      } else {
        oldMembers = Collections.emptyList();
      }
      
      for (DistributionMessage msg: requests) {
        logger.debug(""processing request {}"", msg);

        InternalDistributedMember mbr = null;
        
        if (msg instanceof JoinRequestMessage) {
          mbr = ((JoinRequestMessage)msg).getMemberID();
          if (!oldMembers.contains(mbr)) {
            joinReqs.add(mbr);
          }
        }
        else if (msg instanceof LeaveRequestMessage) {
          mbr = ((LeaveRequestMessage) msg).getMemberID();
          if (oldMembers.contains(mbr)) {
            leaveReqs.add(mbr);
          }
        }
        else if (msg instanceof RemoveMemberMessage) {
          mbr = ((RemoveMemberMessage) msg).getMemberID();
          if (oldMembers.contains(mbr)) {
            removalReqs.add(mbr);
            removalReasons.add(((RemoveMemberMessage) msg).getReason());
          }
        }
        else {
          // TODO: handle removals
          logger.warn(""Unknown membership request encountered: {}"", msg);
        }
      }
      
      NetView newView;
      synchronized(viewInstallationLock) {
        int viewNumber = 0;
        List<InternalDistributedMember> mbrs;
        if (currentView == null) {
          mbrs = new ArrayList<InternalDistributedMember>(joinReqs.size());
        } else {
          viewNumber = currentView.getViewId()+1;
          mbrs = new ArrayList<InternalDistributedMember>(currentView.getMembers());
        }
        mbrs.addAll(joinReqs);
        mbrs.removeAll(leaveReqs);
        mbrs.removeAll(removalReqs);
        newView = new NetView(localAddress, viewNumber, mbrs, leaveReqs,
            removalReqs);
      }
      
      for (InternalDistributedMember mbr: joinReqs) {
        mbr.setVmViewId(newView.getViewId());
      }
      // send removal messages before installing the view so we stop
      // getting messages from members that have been kicked out
      sendRemoveMessages(removalReqs, removalReasons, newView);
      
      // we want to always check for quorum loss but don't act on it
      // unless network-partition-detection is enabled
      if ( !(checkForPartition(newView) && quorumRequired) ) {
        sendJoinResponses(joinReqs, newView);
      }

      if (quorumRequired) {
        boolean prepared = false;
        do {
          if (this.shutdown || Thread.currentThread().isInterrupted()) {
            return false;
          }
          prepared = prepareView(newView, joinReqs);
          if (!prepared && quorumRequired) {
            Set<InternalDistributedMember> unresponsive = prepareProcessor.getUnresponsiveMembers();
            try {
              removeHealthyMembers(unresponsive);
            } catch (InterruptedException e) {
              // abort the view if interrupted
              shutdown = true;
              return false;
            }
  
            if (!unresponsive.isEmpty()) {
              List<InternalDistributedMember> failures = new ArrayList<InternalDistributedMember>(currentView.getCrashedMembers().size() + unresponsive.size());
              failures.addAll(unresponsive);

              NetView conflictingView = prepareProcessor.getConflictingView();
              if (conflictingView != null
                  && !conflictingView.getCreator().equals(localAddress)
                  && conflictingView.getViewId() > newView.getViewId()
                  && (lastConflictingView == null || conflictingView.getViewId() > lastConflictingView.getViewId())) {
                lastConflictingView = conflictingView;
                failures.addAll(conflictingView.getCrashedMembers());
              }

              failures.removeAll(removalReqs);
              if (failures.size() > 0) {
                // abort the current view and try again
                removalReqs.addAll(failures);
                newView = new NetView(localAddress, newView.getViewId()+1, newView.getMembers(), leaveReqs,
                    removalReqs);
              }
            }
          }
        } while (!prepared);
      } // quorumRequired
      
      lastConflictingView = null;
      
      sendView(newView, joinReqs);
      return true;
    }",True
"    boolean createAndSendView(List<DistributionMessage> requests) {
      List<InternalDistributedMember> joinReqs = new ArrayList<InternalDistributedMember>();
      List<InternalDistributedMember> leaveReqs = new ArrayList<InternalDistributedMember>();
      List<InternalDistributedMember> removalReqs = new ArrayList<InternalDistributedMember>();
      List<String> removalReasons = new ArrayList<String>();
      
      NetView oldView = currentView;
      List<InternalDistributedMember> oldMembers;
      if (oldView != null) {
        oldMembers = oldView.getMembers();
      } else {
        oldMembers = Collections.emptyList();
      }
      
      for (DistributionMessage msg: requests) {
        logger.debug(""processing request {}"", msg);

        InternalDistributedMember mbr = null;
        
        if (msg instanceof JoinRequestMessage) {
          mbr = ((JoinRequestMessage)msg).getMemberID();
          if (!oldMembers.contains(mbr) && !joinReqs.contains(mbr)) {
            joinReqs.add(mbr);
          }
        }
        else if (msg instanceof LeaveRequestMessage) {
          mbr = ((LeaveRequestMessage) msg).getMemberID();
          if (oldMembers.contains(mbr) && !leaveReqs.contains(mbr)) {
            leaveReqs.add(mbr);
          }
        }
        else if (msg instanceof RemoveMemberMessage) {
          mbr = ((RemoveMemberMessage) msg).getMemberID();
          if (oldMembers.contains(mbr) && !leaveReqs.contains(mbr) && !removalReqs.contains(mbr)) {
            removalReqs.add(mbr);
            removalReasons.add(((RemoveMemberMessage) msg).getReason());
          }
        }
        else {
          logger.warn(""Unknown membership request encountered: {}"", msg);
        }
      }
      
      NetView newView;
      synchronized(viewInstallationLock) {
        int viewNumber = 0;
        List<InternalDistributedMember> mbrs;
        if (currentView == null) {
          mbrs = new ArrayList<InternalDistributedMember>(joinReqs.size());
        } else {
          viewNumber = currentView.getViewId()+1;
          mbrs = new ArrayList<InternalDistributedMember>(currentView.getMembers());
        }
        mbrs.addAll(joinReqs);
        mbrs.removeAll(leaveReqs);
        mbrs.removeAll(removalReqs);
        newView = new NetView(localAddress, viewNumber, mbrs, leaveReqs,
            removalReqs);
      }
      
      for (InternalDistributedMember mbr: joinReqs) {
        mbr.setVmViewId(newView.getViewId());
      }
      // send removal messages before installing the view so we stop
      // getting messages from members that have been kicked out
      sendRemoveMessages(removalReqs, removalReasons, newView);
      
      // if there are no membership changes then abort creation of
      // the new view
      if (newView.getMembers().equals(currentView.getMembers())) {
        logger.info(""membership hasn't changed - aborting new view {}"", newView);
        return true;
      }
      
      // we want to always check for quorum loss but don't act on it
      // unless network-partition-detection is enabled
      if ( !(isNetworkPartition(newView) && quorumRequired) ) {
        sendJoinResponses(joinReqs, newView);
      }

      if (quorumRequired) {
        boolean prepared = false;
        do {
          if (this.shutdown || Thread.currentThread().isInterrupted()) {
            return false;
          }
          prepared = prepareView(newView, joinReqs);
          if (!prepared && quorumRequired) {
            Set<InternalDistributedMember> unresponsive = prepareProcessor.getUnresponsiveMembers();
            try {
              removeHealthyMembers(unresponsive);
            } catch (InterruptedException e) {
              // abort the view if interrupted
              shutdown = true;
              return false;
            }
  
            if (!unresponsive.isEmpty()) {
              List<InternalDistributedMember> failures = new ArrayList<InternalDistributedMember>(currentView.getCrashedMembers().size() + unresponsive.size());
              failures.addAll(unresponsive);

              NetView conflictingView = prepareProcessor.getConflictingView();
              if (conflictingView != null
                  && !conflictingView.getCreator().equals(localAddress)
                  && conflictingView.getViewId() > newView.getViewId()
                  && (lastConflictingView == null || conflictingView.getViewId() > lastConflictingView.getViewId())) {
                lastConflictingView = conflictingView;
                failures.addAll(conflictingView.getCrashedMembers());
              }

              failures.removeAll(removalReqs);
              if (failures.size() > 0) {
                // abort the current view and try again
                removalReqs.addAll(failures);
                newView = new NetView(localAddress, newView.getViewId()+1, newView.getMembers(), leaveReqs,
                    removalReqs);
              }
            }
          }
        } while (!prepared);
      } // quorumRequired
      
      lastConflictingView = null;
      
      sendView(newView, joinReqs);
      return true;
    }",False
"  public void installView(NetView newView) {
    synchronized(viewInstallationLock) {
      if (currentView != null && currentView.getViewId() >= newView.getViewId()) {
        // old view - ignore it
        return;
      }
      
      if (checkForPartition(newView)) {
        if (quorumRequired) {
          List<InternalDistributedMember> crashes = newView.getActualCrashedMembers(currentView);
          services.getManager().forceDisconnect(
              LocalizedStrings.Network_partition_detected.toLocalizedString(crashes.size(), crashes));
        }
        return;
      }
      
      currentView = newView;
      preparedView = null;
      lastConflictingView = null;
      services.installView(newView);
      
      if (!newView.getCreator().equals(this.localAddress)) {
        if (newView.shouldBeCoordinator(this.localAddress)) {
          becomeCoordinator();
        } else if (this.isCoordinator) {
          // stop being coordinator
          stateLock.writeLock().lock();
          try {
            stopCoordinatorServices();
            this.isCoordinator = false;
          } finally {
            stateLock.writeLock().unlock();
          }
        }
      }
      if (!this.isCoordinator) {
        // get rid of outdated requests.  It's possible some requests are
        // newer than the view just processed - the senders will have to
        // resend these
        synchronized(viewRequests) {
          for (Iterator<DistributionMessage> it = viewRequests.iterator(); it.hasNext(); ) {
            DistributionMessage m = it.next();
            if (m instanceof JoinRequestMessage) {
              it.remove();
            } else if (m instanceof LeaveRequestMessage) {
              if (!currentView.contains(((LeaveRequestMessage)m).getMemberID())) {
                it.remove();
              }
            } else if (m instanceof RemoveMemberMessage) {
              if (!currentView.contains(((RemoveMemberMessage)m).getMemberID())) {
                it.remove();
              }
            }
          }
        }
      }
    }
  }",True
"  public void installView(NetView newView) {
    
    logger.info(""received new view: {}"", newView);
    
    synchronized(viewInstallationLock) {
      if (currentView != null && currentView.getViewId() >= newView.getViewId()) {
        // old view - ignore it
        return;
      }
      
      if (isNetworkPartition(newView)) {
        if (quorumRequired) {
          List<InternalDistributedMember> crashes = newView.getActualCrashedMembers(currentView);
          services.getManager().forceDisconnect(
              LocalizedStrings.Network_partition_detected.toLocalizedString(crashes.size(), crashes));
        }
        return;
      }
      
      currentView = newView;
      preparedView = null;
      lastConflictingView = null;
      services.installView(newView);
      
      if (!newView.getCreator().equals(this.localAddress)) {
        if (newView.shouldBeCoordinator(this.localAddress)) {
          becomeCoordinator();
        } else if (this.isCoordinator) {
          // stop being coordinator
          stateLock.writeLock().lock();
          try {
            stopCoordinatorServices();
            this.isCoordinator = false;
          } finally {
            stateLock.writeLock().unlock();
          }
        }
      }
      if (!this.isCoordinator) {
        // get rid of outdated requests.  It's possible some requests are
        // newer than the view just processed - the senders will have to
        // resend these
        synchronized(viewRequests) {
          for (Iterator<DistributionMessage> it = viewRequests.iterator(); it.hasNext(); ) {
            DistributionMessage m = it.next();
            if (m instanceof JoinRequestMessage) {
              it.remove();
            } else if (m instanceof LeaveRequestMessage) {
              if (!currentView.contains(((LeaveRequestMessage)m).getMemberID())) {
                it.remove();
              }
            } else if (m instanceof RemoveMemberMessage) {
              if (!currentView.contains(((RemoveMemberMessage)m).getMemberID())) {
                it.remove();
              }
            }
          }
        }
      }
    }
  }",False
"  void sendView(NetView view, Collection<InternalDistributedMember> newMembers) {
    sendView(view, newMembers, false, this.viewProcessor);
  }",True
"  boolean sendView(NetView view, Collection<InternalDistributedMember> newMembers, boolean preparing, ViewReplyProcessor rp) {
    int id = view.getViewId();
    InstallViewMessage msg = new InstallViewMessage(view, services.getAuthenticator().getCredentials(this.localAddress), preparing);
    Set<InternalDistributedMember> recips = new HashSet<InternalDistributedMember>(view.getMembers());

    recips.removeAll(newMembers); // new members get the view in a JoinResponseMessage
    recips.remove(this.localAddress); // no need to send it to ourselves

    recips.addAll(view.getCrashedMembers());

    logger.info((preparing? ""preparing"" : ""sending"") + "" new view "" + view);

    if (preparing) {
      this.preparedView = view;
    } else {
      installView(view);
    }
    
    if (recips.isEmpty()) {
      return true;
    }
    
    msg.setRecipients(recips);
    rp.initialize(id, recips);
    services.getMessenger().send(msg);

    // only wait for responses during preparation
    if (preparing) {
      Set<InternalDistributedMember> failedToRespond = rp.waitForResponses();

      logger.info(""View Creator is finished waiting for responses to view preparation"");
      
      InternalDistributedMember conflictingViewSender = rp.getConflictingViewSender();
      NetView conflictingView = rp.getConflictingView();
      if (conflictingView != null) {
        logger.warn(""View Creator received a conflicting membership view from "" + conflictingViewSender
            + "" during preparation: "" + conflictingView);
        return false;
      }
      
      if (!failedToRespond.isEmpty()  &&  (services.getCancelCriterion().cancelInProgress() == null)) {
        logger.warn(""these members failed to respond to the view change: "" + failedToRespond);
        return false;
      }
    }
    
    return true;
  }",False
"  private void processRemoveRequest(RemoveMemberMessage incomingRequest) {
    NetView v = currentView;
    if (logger.isDebugEnabled()) {
      logger.debug(""JoinLeave.processRemoveRequest invoked.  isCoordinator=""+isCoordinator+ ""; isStopping=""+isStopping
          +""; cancelInProgress=""+services.getCancelCriterion().isCancelInProgress());
    }
    InternalDistributedMember mbr = incomingRequest.getMemberID();

    if (v != null  &&  !v.contains(incomingRequest.getSender())) {
      logger.info(""Membership ignoring removal request for "" + mbr + "" from non-member "" + incomingRequest.getSender());
      return;
    }
    
    logger.info(""Membership received a request to remove "" + mbr
        + ""; reason=""+incomingRequest.getReason());

    if (mbr.equals(this.localAddress)) {
      // oops - I've been kicked out
      services.getManager().forceDisconnect(incomingRequest.getReason());
      return;
    }
    
    if (!isCoordinator && !isStopping && !services.getCancelCriterion().isCancelInProgress()) {
      logger.debug(""JoinLeave is checking to see if I should become coordinator"");
      NetView check = new NetView(v, v.getViewId()+1);
      check.remove(mbr);
      if (check.getCoordinator().equals(localAddress)) {
        becomeCoordinator(mbr);
      }
    }
    else {
      if (!isStopping && !services.getCancelCriterion().isCancelInProgress()) {
        recordViewRequest(incomingRequest);
      }
    }
  }",True
"  private void processRemoveRequest(RemoveMemberMessage incomingRequest) {
    NetView v = currentView;
    if (logger.isDebugEnabled()) {
      logger.debug(""JoinLeave.processRemoveRequest invoked.  isCoordinator=""+isCoordinator+ ""; isStopping=""+isStopping
          +""; cancelInProgress=""+services.getCancelCriterion().isCancelInProgress());
    }
    InternalDistributedMember mbr = incomingRequest.getMemberID();

    if (v != null  &&  !v.contains(incomingRequest.getSender())) {
      logger.info(""Membership ignoring removal request for "" + mbr + "" from non-member "" + incomingRequest.getSender());
      return;
    }
    
    logger.info(""Membership received a request to remove "" + mbr
        + ""; reason=""+incomingRequest.getReason());

    if (mbr.equals(this.localAddress)) {
      // oops - I've been kicked out
      forceDisconnect(incomingRequest.getReason());
      return;
    }
    
    if (!isCoordinator && !isStopping && !services.getCancelCriterion().isCancelInProgress()) {
      logger.debug(""JoinLeave is checking to see if I should become coordinator"");
      NetView check = new NetView(v, v.getViewId()+1);
      check.remove(mbr);
      if (check.getCoordinator().equals(localAddress)) {
        becomeCoordinator(mbr);
      }
    }
    else {
      if (!isStopping && !services.getCancelCriterion().isCancelInProgress()) {
        recordViewRequest(incomingRequest);
      }
    }
  }",False
"    public void run() {
      List<DistributionMessage> requests = null;
      logger.info(""View Creator thread is starting"");
      long okayToCreateView = System.currentTimeMillis() + MEMBER_REQUEST_COLLECTION_INTERVAL;
      try {
        for (;;) {
          synchronized(viewRequests) {
            if (shutdown) {
              return;
            }
            if (viewRequests.isEmpty()) {
              try {
                logger.debug(""View Creator is waiting for requests"");
                viewRequests.wait();
              } catch (InterruptedException e) {
                return;
              }
            } else {
              if (System.currentTimeMillis() < okayToCreateView) {
                // sleep to let more requests arrive
                try {
                  sleep(100);
                  continue;
                } catch (InterruptedException e) {
                  return;
                }
              } else {
                // time to create a new membership view
                if (requests == null) {
                  requests = new ArrayList<DistributionMessage>(viewRequests);
                } else {
                  requests.addAll(viewRequests);
                }
                viewRequests.clear();
                okayToCreateView = System.currentTimeMillis() + MEMBER_REQUEST_COLLECTION_INTERVAL;
              }
            }
          } // synchronized
          if (requests != null  && !requests.isEmpty()) {
            logger.debug(""View Creator is processing {} requests for the next membership view"", requests.size());
            /*boolean success = */createAndSendView(requests);
            requests = null;
          }
        }
      } finally {
        shutdown = true;
      }
    }",True
"    public void run() {
      List<DistributionMessage> requests = null;
      logger.info(""View Creator thread is starting"");
      long okayToCreateView = System.currentTimeMillis() + MEMBER_REQUEST_COLLECTION_INTERVAL;
      try {
        for (;;) {
          synchronized(viewRequests) {
            if (shutdown) {
              return;
            }
            if (viewRequests.isEmpty()) {
              try {
                logger.debug(""View Creator is waiting for requests"");
                waiting = true;
                viewRequests.wait();
              } catch (InterruptedException e) {
                return;
              } finally {
                waiting = false;
              }
            } else {
              if (System.currentTimeMillis() < okayToCreateView) {
                // sleep to let more requests arrive
                try {
                  sleep(100);
                  continue;
                } catch (InterruptedException e) {
                  return;
                }
              } else {
                // time to create a new membership view
                if (requests == null) {
                  requests = new ArrayList<DistributionMessage>(viewRequests);
                } else {
                  requests.addAll(viewRequests);
                }
                viewRequests.clear();
                okayToCreateView = System.currentTimeMillis() + MEMBER_REQUEST_COLLECTION_INTERVAL;
              }
            }
          } // synchronized
          if (requests != null  && !requests.isEmpty()) {
            logger.debug(""View Creator is processing {} requests for the next membership view"", requests.size());
            /*boolean success = */createAndSendView(requests);
            requests = null;
          }
        }
      } finally {
        shutdown = true;
      }
    }",False
"    boolean isWaiting() {
      return waiting;
    }",False
"  public NetView getPreparedView() {
    return this.preparedView;
  }",False
"  private boolean checkForPartition(NetView newView) {
    if (currentView == null) {
      return false;
    }
    int oldWeight = currentView.memberWeight();
    int failedWeight = newView.getCrashedMemberWeight(currentView);
    if (failedWeight > 0) {
      if (logger.isInfoEnabled()) {
        newView.logCrashedMemberWeights(currentView, logger);
      }
      int failurePoint = (int)(Math.round(51 * oldWeight) / 100.0);
      if (failedWeight > failurePoint) {
        services.getManager().quorumLost(newView.getActualCrashedMembers(currentView), currentView);
        return true;
      }
    }
    return false;
  }",True
"          } finally {
            stateLock.writeLock().unlock();
          }
        }
      }
      if (!this.isCoordinator) {
        // get rid of outdated requests.  It's possible some requests are
        // newer than the view just processed - the senders will have to
        // resend these
        synchronized(viewRequests) {
          for (Iterator<DistributionMessage> it = viewRequests.iterator(); it.hasNext(); ) {
            DistributionMessage m = it.next();
            if (m instanceof JoinRequestMessage) {
              it.remove();
            } else if (m instanceof LeaveRequestMessage) {
              if (!currentView.contains(((LeaveRequestMessage)m).getMemberID())) {
                it.remove();
              }",False
"  public void remove(InternalDistributedMember m, String reason) {
    NetView v = this.currentView;
    if (v != null) {
      RemoveMemberMessage msg = new RemoveMemberMessage(v.getCoordinator(), m,
          reason);
      services.getMessenger().send(msg);
    }
  }",True
"  public void remove(InternalDistributedMember m, String reason) {
    NetView v = this.currentView;
    
    if (v != null) {
      RemoveMemberMessage msg = new RemoveMemberMessage(v.getCoordinator(), m,
          reason);
      services.getMessenger().send(msg);
    }
  }",False
"  private void processViewMessage(InstallViewMessage m) {
    NetView view = m.getView();
    
    if (currentView != null  &&  view.getViewId() < currentView.getViewId()) {
      // ignore old views
      ackView(m);
      return;
    }
    
    
    if (m.isPreparing()) {
      if (this.preparedView != null && this.preparedView.getViewId() >= view.getViewId()) {
        services.getMessenger().send(new ViewAckMessage(m.getSender(), this.preparedView));
      }
      else {
        this.preparedView = view;
        ackView(m);
      }
    }
    else { // !preparing
      if (currentView != null  &&  !view.contains(this.localAddress)) {
        if (quorumRequired) {
          services.getManager().forceDisconnect(""This node is no longer in the membership view"");
        }
      }
      else {
        ackView(m);
        installView(view);
      }
    }
  }",True
"  private void processViewMessage(InstallViewMessage m) {
    NetView view = m.getView();
    
    if (currentView != null  &&  view.getViewId() < currentView.getViewId()) {
      // ignore old views
      ackView(m);
      return;
    }
    
    
    if (m.isPreparing()) {
      if (this.preparedView != null && this.preparedView.getViewId() >= view.getViewId()) {
        services.getMessenger().send(new ViewAckMessage(m.getSender(), this.preparedView));
      }
      else {
        this.preparedView = view;
        ackView(m);
      }
    }
    else { // !preparing
      if (currentView != null  &&  !view.contains(this.localAddress)) {
        if (quorumRequired) {
          forceDisconnect(""This node is no longer in the membership view"");
        }
      }
      else {
        ackView(m);
        installView(view);
      }
    }
  }",False
"  private void becomeCoordinator() {
    becomeCoordinator(null);
  }",True
"  void becomeCoordinator() { // package access for unit testing
    becomeCoordinator(null);
  }",False
"  ViewCreator getViewCreator() {
    return viewCreator;
  }",False
"  public boolean isStopping() {
    return this.isStopping;
  }",False
"  private void becomeCoordinator(InternalDistributedMember oldCoordinator) {
    stateLock.writeLock().lock();
    try {
      if (isCoordinator) {
        return;
      }
      logger.info(""This member is becoming the membership coordinator with address {}"", localAddress);
      isCoordinator = true;
      if (currentView == null) {
        // create the initial membership view
        NetView newView = new NetView(this.localAddress);
        this.localAddress.setVmViewId(0);
        installView(newView);
        isJoined = true;
        startCoordinatorServices();
      } else {
        // create and send out a new view
        NetView newView;
        synchronized(viewInstallationLock) {
          int viewNumber = currentView.getViewId() + 5;
          List<InternalDistributedMember> mbrs = new ArrayList<InternalDistributedMember>(currentView.getMembers());
          if (!mbrs.contains(localAddress)) {
            mbrs.add(localAddress);
          }
          List<InternalDistributedMember> leaving = new ArrayList<InternalDistributedMember>();
          if (oldCoordinator != null) {
            leaving.add(oldCoordinator);
          }
          newView = new NetView(this.localAddress, viewNumber, mbrs, leaving,
              Collections.<InternalDistributedMember>emptyList());
        }
        sendView(newView, Collections.<InternalDistributedMember>emptyList());
        startCoordinatorServices();
      }
    } finally {
      stateLock.writeLock().unlock();
    }
  }",False
"  private void forceDisconnect(String reason) {
    this.isStopping = true;
    services.getManager().forceDisconnect(reason);
  }",False
"  public boolean isCoordinator() {
    return this.isCoordinator;
  }",False
"  private void processLeaveRequest(LeaveRequestMessage incomingRequest) {

    logger.info(""received leave request from {} for {}"", incomingRequest.getSender(), incomingRequest.getMemberID());

    NetView v = currentView;
    if (logger.isDebugEnabled()) {
      logger.debug(""JoinLeave.processLeaveRequest invoked.  isCoordinator=""+isCoordinator+ ""; isStopping=""+isStopping
          +""; cancelInProgress=""+services.getCancelCriterion().isCancelInProgress());
    }
    
    if (incomingRequest.getMemberID().equals(this.localAddress)) {
      logger.info(""I am being told to leave the distributed system"");
      services.getManager().forceDisconnect(incomingRequest.getReason());
    }
    if (!isCoordinator && !isStopping && !services.getCancelCriterion().isCancelInProgress()) {
      logger.debug(""JoinLeave is checking to see if I should become coordinator"");
      NetView check = new NetView(v, v.getViewId()+1);
      check.remove(incomingRequest.getMemberID());
      if (check.getCoordinator().equals(localAddress)) {
        becomeCoordinator(incomingRequest.getMemberID());
      }
    }
    else {
      if (!isStopping && !services.getCancelCriterion().isCancelInProgress()) {
        recordViewRequest(incomingRequest);
      }
    }
  }",True
"  private void processLeaveRequest(LeaveRequestMessage incomingRequest) {

    logger.info(""received leave request from {} for {}"", incomingRequest.getSender(), incomingRequest.getMemberID());
    
    
    NetView v = currentView;
    InternalDistributedMember mbr = incomingRequest.getMemberID();
    
    if (logger.isDebugEnabled()) {
      logger.debug(""JoinLeave.processLeaveRequest invoked.  isCoordinator=""+isCoordinator+ ""; isStopping=""+isStopping
          +""; cancelInProgress=""+services.getCancelCriterion().isCancelInProgress());
    }

    if (!v.contains(mbr) && mbr.getVmViewId() < v.getViewId()) {
      logger.debug(""ignoring leave request from old member"");
      return;
    }
    
    if (incomingRequest.getMemberID().equals(this.localAddress)) {
      logger.info(""I am being told to leave the distributed system"");
      forceDisconnect(incomingRequest.getReason());
    }
    
    if (!isCoordinator && !isStopping && !services.getCancelCriterion().isCancelInProgress()) {
      logger.debug(""JoinLeave is checking to see if I should become coordinator"");
      NetView check = new NetView(v, v.getViewId()+1);
      check.remove(incomingRequest.getMemberID());
      if (check.getCoordinator().equals(localAddress)) {
        becomeCoordinator(incomingRequest.getMemberID());
      }
    }
    else {
      if (!isStopping && !services.getCancelCriterion().isCancelInProgress()) {
        recordViewRequest(incomingRequest);
      }
    }
  }",False
"  private boolean isNetworkPartition(NetView newView) {
    if (currentView == null) {
      return false;
    }
    int oldWeight = currentView.memberWeight();
    int failedWeight = newView.getCrashedMemberWeight(currentView);
    if (failedWeight > 0) {
      if (logger.isInfoEnabled()) {
        newView.logCrashedMemberWeights(currentView, logger);
      }
      int failurePoint = (int)(Math.round(51 * oldWeight) / 100.0);
      if (failedWeight > failurePoint) {
        logger.warn(""total weight lost in this view change is {} of {}.  Quorum has been lost!"",
            failedWeight, oldWeight);
        services.getManager().quorumLost(newView.getActualCrashedMembers(currentView), currentView);
        return true;
      }
    }
    return false;
  }",False
"  public LeaveRequestMessage(InternalDistributedMember coord, InternalDistributedMember id, String reason) {
    super();
    setRecipient(coord);
    this.memberID = id;
  }",True
"  public LeaveRequestMessage(InternalDistributedMember coord, InternalDistributedMember id, String reason) {
    super();
    setRecipient(coord);
    this.memberID = id;
    this.reason = reason;
  }",False
"  public String toString() {
    return getShortClassName() + ""("" + memberID
        + ""; reason="" + reason + "")"";
  }",False
"  private String replaceStrings(String properties, String property, String value) {
    StringBuffer sb = new StringBuffer();
    int start = 0;
    int index = properties.indexOf(property);
    while (index != -1) {
      sb.append(properties.substring(start, index));
      sb.append(value);

      start = index + property.length();
      index = properties.indexOf(property, start);
    }
    sb.append(properties.substring(start));
    return sb.toString();
  }",True
"    if (this.myChannel != null) {
      this.myChannel.disconnect();
    }
  }
  
  /**
   * Puller receives incoming JGroups messages and passes them to a handler
   */
  class JGroupsReceiver implements Receiver  {
  
    @Override
    public void receive(Message jgmsg) {
      if (services.getManager().shutdownInProgress()) {
        return;",False
"  private Message createJGMessage(DistributionMessage gfmsg, JGAddress src, short version) {
    if(gfmsg instanceof DirectReplyMessage) {
      ((DirectReplyMessage) gfmsg).registerProcessor();
    }
    Message msg = new Message();
    msg.setDest(null);
    msg.setSrc(src);
    //log.info(""Creating message with payload "" + gfmsg);
    if (gfmsg.getProcessorType() == DistributionManager.HIGH_PRIORITY_EXECUTOR
        || gfmsg instanceof HighPriorityDistributionMessage) {
      msg.setFlag(Flag.OOB);
      msg.setFlag(Flag.DONT_BUNDLE);
      msg.setFlag(Flag.NO_FC);
      msg.setFlag(Flag.SKIP_BARRIER);
    }
    if (gfmsg instanceof DistributedCacheOperation.CacheOperationMessage) {
      // we don't want to see our own cache operation messages
      msg.setTransientFlag(Message.TransientFlag.DONT_LOOPBACK);
    }
    try {
      long start = services.getStatistics().startMsgSerialization();
      HeapDataOutputStream out_stream =
        new HeapDataOutputStream(Version.fromOrdinalOrCurrent(version));
      Version.CURRENT.writeOrdinal(out_stream, true);
      DataSerializer.writeObject(this.localAddress.getNetMember(), out_stream);
      DataSerializer.writeObject(gfmsg, out_stream);
      msg.setBuffer(out_stream.toByteArray());
      services.getStatistics().endMsgSerialization(start);
    }
    catch(IOException ex) {
        IllegalArgumentException ia = new
          IllegalArgumentException(""Error serializing message"");
        ia.initCause(ex);
        throw ia;
        //throw new IllegalArgumentException(ex.toString());
    }
    return msg;
  }",True
"  Message createJGMessage(DistributionMessage gfmsg, JGAddress src, short version) {
    if(gfmsg instanceof DirectReplyMessage) {
      ((DirectReplyMessage) gfmsg).registerProcessor();
    }
    Message msg = new Message();
    msg.setDest(null);
    msg.setSrc(src);
    //log.info(""Creating message with payload "" + gfmsg);
    if (gfmsg.getProcessorType() == DistributionManager.HIGH_PRIORITY_EXECUTOR
        || gfmsg instanceof HighPriorityDistributionMessage) {
      msg.setFlag(Flag.OOB);
      msg.setFlag(Flag.DONT_BUNDLE);
      msg.setFlag(Flag.NO_FC);
      msg.setFlag(Flag.SKIP_BARRIER);
    }
    if (gfmsg instanceof DistributedCacheOperation.CacheOperationMessage) {
      // we don't want to see our own cache operation messages
      msg.setTransientFlag(Message.TransientFlag.DONT_LOOPBACK);
    }
    try {
      long start = services.getStatistics().startMsgSerialization();
      HeapDataOutputStream out_stream =
        new HeapDataOutputStream(Version.fromOrdinalOrCurrent(version));
      Version.CURRENT.writeOrdinal(out_stream, true);
      DataSerializer.writeObject(this.localAddress.getNetMember(), out_stream);
      DataSerializer.writeObject(gfmsg, out_stream);
      msg.setBuffer(out_stream.toByteArray());
      services.getStatistics().endMsgSerialization(start);
    }
    catch(IOException ex) {
        IllegalArgumentException ia = new
          IllegalArgumentException(""Error serializing message"");
        ia.initCause(ex);
        throw ia;
        //throw new IllegalArgumentException(ex.toString());
    }
    return msg;
  }",False
"  public void setJGroupsStackConfigForTesting(String config) {
    this.jgStackConfig = config;
  }",False
"    public void receive(Message jgmsg) {
      if (services.getManager().shutdownInProgress())
        return;

      if (logger.isDebugEnabled()) {
        logger.debug(""JGroupsMessenger received {} headers: {}"", jgmsg, jgmsg.getHeaders());
      }
      
      Object o = readJGMessage(jgmsg);
      if (o == null) {
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_GEMFIRE_RECEIVED_NULL_MESSAGE_FROM__0, String.valueOf(jgmsg)));
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_MESSAGE_HEADERS__0, jgmsg.printObjectHeaders()));
        return;
      } else if ( !(o instanceof DistributionMessage) ) {
        logger.warn(""Received something other than a message from "" + jgmsg.getSrc() + "": "" + o);
        return;
      }

      DistributionMessage msg = (DistributionMessage)o;
      
      // admin-only VMs don't have caches, so we ignore cache operations
      // multicast to them, avoiding deserialization cost and classpath
      // problems
      if ( (services.getConfig().getTransport().getVmKind() == DistributionManager.ADMIN_ONLY_DM_TYPE)
           && (msg instanceof DistributedCacheOperation.CacheOperationMessage)) {
        if (logger.isTraceEnabled())
          logger.trace(""Membership: admin VM discarding cache operation message {}"", jgmsg.getObject());
        return;
      }

      msg.resetTimestamp();
      msg.setBytesRead(jgmsg.getLength());
            
      if (msg.getSender() == null) {
        Exception e = new Exception(LocalizedStrings.GroupMembershipService_NULL_SENDER.toLocalizedString());
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_GEMFIRE_RECEIVED_A_MESSAGE_WITH_NO_SENDER_ADDRESS), e);
      }
      
      try {
        filterIncomingMessage(msg);
        MessageHandler h = getMessageHandler(msg);
        logger.trace(""Handler for this message is {}"", h);
        h.processMessage(msg);
      }
      catch (MemberShunnedException e) {
        // message from non-member - ignore
      }
    }",True
"    public void receive(Message jgmsg) {
      if (services.getManager().shutdownInProgress()) {
        return;
      }

      if (logger.isDebugEnabled()) {
        logger.debug(""JGroupsMessenger received {} headers: {}"", jgmsg, jgmsg.getHeaders());
      }
      
      Object o = readJGMessage(jgmsg);
      if (o == null) {
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_GEMFIRE_RECEIVED_NULL_MESSAGE_FROM__0, String.valueOf(jgmsg)));
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_MESSAGE_HEADERS__0, jgmsg.printObjectHeaders()));
        return;
      } else if ( !(o instanceof DistributionMessage) ) {
        logger.warn(""Received something other than a message from "" + jgmsg.getSrc() + "": "" + o);
        return;
      }

      DistributionMessage msg = (DistributionMessage)o;
      
      // admin-only VMs don't have caches, so we ignore cache operations
      // multicast to them, avoiding deserialization cost and classpath
      // problems
      if ( (services.getConfig().getTransport().getVmKind() == DistributionManager.ADMIN_ONLY_DM_TYPE)
           && (msg instanceof DistributedCacheOperation.CacheOperationMessage)) {
        if (logger.isTraceEnabled())
          logger.trace(""Membership: admin VM discarding cache operation message {}"", jgmsg.getObject());
        return;
      }

      msg.resetTimestamp();
      msg.setBytesRead(jgmsg.getLength());
            
      if (msg.getSender() == null) {
        Exception e = new Exception(LocalizedStrings.GroupMembershipService_NULL_SENDER.toLocalizedString());
        logger.warn(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_GEMFIRE_RECEIVED_A_MESSAGE_WITH_NO_SENDER_ADDRESS), e);
      }
      
      try {
        filterIncomingMessage(msg);
        MessageHandler h = getMessageHandler(msg);
        logger.trace(""Handler for this message is {}"", h);
        h.processMessage(msg);
      }
      catch (MemberShunnedException e) {
        // message from non-member - ignore
      }
    }",False
"    public BoundedLinkedHashMap(int initialCapacity, float loadFactor, int maximumNumberOfEntries) {
      super(initialCapacity, loadFactor);
      this._maximumNumberOfEntries = maximumNumberOfEntries;
    }",False
"    public BoundedLinkedHashMap(int maximumNumberOfEntries) {
      super();
      this._maximumNumberOfEntries = maximumNumberOfEntries;
    }",False
"    protected boolean removeEldestEntry(Map.Entry entry) {
      return size() > this._maximumNumberOfEntries;
    }",False
"    public BoundedLinkedHashMap(int initialCapacity, int maximumNumberOfEntries) {
      super(initialCapacity);
      this._maximumNumberOfEntries = maximumNumberOfEntries;
    }",False
"  protected void processView(long newViewId, NetView newView)
  {
    // Sanity check...
     if (logger.isDebugEnabled()) {
      StringBuffer msg = new StringBuffer(200);
      msg.append(""Membership: Processing view "");
      msg.append(newView);
      msg.append(""} on "" + address.toString());
      if (logger.isDebugEnabled()) {
        logger.debug(LogMarker.DM_VIEWS, msg);
      }
      if (!newView.contains(address)) {
        logger.info(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_THE_MEMBER_WITH_ID_0_IS_NO_LONGER_IN_MY_OWN_VIEW_1,
            new Object[] {address, newView}));
      }
    }
     
//     if (newView.getCrashedMembers().size() > 0) {
//       // dump stack for debugging #39827
//       OSProcess.printStacks(0);
//     }
    // We perform the update under a global lock so that other
    // incoming events will not be lost in terms of our global view.
    synchronized (latestViewLock) {
      // first determine the version for multicast message serialization
      Version version = Version.CURRENT;
      for (Iterator<Map.Entry<InternalDistributedMember, Long>> it=surpriseMembers.entrySet().iterator(); it.hasNext(); ) {
        InternalDistributedMember mbr = it.next().getKey();
        Version itsVersion = mbr.getVersionObject();
        if (itsVersion != null && version.compareTo(itsVersion) < 0) {
          version = itsVersion;
        }
      }
      for (InternalDistributedMember mbr: newView.getMembers()) {
        Version itsVersion = mbr.getVersionObject();
        if (itsVersion != null && itsVersion.compareTo(version) < 0) {
          version = mbr.getVersionObject();
        }
      }
      disableMulticastForRollingUpgrade = !version.equals(Version.CURRENT);
      
      if (newViewId < latestViewId) {
        // ignore this view since it is old news
        if (newViewId < latestViewId && logger.isDebugEnabled(LogMarker.DISTRIBUTION_VIEWS)) {
          logger.debug(LogMarker.DISTRIBUTION_VIEWS, ""Membership: Ignoring view (with id {}) since it is older than the last view (with id {}); ignoredView={}"",
              newViewId, latestViewId, newView);
        }
        return;
      }

      // Save previous view, for delta analysis
      NetView priorView = latestView;
      
      // update the view to reflect our changes, so that
      // callbacks will see the new (updated) view.
      latestViewId = newViewId;
      latestView = new NetView(newView, newView.getViewId());
      
      // look for additions
      for (int i = 0; i < newView.getMembers().size(); i++) { // additions
        InternalDistributedMember m = (InternalDistributedMember)newView.getMembers().get(i);
        
        // Once a member has been seen via JGroups, remove them from the
        // newborn set
        boolean wasSurprise = surpriseMembers.remove(m) != null;
        
        // bug #45155 - membership view processing was slow, causing a member to connect as ""surprise""
        // and the surprise timeout removed the member and shunned it, keeping it from being
        // recognized as a valid member when it was finally seen in a view
//        if (isShunned(m)) {
//          warnShuns.add(m);
//          continue;
//        }

        // if it's in a view, it's no longer suspect
        suspectedMembers.remove(m);

        if (priorView.contains(m) || wasSurprise) {
          continue; // already seen
        }
      
        // ARB: unblock any waiters for this particular member.
        // i.e. signal any waiting threads in tcpconduit.
        String authInit = this.services.getConfig().getDistributionConfig().getSecurityPeerAuthInit();
        boolean isSecure = authInit != null && authInit.length() != 0;

        if (isSecure) {
          CountDownLatch currentLatch;
          if ((currentLatch = (CountDownLatch)memberLatch.get(m)) != null) {
            currentLatch.countDown();
          }
        }

        // fix for bug #42006, lingering old identity
        Object oldStub = this.memberToStubMap.remove(m);
        if (oldStub != null) {
          this.stubToMemberMap.remove(oldStub);
        }

        if (shutdownInProgress()) {
          logger.info(LogMarker.DM_VIEWS, LocalizedMessage.create(
              LocalizedStrings.GroupMembershipService_MEMBERSHIP_SHUNNING_MEMBER__0__DURING_OUR_SHUTDOWN, m));
          addShunnedMember(m);
          continue; // no additions processed after shutdown begins
        } else {
          boolean wasShunned = endShun(m); // bug #45158 - no longer shun a process that is now in view
          if (wasShunned && logger.isDebugEnabled()) {
            logger.debug(""No longer shunning {} as it is in the current membership view"", m);
          }
        }
        
        logger.info(LocalizedMessage.create(LocalizedStrings.GroupMembershipService_MEMBERSHIP_PROCESSING_ADDITION__0_, m));

        try {
          listener.newMemberConnected(m, getStubForMember(m));
        }
        catch (VirtualMachineError err) {
          SystemFailure.initiateFailure(err);
          // If this ever returns, rethrow the error.  We're poisoned
          // now, so don't let this thread continue.
          throw err;
        }
        catch (DistributedSystemDisconnectedException e) {
          // don't log shutdown exceptions
        }
        catch (Throwable t) {
          // Whenever you catch Error or Throwable, you must also
          // catch VirtualMachineError (see above).  However, there is
          // _still_ a possibility that you are dealing with a cascading
          // error condition, so you also need to check to see if the JVM
          // is still usable:
          SystemFailure.checkFailure();
          logger.info(LocalizedMessage.create(
              LocalizedStrings.GroupMembershipService_MEMBERSHIP_FAULT_WHILE_PROCESSING_VIEW_ADDITION_OF__0, m), t);
        }
      } // additions
      
      // look for departures
      for (int i = 0; i < priorView.getMembers().size(); i++) { // departures
        InternalDistributedMember m = (InternalDistributedMember)priorView.getMembers().get(i);
        if (newView.contains(m)) {
          continue; // still alive
        }
        
        if (surpriseMembers.containsKey(m)) {
          continue; // member has not yet appeared in JGroups view
        }

        try {
          logger.info(LogMarker.DM_VIEWS, LocalizedMessage.create(
              LocalizedStrings.GroupMembershipService_MEMBERSHIP_PROCESSING_DEPARTING_MEMBER__0_, m));
          removeWithViewLock(m,
              newView.getCrashedMembers().contains(m) || suspectedMembers.containsKey(m)
              , ""departed JGroups view"");
        }
        catch (VirtualMachineError err) {
          SystemFailure.initiateFailure(err);
          // If this ever returns, rethrow the error.  We're poisoned
          // now, so don't let this thread continue.
          throw err;
        }
        catch (Throwable t) {
          // Whenever you catch Error or Throwable, you must also
          // catch VirtualMachineError (see above).  However, there is
          // _still_ a possibility that you are dealing with a cascading
          // error condition, so you also need to check to see if the JVM
          // is still usable:
          SystemFailure.checkFailure();
          logger.info(LocalizedMessage.create(
              LocalizedStrings.GroupMembershipService_MEMBERSHIP_FAULT_WHILE_PROCESSING_VIEW_REMOVAL_OF__0, m), t);
        }
      } // departures
      
      // expire surprise members, add others to view
      long oldestAllowed = System.currentTimeMillis() - this.surpriseMemberTimeout;
      for (Iterator<Map.Entry<InternalDistributedMember, Long>> it=surpriseMembers.entrySet().iterator(); it.hasNext(); ) {
        Map.Entry<InternalDistributedMember, Long> entry = it.next();
        Long birthtime = (Long)entry.getValue();
        if (birthtime.longValue() < oldestAllowed) {
          it.remove();
          InternalDistributedMember m = entry.getKey();
          logger.info(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_EXPIRING_MEMBERSHIP_OF_SURPRISE_MEMBER_0, m));
          removeWithViewLock(m, true, ""not seen in membership view in ""
              + this.surpriseMemberTimeout + ""ms"");
        }
        else {
          if (!latestView.contains(entry.getKey())) {
            latestView.add(entry.getKey());
          }
        }
      }
      // expire suspected members
      oldestAllowed = System.currentTimeMillis() - this.suspectMemberTimeout;
      for (Iterator it=suspectedMembers.entrySet().iterator(); it.hasNext(); ) {
        Map.Entry entry = (Map.Entry)it.next();
        Long birthtime = (Long)entry.getValue();
        if (birthtime.longValue() < oldestAllowed) {
          InternalDistributedMember m = (InternalDistributedMember)entry.getKey();
          it.remove();
          if (logger.isTraceEnabled(LogMarker.DISTRIBUTION_VIEWS)) {
            logger.trace(LogMarker.DISTRIBUTION_VIEWS, ""Membership: expiring suspect member <{}>"", m);
          }
        }
      }
      try {
        listener.viewInstalled(latestView);
        startCleanupTimer();
      }
      catch (DistributedSystemDisconnectedException se) {
      }
    } // synchronized
    logger.info(LogMarker.DM_VIEWS, LocalizedMessage.create(
        LocalizedStrings.GroupMembershipService_MEMBERSHIP_FINISHED_VIEW_PROCESSING_VIEWID___0, Long.valueOf(newViewId)));
  }",True
"  protected void processView(long newViewId, NetView newView)
  {
    // Sanity check...
     if (logger.isDebugEnabled()) {
      StringBuffer msg = new StringBuffer(200);
      msg.append(""Membership: Processing view "");
      msg.append(newView);
      msg.append(""} on "" + address.toString());
      if (logger.isDebugEnabled()) {
        logger.debug(LogMarker.DM_VIEWS, msg);
      }
      if (!newView.contains(address)) {
        logger.info(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_THE_MEMBER_WITH_ID_0_IS_NO_LONGER_IN_MY_OWN_VIEW_1,
            new Object[] {address, newView}));
      }
    }
     
//     if (newView.getCrashedMembers().size() > 0) {
//       // dump stack for debugging #39827
//       OSProcess.printStacks(0);
//     }
    // We perform the update under a global lock so that other
    // incoming events will not be lost in terms of our global view.
    latestViewLock.writeLock().lock();
    try {
      // first determine the version for multicast message serialization
      Version version = Version.CURRENT;
      for (Iterator<Map.Entry<InternalDistributedMember, Long>> it=surpriseMembers.entrySet().iterator(); it.hasNext(); ) {
        InternalDistributedMember mbr = it.next().getKey();
        Version itsVersion = mbr.getVersionObject();
        if (itsVersion != null && version.compareTo(itsVersion) < 0) {
          version = itsVersion;
        }
      }
      for (InternalDistributedMember mbr: newView.getMembers()) {
        Version itsVersion = mbr.getVersionObject();
        if (itsVersion != null && itsVersion.compareTo(version) < 0) {
          version = mbr.getVersionObject();
        }
      }
      disableMulticastForRollingUpgrade = !version.equals(Version.CURRENT);
      
      if (newViewId < latestViewId) {
        // ignore this view since it is old news
        if (newViewId < latestViewId && logger.isDebugEnabled(LogMarker.DISTRIBUTION_VIEWS)) {
          logger.debug(LogMarker.DISTRIBUTION_VIEWS, ""Membership: Ignoring view (with id {}) since it is older than the last view (with id {}); ignoredView={}"",
              newViewId, latestViewId, newView);
        }
        return;
      }

      // Save previous view, for delta analysis
      NetView priorView = latestView;
      
      // update the view to reflect our changes, so that
      // callbacks will see the new (updated) view.
      latestViewId = newViewId;
      latestView = new NetView(newView, newView.getViewId());
      
      // look for additions
      for (int i = 0; i < newView.getMembers().size(); i++) { // additions
        InternalDistributedMember m = (InternalDistributedMember)newView.getMembers().get(i);
        
        // Once a member has been seen via JGroups, remove them from the
        // newborn set
        boolean wasSurprise = surpriseMembers.remove(m) != null;
        
        // bug #45155 - membership view processing was slow, causing a member to connect as ""surprise""
        // and the surprise timeout removed the member and shunned it, keeping it from being
        // recognized as a valid member when it was finally seen in a view
//        if (isShunned(m)) {
//          warnShuns.add(m);
//          continue;
//        }

        // if it's in a view, it's no longer suspect
        suspectedMembers.remove(m);

        if (priorView.contains(m) || wasSurprise) {
          continue; // already seen
        }
      
        // ARB: unblock any waiters for this particular member.
        // i.e. signal any waiting threads in tcpconduit.
        String authInit = this.services.getConfig().getDistributionConfig().getSecurityPeerAuthInit();
        boolean isSecure = authInit != null && authInit.length() != 0;

        if (isSecure) {
          CountDownLatch currentLatch;
          if ((currentLatch = (CountDownLatch)memberLatch.get(m)) != null) {
            currentLatch.countDown();
          }
        }

        // fix for bug #42006, lingering old identity
        Object oldStub = this.memberToStubMap.remove(m);
        if (oldStub != null) {
          this.stubToMemberMap.remove(oldStub);
        }

        if (shutdownInProgress()) {
          logger.info(LogMarker.DM_VIEWS, LocalizedMessage.create(
              LocalizedStrings.GroupMembershipService_MEMBERSHIP_SHUNNING_MEMBER__0__DURING_OUR_SHUTDOWN, m));
          addShunnedMember(m);
          continue; // no additions processed after shutdown begins
        } else {
          boolean wasShunned = endShun(m); // bug #45158 - no longer shun a process that is now in view
          if (wasShunned && logger.isDebugEnabled()) {
            logger.debug(""No longer shunning {} as it is in the current membership view"", m);
          }
        }
        
        logger.info(LocalizedMessage.create(LocalizedStrings.GroupMembershipService_MEMBERSHIP_PROCESSING_ADDITION__0_, m));

        try {
          listener.newMemberConnected(m, getStubForMember(m));
        }
        catch (VirtualMachineError err) {
          SystemFailure.initiateFailure(err);
          // If this ever returns, rethrow the error.  We're poisoned
          // now, so don't let this thread continue.
          throw err;
        }
        catch (DistributedSystemDisconnectedException e) {
          // don't log shutdown exceptions
        }
        catch (Throwable t) {
          // Whenever you catch Error or Throwable, you must also
          // catch VirtualMachineError (see above).  However, there is
          // _still_ a possibility that you are dealing with a cascading
          // error condition, so you also need to check to see if the JVM
          // is still usable:
          SystemFailure.checkFailure();
          logger.info(LocalizedMessage.create(
              LocalizedStrings.GroupMembershipService_MEMBERSHIP_FAULT_WHILE_PROCESSING_VIEW_ADDITION_OF__0, m), t);
        }
      } // additions
      
      // look for departures
      for (int i = 0; i < priorView.getMembers().size(); i++) { // departures
        InternalDistributedMember m = (InternalDistributedMember)priorView.getMembers().get(i);
        if (newView.contains(m)) {
          continue; // still alive
        }
        
        if (surpriseMembers.containsKey(m)) {
          continue; // member has not yet appeared in JGroups view
        }

        try {
          logger.info(LogMarker.DM_VIEWS, LocalizedMessage.create(
              LocalizedStrings.GroupMembershipService_MEMBERSHIP_PROCESSING_DEPARTING_MEMBER__0_, m));
          removeWithViewLock(m,
              newView.getCrashedMembers().contains(m) || suspectedMembers.containsKey(m)
              , ""departed JGroups view"");
        }
        catch (VirtualMachineError err) {
          SystemFailure.initiateFailure(err);
          // If this ever returns, rethrow the error.  We're poisoned
          // now, so don't let this thread continue.
          throw err;
        }
        catch (Throwable t) {
          // Whenever you catch Error or Throwable, you must also
          // catch VirtualMachineError (see above).  However, there is
          // _still_ a possibility that you are dealing with a cascading
          // error condition, so you also need to check to see if the JVM
          // is still usable:
          SystemFailure.checkFailure();
          logger.info(LocalizedMessage.create(
              LocalizedStrings.GroupMembershipService_MEMBERSHIP_FAULT_WHILE_PROCESSING_VIEW_REMOVAL_OF__0, m), t);
        }
      } // departures
      
      // expire surprise members, add others to view
      long oldestAllowed = System.currentTimeMillis() - this.surpriseMemberTimeout;
      for (Iterator<Map.Entry<InternalDistributedMember, Long>> it=surpriseMembers.entrySet().iterator(); it.hasNext(); ) {
        Map.Entry<InternalDistributedMember, Long> entry = it.next();
        Long birthtime = (Long)entry.getValue();
        if (birthtime.longValue() < oldestAllowed) {
          it.remove();
          InternalDistributedMember m = entry.getKey();
          logger.info(LocalizedMessage.create(
            LocalizedStrings.GroupMembershipService_MEMBERSHIP_EXPIRING_MEMBERSHIP_OF_SURPRISE_MEMBER_0, m));
          removeWithViewLock(m, true, ""not seen in membership view in ""
              + this.surpriseMemberTimeout + ""ms"");
        }
        else {
          if (!latestView.contains(entry.getKey())) {
            latestView.add(entry.getKey());
          }
        }
      }
      // expire suspected members
      oldestAllowed = System.currentTimeMillis() - this.suspectMemberTimeout;
      for (Iterator it=suspectedMembers.entrySet().iterator(); it.hasNext(); ) {
        Map.Entry entry = (Map.Entry)it.next();
        Long birthtime = (Long)entry.getValue();
        if (birthtime.longValue() < oldestAllowed) {
          InternalDistributedMember m = (InternalDistributedMember)entry.getKey();
          it.remove();
          if (logger.isTraceEnabled(LogMarker.DISTRIBUTION_VIEWS)) {
            logger.trace(LogMarker.DISTRIBUTION_VIEWS, ""Membership: expiring suspect member <{}>"", m);
          }
        }
      }
      try {
        listener.viewInstalled(latestView);
        startCleanupTimer();
      }
      catch (DistributedSystemDisconnectedException se) {
      }
    } finally {
      latestViewLock.writeLock().unlock();
    }
    logger.info(LogMarker.DM_VIEWS, LocalizedMessage.create(
        LocalizedStrings.GroupMembershipService_MEMBERSHIP_FINISHED_VIEW_PROCESSING_VIEWID___0, Long.valueOf(newViewId)));
  }",False
"    public ViewLock() {
    }",True
"     * indicates whether the event is a departure, a surprise connect
     * (i.e., before the view message arrived), a view, or a regular",False
"    public int getMaximumNumberOfEntries(){
      return this._maximumNumberOfEntries;
    }",False
"    public void quorumLost(Set<InternalDistributedMember> failures,
        List<InternalDistributedMember> remainingMembers) {
    }",True
"    nonDefault.put(DistributionConfig.LOG_LEVEL_NAME, ""fine"");
    nonDefault.put(DistributionConfig.LOCATORS_NAME, """");
    DistributionConfigImpl config = new DistributionConfigImpl(nonDefault);",False
"    public boolean isShutdownMsgSent() {
      return false;
    }",True
"    public void messageReceived(DistributionMessage o) {
    }",True
"    public void memberSuspect(InternalDistributedMember suspect,
        InternalDistributedMember whoSuspected) {
    }",True
"    try {
      joinLeave.init(services);
      fail(""expected a GemFireConfigException to be thrown because no locators are configured"");",False
    public void endJob(){},True
"    public void memberDeparted(InternalDistributedMember id, boolean crashed,
        String reason) {
    }",True
"    
    Services services = mock(Services.class);
    when(services.getConfig()).thenReturn(serviceConfig);",False
"  protected void tearDown() throws Exception {
    LogService.setBaseLogLevel(baseLogLevel);
  }",True
"  protected void tearDown() throws Exception {
//    LogService.setBaseLogLevel(baseLogLevel);
  }",False
    public void startJob() {},True
"    public void newMemberConnected(InternalDistributedMember m, Stub stub) {
    }",True
"
    ServiceConfig serviceConfig = mock(ServiceConfig.class);",False
"  public void testMulticastDiscoveryNotAllowed() {
    Properties nonDefault = new Properties();
    nonDefault.put(DistributionConfig.DISABLE_TCP_NAME, ""true"");
    nonDefault.put(DistributionConfig.MCAST_PORT_NAME, ""12345"");
    nonDefault.put(DistributionConfig.LOG_FILE_NAME, """");
    nonDefault.put(DistributionConfig.LOG_LEVEL_NAME, ""fine"");
    nonDefault.put(DistributionConfig.LOCATORS_NAME, """");
    DistributionConfigImpl config = new DistributionConfigImpl(nonDefault);
    RemoteTransportConfig transport = new RemoteTransportConfig(config,
        DistributionManager.NORMAL_DM_TYPE);

    ServiceConfig serviceConfig = mock(ServiceConfig.class);
    when(serviceConfig.getDistributionConfig()).thenReturn(config);
    when(serviceConfig.getTransport()).thenReturn(transport);
    
    Services services = mock(Services.class);
    when(services.getConfig()).thenReturn(serviceConfig);
    
    GMSJoinLeave joinLeave = new GMSJoinLeave();
    try {
      joinLeave.init(services);
      fail(""expected a GemFireConfigException to be thrown because no locators are configured"");
    } catch (GemFireConfigException e) {
      // expected
    }
  }",False
"  public static void setupClass() {
    baseLogLevel = LogService.getBaseLogLevel();
    LogService.setBaseLogLevel(Level.DEBUG);
  }",True
"  public static void setupClass() {
//    baseLogLevel = LogService.getBaseLogLevel();
//    LogService.setBaseLogLevel(Level.DEBUG);
  }",False
"  public void testFailedWeight() throws Exception {
    // in #47342 a new view was created that contained a member that was joining but
    // was no longer reachable.  The member was included in the failed-weight and not
    // in the previous view-weight, causing a spurious network partition to be declared
    InternalDistributedMember members[] = new InternalDistributedMember[] {
        new InternalDistributedMember(""localhost"", 1), new InternalDistributedMember(""localhost"", 2), new InternalDistributedMember(""localhost"", 3),
        new InternalDistributedMember(""localhost"", 4), new InternalDistributedMember(""localhost"", 5), new InternalDistributedMember(""localhost"", 6)};
    int i = 0;
    // weight 3
    members[i].setVmKind(DistributionManager.LOCATOR_DM_TYPE);
    members[i++].getNetMember().setPreferredForCoordinator(true);
    // weight 3
    members[i].setVmKind(DistributionManager.LOCATOR_DM_TYPE);
    members[i++].getNetMember().setPreferredForCoordinator(true);
    // weight 15 (cache+leader)
    members[i].setVmKind(DistributionManager.NORMAL_DM_TYPE);
    members[i++].getNetMember().setPreferredForCoordinator(false);
    // weight 0
    members[i].setVmKind(DistributionManager.ADMIN_ONLY_DM_TYPE);
    members[i++].getNetMember().setPreferredForCoordinator(false);
    // weight 0
    members[i].setVmKind(DistributionManager.ADMIN_ONLY_DM_TYPE);
    members[i++].getNetMember().setPreferredForCoordinator(false);
    // weight 10
    members[i].setVmKind(DistributionManager.NORMAL_DM_TYPE);
    members[i++].getNetMember().setPreferredForCoordinator(false);
    
    List<InternalDistributedMember> vmbrs = new ArrayList(members.length);
    for (i=0; i<members.length; i++) {
      vmbrs.add(members[i]);
    }
    NetView lastView = new NetView(members[0], 4, vmbrs, Collections.EMPTY_LIST, Collections.EMPTY_LIST);
    InternalDistributedMember leader = members[2];
    assertTrue(!leader.getNetMember().preferredForCoordinator());
    
    InternalDistributedMember joiningMember = new InternalDistributedMember(""localhost"", 7);
    joiningMember.setVmKind(DistributionManager.NORMAL_DM_TYPE);
    joiningMember.getNetMember().setPreferredForCoordinator(false);
    
    // have the joining member and another cache process (weight 10) in the failed members
    // collection and check to make sure that the joining member is not included in failed
    // weight calcs.
    List<InternalDistributedMember> failedMembers = new ArrayList<InternalDistributedMember>(3);
    failedMembers.add(joiningMember);
    failedMembers.add(members[members.length-1]); // cache
    failedMembers.add(members[members.length-2]); // admin
    List<InternalDistributedMember> newMbrs = new ArrayList<InternalDistributedMember>(lastView.getMembers());
    newMbrs.removeAll(failedMembers);
    NetView newView = new NetView(members[0], 5, newMbrs, Collections.EMPTY_LIST, failedMembers);
    
    int failedWeight = newView.getCrashedMemberWeight(lastView);
//    System.out.println(""last view = "" + lastView);
//    System.out.println(""failed mbrs = "" + failedMembers);
//    System.out.println(""failed weight = "" + failedWeight);
    assertEquals(""failure weight calculation is incorrect"", 10, failedWeight);
    List<InternalDistributedMember> actual = newView.getActualCrashedMembers(lastView);
    assertTrue(!actual.contains(members[members.length-2]));
  }",True
"  public void testFailedWeight() throws Exception {
    // in #47342 a new view was created that contained a member that was joining but
    // was no longer reachable.  The member was included in the failed-weight and not
    // in the previous view-weight, causing a spurious network partition to be declared
    InternalDistributedMember members[] = new InternalDistributedMember[] {
        new InternalDistributedMember(""localhost"", 1), new InternalDistributedMember(""localhost"", 2), new InternalDistributedMember(""localhost"", 3),
        new InternalDistributedMember(""localhost"", 4), new InternalDistributedMember(""localhost"", 5), new InternalDistributedMember(""localhost"", 6)};
    int i = 0;
    // weight 3
    members[i].setVmKind(DistributionManager.LOCATOR_DM_TYPE);
    members[i++].getNetMember().setPreferredForCoordinator(true);
    // weight 3
    members[i].setVmKind(DistributionManager.LOCATOR_DM_TYPE);
    members[i++].getNetMember().setPreferredForCoordinator(true);
    // weight 15 (cache+leader)
    members[i].setVmKind(DistributionManager.NORMAL_DM_TYPE);
    members[i++].getNetMember().setPreferredForCoordinator(false);
    // weight 0
    members[i].setVmKind(DistributionManager.ADMIN_ONLY_DM_TYPE);
    members[i++].getNetMember().setPreferredForCoordinator(false);
    // weight 0
    members[i].setVmKind(DistributionManager.ADMIN_ONLY_DM_TYPE);
    members[i++].getNetMember().setPreferredForCoordinator(false);
    // weight 10
    members[i].setVmKind(DistributionManager.NORMAL_DM_TYPE);
    members[i++].getNetMember().setPreferredForCoordinator(false);
    
    List<InternalDistributedMember> vmbrs = new ArrayList<>(members.length);
    for (i=0; i<members.length; i++) {
      vmbrs.add(members[i]);
    }
    List<InternalDistributedMember> empty = Collections.emptyList();
    NetView lastView = new NetView(members[0], 4, vmbrs, empty, empty);
    InternalDistributedMember leader = members[2];
    assertTrue(!leader.getNetMember().preferredForCoordinator());
    
    InternalDistributedMember joiningMember = new InternalDistributedMember(""localhost"", 7);
    joiningMember.setVmKind(DistributionManager.NORMAL_DM_TYPE);
    joiningMember.getNetMember().setPreferredForCoordinator(false);
    
    // have the joining member and another cache process (weight 10) in the failed members
    // collection and check to make sure that the joining member is not included in failed
    // weight calcs.
    List<InternalDistributedMember> failedMembers = new ArrayList<InternalDistributedMember>(3);
    failedMembers.add(joiningMember);
    failedMembers.add(members[members.length-1]); // cache
    failedMembers.add(members[members.length-2]); // admin
    List<InternalDistributedMember> newMbrs = new ArrayList<InternalDistributedMember>(lastView.getMembers());
    newMbrs.removeAll(failedMembers);
    NetView newView = new NetView(members[0], 5, newMbrs, empty, failedMembers);
    
    int failedWeight = newView.getCrashedMemberWeight(lastView);
//    System.out.println(""last view = "" + lastView);
//    System.out.println(""failed mbrs = "" + failedMembers);
//    System.out.println(""failed weight = "" + failedWeight);
    assertEquals(""failure weight calculation is incorrect"", 10, failedWeight);
    List<InternalDistributedMember> actual = newView.getActualCrashedMembers(lastView);
    assertTrue(!actual.contains(members[members.length-2]));
  }",False
"    public DistributionManager getDM() {
      return null;
    }",True
"  public void testJoinLeave() throws Exception {
    
    MembershipManager m1=null, m2=null;
    Locator l = null;
    
    try {
      
      // boot up a locator
      int port = AvailablePortHelper.getRandomAvailableTCPPort();
      InetAddress localHost = SocketCreator.getLocalHost();
      
      // this locator will hook itself up with the first MembershipManager
      // to be created
      l = Locator.startLocator(port, new File(""""), localHost);

      // create configuration objects
      Properties nonDefault = new Properties();
      nonDefault.put(DistributionConfig.DISABLE_TCP_NAME, ""true"");
      nonDefault.put(DistributionConfig.MCAST_PORT_NAME, ""0"");
      nonDefault.put(DistributionConfig.LOG_FILE_NAME, """");
      nonDefault.put(DistributionConfig.LOG_LEVEL_NAME, ""fine"");
      nonDefault.put(DistributionConfig.LOCATORS_NAME, localHost.getHostName()+'['+port+']');
      DistributionConfigImpl config = new DistributionConfigImpl(nonDefault);
      RemoteTransportConfig transport = new RemoteTransportConfig(config,
          DistributionManager.NORMAL_DM_TYPE);

      // start the first membership manager
      MembershipListener listener1 = new MembershipListener();
      DMStats stats1 = new MyStats();
      m1 = MemberFactory.newMembershipManager(listener1, config, transport, stats1);

      // start the second membership manager
      MembershipListener listener2 = new MembershipListener();
      DMStats stats2 = new MyStats();
      m2 = MemberFactory.newMembershipManager(listener2, config, transport, stats2);
      
      assert m2.getView().size() == 2;
      assert m1.getView().size() == 2;
      assert m1.getView().getViewId() == m2.getView().getViewId();
      
      m2.shutdown();
      assert !m2.isConnected();
      
      assert m1.getView().size() == 1;
    }
    finally {
      System.getProperties().remove(ConfigurationFactory.CONFIGURATION_FILE_PROPERTY);
      LogService.reconfigure();
      
      if (m2 != null) {
        m2.shutdown();
      }
      if (m1 != null) {
        m1.shutdown();
      }
      if (l != null) {
        l.stop();
      }
    }
    
  }",True
"  @Test
  public void testMultipleManagersInSameProcess() throws Exception {
    
    MembershipManager m1=null, m2=null;
    Locator l = null;
    
    try {
      
      // boot up a locator
      int port = AvailablePortHelper.getRandomAvailableTCPPort();
      InetAddress localHost = SocketCreator.getLocalHost();
      
      // this locator will hook itself up with the first MembershipManager
      // to be created
//      l = Locator.startLocator(port, new File(""""), localHost);
      l = InternalLocator.startLocator(port, new File(""""), null,
          null, null, localHost, false, new Properties(), true, false, null,
          false);

      // create configuration objects
      Properties nonDefault = new Properties();
      nonDefault.put(DistributionConfig.DISABLE_TCP_NAME, ""true"");
      nonDefault.put(DistributionConfig.MCAST_PORT_NAME, ""0"");
      nonDefault.put(DistributionConfig.LOG_FILE_NAME, """");
      nonDefault.put(DistributionConfig.LOG_LEVEL_NAME, ""fine"");
      nonDefault.put(DistributionConfig.LOCATORS_NAME, localHost.getHostName()+'['+port+']');
      DistributionConfigImpl config = new DistributionConfigImpl(nonDefault);
      RemoteTransportConfig transport = new RemoteTransportConfig(config,
          DistributionManager.NORMAL_DM_TYPE);

      // start the first membership manager
      DistributedMembershipListener listener1 = mock(DistributedMembershipListener.class);
      DMStats stats1 = mock(DMStats.class);
      m1 = MemberFactory.newMembershipManager(listener1, config, transport, stats1);

      // start the second membership manager
      DistributedMembershipListener listener2 = mock(DistributedMembershipListener.class);
      DMStats stats2 = mock(DMStats.class);
      m2 = MemberFactory.newMembershipManager(listener2, config, transport, stats2);
      
      assert m2.getView().size() == 2;
      assert m1.getView().size() == 2;
      assert m1.getView().getViewId() == m2.getView().getViewId();
      
      m2.shutdown();
      assert !m2.isConnected();
      
      assert m1.getView().size() == 1;
    }
    finally {
      
      if (m2 != null) {
        m2.shutdown();
      }
      if (m1 != null) {
        m1.shutdown();
      }
      if (l != null) {
        l.stop();
      }
    }",False
"  public void testMultipleManagersInSameProcess() throws Exception {
    
    MembershipManager m1=null, m2=null;
    Locator l = null;
    
    try {
      
      // boot up a locator
      int port = AvailablePortHelper.getRandomAvailableTCPPort();
      InetAddress localHost = SocketCreator.getLocalHost();
      
      // this locator will hook itself up with the first MembershipManager
      // to be created
//      l = Locator.startLocator(port, new File(""""), localHost);
      l = InternalLocator.startLocator(port, new File(""""), null,
          null, null, localHost, false, new Properties(), true, false, null,
          false);

      // create configuration objects
      Properties nonDefault = new Properties();
      nonDefault.put(DistributionConfig.DISABLE_TCP_NAME, ""true"");
      nonDefault.put(DistributionConfig.MCAST_PORT_NAME, ""0"");
      nonDefault.put(DistributionConfig.LOG_FILE_NAME, """");
      nonDefault.put(DistributionConfig.LOG_LEVEL_NAME, ""fine"");
      nonDefault.put(DistributionConfig.LOCATORS_NAME, localHost.getHostName()+'['+port+']');
      DistributionConfigImpl config = new DistributionConfigImpl(nonDefault);
      RemoteTransportConfig transport = new RemoteTransportConfig(config,
          DistributionManager.NORMAL_DM_TYPE);

      // start the first membership manager
      DistributedMembershipListener listener1 = mock(DistributedMembershipListener.class);
      DMStats stats1 = mock(DMStats.class);
      m1 = MemberFactory.newMembershipManager(listener1, config, transport, stats1);

      // start the second membership manager
      DistributedMembershipListener listener2 = mock(DistributedMembershipListener.class);
      DMStats stats2 = mock(DMStats.class);
      m2 = MemberFactory.newMembershipManager(listener2, config, transport, stats2);
      
      assert m2.getView().size() == 2;
      assert m1.getView().size() == 2;
      assert m1.getView().getViewId() == m2.getView().getViewId();
      
      m2.shutdown();
      assert !m2.isConnected();
      
      assert m1.getView().size() == 1;
    }
    finally {
      
      if (m2 != null) {
        m2.shutdown();
      }
      if (m1 != null) {
        m1.shutdown();
      }
      if (l != null) {
        l.stop();
      }
    }
  }",False
"    public void viewInstalled(NetView view) {
    }",True
"    Properties nonDefault = new Properties();
    nonDefault.put(DistributionConfig.DISABLE_TCP_NAME, ""true"");",False
"    public void membershipFailure(String reason, Throwable t) {
    }",True
"  public static void crashDistributedSystem(final DistributedSystem msys) {
    MembershipManagerHelper.inhibitForcedDisconnectLogging(true);
    MembershipManagerHelper.playDead(msys);
    getMembershipManager(msys).uncleanShutdown(""test is forcing disconnect"", new ForcedDisconnectException(""test is forcing disconnect""));
    MembershipManagerHelper.inhibitForcedDisconnectLogging(false);
  }",True
"  public static void crashDistributedSystem(final DistributedSystem msys) {
    MembershipManagerHelper.inhibitForcedDisconnectLogging(true);
    MembershipManagerHelper.playDead(msys);
    ((GMSMembershipManager)getMembershipManager(msys)).forceDisconnect(""for testing"");
    MembershipManagerHelper.inhibitForcedDisconnectLogging(false);
  }",False
"    public Object answer(InvocationOnMock invocation) {
      //do we only expect a join response on a failure?
      methodExecuted = true;
      return null;
    }",False
"  public void testNonMemberCantRemoveMember() throws Exception {
    String reason = ""testing"";
    initMocks();
    prepareAndInstallView();
    // test that a non-member can't remove another member
    RemoveMemberMessage msg = new RemoveMemberMessage(mockMembers[0], mockMembers[1], reason);
    msg.setSender(new InternalDistributedMember(""localhost"", 9000));
    gmsJoinLeave.processMessage(msg);
    Assert.assertTrue(""RemoveMemberMessage should not have been added to view requests"", gmsJoinLeave.getViewRequests().size() == 0);
  }",False
"  public void testDuplicateJoinRequestDoesNotCauseNewView() throws Exception {
    initMocks();
    prepareAndInstallView();
    gmsJoinLeave.getView().add(gmsJoinLeaveMemberId);
    gmsJoinLeave.getView().add(mockMembers[1]);
    gmsJoinLeave.becomeCoordinator();
    JoinRequestMessage msg = new JoinRequestMessage(gmsJoinLeaveMemberId, mockMembers[2], null);
    msg.setSender(mockMembers[2]);
    gmsJoinLeave.processMessage(msg);
    msg = new JoinRequestMessage(gmsJoinLeaveMemberId, mockMembers[2], null);
    msg.setSender(mockMembers[2]);
    gmsJoinLeave.processMessage(msg);
    
    waitForViewAndNoRequestsInProgress(7);
    
    NetView view = gmsJoinLeave.getView();
    Assert.assertTrue(""expected member to be added: "" + mockMembers[2] + ""; view: "" + view,
        view.contains(mockMembers[2]));
    List<InternalDistributedMember> members = view.getMembers();
    int occurrences = 0;
    for (InternalDistributedMember mbr: members) {
      if (mbr.equals(mockMembers[2])) {
        occurrences += 1;
      }
    }
    Assert.assertTrue(""expected member to only be in the view once: "" + mockMembers[2] + ""; view: "" + view,
        occurrences == 1);
  }",False
"  public void testQuorumLossNotificationWithNetworkPartitionDetectionDisabled() throws IOException {
    initMocks(false);
    prepareAndInstallView();
    
    // set up a view with sufficient members, then create a new view
    // where enough weight is lost to cause a network partition
    
    List<InternalDistributedMember> mbrs = new LinkedList<InternalDistributedMember>();
    List<InternalDistributedMember> shutdowns = new LinkedList<InternalDistributedMember>();
    List<InternalDistributedMember> crashes = new LinkedList<InternalDistributedMember>();
    mbrs.add(mockMembers[0]);
    mbrs.add(mockMembers[1]);
    mbrs.add(mockMembers[2]);
    mbrs.add(gmsJoinLeaveMemberId);
    
    ((GMSMember)mockMembers[1].getNetMember()).setMemberWeight((byte)20);
  
    NetView newView = new NetView(mockMembers[0], gmsJoinLeave.getView().getViewId()+1, mbrs, shutdowns, crashes);
    InstallViewMessage installViewMessage = new InstallViewMessage(newView, credentials, false);
    gmsJoinLeave.processMessage(installViewMessage);
    
    crashes = new LinkedList<>(crashes);
    crashes.add(mockMembers[1]);
    crashes.add(mockMembers[2]);
    mbrs = new LinkedList<>(mbrs);
    mbrs.remove(mockMembers[1]);
    mbrs.remove(mockMembers[2]);
    NetView partitionView = new NetView(mockMembers[0], newView.getViewId()+1, mbrs, shutdowns, crashes);
    installViewMessage = new InstallViewMessage(partitionView, credentials, false);
    gmsJoinLeave.processMessage(installViewMessage);
    
    verify(manager, never()).forceDisconnect(any(String.class));
    verify(manager).quorumLost(crashes, newView);
  }",False
"  public void testLeaveCausesForcedDisconnect() throws Exception {
    String reason = ""testing"";
    initMocks();
    prepareAndInstallView();
    gmsJoinLeave.getView().add(gmsJoinLeaveMemberId);
    gmsJoinLeave.getView().add(mockMembers[1]);
    LeaveRequestMessage msg = new LeaveRequestMessage(gmsJoinLeave.getMemberID(), gmsJoinLeave.getMemberID(), reason);
    msg.setSender(mockMembers[1]);
    gmsJoinLeave.processMessage(msg);
    verify(manager).forceDisconnect(reason);
  }",False
"  public void testNetworkPartitionDetected() throws IOException {
    initMocks(true);
    prepareAndInstallView();
    
    // set up a view with sufficient members, then create a new view
    // where enough weight is lost to cause a network partition
    
    List<InternalDistributedMember> mbrs = new LinkedList<InternalDistributedMember>();
    List<InternalDistributedMember> shutdowns = new LinkedList<InternalDistributedMember>();
    List<InternalDistributedMember> crashes = new LinkedList<InternalDistributedMember>();
    mbrs.add(mockMembers[0]);
    mbrs.add(mockMembers[1]);
    mbrs.add(mockMembers[2]);
    mbrs.add(gmsJoinLeaveMemberId);
    
    ((GMSMember)mockMembers[1].getNetMember()).setMemberWeight((byte)20);
  
    NetView newView = new NetView(mockMembers[0], gmsJoinLeave.getView().getViewId()+1, mbrs, shutdowns, crashes);
    InstallViewMessage installViewMessage = new InstallViewMessage(newView, credentials, false);
    gmsJoinLeave.processMessage(installViewMessage);
    
    crashes = new LinkedList<>(crashes);
    crashes.add(mockMembers[1]);
    crashes.add(mockMembers[2]);
    mbrs = new LinkedList<>(mbrs);
    mbrs.remove(mockMembers[1]);
    mbrs.remove(mockMembers[2]);
    NetView partitionView = new NetView(mockMembers[0], newView.getViewId()+1, mbrs, shutdowns, crashes);
    installViewMessage = new InstallViewMessage(partitionView, credentials, false);
    gmsJoinLeave.processMessage(installViewMessage);
    
    verify(manager).forceDisconnect(any(String.class));
    verify(manager).quorumLost(crashes, newView);
  }",False
"  public void initMocks(boolean enableNetworkPartition) throws UnknownHostException {
    mockDistConfig = mock(DistributionConfig.class);
    when(mockDistConfig.getEnableNetworkPartitionDetection()).thenReturn(enableNetworkPartition);
    when(mockDistConfig.getLocators()).thenReturn(""localhost[8888]"");
    mockConfig = mock(ServiceConfig.class);
    when(mockConfig.getDistributionConfig()).thenReturn(mockDistConfig);
    when(mockDistConfig.getLocators()).thenReturn(""localhost[12345]"");
    when(mockDistConfig.getMcastPort()).thenReturn(0);
    
    authenticator = mock(Authenticator.class);
    gmsJoinLeaveMemberId = new InternalDistributedMember(""localhost"", 8887);
    
    messenger = mock(Messenger.class);
    when(messenger.getMemberID()).thenReturn(gmsJoinLeaveMemberId);

    stopper = mock(Stopper.class);
    when(stopper.isCancelInProgress()).thenReturn(false);
    
    manager = mock(Manager.class);
    
    services = mock(Services.class);
    when(services.getAuthenticator()).thenReturn(authenticator);
    when(services.getConfig()).thenReturn(mockConfig);
    when(services.getMessenger()).thenReturn(messenger);
    when(services.getCancelCriterion()).thenReturn(stopper);
    when(services.getManager()).thenReturn(manager);
    
    mockMembers = new InternalDistributedMember[4];
    for (int i = 0; i < mockMembers.length; i++) {
      mockMembers[i] = new InternalDistributedMember(""localhost"", 8888 + i);
    }
    mockOldMember = new InternalDistributedMember(""localhost"", 8700, Version.GFE_56);

    gmsJoinLeave = new GMSJoinLeave();
    gmsJoinLeave.init(services);
    gmsJoinLeave.start();
    gmsJoinLeave.started();
  }",False
"  public void testDuplicateLeaveRequestDoesNotCauseNewView() throws Exception {
    String reason = ""testing"";
    initMocks();
    prepareAndInstallView();
    gmsJoinLeave.getView().add(gmsJoinLeaveMemberId);
    gmsJoinLeave.becomeCoordinator();

    LeaveRequestMessage msg = new LeaveRequestMessage(gmsJoinLeave.getMemberID(), mockMembers[0], reason);
    msg.setSender(mockMembers[0]);
    gmsJoinLeave.processMessage(msg);
    msg = new LeaveRequestMessage(gmsJoinLeave.getMemberID(), mockMembers[0], reason);
    msg.setSender(mockMembers[0]);
    gmsJoinLeave.processMessage(msg);
    
    waitForViewAndNoRequestsInProgress(7);

    NetView view = gmsJoinLeave.getView();
    Assert.assertTrue(""expected member to be removed: "" + mockMembers[0] + ""; view: "" + view,
        !view.contains(mockMembers[0]));
    Assert.assertTrue(""expected member to be in shutdownMembers collection: "" + mockMembers[0] + ""; view: "" + view,
        view.getShutdownMembers().contains(mockMembers[0]));
  }",False
"  public void testRemoveCausesForcedDisconnect() throws Exception {
    String reason = ""testing"";
    initMocks();
    prepareAndInstallView();
    gmsJoinLeave.getView().add(mockMembers[1]);
    RemoveMemberMessage msg = new RemoveMemberMessage(mockMembers[0], gmsJoinLeave.getMemberID(), reason);
    msg.setSender(mockMembers[1]);
    gmsJoinLeave.processMessage(msg);
    verify(manager).forceDisconnect(reason);
  }",False
"  public void testLeaveOfNonMemberIsNoOp() throws Exception {
    String reason = ""testing"";
    initMocks();
    prepareAndInstallView();
    mockMembers[1].setVmViewId(gmsJoinLeave.getView().getViewId()-1);
    LeaveRequestMessage msg = new LeaveRequestMessage(gmsJoinLeave.getMemberID(), mockMembers[1], reason);
    msg.setSender(mockMembers[1]);
    gmsJoinLeave.processMessage(msg);
    Assert.assertTrue(""Expected leave request from non-member to be ignored"", gmsJoinLeave.getViewRequests().isEmpty());
  }",False
"  public void testOlderPreparedViewBeforeFirstViewInstalled() throws IOException {
    initMocks();
    prepareView();
    
    int viewId = 0;
    List<InternalDistributedMember> mbrs = new LinkedList<InternalDistributedMember>();
    List<InternalDistributedMember> shutdowns = new LinkedList<InternalDistributedMember>();
    List<InternalDistributedMember> crashes = new LinkedList<InternalDistributedMember>();
    mbrs.add(mockMembers[1]);
    mbrs.add(mockMembers[2]);
    mbrs.add(mockMembers[3]);
   
    //install the view
    NetView netView = new NetView(mockMembers[0], viewId, mbrs, shutdowns, crashes);
    InstallViewMessage installViewMessage = new InstallViewMessage(netView, credentials, true);
    gmsJoinLeave.processMessage(installViewMessage);
    
    Assert.assertNotEquals(netView, gmsJoinLeave.getView());
  }",True
"    List<InternalDistributedMember> shutdowns = new LinkedList<InternalDistributedMember>();
    List<InternalDistributedMember> crashes = new LinkedList<InternalDistributedMember>();
    mbrs.add(mockMembers[1]);
    mbrs.add(mockMembers[2]);
    mbrs.add(mockMembers[3]);
   
    //install the view
    NetView netView = new NetView(mockMembers[0], viewId, mbrs, shutdowns, crashes);
    InstallViewMessage installViewMessage = new InstallViewMessage(netView, credentials, false);
    gmsJoinLeave.processMessage(installViewMessage);
    
    Assert.assertNotEquals(netView, gmsJoinLeave.getView());
    verify(mockManager).forceDisconnect(any(String.class));
  }
  
  private class MethodExecuted implements Answer {
    private boolean methodExecuted = false;
    @Override
    public Object answer(InvocationOnMock invocation) {",False
"  private void waitForViewAndNoRequestsInProgress(int viewId) throws InterruptedException {
    // wait for the view processing thread to collect and process the requests
    int sleeps = 0;
    while( !gmsJoinLeave.isStopping() && !gmsJoinLeave.getViewCreator().isWaiting()
        && (!gmsJoinLeave.getViewRequests().isEmpty() || gmsJoinLeave.getView().getViewId() != viewId) ) {
      if (sleeps++ > 20) {
        System.out.println(""view requests: "" + gmsJoinLeave.getViewRequests());
        System.out.println(""current view: "" + gmsJoinLeave.getView());
        throw new RuntimeException(""timeout waiting for view #"" + viewId);
      }
      Thread.sleep(1000);
    }
  }",False
"    public boolean isMethodExecuted() {
      return methodExecuted;
    }",False
"  public void testDuplicateRemoveRequestDoesNotCauseNewView() throws Exception {
    String reason = ""testing"";
    initMocks();
    prepareAndInstallView();
    gmsJoinLeave.getView().add(gmsJoinLeaveMemberId);
    gmsJoinLeave.getView().add(mockMembers[1]);
    gmsJoinLeave.becomeCoordinator();
    RemoveMemberMessage msg = new RemoveMemberMessage(gmsJoinLeave.getMemberID(), mockMembers[0], reason);
    msg.setSender(mockMembers[0]);
    gmsJoinLeave.processMessage(msg);
    msg = new RemoveMemberMessage(gmsJoinLeave.getMemberID(), mockMembers[0], reason);
    msg.setSender(mockMembers[0]);
    gmsJoinLeave.processMessage(msg);
    
    waitForViewAndNoRequestsInProgress(7);
    
    NetView view = gmsJoinLeave.getView();
    Assert.assertTrue(""expected member to be removed: "" + mockMembers[0] + ""; view: "" + view,
        !view.contains(mockMembers[0]));
    Assert.assertTrue(""expected member to be in crashedMembers collection: "" + mockMembers[0] + ""; view: "" + view,
        view.getCrashedMembers().contains(mockMembers[0]));
  }",False
"  public void testBecomeCoordinator() throws Exception {
    String reason = ""testing"";
    initMocks();
    prepareAndInstallView();
    NetView view = gmsJoinLeave.getView();
    view.add(gmsJoinLeaveMemberId);
    InternalDistributedMember creator = view.getCreator();
    LeaveRequestMessage msg = new LeaveRequestMessage(creator, creator, reason);
    msg.setSender(creator);
    gmsJoinLeave.processMessage(msg);
    Assert.assertTrue(""Expected becomeCoordinator to be invoked"", gmsJoinLeave.isCoordinator());
  }",False
"  public void testConflictingPrepare() throws Exception {
    initMocks(true);
    prepareAndInstallView();
    
    NetView gmsView = gmsJoinLeave.getView();
    NetView newView = new NetView(gmsView, gmsView.getViewId()+6);
    InstallViewMessage msg = new InstallViewMessage(newView, null, true);
    gmsJoinLeave.processMessage(msg);
    
    NetView alternateView = new NetView(gmsView, gmsView.getViewId()+1);
    msg = new InstallViewMessage(alternateView, null, true);
    gmsJoinLeave.processMessage(msg);
    
    Assert.assertTrue(gmsJoinLeave.getPreparedView().equals(newView));
  }",False
"  void setFileSystem(final FileSystem fileSystem) {
    this.fileSystem = fileSystem;
    this.chunkSize = fileSystem.chunkSize;
  }",True
"  void setFileSystem(final FileSystem fileSystem) {
    this.fileSystem = fileSystem;
    this.chunkSize = FileSystem.CHUNK_SIZE;
  }",False
"  public void close() throws IOException {
    if (open) {
      flushBuffer();
      file.modified = System.currentTimeMillis();
      file.getFileSystem().updateFile(file);
      open = false;
      buffer = null;
    }
  }",True
"  public void close() throws IOException {
    if (open) {
      flushBuffer();
      file.modified = System.currentTimeMillis();
      file.length = length;
      file.chunks = chunks;
      file.getFileSystem().updateFile(file);
      open = false;
      buffer = null;
    }
  }",False
"  private void flushBuffer() {
    byte[] chunk = Arrays.copyOfRange(buffer.array(), buffer.arrayOffset(), buffer.position());
    file.getFileSystem().putChunk(file, file.chunks++, chunk);
    buffer.rewind();
  }",True
"  private void flushBuffer() {
    byte[] chunk = Arrays.copyOfRange(buffer.array(), buffer.arrayOffset(), buffer.position());
    file.getFileSystem().putChunk(file, chunks++, chunk);
    buffer.rewind();
  }",False
"  public void write(final int b) throws IOException {
    assertOpen();
    
    if (buffer.remaining() == 0) {
      flushBuffer();
    }

    buffer.put((byte) b);
    file.length++;
  }",True
"  public void write(final byte[] b, int off, int len) throws IOException {
    assertOpen();
    
    while (len > 0) {
      if (buffer.remaining() == 0) {
        flushBuffer();
      }

      final int min = Math.min(buffer.remaining(), len);
      buffer.put(b, off, min);
      off += min;
      len -= min;
      length += min;
    }
  }",False
"  public void write(final int b) throws IOException {
    assertOpen();
    
    if (buffer.remaining() == 0) {
      flushBuffer();
    }

    buffer.put((byte) b);
    length++;
  }",False
"  public FileOutputStream(final File file) {
    this.file = file;
    buffer = ByteBuffer.allocate(file.getChunkSize());
  }",True
"  public FileOutputStream(final File file) {
    this.file = file;
    buffer = ByteBuffer.allocate(file.getChunkSize());
    this.length = file.length;
    this.chunks = file.chunks;
  }",False
"  byte[] getChunk(final File file, final int id) {
    final ChunkKey key = new ChunkKey(file.getName(), id);
    final byte[] chunk = chunkRegion.get(key);
    return chunk;
  }",True
"  byte[] getChunk(final File file, final int id) {
    final ChunkKey key = new ChunkKey(file.getName(), id);
    
    //The file's metadata indicates that this chunk shouldn't
    //exist. Purge all of the chunks that are larger than the file metadata
    if(id >= file.chunks) {
      while(chunkRegion.containsKey(key)) {
        chunkRegion.remove(key);
        key.chunkId++;
      }
      
      return null;
    }
    
    final byte[] chunk = chunkRegion.get(key);
    return chunk;
  }",False
"  public byte[] getRandomBytes() {
    byte[] data = new byte[rand.nextInt(LARGE_CHUNK) + SMALL_CHUNK];
    rand.nextBytes(data);
    
    return data;
  }",True
"  public byte[] getRandomBytes() {
    return getRandomBytes(rand.nextInt(LARGE_CHUNK) + SMALL_CHUNK);
  }",False
"    public Object answer(InvocationOnMock invocation) throws Throwable {
      countOperations.answer(invocation);
      Method m = invocation.getMethod();
      return m.invoke(region, invocation.getArguments());
    }",False
"    public void reset() {
      count = 0;
    }",False
"  private File getOrCreateFile(String name) throws IOException {
    try {
      return system.getFile(name);
    } catch(FileNotFoundException e) {
      return system.createFile(name);
    }
  }",False
"  public void testUnclosedStreamLargeFile() throws IOException {
    doUnclosedStream(LARGE_CHUNK);
  }",False
"    private SpyWrapper(CountOperations countOperations, Object region) {
      this.countOperations = countOperations;
      this.region = region;
    }",False
"  public void testUnclosedStreamSmallFile() throws IOException {
    doUnclosedStream(SMALL_CHUNK);
  }",False
"  private void writeBytes(File file, byte[] data) throws IOException {
    OutputStream outputStream = file.getOutputStream();
    outputStream.write(data);
    outputStream.close();
  }",False
"  public void testReadWriteBytes() throws IOException {
    long start = System.currentTimeMillis();
    
    File file1= system.createFile(""testFile1"");
    
    assertEquals(0, file1.getLength());
    
    OutputStream outputStream1 = file1.getOutputStream();
    
    outputStream1.write(2);
    byte[] data = new byte[LARGE_CHUNK];
    rand.nextBytes(data);
    outputStream1.write(data);
    outputStream1.write(44);
    outputStream1.close();
    
    assertEquals(2 + LARGE_CHUNK, file1.getLength());
    assertTrue(file1.getModified() >= start);
    
    OutputStream outputStream2 = file1.getOutputStream();
    
    outputStream2.write(123);
    byte[] data2 = new byte[SMALL_CHUNK];
    rand.nextBytes(data2);
    outputStream2.write(data2);
    outputStream2.close();
    
    assertEquals(3 + LARGE_CHUNK + SMALL_CHUNK, file1.getLength());
    
    InputStream is = file1.getInputStream();
    
    assertEquals(2, is.read());
    byte[] resultData = new byte[LARGE_CHUNK];
    assertEquals(LARGE_CHUNK, is.read(resultData));
    assertArrayEquals(data, resultData);
    assertEquals(44, is.read());
    assertEquals(123, is.read());
    

    //Test read to an offset
    Arrays.fill(resultData, (byte) 0);
    assertEquals(SMALL_CHUNK, is.read(resultData, 50, SMALL_CHUNK));
    
    //Make sure the data read matches
    byte[] expectedData = new byte[LARGE_CHUNK];
    Arrays.fill(expectedData, (byte) 0);
    System.arraycopy(data2, 0, expectedData, 50, data2.length);
    assertArrayEquals(expectedData, resultData);
    
    assertEquals(-1, is.read());
    assertEquals(-1, is.read(data));
    is.close();
    
    //Test the skip interface
    is = file1.getInputStream();
    is.skip(LARGE_CHUNK + 3);
    
    
    Arrays.fill(resultData, (byte) 0);
    assertEquals(SMALL_CHUNK, is.read(resultData));
    
    Arrays.fill(expectedData, (byte) 0);
    System.arraycopy(data2, 0, expectedData, 0, data2.length);
    assertArrayEquals(expectedData, resultData);
    
    assertEquals(-1, is.read());
  }",True
"  public void testReadWriteBytes() throws IOException {
    long start = System.currentTimeMillis();
    
    File file1= system.createFile(""testFile1"");
    
    assertEquals(0, file1.getLength());
    
    OutputStream outputStream1 = file1.getOutputStream();

    //Write some random data. Make sure it fills several chunks
    outputStream1.write(2);
    byte[] data = new byte[LARGE_CHUNK];
    rand.nextBytes(data);
    outputStream1.write(data);
    outputStream1.write(44);
    outputStream1.close();
    
    assertEquals(2 + LARGE_CHUNK, file1.getLength());
    assertTrue(file1.getModified() >= start);
    
    //Append to the file with a new outputstream
    OutputStream outputStream2 = file1.getOutputStream();
    outputStream2.write(123);
    byte[] data2 = new byte[SMALL_CHUNK];
    rand.nextBytes(data2);
    outputStream2.write(data2);
    outputStream2.close();
    
    assertEquals(3 + LARGE_CHUNK + SMALL_CHUNK, file1.getLength());

    //Make sure we can read all fo the data back and it matches
    InputStream is = file1.getInputStream();
    
    assertEquals(2, is.read());
    byte[] resultData = new byte[LARGE_CHUNK];
    assertEquals(LARGE_CHUNK, is.read(resultData));
    assertArrayEquals(data, resultData);
    assertEquals(44, is.read());
    assertEquals(123, is.read());
    

    //Test read to an offset
    Arrays.fill(resultData, (byte) 0);
    assertEquals(SMALL_CHUNK, is.read(resultData, 50, SMALL_CHUNK));
    
    //Make sure the data read matches
    byte[] expectedData = new byte[LARGE_CHUNK];
    Arrays.fill(expectedData, (byte) 0);
    System.arraycopy(data2, 0, expectedData, 50, data2.length);
    assertArrayEquals(expectedData, resultData);
    
    assertEquals(-1, is.read());
    assertEquals(-1, is.read(data));
    is.close();
    
    //Test the skip interface
    is = file1.getInputStream();
    is.skip(LARGE_CHUNK + 3);
    
    
    Arrays.fill(resultData, (byte) 0);
    assertEquals(SMALL_CHUNK, is.read(resultData));
    
    Arrays.fill(expectedData, (byte) 0);
    System.arraycopy(data2, 0, expectedData, 0, data2.length);
    assertArrayEquals(expectedData, resultData);
    
    assertEquals(-1, is.read());
  }",False
"  private void doUnclosedStream(int size) throws IOException {
    String name1 = ""testFile1"";
    File file1= system.createFile(name1);
    byte[] bytes = getRandomBytes(size );
    file1.getOutputStream().write(bytes);
    
    FileSystem system2 = new FileSystem(fileRegion, chunkRegion);
    File file = system2.getFile(name1);
    
    assertTrue(file.getLength() <= bytes.length);
    
    long length = file.getLength();
    
    
    byte[] results = new byte[bytes.length];
    
    if(length == 0) {
      assertEquals(-1, file.getInputStream().read(results));
      assertTrue(chunkRegion.isEmpty());
    } else {
      //Make sure the amount of data we can read matches the length
      assertEquals(length, file.getInputStream().read(results));

      if(length != bytes.length) {
        Arrays.fill(bytes, (int) length, bytes.length, (byte) 0);
      }
      
      assertArrayEquals(bytes, results);
    }
  }",False
"  public byte[] getRandomBytes(int length) {
    byte[] data = new byte[length];
    rand.nextBytes(data);
    
    return data;
  }",False
"  private void assertContents(byte[] data, File file) throws IOException {
    assertEquals(data.length, file.getLength());
    InputStream is = file.getInputStream();
    byte[] results = new byte[data.length];
    assertEquals(file.getLength(), is.read(results));
    assertEquals(-1, is.read());
    is.close();
    
    assertArrayEquals(data, results);
  }",True
"  private void assertContents(byte[] data, File file) throws IOException {
    assertEquals(data.length, file.getLength());
    
    InputStream is = file.getInputStream();
    
    if(data.length == 0) {
      assertEquals(-1, is.read());
      return;
    }
    
    byte[] results = new byte[data.length];
    assertEquals(file.getLength(), is.read(results));
    assertEquals(-1, is.read());
    is.close();
    
    assertArrayEquals(data, results);
  }",False
"  private byte[] writeRandomBytes(File file) throws IOException {
    byte[] file1Data = getRandomBytes();
    OutputStream outputStream = file.getOutputStream();
    outputStream.write(file1Data);
    outputStream.close();
    return file1Data;
  }",True
"  private byte[] writeRandomBytes(File file) throws IOException {
    byte[] file1Data = getRandomBytes();
    writeBytes(file, file1Data);
    return file1Data;
  }",False
"    public void after(int i, Runnable runnable) {
      limit = i;
      limitAction = runnable;
      
    }",False
"    public Object answer(InvocationOnMock invocation) throws Throwable {
      count++;
      if(count >= limit) {
        limitAction.run();
      }
      return null;
    }",False
"  public void setUp() {
    ConcurrentHashMap<String, File> fileRegion = new ConcurrentHashMap<String, File>();
    ConcurrentHashMap<ChunkKey, byte[]> chunkRegion = new ConcurrentHashMap<ChunkKey, byte[]>();
    system = new FileSystem(fileRegion, chunkRegion);
  }",True
"  public void setUp() {
    fileRegion = new ConcurrentHashMap<String, File>();
    chunkRegion = new ConcurrentHashMap<ChunkKey, byte[]>();
    system = new FileSystem(fileRegion, chunkRegion);
  }",False
"  ChunkKey(String fileName, int chunkId) {
    this.fileName = fileName;
    this.chunkId = chunkId;
  }",True
"
  ChunkKey(UUID fileName, int chunkId) {
    this.fileId = fileName;
    this.chunkId = chunkId;",False
"  public boolean equals(Object obj) {
    if (this == obj) {
      return true;
    }
    if (obj == null) {
      return false;
    }
    if (!(obj instanceof ChunkKey)) {
      return false;
    }
    ChunkKey other = (ChunkKey) obj;
    if (chunkId != other.chunkId) {
      return false;
    }
    if (fileName == null) {
      if (other.fileName != null) {
        return false;
      }
    } else if (!fileName.equals(other.fileName)) {
      return false;
    }
    return true;
  }",True
"  public boolean equals(Object obj) {
    if (this == obj) {
      return true;
    }
    if (obj == null) {
      return false;
    }
    if (!(obj instanceof ChunkKey)) {
      return false;
    }
    ChunkKey other = (ChunkKey) obj;
    if (chunkId != other.chunkId) {
      return false;
    }
    if (fileId == null) {
      if (other.fileId != null) {
        return false;
      }
    } else if (!fileId.equals(other.fileId)) {
      return false;
    }
    return true;
  }",False
"  public int hashCode() {
    final int prime = 31;
    int result = 1;
    result = prime * result + fileName.hashCode();
    result = prime * result + chunkId;
    return result;
  }",True
"  public int hashCode() {
    final int prime = 31;
    int result = 1;
    result = prime * result + fileId.hashCode();
    result = prime * result + chunkId;
    return result;
  }",False
"  public UUID getFileId() {
    return fileId;
  }",False
"  public String getFileName() {
    return fileName;
  }",True
"   */
  public UUID getFileId() {
    return fileId;",False
"  ChunkKey(UUID fileName, int chunkId) {
    this.fileId = fileName;
    this.chunkId = chunkId;
  }",False
"  public void putChunk(final File file, final int id, final byte[] chunk) {
    final ChunkKey key = new ChunkKey(file.getName(), id);
    chunkRegion.put(key, chunk);
  }",True
"  public void putChunk(final File file, final int id, final byte[] chunk) {
    final ChunkKey key = new ChunkKey(file.id, id);
    chunkRegion.put(key, chunk);
  }",False
"  public void renameFile(String source, String dest) throws IOException {
    final File destFile = createFile(dest);
    
    // TODO - What is the state of the system if 
    // things crash in the middle of moving this file?
    // Seems like a file will be left with some 
    // dangling chunks at the end of the file
    
    final File sourceFile = fileRegion.get(source);
    if (null == sourceFile) {
      throw new FileNotFoundException(source);
    }

    destFile.chunks = sourceFile.chunks;
    destFile.created = sourceFile.created;
    destFile.length = sourceFile.length;
    destFile.modified = sourceFile.modified;

    // TODO copy on write?
    final ChunkKey sourceKey = new ChunkKey(source, 0);
    while (true) {
      byte[] chunk = chunkRegion.remove(sourceKey);
      if (null == chunk) {
        // no more chunks
        break;
      }
      putChunk(destFile, sourceKey.chunkId, chunk);
      sourceKey.chunkId++;
    }
    
    updateFile(destFile);
    fileRegion.remove(source);
  }",True
"  public void renameFile(String source, String dest) throws IOException {
    final File sourceFile = fileRegion.get(source);
    if (null == sourceFile) {
      throw new FileNotFoundException(source);
    }
    
    final File destFile = createFile(dest);
    
    destFile.chunks = sourceFile.chunks;
    destFile.created = sourceFile.created;
    destFile.length = sourceFile.length;
    destFile.modified = sourceFile.modified;
    destFile.id = sourceFile.id;
    
    // TODO - What is the state of the system if 
    // things crash in the middle of moving this file?
    // Seems like we will have two files pointing
    // at the same data

    fileRegion.remove(source);
  }",False
"  byte[] getChunk(final File file, final int id) {
    final ChunkKey key = new ChunkKey(file.getName(), id);
    
    //The file's metadata indicates that this chunk shouldn't
    //exist. Purge all of the chunks that are larger than the file metadata
    if(id >= file.chunks) {
      while(chunkRegion.containsKey(key)) {
        chunkRegion.remove(key);
        key.chunkId++;
      }
      
      return null;
    }
    
    final byte[] chunk = chunkRegion.get(key);
    return chunk;
  }",True
"  byte[] getChunk(final File file, final int id) {
    final ChunkKey key = new ChunkKey(file.id, id);
    
    //The file's metadata indicates that this chunk shouldn't
    //exist. Purge all of the chunks that are larger than the file metadata
    if(id >= file.chunks) {
      while(chunkRegion.containsKey(key)) {
        chunkRegion.remove(key);
        key.chunkId++;
      }
      
      return null;
    }
    
    final byte[] chunk = chunkRegion.get(key);
    return chunk;
  }",False
"  public void deleteFile(final String name) {
    // TODO locks?

    // TODO - What is the state of the system if 
    // things crash in the middle of removing this file?
    // Seems like a file will be left with some 
    // dangling chunks at the end of the file
    
    // TODO consider removeAll with all ChunkKeys listed.
    final ChunkKey key = new ChunkKey(name, 0);
    while (true) {
      // TODO consider mutable ChunkKey
      if (null == chunkRegion.remove(key)) {
        // no more chunks
        break;
      }
      key.chunkId++;
    }
    
    fileRegion.remove(name);
  }",True
"  public void deleteFile(final String name) throws FileNotFoundException {
    // TODO locks?

    // TODO - What is the state of the system if 
    // things crash in the middle of removing this file?
    // Seems like a file will be left with some 
    // dangling chunks at the end of the file
    File file = fileRegion.remove(name);
    if(file == null) {
      throw new FileNotFoundException(name);
    }
    
    // TODO consider removeAll with all ChunkKeys listed.
    final ChunkKey key = new ChunkKey(file.id, 0);
    while (true) {
      // TODO consider mutable ChunkKey
      if (null == chunkRegion.remove(key)) {
        // no more chunks
        break;
      }
      key.chunkId++;
    }
  }",False
"    public Object answer(InvocationOnMock invocation) throws Throwable {
      count++;
      if(count >= limit) {
        limitAction.run();
      }
      return null;
    }",True
"    public Object answer(InvocationOnMock invocation) throws Throwable {
      count++;
      if(count > limit) {
        limitAction.run();
      }
      return null;
    }",False
"  public void testPartialRename() throws IOException {

    final CountOperations countOperations = new CountOperations();
    //Create a couple of mock regions where we count the operations
    //that happen to them. We will then use this to abort the rename
    //in the middle.
    ConcurrentHashMap<String, File> spyFileRegion = Mockito.mock(ConcurrentHashMap.class, new SpyWrapper(countOperations, fileRegion));
    ConcurrentHashMap<ChunkKey, byte[]> spyChunkRegion = Mockito.mock(ConcurrentHashMap.class, new SpyWrapper(countOperations, chunkRegion));
    
    system = new FileSystem(spyFileRegion, spyChunkRegion);
    
    String name = ""file"";
    File file = system.createFile(name);
    
    ByteArrayOutputStream expected = new ByteArrayOutputStream();

    //Make sure the file has a lot of chunks
    for(int i=0; i < 10; i++) {
      expected.write(writeRandomBytes(file));
    }
    
    String name2 = ""file2"";
    countOperations.reset();
    
    system.renameFile(name, name2);
    
    assertTrue(2 <= countOperations.count);
    
    countOperations.after((int) Math.ceil(countOperations.count / 2.0), new Runnable() {

      @Override
      public void run() {
        throw new CacheClosedException();
      }
    });
    countOperations.reset();
    
    String name3 = ""file3"";
    try {
      system.renameFile(name2, name3);
      fail(""should have seen an error"");
    } catch(CacheClosedException e) {
      
    }
    
    system = new FileSystem(fileRegion, chunkRegion);
    
    //This is not the ideal behavior. We are left
    //with two duplicate files. However, we will still
    //verify that neither file is corrupted.
    assertEquals(2, system.listFileNames().size());
    File sourceFile = system.getFile(name2);
    File destFile = system.getFile(name3);
    
    byte[] expectedBytes = expected.toByteArray();
    
    assertContents(expectedBytes, sourceFile);
    assertContents(expectedBytes, destFile);
  }",False
"  public void testPartialDelete() throws IOException {

    final CountOperations countOperations = new CountOperations();
    //Create a couple of mock regions where we count the operations
    //that happen to them. We will then use this to abort the rename
    //in the middle.
    ConcurrentHashMap<String, File> spyFileRegion = Mockito.mock(ConcurrentHashMap.class, new SpyWrapper(countOperations, fileRegion));
    ConcurrentHashMap<ChunkKey, byte[]> spyChunkRegion = Mockito.mock(ConcurrentHashMap.class, new SpyWrapper(countOperations, chunkRegion));
    
    system = new FileSystem(spyFileRegion, spyChunkRegion);
    
    String name1 = ""file1"";
    String name2 = ""file2"";
    File file1 = system.createFile(name1);
    File file2 = system.createFile(name2);
    
    ByteArrayOutputStream expected = new ByteArrayOutputStream();

    //Make sure the file has a lot of chunks
    for(int i=0; i < 10; i++) {
      byte[] bytes = writeRandomBytes(file1);
      writeBytes(file2, bytes);
      expected.write(bytes);
    }
    
    countOperations.reset();
    
    system.deleteFile(name1);
    
    assertTrue(2 <= countOperations.count);
    
    countOperations.after(countOperations.count / 2, new Runnable() {

      @Override
      public void run() {
        throw new CacheClosedException();
      }
    });
    countOperations.reset();
    
    try {
      system.deleteFile(name2);
      fail(""should have seen an error"");
    } catch(CacheClosedException e) {
      
    }
    
    system = new FileSystem(fileRegion, chunkRegion);
    
    if(system.listFileNames().size() == 0) {
      //File was deleted, but shouldn't have any dangling chunks at this point
      assertEquals(Collections.EMPTY_SET, fileRegion.keySet());
      //TODO - need to purge chunks of deleted files somehow.
//      assertEquals(Collections.EMPTY_SET, chunkRegion.keySet());
    } else {
      file2 = system.getFile(name2);
      assertContents(expected.toByteArray(), file2);
    }
    
  }",False
"  public void testConstructor() throws NoSuchMethodException, SecurityException, IllegalAccessException, IllegalArgumentException, InvocationTargetException {
    SnappyCompressor.getDefaultInstance();
    // repeat findNativeLibrary and make sure it's pointing at a file in tmpdir
    Method findNativeLibraryMethod = SnappyLoader.class.getDeclaredMethod(""findNativeLibrary"", new Class[0]);
    findNativeLibraryMethod.setAccessible(true);
    File nativeLibrary = (File) findNativeLibraryMethod.invoke(null, null);
    System.out.println(nativeLibrary);
    assertNotNull(nativeLibrary);
    assertTrue(nativeLibrary + "" does not exist"", nativeLibrary.exists());
    File tmpDir = new File(System.getProperty(""java.io.tmpdir""));
    assertTrue(tmpDir.exists());
    File parent = nativeLibrary.getParentFile();
    assertNotNull(parent);
    assertEquals(tmpDir, parent);
  }",True
"  public void testConstructor() throws NoSuchMethodException, SecurityException, IllegalAccessException, IllegalArgumentException, InvocationTargetException {
    SnappyCompressor.getDefaultInstance();
    // repeat findNativeLibrary and make sure it's pointing at a file in tmpdir
    Method findNativeLibraryMethod = SnappyLoader.class.getDeclaredMethod(""findNativeLibrary"", new Class[0]);
    findNativeLibraryMethod.setAccessible(true);
    File nativeLibrary = (File) findNativeLibraryMethod.invoke(null);
    System.out.println(nativeLibrary);
    assertNotNull(nativeLibrary);
    assertTrue(nativeLibrary + "" does not exist"", nativeLibrary.exists());
    File tmpDir = new File(System.getProperty(""java.io.tmpdir""));
    assertTrue(tmpDir.exists());
    File parent = nativeLibrary.getParentFile();
    assertNotNull(parent);
    assertEquals(tmpDir, parent);
  }",False
"  private static boolean isHydra() {
    try {
      //TODO - this is hacky way to test for a hydra environment - see
      //if there is registered test configuration object.
      Class<?> clazz = Class.forName(""hydra.TestConfig"");
      Method getInstance = clazz.getMethod(""getInstance"", new Class[0]);
      getInstance.invoke(null, null);
      return true;
    } catch (Exception e) {
      return false;
    }
  }",True
"  private static boolean isHydra() {
    try {
      //TODO - this is hacky way to test for a hydra environment - see
      //if there is registered test configuration object.
      Class<?> clazz = Class.forName(""hydra.TestConfig"");
      Method getInstance = clazz.getMethod(""getInstance"", new Class[0]);
      getInstance.invoke(null);
      return true;
    } catch (Exception e) {
      return false;
    }
  }",False
"  public void testRegionExpirationAfterMutate()
  throws CacheException, InterruptedException {

    final String name = this.getUniqueName();
            ;
    final Object key = ""KEY"";
    final Object value = ""VALUE"";
    
    AttributesFactory factory = new AttributesFactory(getRegionAttributes());
    factory.setStatisticsEnabled(true);
    RegionAttributes attrs = factory.create();
    LocalRegion region = null;
    System.setProperty(LocalRegion.EXPIRY_MS_PROPERTY, ""true"");
    try {
      region = (LocalRegion) createRegion(name, attrs);

      region.create(key, value);

      // Now go from no timeout to a timeout
      Region.Entry entry = region.getEntry(key);
      assertEquals(value, entry.getValue());
      region.getAttributesMutator().setRegionIdleTimeout(new ExpirationAttributes(12000/*ms*/, ExpirationAction.INVALIDATE));
      region.put(key, value);
      long tilt = System.currentTimeMillis();

      ExpiryTask expiryTask = region.getRegionIdleExpiryTask();
      long mediumExpiryTime = expiryTask.getExpirationTime();
      region.getAttributesMutator().setRegionIdleTimeout(new ExpirationAttributes(999000/*ms*/, ExpirationAction.INVALIDATE));
      expiryTask = region.getRegionIdleExpiryTask();
      long hugeExpiryTime = expiryTask.getExpirationTime();
      region.getAttributesMutator().setRegionIdleTimeout(new ExpirationAttributes(20/*ms*/, ExpirationAction.INVALIDATE));
      expiryTask = region.getRegionIdleExpiryTask();
      long shortExpiryTime = expiryTask.getExpirationTime();
      waitForInvalidate(entry, tilt+20, 10);
      assertTrue(""expected hugeExpiryTime="" + hugeExpiryTime + "" to be > than mediumExpiryTime="" + mediumExpiryTime, (hugeExpiryTime - mediumExpiryTime) > 0);
      assertTrue(""expected mediumExpiryTime="" + mediumExpiryTime + "" to be > than shortExpiryTime="" + shortExpiryTime, (mediumExpiryTime - shortExpiryTime) > 0);
    }
    finally {
      System.getProperties().remove(LocalRegion.EXPIRY_MS_PROPERTY);
    }
  }",True
"  public void testRegionExpirationAfterMutate()
  throws CacheException, InterruptedException {

    final String name = this.getUniqueName();
            ;
    final Object key = ""KEY"";
    final Object value = ""VALUE"";
    
    AttributesFactory factory = new AttributesFactory(getRegionAttributes());
    factory.setStatisticsEnabled(true);
    RegionAttributes attrs = factory.create();
    LocalRegion region = null;
    System.setProperty(LocalRegion.EXPIRY_MS_PROPERTY, ""true"");
    try {
      region = (LocalRegion) createRegion(name, attrs);

      region.create(key, value);

      // Now go from no timeout to a timeout
      Region.Entry entry = region.getEntry(key);
      assertEquals(value, entry.getValue());
      region.getAttributesMutator().setRegionIdleTimeout(new ExpirationAttributes(12000/*ms*/, ExpirationAction.INVALIDATE));
      region.put(key, value);
      long tilt = System.currentTimeMillis();

      ExpiryTask expiryTask = region.getRegionIdleExpiryTask();
      long mediumExpiryTime = expiryTask.getExpirationTime();
      region.getAttributesMutator().setRegionIdleTimeout(new ExpirationAttributes(999000/*ms*/, ExpirationAction.INVALIDATE));
      expiryTask = region.getRegionIdleExpiryTask();
      long hugeExpiryTime = expiryTask.getExpirationTime();
      ExpiryTask.suspendExpiration();
      long shortExpiryTime;
      try {
        region.getAttributesMutator().setRegionIdleTimeout(new ExpirationAttributes(20/*ms*/, ExpirationAction.INVALIDATE));
        expiryTask = region.getRegionIdleExpiryTask();
        shortExpiryTime = expiryTask.getExpirationTime();
        } 
      finally {
        ExpiryTask.permitExpiration();
      }
      waitForInvalidate(entry, tilt+20, 10);
      assertTrue(""expected hugeExpiryTime="" + hugeExpiryTime + "" to be > than mediumExpiryTime="" + mediumExpiryTime, (hugeExpiryTime - mediumExpiryTime) > 0);
      assertTrue(""expected mediumExpiryTime="" + mediumExpiryTime + "" to be > than shortExpiryTime="" + shortExpiryTime, (mediumExpiryTime - shortExpiryTime) > 0);
    }
    finally {
      System.getProperties().remove(LocalRegion.EXPIRY_MS_PROPERTY);
    }
  }",False
